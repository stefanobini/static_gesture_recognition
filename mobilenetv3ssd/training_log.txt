Loaded </mnt/sdc1/sbini/static_gesture_recognition/mobilenetv3ssd/settings/demo7_conf.py> as configuration file.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [0]  [   0/3494]  eta: 4:02:42  lr: 0.0010000  loss: 14.4010 (14.4010)  bbox_regression: 3.5149 (3.5149)  classification: 10.8861 (10.8861)  time: 4.1678  data: 2.2547  max mem: 3269
Epoch: [0]  [ 100/3494]  eta: 0:22:28  lr: 0.0010000  loss: 6.0569 (8.1634)  bbox_regression: 1.8626 (2.5711)  classification: 4.1700 (5.5923)  time: 0.3585  data: 0.1295  max mem: 3278
Epoch: [0]  [ 200/3494]  eta: 0:20:44  lr: 0.0010000  loss: 4.2075 (6.5498)  bbox_regression: 1.2739 (2.0551)  classification: 2.9399 (4.4947)  time: 0.3740  data: 0.1312  max mem: 3278
Epoch: [0]  [ 300/3494]  eta: 0:19:49  lr: 0.0010000  loss: 3.7167 (5.6972)  bbox_regression: 1.1061 (1.7617)  classification: 2.5975 (3.9355)  time: 0.3869  data: 0.1440  max mem: 3278
Epoch: [0]  [ 400/3494]  eta: 0:19:05  lr: 0.0010000  loss: 3.2319 (5.1507)  bbox_regression: 0.8895 (1.5669)  classification: 2.3378 (3.5839)  time: 0.3701  data: 0.1324  max mem: 3278
Epoch: [0]  [ 500/3494]  eta: 0:18:25  lr: 0.0010000  loss: 3.0412 (4.7671)  bbox_regression: 0.7944 (1.4292)  classification: 2.2152 (3.3379)  time: 0.3688  data: 0.1312  max mem: 3278
Epoch: [0]  [ 600/3494]  eta: 0:17:40  lr: 0.0010000  loss: 3.0435 (4.4817)  bbox_regression: 0.7595 (1.3260)  classification: 2.1583 (3.1557)  time: 0.3606  data: 0.1303  max mem: 3278
Epoch: [0]  [ 700/3494]  eta: 0:17:01  lr: 0.0010000  loss: 2.8073 (4.2538)  bbox_regression: 0.7155 (1.2424)  classification: 2.0184 (3.0114)  time: 0.3532  data: 0.1239  max mem: 3278
Epoch: [0]  [ 800/3494]  eta: 0:16:24  lr: 0.0010000  loss: 2.6083 (4.0692)  bbox_regression: 0.6350 (1.1751)  classification: 1.9975 (2.8940)  time: 0.3658  data: 0.1235  max mem: 3278
Epoch: [0]  [ 900/3494]  eta: 0:15:44  lr: 0.0010000  loss: 2.6205 (3.9101)  bbox_regression: 0.6167 (1.1185)  classification: 1.9011 (2.7917)  time: 0.3511  data: 0.1211  max mem: 3278
Epoch: [0]  [1000/3494]  eta: 0:15:06  lr: 0.0010000  loss: 2.4187 (3.7709)  bbox_regression: 0.6158 (1.0703)  classification: 1.7988 (2.7006)  time: 0.3529  data: 0.1235  max mem: 3278
Epoch: [0]  [1100/3494]  eta: 0:14:28  lr: 0.0010000  loss: 2.3426 (3.6497)  bbox_regression: 0.5426 (1.0276)  classification: 1.7656 (2.6221)  time: 0.3450  data: 0.1173  max mem: 3278
Epoch: [0]  [1200/3494]  eta: 0:13:51  lr: 0.0010000  loss: 2.3357 (3.5437)  bbox_regression: 0.5624 (0.9906)  classification: 1.7634 (2.5531)  time: 0.3645  data: 0.1332  max mem: 3278
Epoch: [0]  [1300/3494]  eta: 0:13:14  lr: 0.0010000  loss: 2.2128 (3.4502)  bbox_regression: 0.5128 (0.9582)  classification: 1.6839 (2.4920)  time: 0.3655  data: 0.1286  max mem: 3278
Epoch: [0]  [1400/3494]  eta: 0:12:38  lr: 0.0010000  loss: 2.0317 (3.3585)  bbox_regression: 0.4802 (0.9271)  classification: 1.5553 (2.4313)  time: 0.3665  data: 0.1281  max mem: 3278
Epoch: [0]  [1500/3494]  eta: 0:12:01  lr: 0.0010000  loss: 2.1704 (3.2797)  bbox_regression: 0.5251 (0.9005)  classification: 1.6253 (2.3792)  time: 0.3575  data: 0.1273  max mem: 3278
Epoch: [0]  [1600/3494]  eta: 0:11:25  lr: 0.0010000  loss: 2.0955 (3.2058)  bbox_regression: 0.4569 (0.8759)  classification: 1.5938 (2.3299)  time: 0.3747  data: 0.1396  max mem: 3278
Epoch: [0]  [1700/3494]  eta: 0:10:48  lr: 0.0010000  loss: 2.0236 (3.1378)  bbox_regression: 0.5016 (0.8532)  classification: 1.5264 (2.2846)  time: 0.3501  data: 0.1241  max mem: 3278
Epoch: [0]  [1800/3494]  eta: 0:10:11  lr: 0.0010000  loss: 1.9854 (3.0748)  bbox_regression: 0.4581 (0.8327)  classification: 1.4903 (2.2421)  time: 0.3637  data: 0.1292  max mem: 3278
Epoch: [0]  [1900/3494]  eta: 0:09:35  lr: 0.0010000  loss: 1.8750 (3.0165)  bbox_regression: 0.4400 (0.8138)  classification: 1.4764 (2.2027)  time: 0.3546  data: 0.1248  max mem: 3278
Epoch: [0]  [2000/3494]  eta: 0:08:59  lr: 0.0010000  loss: 1.7995 (2.9609)  bbox_regression: 0.4239 (0.7954)  classification: 1.4161 (2.1655)  time: 0.3418  data: 0.1158  max mem: 3278
Epoch: [0]  [2100/3494]  eta: 0:08:23  lr: 0.0010000  loss: 1.9094 (2.9099)  bbox_regression: 0.4386 (0.7789)  classification: 1.4764 (2.1311)  time: 0.3671  data: 0.1282  max mem: 3278
Epoch: [0]  [2200/3494]  eta: 0:07:47  lr: 0.0010000  loss: 1.8662 (2.8659)  bbox_regression: 0.4564 (0.7650)  classification: 1.4203 (2.1009)  time: 0.3709  data: 0.1339  max mem: 3278
Epoch: [0]  [2300/3494]  eta: 0:07:11  lr: 0.0010000  loss: 1.7958 (2.8197)  bbox_regression: 0.4209 (0.7504)  classification: 1.3697 (2.0693)  time: 0.3469  data: 0.1199  max mem: 3278
Epoch: [0]  [2400/3494]  eta: 0:06:35  lr: 0.0010000  loss: 1.6601 (2.7770)  bbox_regression: 0.3955 (0.7367)  classification: 1.2646 (2.0403)  time: 0.3541  data: 0.1233  max mem: 3278
Epoch: [0]  [2500/3494]  eta: 0:05:58  lr: 0.0010000  loss: 1.6594 (2.7361)  bbox_regression: 0.3992 (0.7240)  classification: 1.2612 (2.0121)  time: 0.3629  data: 0.1266  max mem: 3278
Epoch: [0]  [2600/3494]  eta: 0:05:22  lr: 0.0010000  loss: 1.7230 (2.6990)  bbox_regression: 0.4067 (0.7124)  classification: 1.3073 (1.9866)  time: 0.3384  data: 0.1104  max mem: 3278
Epoch: [0]  [2700/3494]  eta: 0:04:46  lr: 0.0010000  loss: 1.6308 (2.6609)  bbox_regression: 0.3571 (0.7004)  classification: 1.2654 (1.9605)  time: 0.3673  data: 0.1282  max mem: 3278
Epoch: [0]  [2800/3494]  eta: 0:04:10  lr: 0.0010000  loss: 1.6148 (2.6260)  bbox_regression: 0.3648 (0.6897)  classification: 1.2427 (1.9363)  time: 0.3528  data: 0.1254  max mem: 3278
Epoch: [0]  [2900/3494]  eta: 0:03:34  lr: 0.0010000  loss: 1.5823 (2.5936)  bbox_regression: 0.3542 (0.6797)  classification: 1.2505 (1.9140)  time: 0.3614  data: 0.1275  max mem: 3278
Epoch: [0]  [3000/3494]  eta: 0:02:58  lr: 0.0010000  loss: 1.5853 (2.5621)  bbox_regression: 0.3514 (0.6694)  classification: 1.2570 (1.8927)  time: 0.3347  data: 0.1133  max mem: 3278
Epoch: [0]  [3100/3494]  eta: 0:02:22  lr: 0.0010000  loss: 1.5151 (2.5314)  bbox_regression: 0.3284 (0.6595)  classification: 1.2148 (1.8719)  time: 0.3556  data: 0.1264  max mem: 3278
Epoch: [0]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 1.5680 (2.5039)  bbox_regression: 0.3568 (0.6510)  classification: 1.1900 (1.8529)  time: 0.3808  data: 0.1405  max mem: 3278
Epoch: [0]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 1.4558 (2.4764)  bbox_regression: 0.3178 (0.6424)  classification: 1.1470 (1.8340)  time: 0.3627  data: 0.1321  max mem: 3278
Epoch: [0]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 1.4893 (2.4496)  bbox_regression: 0.3347 (0.6340)  classification: 1.1864 (1.8157)  time: 0.3593  data: 0.1235  max mem: 3278
Epoch: [0]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 1.5234 (2.4277)  bbox_regression: 0.3393 (0.6272)  classification: 1.1801 (1.8005)  time: 0.3780  data: 0.1291  max mem: 3278
Epoch: [0] Total time: 0:21:11 (0.3639 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:21  model_time: 0.1344 (0.1344)  loss: 1.7720 (1.7720)  bbox_regression: 0.3385 (0.3385)  classification: 1.4335 (1.4335)  time: 2.2463  data: 2.0875  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1234 (0.1270)  loss: 1.6161 (1.6097)  bbox_regression: 0.3849 (0.3779)  classification: 1.2058 (1.2317)  time: 0.2636  data: 0.1227  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1202 (0.1267)  loss: 1.4626 (1.5733)  bbox_regression: 0.3440 (0.3627)  classification: 1.1181 (1.2106)  time: 0.2631  data: 0.1221  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1224 (0.1267)  loss: 1.5891 (1.5680)  bbox_regression: 0.3844 (0.3603)  classification: 1.1982 (1.2076)  time: 0.2666  data: 0.1250  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1177 (0.1258)  loss: 1.5495 (1.5650)  bbox_regression: 0.3527 (0.3593)  classification: 1.1850 (1.2057)  time: 0.2482  data: 0.1200  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1205 (0.1258)  loss: 1.4934 (1.5644)  bbox_regression: 0.3514 (0.3587)  classification: 1.1655 (1.2057)  time: 0.2682  data: 0.1204  max mem: 3278
Validation: Total time: 0:01:59 (0.2726 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [1]  [   0/3494]  eta: 2:04:26  lr: 0.0010000  loss: 1.4020 (1.4020)  bbox_regression: 0.3071 (0.3071)  classification: 1.0949 (1.0949)  time: 2.1368  data: 1.8687  max mem: 3278
Epoch: [1]  [ 100/3494]  eta: 0:21:21  lr: 0.0010000  loss: 1.5328 (1.5089)  bbox_regression: 0.3368 (0.3466)  classification: 1.1603 (1.1622)  time: 0.3600  data: 0.1277  max mem: 3278
Epoch: [1]  [ 200/3494]  eta: 0:20:22  lr: 0.0010000  loss: 1.4519 (1.5045)  bbox_regression: 0.3485 (0.3432)  classification: 1.1207 (1.1613)  time: 0.3652  data: 0.1299  max mem: 3278
Epoch: [1]  [ 300/3494]  eta: 0:19:35  lr: 0.0010000  loss: 1.3795 (1.5020)  bbox_regression: 0.3063 (0.3416)  classification: 1.1176 (1.1604)  time: 0.3617  data: 0.1284  max mem: 3278
Epoch: [1]  [ 400/3494]  eta: 0:18:51  lr: 0.0010000  loss: 1.5440 (1.5025)  bbox_regression: 0.3238 (0.3413)  classification: 1.1907 (1.1612)  time: 0.3553  data: 0.1248  max mem: 3278
Epoch: [1]  [ 500/3494]  eta: 0:18:11  lr: 0.0010000  loss: 1.5610 (1.5082)  bbox_regression: 0.3239 (0.3437)  classification: 1.1850 (1.1645)  time: 0.3455  data: 0.1202  max mem: 3278
Epoch: [1]  [ 600/3494]  eta: 0:17:30  lr: 0.0010000  loss: 1.5100 (1.4996)  bbox_regression: 0.3593 (0.3416)  classification: 1.1507 (1.1580)  time: 0.3571  data: 0.1228  max mem: 3278
Epoch: [1]  [ 700/3494]  eta: 0:16:51  lr: 0.0010000  loss: 1.4030 (1.4913)  bbox_regression: 0.3152 (0.3387)  classification: 1.1048 (1.1526)  time: 0.3613  data: 0.1311  max mem: 3278
Epoch: [1]  [ 800/3494]  eta: 0:16:13  lr: 0.0010000  loss: 1.4701 (1.4857)  bbox_regression: 0.3222 (0.3362)  classification: 1.1594 (1.1494)  time: 0.3593  data: 0.1267  max mem: 3278
Epoch: [1]  [ 900/3494]  eta: 0:15:36  lr: 0.0010000  loss: 1.3377 (1.4835)  bbox_regression: 0.3139 (0.3353)  classification: 1.0769 (1.1482)  time: 0.3602  data: 0.1321  max mem: 3278
Epoch: [1]  [1000/3494]  eta: 0:15:00  lr: 0.0010000  loss: 1.4285 (1.4802)  bbox_regression: 0.3158 (0.3335)  classification: 1.1084 (1.1467)  time: 0.3595  data: 0.1268  max mem: 3278
Epoch: [1]  [1100/3494]  eta: 0:14:22  lr: 0.0010000  loss: 1.3828 (1.4773)  bbox_regression: 0.2964 (0.3326)  classification: 1.1001 (1.1447)  time: 0.3590  data: 0.1280  max mem: 3278
Epoch: [1]  [1200/3494]  eta: 0:13:47  lr: 0.0010000  loss: 1.5530 (1.4724)  bbox_regression: 0.2934 (0.3307)  classification: 1.2081 (1.1417)  time: 0.3599  data: 0.1278  max mem: 3278
Epoch: [1]  [1300/3494]  eta: 0:13:12  lr: 0.0010000  loss: 1.3733 (1.4668)  bbox_regression: 0.2870 (0.3287)  classification: 1.0832 (1.1380)  time: 0.3649  data: 0.1304  max mem: 3278
Epoch: [1]  [1400/3494]  eta: 0:12:35  lr: 0.0010000  loss: 1.2844 (1.4610)  bbox_regression: 0.2620 (0.3266)  classification: 1.0335 (1.1344)  time: 0.3628  data: 0.1352  max mem: 3278
Epoch: [1]  [1500/3494]  eta: 0:11:59  lr: 0.0010000  loss: 1.3927 (1.4581)  bbox_regression: 0.2861 (0.3255)  classification: 1.0885 (1.1326)  time: 0.3620  data: 0.1279  max mem: 3278
Epoch: [1]  [1600/3494]  eta: 0:11:22  lr: 0.0010000  loss: 1.3071 (1.4520)  bbox_regression: 0.3107 (0.3242)  classification: 1.0429 (1.1278)  time: 0.3558  data: 0.1250  max mem: 3278
Epoch: [1]  [1700/3494]  eta: 0:10:46  lr: 0.0010000  loss: 1.3503 (1.4478)  bbox_regression: 0.2943 (0.3229)  classification: 1.0496 (1.1248)  time: 0.3668  data: 0.1322  max mem: 3278
Epoch: [1]  [1800/3494]  eta: 0:10:10  lr: 0.0010000  loss: 1.3149 (1.4432)  bbox_regression: 0.2849 (0.3215)  classification: 1.0292 (1.1216)  time: 0.3653  data: 0.1320  max mem: 3278
Epoch: [1]  [1900/3494]  eta: 0:09:34  lr: 0.0010000  loss: 1.3311 (1.4393)  bbox_regression: 0.2863 (0.3209)  classification: 0.9994 (1.1184)  time: 0.3726  data: 0.1339  max mem: 3278
Epoch: [1]  [2000/3494]  eta: 0:08:59  lr: 0.0010000  loss: 1.3138 (1.4366)  bbox_regression: 0.2653 (0.3201)  classification: 1.0247 (1.1165)  time: 0.3670  data: 0.1327  max mem: 3278
Epoch: [1]  [2100/3494]  eta: 0:08:23  lr: 0.0010000  loss: 1.3154 (1.4318)  bbox_regression: 0.2479 (0.3185)  classification: 1.0499 (1.1133)  time: 0.3691  data: 0.1316  max mem: 3278
Epoch: [1]  [2200/3494]  eta: 0:07:48  lr: 0.0010000  loss: 1.2719 (1.4268)  bbox_regression: 0.2801 (0.3168)  classification: 1.0036 (1.1100)  time: 0.3631  data: 0.1306  max mem: 3278
Epoch: [1]  [2300/3494]  eta: 0:07:12  lr: 0.0010000  loss: 1.3003 (1.4234)  bbox_regression: 0.2776 (0.3155)  classification: 1.0182 (1.1078)  time: 0.3743  data: 0.1334  max mem: 3278
Epoch: [1]  [2400/3494]  eta: 0:06:35  lr: 0.0010000  loss: 1.3427 (1.4204)  bbox_regression: 0.2617 (0.3145)  classification: 1.0607 (1.1058)  time: 0.3671  data: 0.1251  max mem: 3278
Epoch: [1]  [2500/3494]  eta: 0:06:00  lr: 0.0010000  loss: 1.3431 (1.4170)  bbox_regression: 0.2661 (0.3132)  classification: 1.0960 (1.1038)  time: 0.3741  data: 0.1341  max mem: 3278
Epoch: [1]  [2600/3494]  eta: 0:05:23  lr: 0.0010000  loss: 1.2530 (1.4139)  bbox_regression: 0.2792 (0.3122)  classification: 0.9548 (1.1017)  time: 0.3759  data: 0.1365  max mem: 3278
Epoch: [1]  [2700/3494]  eta: 0:04:47  lr: 0.0010000  loss: 1.2507 (1.4091)  bbox_regression: 0.2701 (0.3106)  classification: 0.9896 (1.0985)  time: 0.3701  data: 0.1287  max mem: 3278
Epoch: [1]  [2800/3494]  eta: 0:04:11  lr: 0.0010000  loss: 1.2564 (1.4058)  bbox_regression: 0.2634 (0.3098)  classification: 1.0306 (1.0960)  time: 0.3656  data: 0.1279  max mem: 3278
Epoch: [1]  [2900/3494]  eta: 0:03:35  lr: 0.0010000  loss: 1.2753 (1.4032)  bbox_regression: 0.2565 (0.3087)  classification: 0.9867 (1.0944)  time: 0.3672  data: 0.1344  max mem: 3278
Epoch: [1]  [3000/3494]  eta: 0:02:59  lr: 0.0010000  loss: 1.2423 (1.3985)  bbox_regression: 0.2607 (0.3076)  classification: 0.9857 (1.0910)  time: 0.3648  data: 0.1264  max mem: 3278
Epoch: [1]  [3100/3494]  eta: 0:02:23  lr: 0.0010000  loss: 1.3008 (1.3961)  bbox_regression: 0.2749 (0.3068)  classification: 1.0233 (1.0892)  time: 0.3603  data: 0.1297  max mem: 3278
Epoch: [1]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 1.2939 (1.3935)  bbox_regression: 0.2518 (0.3060)  classification: 1.0068 (1.0875)  time: 0.3593  data: 0.1267  max mem: 3278
Epoch: [1]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 1.2989 (1.3904)  bbox_regression: 0.2617 (0.3052)  classification: 0.9978 (1.0853)  time: 0.3658  data: 0.1320  max mem: 3278
Epoch: [1]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 1.3474 (1.3887)  bbox_regression: 0.2930 (0.3047)  classification: 1.0329 (1.0840)  time: 0.3638  data: 0.1282  max mem: 3278
Epoch: [1]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 1.2372 (1.3865)  bbox_regression: 0.2311 (0.3038)  classification: 0.9845 (1.0827)  time: 0.3581  data: 0.1268  max mem: 3278
Epoch: [1] Total time: 0:21:20 (0.3665 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:17  model_time: 0.1268 (0.1268)  loss: 1.5720 (1.5720)  bbox_regression: 0.2599 (0.2599)  classification: 1.3121 (1.3121)  time: 2.0989  data: 1.9319  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1178 (0.1229)  loss: 1.2644 (1.3274)  bbox_regression: 0.2692 (0.2866)  classification: 0.9648 (1.0408)  time: 0.2661  data: 0.1224  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1323 (0.1251)  loss: 1.2124 (1.2946)  bbox_regression: 0.2569 (0.2746)  classification: 0.9941 (1.0201)  time: 0.2763  data: 0.1268  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1245 (0.1251)  loss: 1.3133 (1.2908)  bbox_regression: 0.2894 (0.2720)  classification: 1.0419 (1.0187)  time: 0.2649  data: 0.1230  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1310 (0.1251)  loss: 1.2919 (1.2874)  bbox_regression: 0.2736 (0.2716)  classification: 1.0063 (1.0158)  time: 0.2799  data: 0.1320  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1284 (0.1251)  loss: 1.1865 (1.2859)  bbox_regression: 0.2601 (0.2713)  classification: 0.9338 (1.0146)  time: 0.2722  data: 0.1234  max mem: 3278
Validation: Total time: 0:01:59 (0.2730 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [2]  [   0/3494]  eta: 1:51:39  lr: 0.0010000  loss: 1.2506 (1.2506)  bbox_regression: 0.2549 (0.2549)  classification: 0.9957 (0.9957)  time: 1.9175  data: 1.6694  max mem: 3278
Epoch: [2]  [ 100/3494]  eta: 0:21:52  lr: 0.0010000  loss: 1.1797 (1.2324)  bbox_regression: 0.2388 (0.2564)  classification: 0.9646 (0.9760)  time: 0.3566  data: 0.1260  max mem: 3278
Epoch: [2]  [ 200/3494]  eta: 0:20:45  lr: 0.0010000  loss: 1.2221 (1.2413)  bbox_regression: 0.2392 (0.2602)  classification: 0.9673 (0.9812)  time: 0.3717  data: 0.1294  max mem: 3278
Epoch: [2]  [ 300/3494]  eta: 0:19:54  lr: 0.0010000  loss: 1.1986 (1.2456)  bbox_regression: 0.2526 (0.2595)  classification: 0.9538 (0.9861)  time: 0.3627  data: 0.1302  max mem: 3278
Epoch: [2]  [ 400/3494]  eta: 0:19:10  lr: 0.0010000  loss: 1.2074 (1.2364)  bbox_regression: 0.2396 (0.2578)  classification: 0.9685 (0.9786)  time: 0.3658  data: 0.1279  max mem: 3278
Epoch: [2]  [ 500/3494]  eta: 0:18:28  lr: 0.0010000  loss: 1.1143 (1.2249)  bbox_regression: 0.2171 (0.2545)  classification: 0.8775 (0.9704)  time: 0.3722  data: 0.1336  max mem: 3278
Epoch: [2]  [ 600/3494]  eta: 0:17:48  lr: 0.0010000  loss: 1.1476 (1.2275)  bbox_regression: 0.2508 (0.2563)  classification: 0.9103 (0.9712)  time: 0.3790  data: 0.1392  max mem: 3278
Epoch: [2]  [ 700/3494]  eta: 0:17:12  lr: 0.0010000  loss: 1.1981 (1.2254)  bbox_regression: 0.2448 (0.2553)  classification: 0.9080 (0.9701)  time: 0.3624  data: 0.1282  max mem: 3278
Epoch: [2]  [ 800/3494]  eta: 0:16:35  lr: 0.0010000  loss: 1.2386 (1.2267)  bbox_regression: 0.2375 (0.2560)  classification: 0.9058 (0.9707)  time: 0.3702  data: 0.1298  max mem: 3278
Epoch: [2]  [ 900/3494]  eta: 0:15:56  lr: 0.0010000  loss: 1.1404 (1.2260)  bbox_regression: 0.2330 (0.2564)  classification: 0.9655 (0.9696)  time: 0.3592  data: 0.1291  max mem: 3278
Epoch: [2]  [1000/3494]  eta: 0:15:19  lr: 0.0010000  loss: 1.3724 (1.2274)  bbox_regression: 0.2686 (0.2573)  classification: 1.0449 (0.9702)  time: 0.3594  data: 0.1271  max mem: 3278
Epoch: [2]  [1100/3494]  eta: 0:14:41  lr: 0.0010000  loss: 1.1155 (1.2256)  bbox_regression: 0.2172 (0.2569)  classification: 0.9229 (0.9687)  time: 0.3765  data: 0.1378  max mem: 3278
Epoch: [2]  [1200/3494]  eta: 0:14:05  lr: 0.0010000  loss: 1.2732 (1.2238)  bbox_regression: 0.2585 (0.2563)  classification: 0.9794 (0.9675)  time: 0.3750  data: 0.1326  max mem: 3278
Epoch: [2]  [1300/3494]  eta: 0:13:28  lr: 0.0010000  loss: 1.0569 (1.2236)  bbox_regression: 0.2249 (0.2563)  classification: 0.8511 (0.9673)  time: 0.3822  data: 0.1377  max mem: 3278
Epoch: [2]  [1400/3494]  eta: 0:12:51  lr: 0.0010000  loss: 1.2477 (1.2246)  bbox_regression: 0.2259 (0.2562)  classification: 1.0282 (0.9685)  time: 0.3590  data: 0.1257  max mem: 3278
Epoch: [2]  [1500/3494]  eta: 0:12:14  lr: 0.0010000  loss: 1.2290 (1.2216)  bbox_regression: 0.2412 (0.2553)  classification: 0.9477 (0.9663)  time: 0.3685  data: 0.1289  max mem: 3278
Epoch: [2]  [1600/3494]  eta: 0:11:37  lr: 0.0010000  loss: 1.1534 (1.2186)  bbox_regression: 0.2445 (0.2551)  classification: 0.9089 (0.9635)  time: 0.3631  data: 0.1286  max mem: 3278
Epoch: [2]  [1700/3494]  eta: 0:10:59  lr: 0.0010000  loss: 1.1156 (1.2181)  bbox_regression: 0.2620 (0.2543)  classification: 0.8483 (0.9637)  time: 0.3672  data: 0.1335  max mem: 3278
Epoch: [2]  [1800/3494]  eta: 0:10:22  lr: 0.0010000  loss: 1.1101 (1.2154)  bbox_regression: 0.2167 (0.2538)  classification: 0.9000 (0.9616)  time: 0.3688  data: 0.1366  max mem: 3278
Epoch: [2]  [1900/3494]  eta: 0:09:46  lr: 0.0010000  loss: 1.2036 (1.2163)  bbox_regression: 0.2180 (0.2539)  classification: 0.9286 (0.9624)  time: 0.3714  data: 0.1319  max mem: 3278
Epoch: [2]  [2000/3494]  eta: 0:09:09  lr: 0.0010000  loss: 1.0906 (1.2153)  bbox_regression: 0.2087 (0.2535)  classification: 0.8919 (0.9618)  time: 0.3612  data: 0.1213  max mem: 3278
Epoch: [2]  [2100/3494]  eta: 0:08:32  lr: 0.0010000  loss: 1.1747 (1.2162)  bbox_regression: 0.2247 (0.2537)  classification: 0.9409 (0.9625)  time: 0.3617  data: 0.1306  max mem: 3278
Epoch: [2]  [2200/3494]  eta: 0:07:55  lr: 0.0010000  loss: 1.0976 (1.2136)  bbox_regression: 0.2165 (0.2532)  classification: 0.8693 (0.9604)  time: 0.3842  data: 0.1375  max mem: 3278
Epoch: [2]  [2300/3494]  eta: 0:07:18  lr: 0.0010000  loss: 1.0934 (1.2132)  bbox_regression: 0.2079 (0.2529)  classification: 0.8949 (0.9602)  time: 0.3585  data: 0.1287  max mem: 3278
Epoch: [2]  [2400/3494]  eta: 0:06:41  lr: 0.0010000  loss: 1.1198 (1.2108)  bbox_regression: 0.2097 (0.2523)  classification: 0.9052 (0.9584)  time: 0.3583  data: 0.1258  max mem: 3278
Epoch: [2]  [2500/3494]  eta: 0:06:04  lr: 0.0010000  loss: 1.1432 (1.2096)  bbox_regression: 0.2262 (0.2522)  classification: 0.9377 (0.9574)  time: 0.3847  data: 0.1376  max mem: 3278
Epoch: [2]  [2600/3494]  eta: 0:05:28  lr: 0.0010000  loss: 1.1837 (1.2088)  bbox_regression: 0.2546 (0.2519)  classification: 0.9511 (0.9568)  time: 0.3712  data: 0.1375  max mem: 3278
Epoch: [2]  [2700/3494]  eta: 0:04:51  lr: 0.0010000  loss: 1.0195 (1.2061)  bbox_regression: 0.2195 (0.2515)  classification: 0.8187 (0.9546)  time: 0.3599  data: 0.1273  max mem: 3278
Epoch: [2]  [2800/3494]  eta: 0:04:14  lr: 0.0010000  loss: 1.1860 (1.2053)  bbox_regression: 0.2082 (0.2511)  classification: 0.9666 (0.9542)  time: 0.3809  data: 0.1405  max mem: 3278
Epoch: [2]  [2900/3494]  eta: 0:03:38  lr: 0.0010000  loss: 1.1704 (1.2046)  bbox_regression: 0.2318 (0.2506)  classification: 0.9386 (0.9540)  time: 0.3729  data: 0.1348  max mem: 3278
Epoch: [2]  [3000/3494]  eta: 0:03:01  lr: 0.0010000  loss: 1.0238 (1.2025)  bbox_regression: 0.2271 (0.2501)  classification: 0.8039 (0.9524)  time: 0.3626  data: 0.1310  max mem: 3278
Epoch: [2]  [3100/3494]  eta: 0:02:24  lr: 0.0010000  loss: 1.0378 (1.2001)  bbox_regression: 0.2031 (0.2493)  classification: 0.8502 (0.9508)  time: 0.3567  data: 0.1283  max mem: 3278
Epoch: [2]  [3200/3494]  eta: 0:01:47  lr: 0.0010000  loss: 1.2085 (1.1993)  bbox_regression: 0.2512 (0.2491)  classification: 0.9745 (0.9502)  time: 0.3779  data: 0.1400  max mem: 3278
Epoch: [2]  [3300/3494]  eta: 0:01:11  lr: 0.0010000  loss: 1.1043 (1.1980)  bbox_regression: 0.2269 (0.2488)  classification: 0.8870 (0.9492)  time: 0.3715  data: 0.1311  max mem: 3278
Epoch: [2]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 1.2279 (1.1966)  bbox_regression: 0.2451 (0.2484)  classification: 0.9805 (0.9482)  time: 0.3642  data: 0.1291  max mem: 3278
Epoch: [2]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 1.0673 (1.1954)  bbox_regression: 0.2243 (0.2481)  classification: 0.8656 (0.9474)  time: 0.3582  data: 0.1269  max mem: 3278
Epoch: [2] Total time: 0:21:32 (0.3700 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:16  model_time: 0.1546 (0.1546)  loss: 1.5580 (1.5580)  bbox_regression: 0.2428 (0.2428)  classification: 1.3152 (1.3152)  time: 1.8223  data: 1.6327  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1244 (0.1213)  loss: 1.1337 (1.2097)  bbox_regression: 0.2382 (0.2530)  classification: 0.9096 (0.9567)  time: 0.2640  data: 0.1236  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1225 (0.1235)  loss: 1.1213 (1.1799)  bbox_regression: 0.2205 (0.2424)  classification: 0.8801 (0.9375)  time: 0.2710  data: 0.1283  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1316 (0.1252)  loss: 1.1701 (1.1740)  bbox_regression: 0.2433 (0.2395)  classification: 0.9415 (0.9345)  time: 0.2690  data: 0.1238  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1345 (0.1255)  loss: 1.1545 (1.1728)  bbox_regression: 0.2246 (0.2391)  classification: 0.8913 (0.9337)  time: 0.2787  data: 0.1282  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1237 (0.1257)  loss: 1.0789 (1.1708)  bbox_regression: 0.2146 (0.2388)  classification: 0.8811 (0.9320)  time: 0.2655  data: 0.1193  max mem: 3278
Validation: Total time: 0:01:59 (0.2734 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [3]  [   0/3494]  eta: 2:07:12  lr: 0.0010000  loss: 1.1198 (1.1198)  bbox_regression: 0.2594 (0.2594)  classification: 0.8603 (0.8603)  time: 2.1844  data: 1.9297  max mem: 3278
Epoch: [3]  [ 100/3494]  eta: 0:21:29  lr: 0.0010000  loss: 0.9908 (1.0904)  bbox_regression: 0.1918 (0.2123)  classification: 0.8061 (0.8780)  time: 0.3661  data: 0.1295  max mem: 3278
Epoch: [3]  [ 200/3494]  eta: 0:20:23  lr: 0.0010000  loss: 1.0783 (1.0857)  bbox_regression: 0.1960 (0.2141)  classification: 0.8678 (0.8716)  time: 0.3619  data: 0.1270  max mem: 3278
Epoch: [3]  [ 300/3494]  eta: 0:19:35  lr: 0.0010000  loss: 0.9900 (1.0924)  bbox_regression: 0.1881 (0.2179)  classification: 0.7739 (0.8745)  time: 0.3573  data: 0.1314  max mem: 3278
Epoch: [3]  [ 400/3494]  eta: 0:18:57  lr: 0.0010000  loss: 1.0231 (1.0953)  bbox_regression: 0.2190 (0.2184)  classification: 0.8004 (0.8769)  time: 0.3608  data: 0.1262  max mem: 3278
Epoch: [3]  [ 500/3494]  eta: 0:18:20  lr: 0.0010000  loss: 1.0596 (1.1003)  bbox_regression: 0.2198 (0.2201)  classification: 0.8614 (0.8802)  time: 0.3697  data: 0.1336  max mem: 3278
Epoch: [3]  [ 600/3494]  eta: 0:17:46  lr: 0.0010000  loss: 1.1075 (1.1030)  bbox_regression: 0.2111 (0.2213)  classification: 0.8733 (0.8817)  time: 0.3611  data: 0.1289  max mem: 3278
Epoch: [3]  [ 700/3494]  eta: 0:17:07  lr: 0.0010000  loss: 1.0238 (1.1048)  bbox_regression: 0.2048 (0.2208)  classification: 0.8120 (0.8840)  time: 0.3724  data: 0.1380  max mem: 3278
Epoch: [3]  [ 800/3494]  eta: 0:16:28  lr: 0.0010000  loss: 1.0998 (1.1048)  bbox_regression: 0.2029 (0.2200)  classification: 0.8390 (0.8848)  time: 0.3659  data: 0.1324  max mem: 3278
Epoch: [3]  [ 900/3494]  eta: 0:15:55  lr: 0.0010000  loss: 1.0656 (1.1050)  bbox_regression: 0.1986 (0.2204)  classification: 0.8538 (0.8846)  time: 0.3696  data: 0.1321  max mem: 3278
Epoch: [3]  [1000/3494]  eta: 0:15:18  lr: 0.0010000  loss: 1.0548 (1.1038)  bbox_regression: 0.2185 (0.2207)  classification: 0.8514 (0.8831)  time: 0.3643  data: 0.1262  max mem: 3278
Epoch: [3]  [1100/3494]  eta: 0:14:40  lr: 0.0010000  loss: 1.0049 (1.1005)  bbox_regression: 0.2022 (0.2204)  classification: 0.7883 (0.8801)  time: 0.3659  data: 0.1315  max mem: 3278
Epoch: [3]  [1200/3494]  eta: 0:14:02  lr: 0.0010000  loss: 1.0747 (1.0980)  bbox_regression: 0.2018 (0.2200)  classification: 0.8338 (0.8780)  time: 0.3669  data: 0.1235  max mem: 3278
Epoch: [3]  [1300/3494]  eta: 0:13:26  lr: 0.0010000  loss: 1.0550 (1.0968)  bbox_regression: 0.1953 (0.2198)  classification: 0.8619 (0.8770)  time: 0.3675  data: 0.1343  max mem: 3278
Epoch: [3]  [1400/3494]  eta: 0:12:49  lr: 0.0010000  loss: 1.0818 (1.1006)  bbox_regression: 0.2223 (0.2209)  classification: 0.8455 (0.8797)  time: 0.3672  data: 0.1358  max mem: 3278
Epoch: [3]  [1500/3494]  eta: 0:12:11  lr: 0.0010000  loss: 0.9898 (1.0997)  bbox_regression: 0.2089 (0.2206)  classification: 0.7698 (0.8791)  time: 0.3695  data: 0.1353  max mem: 3278
Epoch: [3]  [1600/3494]  eta: 0:11:34  lr: 0.0010000  loss: 1.1215 (1.0990)  bbox_regression: 0.1993 (0.2204)  classification: 0.8910 (0.8787)  time: 0.3710  data: 0.1349  max mem: 3278
Epoch: [3]  [1700/3494]  eta: 0:10:58  lr: 0.0010000  loss: 1.0581 (1.1025)  bbox_regression: 0.2069 (0.2215)  classification: 0.8774 (0.8810)  time: 0.3723  data: 0.1400  max mem: 3278
Epoch: [3]  [1800/3494]  eta: 0:10:21  lr: 0.0010000  loss: 1.0291 (1.1023)  bbox_regression: 0.1979 (0.2218)  classification: 0.8457 (0.8805)  time: 0.3590  data: 0.1251  max mem: 3278
Epoch: [3]  [1900/3494]  eta: 0:09:45  lr: 0.0010000  loss: 1.0219 (1.1023)  bbox_regression: 0.2028 (0.2220)  classification: 0.8193 (0.8803)  time: 0.3821  data: 0.1444  max mem: 3278
Epoch: [3]  [2000/3494]  eta: 0:09:08  lr: 0.0010000  loss: 0.9364 (1.1015)  bbox_regression: 0.1638 (0.2215)  classification: 0.7864 (0.8799)  time: 0.3668  data: 0.1361  max mem: 3278
Epoch: [3]  [2100/3494]  eta: 0:08:32  lr: 0.0010000  loss: 0.9529 (1.0990)  bbox_regression: 0.1964 (0.2211)  classification: 0.7759 (0.8780)  time: 0.3733  data: 0.1302  max mem: 3278
Epoch: [3]  [2200/3494]  eta: 0:07:55  lr: 0.0010000  loss: 1.0164 (1.0983)  bbox_regression: 0.1974 (0.2207)  classification: 0.8045 (0.8776)  time: 0.3722  data: 0.1414  max mem: 3278
Epoch: [3]  [2300/3494]  eta: 0:07:19  lr: 0.0010000  loss: 1.1294 (1.0982)  bbox_regression: 0.2329 (0.2209)  classification: 0.8996 (0.8774)  time: 0.3657  data: 0.1331  max mem: 3278
Epoch: [3]  [2400/3494]  eta: 0:06:42  lr: 0.0010000  loss: 1.0256 (1.0968)  bbox_regression: 0.2056 (0.2204)  classification: 0.8151 (0.8764)  time: 0.3709  data: 0.1294  max mem: 3278
Epoch: [3]  [2500/3494]  eta: 0:06:05  lr: 0.0010000  loss: 1.0925 (1.0958)  bbox_regression: 0.2073 (0.2200)  classification: 0.8420 (0.8758)  time: 0.3744  data: 0.1383  max mem: 3278
Epoch: [3]  [2600/3494]  eta: 0:05:28  lr: 0.0010000  loss: 1.0709 (1.0951)  bbox_regression: 0.2011 (0.2199)  classification: 0.8541 (0.8752)  time: 0.3657  data: 0.1269  max mem: 3278
Epoch: [3]  [2700/3494]  eta: 0:04:51  lr: 0.0010000  loss: 0.9769 (1.0939)  bbox_regression: 0.1797 (0.2194)  classification: 0.7969 (0.8745)  time: 0.3646  data: 0.1266  max mem: 3278
Epoch: [3]  [2800/3494]  eta: 0:04:15  lr: 0.0010000  loss: 0.9749 (1.0923)  bbox_regression: 0.1700 (0.2189)  classification: 0.7913 (0.8734)  time: 0.3589  data: 0.1235  max mem: 3278
Epoch: [3]  [2900/3494]  eta: 0:03:38  lr: 0.0010000  loss: 1.0153 (1.0916)  bbox_regression: 0.2239 (0.2188)  classification: 0.7914 (0.8729)  time: 0.3671  data: 0.1283  max mem: 3278
Epoch: [3]  [3000/3494]  eta: 0:03:01  lr: 0.0010000  loss: 1.0233 (1.0914)  bbox_regression: 0.1840 (0.2186)  classification: 0.7948 (0.8728)  time: 0.3808  data: 0.1400  max mem: 3278
Epoch: [3]  [3100/3494]  eta: 0:02:24  lr: 0.0010000  loss: 1.0355 (1.0911)  bbox_regression: 0.2131 (0.2187)  classification: 0.8384 (0.8724)  time: 0.3551  data: 0.1226  max mem: 3278
Epoch: [3]  [3200/3494]  eta: 0:01:48  lr: 0.0010000  loss: 1.0715 (1.0913)  bbox_regression: 0.1855 (0.2186)  classification: 0.8889 (0.8726)  time: 0.3671  data: 0.1309  max mem: 3278
Epoch: [3]  [3300/3494]  eta: 0:01:11  lr: 0.0010000  loss: 1.0132 (1.0905)  bbox_regression: 0.1927 (0.2183)  classification: 0.8186 (0.8723)  time: 0.3650  data: 0.1304  max mem: 3278
Epoch: [3]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 1.0243 (1.0893)  bbox_regression: 0.1911 (0.2180)  classification: 0.8066 (0.8714)  time: 0.3709  data: 0.1382  max mem: 3278
Epoch: [3]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 1.0069 (1.0887)  bbox_regression: 0.1955 (0.2179)  classification: 0.7937 (0.8708)  time: 0.3678  data: 0.1287  max mem: 3278
Epoch: [3] Total time: 0:21:35 (0.3709 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:59  model_time: 0.2417 (0.2417)  loss: 1.4639 (1.4639)  bbox_regression: 0.2234 (0.2234)  classification: 1.2405 (1.2405)  time: 1.9210  data: 1.6491  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1154 (0.1254)  loss: 1.1042 (1.1607)  bbox_regression: 0.2397 (0.2403)  classification: 0.8590 (0.9204)  time: 0.2558  data: 0.1209  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1217 (0.1248)  loss: 1.0205 (1.1207)  bbox_regression: 0.2131 (0.2284)  classification: 0.8794 (0.8923)  time: 0.2720  data: 0.1281  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1221 (0.1251)  loss: 1.1123 (1.1177)  bbox_regression: 0.2245 (0.2257)  classification: 0.9068 (0.8920)  time: 0.2695  data: 0.1262  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1233 (0.1242)  loss: 1.0564 (1.1143)  bbox_regression: 0.2150 (0.2249)  classification: 0.8248 (0.8894)  time: 0.2740  data: 0.1295  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1156 (0.1236)  loss: 0.9873 (1.1137)  bbox_regression: 0.1955 (0.2246)  classification: 0.8278 (0.8891)  time: 0.2500  data: 0.1156  max mem: 3278
Validation: Total time: 0:01:58 (0.2712 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [4]  [   0/3494]  eta: 2:39:18  lr: 0.0010000  loss: 1.0078 (1.0078)  bbox_regression: 0.1822 (0.1822)  classification: 0.8256 (0.8256)  time: 2.7356  data: 2.4777  max mem: 3278
Epoch: [4]  [ 100/3494]  eta: 0:21:55  lr: 0.0010000  loss: 1.0103 (1.0217)  bbox_regression: 0.1875 (0.2075)  classification: 0.8162 (0.8142)  time: 0.3497  data: 0.1125  max mem: 3278
Epoch: [4]  [ 200/3494]  eta: 0:20:39  lr: 0.0010000  loss: 0.9377 (1.0131)  bbox_regression: 0.1778 (0.2025)  classification: 0.7680 (0.8106)  time: 0.3645  data: 0.1278  max mem: 3278
Epoch: [4]  [ 300/3494]  eta: 0:19:55  lr: 0.0010000  loss: 0.9922 (1.0228)  bbox_regression: 0.1779 (0.2038)  classification: 0.7764 (0.8191)  time: 0.3805  data: 0.1445  max mem: 3278
Epoch: [4]  [ 400/3494]  eta: 0:19:10  lr: 0.0010000  loss: 1.0221 (1.0251)  bbox_regression: 0.1939 (0.2035)  classification: 0.8370 (0.8215)  time: 0.3559  data: 0.1273  max mem: 3278
Epoch: [4]  [ 500/3494]  eta: 0:18:27  lr: 0.0010000  loss: 0.9911 (1.0305)  bbox_regression: 0.1841 (0.2051)  classification: 0.7722 (0.8254)  time: 0.3713  data: 0.1422  max mem: 3278
Epoch: [4]  [ 600/3494]  eta: 0:17:49  lr: 0.0010000  loss: 1.0337 (1.0303)  bbox_regression: 0.2056 (0.2047)  classification: 0.8499 (0.8255)  time: 0.3799  data: 0.1329  max mem: 3278
Epoch: [4]  [ 700/3494]  eta: 0:17:10  lr: 0.0010000  loss: 0.9768 (1.0286)  bbox_regression: 0.1965 (0.2042)  classification: 0.7763 (0.8244)  time: 0.3678  data: 0.1319  max mem: 3278
Epoch: [4]  [ 800/3494]  eta: 0:16:32  lr: 0.0010000  loss: 1.0484 (1.0286)  bbox_regression: 0.1872 (0.2032)  classification: 0.8626 (0.8254)  time: 0.3559  data: 0.1252  max mem: 3278
Epoch: [4]  [ 900/3494]  eta: 0:15:55  lr: 0.0010000  loss: 0.9806 (1.0278)  bbox_regression: 0.1869 (0.2033)  classification: 0.8021 (0.8245)  time: 0.3564  data: 0.1256  max mem: 3278
Epoch: [4]  [1000/3494]  eta: 0:15:16  lr: 0.0010000  loss: 0.9758 (1.0270)  bbox_regression: 0.1704 (0.2028)  classification: 0.7858 (0.8242)  time: 0.3684  data: 0.1308  max mem: 3278
Epoch: [4]  [1100/3494]  eta: 0:14:38  lr: 0.0010000  loss: 0.9750 (1.0267)  bbox_regression: 0.1976 (0.2025)  classification: 0.7834 (0.8242)  time: 0.3489  data: 0.1214  max mem: 3278
Epoch: [4]  [1200/3494]  eta: 0:14:01  lr: 0.0010000  loss: 0.9734 (1.0251)  bbox_regression: 0.1980 (0.2023)  classification: 0.8221 (0.8229)  time: 0.3644  data: 0.1312  max mem: 3278
Epoch: [4]  [1300/3494]  eta: 0:13:24  lr: 0.0010000  loss: 1.0211 (1.0267)  bbox_regression: 0.2146 (0.2026)  classification: 0.8276 (0.8241)  time: 0.3710  data: 0.1310  max mem: 3278
Epoch: [4]  [1400/3494]  eta: 0:12:47  lr: 0.0010000  loss: 0.8837 (1.0253)  bbox_regression: 0.1667 (0.2025)  classification: 0.7529 (0.8228)  time: 0.3617  data: 0.1279  max mem: 3278
Epoch: [4]  [1500/3494]  eta: 0:12:08  lr: 0.0010000  loss: 1.0372 (1.0254)  bbox_regression: 0.1860 (0.2022)  classification: 0.8228 (0.8232)  time: 0.3644  data: 0.1341  max mem: 3278
Epoch: [4]  [1600/3494]  eta: 0:11:32  lr: 0.0010000  loss: 0.9951 (1.0259)  bbox_regression: 0.1774 (0.2027)  classification: 0.7973 (0.8232)  time: 0.3604  data: 0.1310  max mem: 3278
Epoch: [4]  [1700/3494]  eta: 0:10:55  lr: 0.0010000  loss: 1.0498 (1.0252)  bbox_regression: 0.1984 (0.2026)  classification: 0.8068 (0.8226)  time: 0.3598  data: 0.1337  max mem: 3278
Epoch: [4]  [1800/3494]  eta: 0:10:18  lr: 0.0010000  loss: 0.9540 (1.0257)  bbox_regression: 0.1739 (0.2027)  classification: 0.7801 (0.8230)  time: 0.3644  data: 0.1307  max mem: 3278
Epoch: [4]  [1900/3494]  eta: 0:09:42  lr: 0.0010000  loss: 1.0525 (1.0284)  bbox_regression: 0.1881 (0.2033)  classification: 0.8813 (0.8251)  time: 0.3753  data: 0.1389  max mem: 3278
Epoch: [4]  [2000/3494]  eta: 0:09:05  lr: 0.0010000  loss: 1.0377 (1.0278)  bbox_regression: 0.1979 (0.2029)  classification: 0.8447 (0.8249)  time: 0.3659  data: 0.1351  max mem: 3278
Epoch: [4]  [2100/3494]  eta: 0:08:28  lr: 0.0010000  loss: 0.9582 (1.0292)  bbox_regression: 0.1671 (0.2030)  classification: 0.7721 (0.8262)  time: 0.3663  data: 0.1322  max mem: 3278
Epoch: [4]  [2200/3494]  eta: 0:07:52  lr: 0.0010000  loss: 1.0168 (1.0288)  bbox_regression: 0.1908 (0.2029)  classification: 0.8235 (0.8259)  time: 0.3705  data: 0.1421  max mem: 3278
Epoch: [4]  [2300/3494]  eta: 0:07:15  lr: 0.0010000  loss: 0.9397 (1.0290)  bbox_regression: 0.1652 (0.2028)  classification: 0.7742 (0.8261)  time: 0.3599  data: 0.1315  max mem: 3278
Epoch: [4]  [2400/3494]  eta: 0:06:38  lr: 0.0010000  loss: 0.9008 (1.0272)  bbox_regression: 0.1638 (0.2023)  classification: 0.7470 (0.8250)  time: 0.3518  data: 0.1277  max mem: 3278
Epoch: [4]  [2500/3494]  eta: 0:06:02  lr: 0.0010000  loss: 0.9333 (1.0258)  bbox_regression: 0.1740 (0.2018)  classification: 0.7325 (0.8240)  time: 0.3547  data: 0.1290  max mem: 3278
Epoch: [4]  [2600/3494]  eta: 0:05:25  lr: 0.0010000  loss: 0.9361 (1.0242)  bbox_regression: 0.1652 (0.2015)  classification: 0.7741 (0.8227)  time: 0.3617  data: 0.1322  max mem: 3278
Epoch: [4]  [2700/3494]  eta: 0:04:49  lr: 0.0010000  loss: 0.9781 (1.0240)  bbox_regression: 0.1758 (0.2013)  classification: 0.8152 (0.8227)  time: 0.3586  data: 0.1230  max mem: 3278
Epoch: [4]  [2800/3494]  eta: 0:04:12  lr: 0.0010000  loss: 0.9290 (1.0233)  bbox_regression: 0.1956 (0.2013)  classification: 0.7288 (0.8219)  time: 0.3273  data: 0.1058  max mem: 3278
Epoch: [4]  [2900/3494]  eta: 0:03:36  lr: 0.0010000  loss: 1.0096 (1.0236)  bbox_regression: 0.1881 (0.2013)  classification: 0.8247 (0.8224)  time: 0.3732  data: 0.1310  max mem: 3278
Epoch: [4]  [3000/3494]  eta: 0:02:59  lr: 0.0010000  loss: 0.9390 (1.0228)  bbox_regression: 0.1824 (0.2011)  classification: 0.7544 (0.8217)  time: 0.3673  data: 0.1319  max mem: 3278
Epoch: [4]  [3100/3494]  eta: 0:02:23  lr: 0.0010000  loss: 0.9139 (1.0222)  bbox_regression: 0.1723 (0.2008)  classification: 0.7469 (0.8214)  time: 0.3656  data: 0.1326  max mem: 3278
Epoch: [4]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 1.0342 (1.0221)  bbox_regression: 0.1769 (0.2008)  classification: 0.8573 (0.8213)  time: 0.3591  data: 0.1263  max mem: 3278
Epoch: [4]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 0.9379 (1.0209)  bbox_regression: 0.1605 (0.2005)  classification: 0.7633 (0.8204)  time: 0.3480  data: 0.1153  max mem: 3278
Epoch: [4]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 0.9716 (1.0206)  bbox_regression: 0.1790 (0.2003)  classification: 0.7864 (0.8203)  time: 0.3530  data: 0.1292  max mem: 3278
Epoch: [4]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.9770 (1.0198)  bbox_regression: 0.1793 (0.2001)  classification: 0.7990 (0.8197)  time: 0.3518  data: 0.1275  max mem: 3278
Epoch: [4] Total time: 0:21:20 (0.3664 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:44  model_time: 0.1415 (0.1415)  loss: 1.4082 (1.4082)  bbox_regression: 0.2127 (0.2127)  classification: 1.1954 (1.1954)  time: 2.0249  data: 1.8578  max mem: 3278
Validation:  [100/437]  eta: 0:01:30  model_time: 0.1208 (0.1186)  loss: 1.0412 (1.1016)  bbox_regression: 0.2476 (0.2217)  classification: 0.8386 (0.8799)  time: 0.2682  data: 0.1262  max mem: 3278
Validation:  [200/437]  eta: 0:01:02  model_time: 0.1167 (0.1195)  loss: 1.0291 (1.0663)  bbox_regression: 0.1911 (0.2097)  classification: 0.8552 (0.8566)  time: 0.2548  data: 0.1193  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1236 (0.1203)  loss: 1.0775 (1.0651)  bbox_regression: 0.1892 (0.2068)  classification: 0.8760 (0.8582)  time: 0.2724  data: 0.1307  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1157 (0.1210)  loss: 1.0469 (1.0614)  bbox_regression: 0.1918 (0.2059)  classification: 0.8509 (0.8555)  time: 0.2229  data: 0.0977  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1183 (0.1209)  loss: 1.0016 (1.0622)  bbox_regression: 0.1774 (0.2059)  classification: 0.8297 (0.8563)  time: 0.2622  data: 0.1265  max mem: 3278
Validation: Total time: 0:01:55 (0.2642 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [5]  [   0/3494]  eta: 2:14:06  lr: 0.0010000  loss: 0.6643 (0.6643)  bbox_regression: 0.1688 (0.1688)  classification: 0.4955 (0.4955)  time: 2.3030  data: 2.0346  max mem: 3278
Epoch: [5]  [ 100/3494]  eta: 0:21:28  lr: 0.0010000  loss: 0.9953 (0.9793)  bbox_regression: 0.1757 (0.1903)  classification: 0.7888 (0.7890)  time: 0.3599  data: 0.1276  max mem: 3278
Epoch: [5]  [ 200/3494]  eta: 0:20:21  lr: 0.0010000  loss: 0.9974 (0.9674)  bbox_regression: 0.1780 (0.1891)  classification: 0.8006 (0.7783)  time: 0.3591  data: 0.1318  max mem: 3278
Epoch: [5]  [ 300/3494]  eta: 0:19:24  lr: 0.0010000  loss: 0.9195 (0.9731)  bbox_regression: 0.1726 (0.1878)  classification: 0.7567 (0.7852)  time: 0.3617  data: 0.1272  max mem: 3278
Epoch: [5]  [ 400/3494]  eta: 0:18:44  lr: 0.0010000  loss: 0.9088 (0.9720)  bbox_regression: 0.1796 (0.1874)  classification: 0.7290 (0.7845)  time: 0.3657  data: 0.1343  max mem: 3278
Epoch: [5]  [ 500/3494]  eta: 0:18:02  lr: 0.0010000  loss: 1.0028 (0.9752)  bbox_regression: 0.1918 (0.1870)  classification: 0.8435 (0.7881)  time: 0.3627  data: 0.1305  max mem: 3278
Epoch: [5]  [ 600/3494]  eta: 0:17:23  lr: 0.0010000  loss: 1.0419 (0.9804)  bbox_regression: 0.1901 (0.1891)  classification: 0.8517 (0.7913)  time: 0.3538  data: 0.1241  max mem: 3278
Epoch: [5]  [ 700/3494]  eta: 0:16:48  lr: 0.0010000  loss: 0.9397 (0.9807)  bbox_regression: 0.1770 (0.1892)  classification: 0.7526 (0.7915)  time: 0.3663  data: 0.1280  max mem: 3278
Epoch: [5]  [ 800/3494]  eta: 0:16:10  lr: 0.0010000  loss: 0.9153 (0.9792)  bbox_regression: 0.1675 (0.1888)  classification: 0.7740 (0.7904)  time: 0.3549  data: 0.1261  max mem: 3278
Epoch: [5]  [ 900/3494]  eta: 0:15:35  lr: 0.0010000  loss: 1.0112 (0.9780)  bbox_regression: 0.1866 (0.1890)  classification: 0.7937 (0.7890)  time: 0.3573  data: 0.1266  max mem: 3278
Epoch: [5]  [1000/3494]  eta: 0:14:56  lr: 0.0010000  loss: 0.9875 (0.9769)  bbox_regression: 0.1878 (0.1892)  classification: 0.8098 (0.7877)  time: 0.3432  data: 0.1203  max mem: 3278
Epoch: [5]  [1100/3494]  eta: 0:14:20  lr: 0.0010000  loss: 0.8969 (0.9761)  bbox_regression: 0.1583 (0.1888)  classification: 0.7386 (0.7872)  time: 0.3697  data: 0.1333  max mem: 3278
Epoch: [5]  [1200/3494]  eta: 0:13:44  lr: 0.0010000  loss: 0.9374 (0.9750)  bbox_regression: 0.1696 (0.1887)  classification: 0.7666 (0.7863)  time: 0.3530  data: 0.1273  max mem: 3278
Epoch: [5]  [1300/3494]  eta: 0:13:08  lr: 0.0010000  loss: 0.8970 (0.9738)  bbox_regression: 0.1652 (0.1884)  classification: 0.7565 (0.7855)  time: 0.3583  data: 0.1271  max mem: 3278
Epoch: [5]  [1400/3494]  eta: 0:12:33  lr: 0.0010000  loss: 0.9232 (0.9730)  bbox_regression: 0.1790 (0.1883)  classification: 0.7246 (0.7847)  time: 0.3568  data: 0.1287  max mem: 3278
Epoch: [5]  [1500/3494]  eta: 0:11:55  lr: 0.0010000  loss: 0.9228 (0.9728)  bbox_regression: 0.1731 (0.1885)  classification: 0.7407 (0.7843)  time: 0.3091  data: 0.1018  max mem: 3278
Epoch: [5]  [1600/3494]  eta: 0:11:19  lr: 0.0010000  loss: 0.8996 (0.9725)  bbox_regression: 0.1835 (0.1887)  classification: 0.7250 (0.7839)  time: 0.3566  data: 0.1277  max mem: 3278
Epoch: [5]  [1700/3494]  eta: 0:10:43  lr: 0.0010000  loss: 0.9618 (0.9717)  bbox_regression: 0.1944 (0.1884)  classification: 0.7684 (0.7833)  time: 0.3486  data: 0.1248  max mem: 3278
Epoch: [5]  [1800/3494]  eta: 0:10:06  lr: 0.0010000  loss: 0.9497 (0.9717)  bbox_regression: 0.1787 (0.1887)  classification: 0.7498 (0.7831)  time: 0.3631  data: 0.1365  max mem: 3278
Epoch: [5]  [1900/3494]  eta: 0:09:31  lr: 0.0010000  loss: 0.8798 (0.9711)  bbox_regression: 0.1516 (0.1881)  classification: 0.7392 (0.7830)  time: 0.3537  data: 0.1258  max mem: 3278
Epoch: [5]  [2000/3494]  eta: 0:08:54  lr: 0.0010000  loss: 0.8681 (0.9714)  bbox_regression: 0.1697 (0.1881)  classification: 0.7405 (0.7833)  time: 0.3369  data: 0.1142  max mem: 3278
Epoch: [5]  [2100/3494]  eta: 0:08:19  lr: 0.0010000  loss: 0.9609 (0.9701)  bbox_regression: 0.1765 (0.1877)  classification: 0.7558 (0.7823)  time: 0.3663  data: 0.1367  max mem: 3278
Epoch: [5]  [2200/3494]  eta: 0:07:43  lr: 0.0010000  loss: 0.9078 (0.9698)  bbox_regression: 0.1609 (0.1875)  classification: 0.7200 (0.7824)  time: 0.3792  data: 0.1356  max mem: 3278
Epoch: [5]  [2300/3494]  eta: 0:07:07  lr: 0.0010000  loss: 0.9535 (0.9702)  bbox_regression: 0.1834 (0.1876)  classification: 0.7556 (0.7825)  time: 0.3690  data: 0.1337  max mem: 3278
Epoch: [5]  [2400/3494]  eta: 0:06:31  lr: 0.0010000  loss: 0.8968 (0.9717)  bbox_regression: 0.1763 (0.1879)  classification: 0.7407 (0.7838)  time: 0.3584  data: 0.1276  max mem: 3278
Epoch: [5]  [2500/3494]  eta: 0:05:56  lr: 0.0010000  loss: 0.8853 (0.9713)  bbox_regression: 0.1829 (0.1876)  classification: 0.7253 (0.7837)  time: 0.3444  data: 0.1159  max mem: 3278
Epoch: [5]  [2600/3494]  eta: 0:05:20  lr: 0.0010000  loss: 0.9346 (0.9709)  bbox_regression: 0.1764 (0.1875)  classification: 0.7827 (0.7835)  time: 0.3504  data: 0.1254  max mem: 3278
Epoch: [5]  [2700/3494]  eta: 0:04:44  lr: 0.0010000  loss: 0.9350 (0.9702)  bbox_regression: 0.1519 (0.1872)  classification: 0.7104 (0.7829)  time: 0.3556  data: 0.1260  max mem: 3278
Epoch: [5]  [2800/3494]  eta: 0:04:08  lr: 0.0010000  loss: 0.9890 (0.9705)  bbox_regression: 0.1736 (0.1874)  classification: 0.7956 (0.7831)  time: 0.3614  data: 0.1270  max mem: 3278
Epoch: [5]  [2900/3494]  eta: 0:03:32  lr: 0.0010000  loss: 0.9341 (0.9700)  bbox_regression: 0.1805 (0.1873)  classification: 0.7801 (0.7827)  time: 0.3519  data: 0.1236  max mem: 3278
Epoch: [5]  [3000/3494]  eta: 0:02:56  lr: 0.0010000  loss: 0.9597 (0.9703)  bbox_regression: 0.1681 (0.1872)  classification: 0.7876 (0.7830)  time: 0.3567  data: 0.1307  max mem: 3278
Epoch: [5]  [3100/3494]  eta: 0:02:20  lr: 0.0010000  loss: 0.9466 (0.9698)  bbox_regression: 0.1831 (0.1872)  classification: 0.7513 (0.7826)  time: 0.3542  data: 0.1248  max mem: 3278
Epoch: [5]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.9567 (0.9690)  bbox_regression: 0.1894 (0.1869)  classification: 0.7390 (0.7820)  time: 0.3533  data: 0.1241  max mem: 3278
Epoch: [5]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.9221 (0.9682)  bbox_regression: 0.1624 (0.1869)  classification: 0.7450 (0.7813)  time: 0.3626  data: 0.1302  max mem: 3278
Epoch: [5]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 1.0128 (0.9679)  bbox_regression: 0.1750 (0.1868)  classification: 0.8400 (0.7812)  time: 0.3638  data: 0.1264  max mem: 3278
Epoch: [5]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.9463 (0.9668)  bbox_regression: 0.1830 (0.1865)  classification: 0.7791 (0.7803)  time: 0.3524  data: 0.1297  max mem: 3278
Epoch: [5] Total time: 0:21:01 (0.3610 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:17  model_time: 0.1277 (0.1277)  loss: 1.3914 (1.3914)  bbox_regression: 0.2213 (0.2213)  classification: 1.1700 (1.1700)  time: 1.8259  data: 1.6792  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1224 (0.1221)  loss: 1.0145 (1.0615)  bbox_regression: 0.2276 (0.2115)  classification: 0.7961 (0.8500)  time: 0.2711  data: 0.1279  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1184 (0.1229)  loss: 0.9681 (1.0289)  bbox_regression: 0.1906 (0.2011)  classification: 0.8009 (0.8279)  time: 0.2710  data: 0.1326  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1135 (0.1219)  loss: 1.0478 (1.0241)  bbox_regression: 0.1723 (0.1978)  classification: 0.8242 (0.8263)  time: 0.2490  data: 0.1161  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1177 (0.1219)  loss: 0.9694 (1.0203)  bbox_regression: 0.1854 (0.1971)  classification: 0.7846 (0.8232)  time: 0.2301  data: 0.0989  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1169 (0.1218)  loss: 0.9317 (1.0203)  bbox_regression: 0.1705 (0.1969)  classification: 0.7711 (0.8233)  time: 0.2614  data: 0.1233  max mem: 3278
Validation: Total time: 0:01:56 (0.2670 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [6]  [   0/3494]  eta: 1:58:53  lr: 0.0010000  loss: 0.6401 (0.6401)  bbox_regression: 0.1149 (0.1149)  classification: 0.5253 (0.5253)  time: 2.0418  data: 1.7983  max mem: 3278
Epoch: [6]  [ 100/3494]  eta: 0:21:19  lr: 0.0010000  loss: 0.8090 (0.8924)  bbox_regression: 0.1512 (0.1686)  classification: 0.6530 (0.7238)  time: 0.3559  data: 0.1298  max mem: 3278
Epoch: [6]  [ 200/3494]  eta: 0:20:11  lr: 0.0010000  loss: 0.8929 (0.8936)  bbox_regression: 0.1724 (0.1713)  classification: 0.7279 (0.7223)  time: 0.3680  data: 0.1256  max mem: 3278
Epoch: [6]  [ 300/3494]  eta: 0:19:25  lr: 0.0010000  loss: 0.9247 (0.9050)  bbox_regression: 0.1486 (0.1725)  classification: 0.7308 (0.7325)  time: 0.3576  data: 0.1311  max mem: 3278
Epoch: [6]  [ 400/3494]  eta: 0:18:46  lr: 0.0010000  loss: 0.9400 (0.9070)  bbox_regression: 0.1712 (0.1723)  classification: 0.7460 (0.7347)  time: 0.3645  data: 0.1312  max mem: 3278
Epoch: [6]  [ 500/3494]  eta: 0:18:06  lr: 0.0010000  loss: 0.8253 (0.9110)  bbox_regression: 0.1569 (0.1733)  classification: 0.6666 (0.7377)  time: 0.3727  data: 0.1293  max mem: 3278
Epoch: [6]  [ 600/3494]  eta: 0:17:29  lr: 0.0010000  loss: 0.9060 (0.9148)  bbox_regression: 0.1738 (0.1742)  classification: 0.7680 (0.7406)  time: 0.3628  data: 0.1261  max mem: 3278
Epoch: [6]  [ 700/3494]  eta: 0:16:54  lr: 0.0010000  loss: 0.9000 (0.9189)  bbox_regression: 0.1734 (0.1750)  classification: 0.7246 (0.7439)  time: 0.3717  data: 0.1314  max mem: 3278
Epoch: [6]  [ 800/3494]  eta: 0:16:16  lr: 0.0010000  loss: 0.8753 (0.9273)  bbox_regression: 0.1506 (0.1769)  classification: 0.7308 (0.7505)  time: 0.3741  data: 0.1364  max mem: 3278
Epoch: [6]  [ 900/3494]  eta: 0:15:40  lr: 0.0010000  loss: 0.8759 (0.9259)  bbox_regression: 0.1520 (0.1763)  classification: 0.7322 (0.7496)  time: 0.3575  data: 0.1310  max mem: 3278
Epoch: [6]  [1000/3494]  eta: 0:15:04  lr: 0.0010000  loss: 0.9457 (0.9284)  bbox_regression: 0.1712 (0.1770)  classification: 0.7624 (0.7514)  time: 0.3688  data: 0.1296  max mem: 3278
Epoch: [6]  [1100/3494]  eta: 0:14:28  lr: 0.0010000  loss: 0.8518 (0.9282)  bbox_regression: 0.1578 (0.1772)  classification: 0.6799 (0.7510)  time: 0.3655  data: 0.1304  max mem: 3278
Epoch: [6]  [1200/3494]  eta: 0:13:51  lr: 0.0010000  loss: 0.8218 (0.9284)  bbox_regression: 0.1592 (0.1777)  classification: 0.6620 (0.7507)  time: 0.3625  data: 0.1326  max mem: 3278
Epoch: [6]  [1300/3494]  eta: 0:13:13  lr: 0.0010000  loss: 0.9256 (0.9307)  bbox_regression: 0.1676 (0.1782)  classification: 0.7623 (0.7525)  time: 0.3532  data: 0.1282  max mem: 3278
Epoch: [6]  [1400/3494]  eta: 0:12:38  lr: 0.0010000  loss: 0.8729 (0.9292)  bbox_regression: 0.1651 (0.1780)  classification: 0.6993 (0.7512)  time: 0.3745  data: 0.1370  max mem: 3278
Epoch: [6]  [1500/3494]  eta: 0:12:01  lr: 0.0010000  loss: 0.9293 (0.9296)  bbox_regression: 0.1633 (0.1779)  classification: 0.7251 (0.7517)  time: 0.3617  data: 0.1299  max mem: 3278
Epoch: [6]  [1600/3494]  eta: 0:11:25  lr: 0.0010000  loss: 0.9626 (0.9318)  bbox_regression: 0.2035 (0.1782)  classification: 0.7567 (0.7535)  time: 0.3540  data: 0.1218  max mem: 3278
Epoch: [6]  [1700/3494]  eta: 0:10:49  lr: 0.0010000  loss: 0.9054 (0.9322)  bbox_regression: 0.1687 (0.1782)  classification: 0.7499 (0.7540)  time: 0.3557  data: 0.1278  max mem: 3278
Epoch: [6]  [1800/3494]  eta: 0:10:12  lr: 0.0010000  loss: 0.8422 (0.9327)  bbox_regression: 0.1542 (0.1784)  classification: 0.6910 (0.7543)  time: 0.3521  data: 0.1232  max mem: 3278
Epoch: [6]  [1900/3494]  eta: 0:09:36  lr: 0.0010000  loss: 0.7937 (0.9304)  bbox_regression: 0.1418 (0.1780)  classification: 0.6466 (0.7524)  time: 0.3622  data: 0.1292  max mem: 3278
Epoch: [6]  [2000/3494]  eta: 0:09:00  lr: 0.0010000  loss: 0.8802 (0.9300)  bbox_regression: 0.1560 (0.1783)  classification: 0.7049 (0.7518)  time: 0.3692  data: 0.1288  max mem: 3278
Epoch: [6]  [2100/3494]  eta: 0:08:24  lr: 0.0010000  loss: 0.8658 (0.9298)  bbox_regression: 0.1696 (0.1781)  classification: 0.7106 (0.7517)  time: 0.3613  data: 0.1300  max mem: 3278
Epoch: [6]  [2200/3494]  eta: 0:07:48  lr: 0.0010000  loss: 0.9093 (0.9290)  bbox_regression: 0.1741 (0.1777)  classification: 0.7009 (0.7513)  time: 0.3788  data: 0.1419  max mem: 3278
Epoch: [6]  [2300/3494]  eta: 0:07:11  lr: 0.0010000  loss: 0.8824 (0.9286)  bbox_regression: 0.1647 (0.1776)  classification: 0.7268 (0.7511)  time: 0.3630  data: 0.1295  max mem: 3278
Epoch: [6]  [2400/3494]  eta: 0:06:35  lr: 0.0010000  loss: 0.8741 (0.9273)  bbox_regression: 0.1572 (0.1770)  classification: 0.7237 (0.7503)  time: 0.3681  data: 0.1381  max mem: 3278
Epoch: [6]  [2500/3494]  eta: 0:05:59  lr: 0.0010000  loss: 0.8766 (0.9275)  bbox_regression: 0.1612 (0.1769)  classification: 0.7225 (0.7506)  time: 0.3698  data: 0.1379  max mem: 3278
Epoch: [6]  [2600/3494]  eta: 0:05:23  lr: 0.0010000  loss: 0.8509 (0.9275)  bbox_regression: 0.1617 (0.1768)  classification: 0.6786 (0.7507)  time: 0.3662  data: 0.1291  max mem: 3278
Epoch: [6]  [2700/3494]  eta: 0:04:47  lr: 0.0010000  loss: 0.9120 (0.9276)  bbox_regression: 0.1771 (0.1767)  classification: 0.7442 (0.7508)  time: 0.3249  data: 0.1051  max mem: 3278
Epoch: [6]  [2800/3494]  eta: 0:04:10  lr: 0.0010000  loss: 0.9512 (0.9284)  bbox_regression: 0.1680 (0.1769)  classification: 0.7845 (0.7515)  time: 0.3622  data: 0.1279  max mem: 3278
Epoch: [6]  [2900/3494]  eta: 0:03:34  lr: 0.0010000  loss: 0.8406 (0.9283)  bbox_regression: 0.1451 (0.1767)  classification: 0.6924 (0.7515)  time: 0.3672  data: 0.1363  max mem: 3278
Epoch: [6]  [3000/3494]  eta: 0:02:58  lr: 0.0010000  loss: 0.8253 (0.9277)  bbox_regression: 0.1486 (0.1765)  classification: 0.6800 (0.7512)  time: 0.3693  data: 0.1372  max mem: 3278
Epoch: [6]  [3100/3494]  eta: 0:02:22  lr: 0.0010000  loss: 0.8490 (0.9270)  bbox_regression: 0.1645 (0.1765)  classification: 0.7034 (0.7505)  time: 0.3662  data: 0.1341  max mem: 3278
Epoch: [6]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 0.8888 (0.9262)  bbox_regression: 0.1595 (0.1764)  classification: 0.6993 (0.7498)  time: 0.3479  data: 0.1213  max mem: 3278
Epoch: [6]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 0.9039 (0.9259)  bbox_regression: 0.1625 (0.1761)  classification: 0.7236 (0.7498)  time: 0.3623  data: 0.1289  max mem: 3278
Epoch: [6]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 1.0152 (0.9260)  bbox_regression: 0.1873 (0.1761)  classification: 0.8262 (0.7499)  time: 0.3638  data: 0.1302  max mem: 3278
Epoch: [6]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.9042 (0.9266)  bbox_regression: 0.1569 (0.1763)  classification: 0.7246 (0.7503)  time: 0.3476  data: 0.1254  max mem: 3278
Epoch: [6] Total time: 0:21:12 (0.3641 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:20  model_time: 0.1305 (0.1305)  loss: 1.3437 (1.3437)  bbox_regression: 0.1838 (0.1838)  classification: 1.1599 (1.1599)  time: 2.2442  data: 2.0923  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1139 (0.1201)  loss: 0.9579 (1.0530)  bbox_regression: 0.2073 (0.2059)  classification: 0.7349 (0.8471)  time: 0.2554  data: 0.1217  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1173 (0.1194)  loss: 1.0031 (1.0185)  bbox_regression: 0.1871 (0.1961)  classification: 0.7869 (0.8224)  time: 0.2626  data: 0.1239  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1176 (0.1195)  loss: 1.0742 (1.0176)  bbox_regression: 0.1686 (0.1937)  classification: 0.8651 (0.8239)  time: 0.2638  data: 0.1243  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1131 (0.1199)  loss: 1.0145 (1.0131)  bbox_regression: 0.1854 (0.1932)  classification: 0.8102 (0.8200)  time: 0.2519  data: 0.1182  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1134 (0.1195)  loss: 0.9184 (1.0121)  bbox_regression: 0.1630 (0.1928)  classification: 0.7398 (0.8193)  time: 0.2488  data: 0.1182  max mem: 3278
Validation: Total time: 0:01:55 (0.2642 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [7]  [   0/3494]  eta: 2:22:45  lr: 0.0010000  loss: 1.4414 (1.4414)  bbox_regression: 0.2627 (0.2627)  classification: 1.1787 (1.1787)  time: 2.4514  data: 2.2171  max mem: 3278
Epoch: [7]  [ 100/3494]  eta: 0:21:34  lr: 0.0010000  loss: 0.8287 (0.8787)  bbox_regression: 0.1657 (0.1618)  classification: 0.6796 (0.7168)  time: 0.3551  data: 0.1278  max mem: 3278
Epoch: [7]  [ 200/3494]  eta: 0:20:12  lr: 0.0010000  loss: 0.7895 (0.8851)  bbox_regression: 0.1393 (0.1642)  classification: 0.6300 (0.7209)  time: 0.3581  data: 0.1280  max mem: 3278
Epoch: [7]  [ 300/3494]  eta: 0:19:25  lr: 0.0010000  loss: 0.8071 (0.8796)  bbox_regression: 0.1508 (0.1644)  classification: 0.6737 (0.7152)  time: 0.3596  data: 0.1287  max mem: 3278
Epoch: [7]  [ 400/3494]  eta: 0:18:40  lr: 0.0010000  loss: 0.8599 (0.8873)  bbox_regression: 0.1722 (0.1682)  classification: 0.6647 (0.7191)  time: 0.3499  data: 0.1259  max mem: 3278
Epoch: [7]  [ 500/3494]  eta: 0:18:03  lr: 0.0010000  loss: 0.8808 (0.8851)  bbox_regression: 0.1603 (0.1680)  classification: 0.7387 (0.7170)  time: 0.3596  data: 0.1262  max mem: 3278
Epoch: [7]  [ 600/3494]  eta: 0:17:22  lr: 0.0010000  loss: 0.8101 (0.8852)  bbox_regression: 0.1610 (0.1684)  classification: 0.6488 (0.7169)  time: 0.3553  data: 0.1274  max mem: 3278
Epoch: [7]  [ 700/3494]  eta: 0:16:42  lr: 0.0010000  loss: 0.8840 (0.8862)  bbox_regression: 0.1622 (0.1684)  classification: 0.6954 (0.7178)  time: 0.3548  data: 0.1263  max mem: 3278
Epoch: [7]  [ 800/3494]  eta: 0:16:07  lr: 0.0010000  loss: 0.9037 (0.8877)  bbox_regression: 0.1749 (0.1687)  classification: 0.6882 (0.7190)  time: 0.3700  data: 0.1342  max mem: 3278
Epoch: [7]  [ 900/3494]  eta: 0:15:31  lr: 0.0010000  loss: 0.8144 (0.8905)  bbox_regression: 0.1461 (0.1689)  classification: 0.6716 (0.7216)  time: 0.3543  data: 0.1255  max mem: 3278
Epoch: [7]  [1000/3494]  eta: 0:14:55  lr: 0.0010000  loss: 0.8478 (0.8908)  bbox_regression: 0.1695 (0.1692)  classification: 0.6635 (0.7216)  time: 0.3613  data: 0.1269  max mem: 3278
Epoch: [7]  [1100/3494]  eta: 0:14:18  lr: 0.0010000  loss: 0.9351 (0.8928)  bbox_regression: 0.1647 (0.1697)  classification: 0.7225 (0.7231)  time: 0.3628  data: 0.1291  max mem: 3278
Epoch: [7]  [1200/3494]  eta: 0:13:42  lr: 0.0010000  loss: 0.8660 (0.8921)  bbox_regression: 0.1623 (0.1697)  classification: 0.7028 (0.7224)  time: 0.3682  data: 0.1365  max mem: 3278
Epoch: [7]  [1300/3494]  eta: 0:13:07  lr: 0.0010000  loss: 0.8840 (0.8907)  bbox_regression: 0.1662 (0.1691)  classification: 0.7212 (0.7216)  time: 0.3721  data: 0.1341  max mem: 3278
Epoch: [7]  [1400/3494]  eta: 0:12:30  lr: 0.0010000  loss: 0.8332 (0.8906)  bbox_regression: 0.1594 (0.1693)  classification: 0.6847 (0.7213)  time: 0.3632  data: 0.1328  max mem: 3278
Epoch: [7]  [1500/3494]  eta: 0:11:54  lr: 0.0010000  loss: 0.8722 (0.8881)  bbox_regression: 0.1655 (0.1687)  classification: 0.7187 (0.7194)  time: 0.3576  data: 0.1312  max mem: 3278
Epoch: [7]  [1600/3494]  eta: 0:11:18  lr: 0.0010000  loss: 0.9010 (0.8884)  bbox_regression: 0.1603 (0.1687)  classification: 0.7027 (0.7197)  time: 0.3453  data: 0.1218  max mem: 3278
Epoch: [7]  [1700/3494]  eta: 0:10:42  lr: 0.0010000  loss: 0.8966 (0.8863)  bbox_regression: 0.1431 (0.1681)  classification: 0.6849 (0.7182)  time: 0.3661  data: 0.1368  max mem: 3278
Epoch: [7]  [1800/3494]  eta: 0:10:07  lr: 0.0010000  loss: 0.8211 (0.8877)  bbox_regression: 0.1482 (0.1684)  classification: 0.6821 (0.7193)  time: 0.3490  data: 0.1240  max mem: 3278
Epoch: [7]  [1900/3494]  eta: 0:09:31  lr: 0.0010000  loss: 0.8101 (0.8870)  bbox_regression: 0.1379 (0.1681)  classification: 0.6687 (0.7189)  time: 0.3758  data: 0.1390  max mem: 3278
Epoch: [7]  [2000/3494]  eta: 0:08:55  lr: 0.0010000  loss: 0.9033 (0.8886)  bbox_regression: 0.1602 (0.1685)  classification: 0.7151 (0.7201)  time: 0.3541  data: 0.1275  max mem: 3278
Epoch: [7]  [2100/3494]  eta: 0:08:19  lr: 0.0010000  loss: 0.8080 (0.8879)  bbox_regression: 0.1497 (0.1682)  classification: 0.6658 (0.7197)  time: 0.3638  data: 0.1280  max mem: 3278
Epoch: [7]  [2200/3494]  eta: 0:07:43  lr: 0.0010000  loss: 0.8900 (0.8879)  bbox_regression: 0.1641 (0.1682)  classification: 0.7334 (0.7196)  time: 0.3555  data: 0.1317  max mem: 3278
Epoch: [7]  [2300/3494]  eta: 0:07:07  lr: 0.0010000  loss: 0.9071 (0.8888)  bbox_regression: 0.1606 (0.1683)  classification: 0.7578 (0.7205)  time: 0.3724  data: 0.1310  max mem: 3278
Epoch: [7]  [2400/3494]  eta: 0:06:32  lr: 0.0010000  loss: 0.8373 (0.8885)  bbox_regression: 0.1554 (0.1680)  classification: 0.6590 (0.7204)  time: 0.3557  data: 0.1286  max mem: 3278
Epoch: [7]  [2500/3494]  eta: 0:05:56  lr: 0.0010000  loss: 0.8402 (0.8890)  bbox_regression: 0.1467 (0.1684)  classification: 0.6930 (0.7206)  time: 0.3699  data: 0.1357  max mem: 3278
Epoch: [7]  [2600/3494]  eta: 0:05:20  lr: 0.0010000  loss: 0.8636 (0.8891)  bbox_regression: 0.1497 (0.1682)  classification: 0.7139 (0.7208)  time: 0.3550  data: 0.1259  max mem: 3278
Epoch: [7]  [2700/3494]  eta: 0:04:44  lr: 0.0010000  loss: 0.8226 (0.8891)  bbox_regression: 0.1389 (0.1681)  classification: 0.6882 (0.7209)  time: 0.3605  data: 0.1305  max mem: 3278
Epoch: [7]  [2800/3494]  eta: 0:04:08  lr: 0.0010000  loss: 0.8228 (0.8901)  bbox_regression: 0.1462 (0.1682)  classification: 0.6759 (0.7219)  time: 0.3514  data: 0.1239  max mem: 3278
Epoch: [7]  [2900/3494]  eta: 0:03:32  lr: 0.0010000  loss: 0.8439 (0.8906)  bbox_regression: 0.1361 (0.1682)  classification: 0.6777 (0.7224)  time: 0.3542  data: 0.1262  max mem: 3278
Epoch: [7]  [3000/3494]  eta: 0:02:57  lr: 0.0010000  loss: 0.8977 (0.8911)  bbox_regression: 0.1651 (0.1682)  classification: 0.7031 (0.7228)  time: 0.3418  data: 0.1207  max mem: 3278
Epoch: [7]  [3100/3494]  eta: 0:02:21  lr: 0.0010000  loss: 0.8782 (0.8908)  bbox_regression: 0.1575 (0.1681)  classification: 0.7061 (0.7227)  time: 0.3607  data: 0.1305  max mem: 3278
Epoch: [7]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.8579 (0.8901)  bbox_regression: 0.1534 (0.1680)  classification: 0.7187 (0.7222)  time: 0.3638  data: 0.1304  max mem: 3278
Epoch: [7]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.8172 (0.8898)  bbox_regression: 0.1469 (0.1678)  classification: 0.6750 (0.7220)  time: 0.3614  data: 0.1310  max mem: 3278
Epoch: [7]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 0.8563 (0.8907)  bbox_regression: 0.1606 (0.1680)  classification: 0.6914 (0.7227)  time: 0.3581  data: 0.1293  max mem: 3278
Epoch: [7]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.9189 (0.8919)  bbox_regression: 0.1622 (0.1684)  classification: 0.7370 (0.7235)  time: 0.3448  data: 0.1208  max mem: 3278
Epoch: [7] Total time: 0:21:02 (0.3612 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:35  model_time: 0.1392 (0.1392)  loss: 1.2242 (1.2242)  bbox_regression: 0.1525 (0.1525)  classification: 1.0717 (1.0717)  time: 2.0040  data: 1.8383  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1203 (0.1219)  loss: 0.9694 (1.0214)  bbox_regression: 0.2008 (0.1998)  classification: 0.7386 (0.8216)  time: 0.2601  data: 0.1220  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1180 (0.1222)  loss: 0.9753 (0.9933)  bbox_regression: 0.1898 (0.1905)  classification: 0.7964 (0.8028)  time: 0.2632  data: 0.1224  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1129 (0.1207)  loss: 1.0075 (0.9919)  bbox_regression: 0.1636 (0.1879)  classification: 0.8494 (0.8040)  time: 0.2542  data: 0.1204  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1133 (0.1213)  loss: 0.9217 (0.9866)  bbox_regression: 0.1787 (0.1872)  classification: 0.7327 (0.7994)  time: 0.2535  data: 0.1200  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1193 (0.1213)  loss: 0.8591 (0.9853)  bbox_regression: 0.1670 (0.1871)  classification: 0.7051 (0.7982)  time: 0.2628  data: 0.1252  max mem: 3278
Validation: Total time: 0:01:56 (0.2658 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [8]  [   0/3494]  eta: 2:16:19  lr: 0.0010000  loss: 1.0441 (1.0441)  bbox_regression: 0.1882 (0.1882)  classification: 0.8560 (0.8560)  time: 2.3410  data: 2.0875  max mem: 3278
Epoch: [8]  [ 100/3494]  eta: 0:21:24  lr: 0.0010000  loss: 0.8654 (0.8463)  bbox_regression: 0.1560 (0.1603)  classification: 0.6821 (0.6859)  time: 0.3429  data: 0.1192  max mem: 3278
Epoch: [8]  [ 200/3494]  eta: 0:20:19  lr: 0.0010000  loss: 0.8361 (0.8504)  bbox_regression: 0.1481 (0.1580)  classification: 0.6875 (0.6924)  time: 0.3709  data: 0.1346  max mem: 3278
Epoch: [8]  [ 300/3494]  eta: 0:19:35  lr: 0.0010000  loss: 0.8297 (0.8386)  bbox_regression: 0.1425 (0.1547)  classification: 0.6532 (0.6839)  time: 0.3655  data: 0.1263  max mem: 3278
Epoch: [8]  [ 400/3494]  eta: 0:18:53  lr: 0.0010000  loss: 0.7228 (0.8358)  bbox_regression: 0.1417 (0.1542)  classification: 0.5986 (0.6816)  time: 0.3530  data: 0.1261  max mem: 3278
Epoch: [8]  [ 500/3494]  eta: 0:18:12  lr: 0.0010000  loss: 0.8114 (0.8412)  bbox_regression: 0.1537 (0.1555)  classification: 0.6727 (0.6857)  time: 0.3524  data: 0.1265  max mem: 3278
Epoch: [8]  [ 600/3494]  eta: 0:17:35  lr: 0.0010000  loss: 0.8846 (0.8489)  bbox_regression: 0.1718 (0.1574)  classification: 0.6910 (0.6915)  time: 0.3599  data: 0.1265  max mem: 3278
Epoch: [8]  [ 700/3494]  eta: 0:16:53  lr: 0.0010000  loss: 0.8260 (0.8524)  bbox_regression: 0.1583 (0.1587)  classification: 0.6503 (0.6937)  time: 0.3515  data: 0.1247  max mem: 3278
Epoch: [8]  [ 800/3494]  eta: 0:16:16  lr: 0.0010000  loss: 0.7993 (0.8515)  bbox_regression: 0.1443 (0.1586)  classification: 0.6545 (0.6928)  time: 0.3601  data: 0.1288  max mem: 3278
Epoch: [8]  [ 900/3494]  eta: 0:15:39  lr: 0.0010000  loss: 0.8072 (0.8563)  bbox_regression: 0.1464 (0.1598)  classification: 0.6343 (0.6965)  time: 0.3520  data: 0.1221  max mem: 3278
Epoch: [8]  [1000/3494]  eta: 0:15:04  lr: 0.0010000  loss: 0.8703 (0.8585)  bbox_regression: 0.1506 (0.1608)  classification: 0.7064 (0.6977)  time: 0.3737  data: 0.1372  max mem: 3278
Epoch: [8]  [1100/3494]  eta: 0:14:26  lr: 0.0010000  loss: 0.8017 (0.8567)  bbox_regression: 0.1578 (0.1603)  classification: 0.6533 (0.6963)  time: 0.3567  data: 0.1293  max mem: 3278
Epoch: [8]  [1200/3494]  eta: 0:13:49  lr: 0.0010000  loss: 0.8052 (0.8575)  bbox_regression: 0.1471 (0.1608)  classification: 0.6087 (0.6967)  time: 0.3636  data: 0.1301  max mem: 3278
Epoch: [8]  [1300/3494]  eta: 0:13:12  lr: 0.0010000  loss: 0.8223 (0.8577)  bbox_regression: 0.1386 (0.1606)  classification: 0.6782 (0.6970)  time: 0.3628  data: 0.1365  max mem: 3278
Epoch: [8]  [1400/3494]  eta: 0:12:35  lr: 0.0010000  loss: 0.8114 (0.8558)  bbox_regression: 0.1256 (0.1599)  classification: 0.6887 (0.6959)  time: 0.3528  data: 0.1262  max mem: 3278
Epoch: [8]  [1500/3494]  eta: 0:11:59  lr: 0.0010000  loss: 0.8711 (0.8570)  bbox_regression: 0.1561 (0.1603)  classification: 0.6909 (0.6967)  time: 0.3690  data: 0.1355  max mem: 3278
Epoch: [8]  [1600/3494]  eta: 0:11:22  lr: 0.0010000  loss: 0.7915 (0.8559)  bbox_regression: 0.1473 (0.1603)  classification: 0.6367 (0.6956)  time: 0.3325  data: 0.1147  max mem: 3278
Epoch: [8]  [1700/3494]  eta: 0:10:46  lr: 0.0010000  loss: 0.8143 (0.8575)  bbox_regression: 0.1533 (0.1605)  classification: 0.6618 (0.6970)  time: 0.3651  data: 0.1363  max mem: 3278
Epoch: [8]  [1800/3494]  eta: 0:10:10  lr: 0.0010000  loss: 0.8956 (0.8582)  bbox_regression: 0.1397 (0.1606)  classification: 0.7163 (0.6976)  time: 0.3678  data: 0.1312  max mem: 3278
Epoch: [8]  [1900/3494]  eta: 0:09:33  lr: 0.0010000  loss: 0.8243 (0.8574)  bbox_regression: 0.1420 (0.1604)  classification: 0.6864 (0.6970)  time: 0.3613  data: 0.1309  max mem: 3278
Epoch: [8]  [2000/3494]  eta: 0:08:57  lr: 0.0010000  loss: 0.7721 (0.8591)  bbox_regression: 0.1394 (0.1605)  classification: 0.6347 (0.6986)  time: 0.3575  data: 0.1297  max mem: 3278
Epoch: [8]  [2100/3494]  eta: 0:08:21  lr: 0.0010000  loss: 0.8347 (0.8620)  bbox_regression: 0.1542 (0.1610)  classification: 0.6685 (0.7010)  time: 0.3629  data: 0.1276  max mem: 3278
Epoch: [8]  [2200/3494]  eta: 0:07:45  lr: 0.0010000  loss: 0.9273 (0.8629)  bbox_regression: 0.1944 (0.1615)  classification: 0.7262 (0.7014)  time: 0.3609  data: 0.1305  max mem: 3278
Epoch: [8]  [2300/3494]  eta: 0:07:09  lr: 0.0010000  loss: 0.8683 (0.8630)  bbox_regression: 0.1550 (0.1617)  classification: 0.6710 (0.7013)  time: 0.3623  data: 0.1295  max mem: 3278
Epoch: [8]  [2400/3494]  eta: 0:06:33  lr: 0.0010000  loss: 0.8538 (0.8637)  bbox_regression: 0.1393 (0.1617)  classification: 0.7082 (0.7020)  time: 0.3538  data: 0.1259  max mem: 3278
Epoch: [8]  [2500/3494]  eta: 0:05:57  lr: 0.0010000  loss: 0.8924 (0.8643)  bbox_regression: 0.1456 (0.1618)  classification: 0.7314 (0.7025)  time: 0.3633  data: 0.1321  max mem: 3278
Epoch: [8]  [2600/3494]  eta: 0:05:21  lr: 0.0010000  loss: 0.8197 (0.8651)  bbox_regression: 0.1312 (0.1617)  classification: 0.7032 (0.7034)  time: 0.3554  data: 0.1231  max mem: 3278
Epoch: [8]  [2700/3494]  eta: 0:04:45  lr: 0.0010000  loss: 0.7641 (0.8646)  bbox_regression: 0.1429 (0.1617)  classification: 0.6535 (0.7030)  time: 0.3331  data: 0.1133  max mem: 3278
Epoch: [8]  [2800/3494]  eta: 0:04:09  lr: 0.0010000  loss: 0.8541 (0.8638)  bbox_regression: 0.1742 (0.1614)  classification: 0.6801 (0.7024)  time: 0.3578  data: 0.1275  max mem: 3278
Epoch: [8]  [2900/3494]  eta: 0:03:33  lr: 0.0010000  loss: 0.8794 (0.8642)  bbox_regression: 0.1520 (0.1615)  classification: 0.7219 (0.7026)  time: 0.3520  data: 0.1250  max mem: 3278
Epoch: [8]  [3000/3494]  eta: 0:02:57  lr: 0.0010000  loss: 0.8187 (0.8643)  bbox_regression: 0.1462 (0.1617)  classification: 0.6593 (0.7027)  time: 0.3523  data: 0.1243  max mem: 3278
Epoch: [8]  [3100/3494]  eta: 0:02:21  lr: 0.0010000  loss: 0.7725 (0.8636)  bbox_regression: 0.1514 (0.1615)  classification: 0.6090 (0.7021)  time: 0.3668  data: 0.1369  max mem: 3278
Epoch: [8]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.7897 (0.8634)  bbox_regression: 0.1397 (0.1614)  classification: 0.6378 (0.7020)  time: 0.3619  data: 0.1294  max mem: 3278
Epoch: [8]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.7993 (0.8641)  bbox_regression: 0.1606 (0.1617)  classification: 0.6175 (0.7024)  time: 0.3496  data: 0.1247  max mem: 3278
Epoch: [8]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 0.8795 (0.8631)  bbox_regression: 0.1734 (0.1614)  classification: 0.7037 (0.7017)  time: 0.3638  data: 0.1304  max mem: 3278
Epoch: [8]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.8230 (0.8631)  bbox_regression: 0.1543 (0.1613)  classification: 0.6615 (0.7018)  time: 0.3605  data: 0.1285  max mem: 3278
Epoch: [8] Total time: 0:21:06 (0.3624 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:09:58  model_time: 0.1533 (0.1533)  loss: 1.0741 (1.0741)  bbox_regression: 0.1614 (0.1614)  classification: 0.9127 (0.9127)  time: 1.3685  data: 1.1799  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1168 (0.1246)  loss: 0.9524 (0.9982)  bbox_regression: 0.1997 (0.1932)  classification: 0.7314 (0.8050)  time: 0.2616  data: 0.1264  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1189 (0.1218)  loss: 0.9379 (0.9634)  bbox_regression: 0.1676 (0.1833)  classification: 0.7289 (0.7801)  time: 0.2740  data: 0.1353  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1184 (0.1220)  loss: 0.9576 (0.9638)  bbox_regression: 0.1694 (0.1813)  classification: 0.7787 (0.7825)  time: 0.2696  data: 0.1282  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1180 (0.1217)  loss: 0.9131 (0.9611)  bbox_regression: 0.1649 (0.1810)  classification: 0.7052 (0.7802)  time: 0.2595  data: 0.1231  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1182 (0.1216)  loss: 0.8753 (0.9624)  bbox_regression: 0.1564 (0.1809)  classification: 0.7118 (0.7815)  time: 0.2632  data: 0.1225  max mem: 3278
Validation: Total time: 0:01:56 (0.2659 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [9]  [   0/3494]  eta: 1:55:36  lr: 0.0010000  loss: 0.9945 (0.9945)  bbox_regression: 0.1803 (0.1803)  classification: 0.8142 (0.8142)  time: 1.9853  data: 1.7437  max mem: 3278
Epoch: [9]  [ 100/3494]  eta: 0:21:40  lr: 0.0010000  loss: 0.7611 (0.8410)  bbox_regression: 0.1599 (0.1539)  classification: 0.6388 (0.6871)  time: 0.3615  data: 0.1292  max mem: 3278
Epoch: [9]  [ 200/3494]  eta: 0:20:16  lr: 0.0010000  loss: 0.8273 (0.8317)  bbox_regression: 0.1514 (0.1540)  classification: 0.6721 (0.6776)  time: 0.3305  data: 0.1163  max mem: 3278
Epoch: [9]  [ 300/3494]  eta: 0:19:23  lr: 0.0010000  loss: 0.7600 (0.8412)  bbox_regression: 0.1339 (0.1558)  classification: 0.6345 (0.6854)  time: 0.3545  data: 0.1242  max mem: 3278
Epoch: [9]  [ 400/3494]  eta: 0:18:40  lr: 0.0010000  loss: 0.7626 (0.8411)  bbox_regression: 0.1527 (0.1583)  classification: 0.6260 (0.6828)  time: 0.3610  data: 0.1288  max mem: 3278
Epoch: [9]  [ 500/3494]  eta: 0:17:59  lr: 0.0010000  loss: 0.8320 (0.8404)  bbox_regression: 0.1524 (0.1575)  classification: 0.7091 (0.6829)  time: 0.3575  data: 0.1250  max mem: 3278
Epoch: [9]  [ 600/3494]  eta: 0:17:25  lr: 0.0010000  loss: 0.8046 (0.8351)  bbox_regression: 0.1529 (0.1565)  classification: 0.6577 (0.6786)  time: 0.3680  data: 0.1313  max mem: 3278
Epoch: [9]  [ 700/3494]  eta: 0:16:47  lr: 0.0010000  loss: 0.8418 (0.8365)  bbox_regression: 0.1396 (0.1563)  classification: 0.6679 (0.6802)  time: 0.3644  data: 0.1305  max mem: 3278
Epoch: [9]  [ 800/3494]  eta: 0:16:10  lr: 0.0010000  loss: 0.7477 (0.8369)  bbox_regression: 0.1222 (0.1558)  classification: 0.6492 (0.6811)  time: 0.3627  data: 0.1334  max mem: 3278
Epoch: [9]  [ 900/3494]  eta: 0:15:35  lr: 0.0010000  loss: 0.8252 (0.8363)  bbox_regression: 0.1574 (0.1557)  classification: 0.6226 (0.6807)  time: 0.3754  data: 0.1348  max mem: 3278
Epoch: [9]  [1000/3494]  eta: 0:15:01  lr: 0.0010000  loss: 0.7541 (0.8349)  bbox_regression: 0.1274 (0.1551)  classification: 0.6400 (0.6798)  time: 0.3646  data: 0.1278  max mem: 3278
Epoch: [9]  [1100/3494]  eta: 0:14:23  lr: 0.0010000  loss: 0.8307 (0.8343)  bbox_regression: 0.1544 (0.1548)  classification: 0.6613 (0.6796)  time: 0.3554  data: 0.1254  max mem: 3278
Epoch: [9]  [1200/3494]  eta: 0:13:46  lr: 0.0010000  loss: 0.8525 (0.8361)  bbox_regression: 0.1536 (0.1553)  classification: 0.7004 (0.6808)  time: 0.3551  data: 0.1276  max mem: 3278
Epoch: [9]  [1300/3494]  eta: 0:13:09  lr: 0.0010000  loss: 0.7888 (0.8328)  bbox_regression: 0.1567 (0.1547)  classification: 0.6295 (0.6782)  time: 0.3539  data: 0.1279  max mem: 3278
Epoch: [9]  [1400/3494]  eta: 0:12:33  lr: 0.0010000  loss: 0.8648 (0.8333)  bbox_regression: 0.1504 (0.1548)  classification: 0.7045 (0.6785)  time: 0.3605  data: 0.1284  max mem: 3278
Epoch: [9]  [1500/3494]  eta: 0:11:57  lr: 0.0010000  loss: 0.7802 (0.8336)  bbox_regression: 0.1345 (0.1550)  classification: 0.6566 (0.6787)  time: 0.3647  data: 0.1302  max mem: 3278
Epoch: [9]  [1600/3494]  eta: 0:11:21  lr: 0.0010000  loss: 0.7428 (0.8342)  bbox_regression: 0.1265 (0.1551)  classification: 0.6284 (0.6791)  time: 0.3659  data: 0.1362  max mem: 3278
Epoch: [9]  [1700/3494]  eta: 0:10:46  lr: 0.0010000  loss: 0.7425 (0.8340)  bbox_regression: 0.1255 (0.1551)  classification: 0.6099 (0.6789)  time: 0.3650  data: 0.1314  max mem: 3278
Epoch: [9]  [1800/3494]  eta: 0:10:10  lr: 0.0010000  loss: 0.8847 (0.8342)  bbox_regression: 0.1610 (0.1553)  classification: 0.6868 (0.6789)  time: 0.3389  data: 0.1113  max mem: 3278
Epoch: [9]  [1900/3494]  eta: 0:09:34  lr: 0.0010000  loss: 0.7857 (0.8339)  bbox_regression: 0.1291 (0.1555)  classification: 0.6399 (0.6784)  time: 0.3642  data: 0.1301  max mem: 3278
Epoch: [9]  [2000/3494]  eta: 0:08:58  lr: 0.0010000  loss: 0.8464 (0.8322)  bbox_regression: 0.1575 (0.1551)  classification: 0.6697 (0.6770)  time: 0.3619  data: 0.1307  max mem: 3278
Epoch: [9]  [2100/3494]  eta: 0:08:22  lr: 0.0010000  loss: 0.7962 (0.8325)  bbox_regression: 0.1471 (0.1552)  classification: 0.6457 (0.6773)  time: 0.3682  data: 0.1304  max mem: 3278
Epoch: [9]  [2200/3494]  eta: 0:07:46  lr: 0.0010000  loss: 0.9020 (0.8342)  bbox_regression: 0.1588 (0.1555)  classification: 0.7644 (0.6787)  time: 0.3650  data: 0.1360  max mem: 3278
Epoch: [9]  [2300/3494]  eta: 0:07:10  lr: 0.0010000  loss: 0.8540 (0.8354)  bbox_regression: 0.1429 (0.1558)  classification: 0.7125 (0.6796)  time: 0.3623  data: 0.1294  max mem: 3278
Epoch: [9]  [2400/3494]  eta: 0:06:34  lr: 0.0010000  loss: 0.7755 (0.8374)  bbox_regression: 0.1551 (0.1563)  classification: 0.6486 (0.6811)  time: 0.3512  data: 0.1246  max mem: 3278
Epoch: [9]  [2500/3494]  eta: 0:05:58  lr: 0.0010000  loss: 0.7681 (0.8377)  bbox_regression: 0.1390 (0.1563)  classification: 0.6275 (0.6814)  time: 0.3680  data: 0.1333  max mem: 3278
Epoch: [9]  [2600/3494]  eta: 0:05:22  lr: 0.0010000  loss: 0.8199 (0.8373)  bbox_regression: 0.1570 (0.1561)  classification: 0.6423 (0.6812)  time: 0.3393  data: 0.1089  max mem: 3278
Epoch: [9]  [2700/3494]  eta: 0:04:46  lr: 0.0010000  loss: 0.7714 (0.8365)  bbox_regression: 0.1373 (0.1560)  classification: 0.6279 (0.6805)  time: 0.3694  data: 0.1342  max mem: 3278
Epoch: [9]  [2800/3494]  eta: 0:04:10  lr: 0.0010000  loss: 0.8457 (0.8362)  bbox_regression: 0.1478 (0.1558)  classification: 0.6868 (0.6804)  time: 0.3490  data: 0.1209  max mem: 3278
Epoch: [9]  [2900/3494]  eta: 0:03:34  lr: 0.0010000  loss: 0.8345 (0.8375)  bbox_regression: 0.1501 (0.1558)  classification: 0.6759 (0.6816)  time: 0.3653  data: 0.1311  max mem: 3278
Epoch: [9]  [3000/3494]  eta: 0:02:58  lr: 0.0010000  loss: 0.7683 (0.8377)  bbox_regression: 0.1311 (0.1559)  classification: 0.6456 (0.6819)  time: 0.3639  data: 0.1284  max mem: 3278
Epoch: [9]  [3100/3494]  eta: 0:02:22  lr: 0.0010000  loss: 0.7864 (0.8379)  bbox_regression: 0.1429 (0.1557)  classification: 0.6511 (0.6822)  time: 0.3569  data: 0.1254  max mem: 3278
Epoch: [9]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.7742 (0.8378)  bbox_regression: 0.1367 (0.1557)  classification: 0.6375 (0.6822)  time: 0.3596  data: 0.1263  max mem: 3278
Epoch: [9]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.8190 (0.8386)  bbox_regression: 0.1614 (0.1558)  classification: 0.6554 (0.6828)  time: 0.3605  data: 0.1274  max mem: 3278
Epoch: [9]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 0.8087 (0.8395)  bbox_regression: 0.1378 (0.1560)  classification: 0.6444 (0.6835)  time: 0.3528  data: 0.1278  max mem: 3278
Epoch: [9]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.8990 (0.8401)  bbox_regression: 0.1446 (0.1562)  classification: 0.7256 (0.6840)  time: 0.3551  data: 0.1279  max mem: 3278
Epoch: [9] Total time: 0:21:09 (0.3634 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:26  model_time: 0.1406 (0.1406)  loss: 1.1250 (1.1250)  bbox_regression: 0.1576 (0.1576)  classification: 0.9674 (0.9674)  time: 1.8446  data: 1.6839  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1159 (0.1234)  loss: 0.9785 (0.9948)  bbox_regression: 0.1908 (0.1936)  classification: 0.7412 (0.8012)  time: 0.2569  data: 0.1202  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1156 (0.1223)  loss: 0.8676 (0.9588)  bbox_regression: 0.1668 (0.1841)  classification: 0.7067 (0.7747)  time: 0.2625  data: 0.1249  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1227 (0.1228)  loss: 0.9697 (0.9566)  bbox_regression: 0.1656 (0.1809)  classification: 0.7908 (0.7757)  time: 0.2692  data: 0.1275  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1158 (0.1232)  loss: 0.9358 (0.9516)  bbox_regression: 0.1601 (0.1807)  classification: 0.7122 (0.7710)  time: 0.2591  data: 0.1231  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1271 (0.1232)  loss: 0.9079 (0.9518)  bbox_regression: 0.1504 (0.1806)  classification: 0.7026 (0.7712)  time: 0.2649  data: 0.1211  max mem: 3278
Validation: Total time: 0:01:57 (0.2699 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [10]  [   0/3494]  eta: 1:51:57  lr: 0.0010000  loss: 0.8120 (0.8120)  bbox_regression: 0.1795 (0.1795)  classification: 0.6324 (0.6324)  time: 1.9226  data: 1.6094  max mem: 3278
Epoch: [10]  [ 100/3494]  eta: 0:20:19  lr: 0.0010000  loss: 0.7590 (0.8047)  bbox_regression: 0.1312 (0.1515)  classification: 0.6179 (0.6531)  time: 0.3543  data: 0.1255  max mem: 3278
Epoch: [10]  [ 200/3494]  eta: 0:19:45  lr: 0.0010000  loss: 0.7228 (0.7946)  bbox_regression: 0.1248 (0.1492)  classification: 0.6067 (0.6454)  time: 0.3736  data: 0.1434  max mem: 3278
Epoch: [10]  [ 300/3494]  eta: 0:19:04  lr: 0.0010000  loss: 0.7585 (0.7970)  bbox_regression: 0.1372 (0.1472)  classification: 0.6499 (0.6498)  time: 0.3545  data: 0.1260  max mem: 3278
Epoch: [10]  [ 400/3494]  eta: 0:18:22  lr: 0.0010000  loss: 0.7397 (0.7980)  bbox_regression: 0.1301 (0.1474)  classification: 0.6130 (0.6505)  time: 0.3690  data: 0.1354  max mem: 3278
Epoch: [10]  [ 500/3494]  eta: 0:17:50  lr: 0.0010000  loss: 0.7539 (0.8024)  bbox_regression: 0.1315 (0.1483)  classification: 0.6116 (0.6541)  time: 0.3544  data: 0.1282  max mem: 3278
Epoch: [10]  [ 600/3494]  eta: 0:17:16  lr: 0.0010000  loss: 0.7163 (0.7991)  bbox_regression: 0.1237 (0.1474)  classification: 0.5707 (0.6517)  time: 0.3567  data: 0.1279  max mem: 3278
Epoch: [10]  [ 700/3494]  eta: 0:16:36  lr: 0.0010000  loss: 0.7736 (0.8015)  bbox_regression: 0.1344 (0.1474)  classification: 0.6299 (0.6542)  time: 0.3530  data: 0.1244  max mem: 3278
Epoch: [10]  [ 800/3494]  eta: 0:16:01  lr: 0.0010000  loss: 0.7560 (0.8055)  bbox_regression: 0.1329 (0.1477)  classification: 0.6170 (0.6578)  time: 0.3647  data: 0.1335  max mem: 3278
Epoch: [10]  [ 900/3494]  eta: 0:15:24  lr: 0.0010000  loss: 0.7577 (0.8065)  bbox_regression: 0.1403 (0.1482)  classification: 0.6047 (0.6582)  time: 0.3209  data: 0.1054  max mem: 3278
Epoch: [10]  [1000/3494]  eta: 0:14:49  lr: 0.0010000  loss: 0.7539 (0.8062)  bbox_regression: 0.1452 (0.1488)  classification: 0.6078 (0.6573)  time: 0.3651  data: 0.1318  max mem: 3278
Epoch: [10]  [1100/3494]  eta: 0:14:15  lr: 0.0010000  loss: 0.8046 (0.8077)  bbox_regression: 0.1545 (0.1494)  classification: 0.6620 (0.6583)  time: 0.3624  data: 0.1280  max mem: 3278
Epoch: [10]  [1200/3494]  eta: 0:13:39  lr: 0.0010000  loss: 0.7879 (0.8082)  bbox_regression: 0.1511 (0.1497)  classification: 0.6475 (0.6585)  time: 0.3698  data: 0.1331  max mem: 3278
Epoch: [10]  [1300/3494]  eta: 0:13:04  lr: 0.0010000  loss: 0.8481 (0.8109)  bbox_regression: 0.1254 (0.1501)  classification: 0.7009 (0.6608)  time: 0.3582  data: 0.1261  max mem: 3278
Epoch: [10]  [1400/3494]  eta: 0:12:30  lr: 0.0010000  loss: 0.8306 (0.8121)  bbox_regression: 0.1525 (0.1504)  classification: 0.6772 (0.6617)  time: 0.3649  data: 0.1278  max mem: 3278
Epoch: [10]  [1500/3494]  eta: 0:11:53  lr: 0.0010000  loss: 0.7616 (0.8117)  bbox_regression: 0.1330 (0.1502)  classification: 0.6365 (0.6616)  time: 0.3587  data: 0.1315  max mem: 3278
Epoch: [10]  [1600/3494]  eta: 0:11:18  lr: 0.0010000  loss: 0.8084 (0.8134)  bbox_regression: 0.1366 (0.1501)  classification: 0.6720 (0.6633)  time: 0.3541  data: 0.1267  max mem: 3278
Epoch: [10]  [1700/3494]  eta: 0:10:41  lr: 0.0010000  loss: 0.7655 (0.8140)  bbox_regression: 0.1448 (0.1503)  classification: 0.6419 (0.6637)  time: 0.3616  data: 0.1323  max mem: 3278
Epoch: [10]  [1800/3494]  eta: 0:10:05  lr: 0.0010000  loss: 0.8421 (0.8151)  bbox_regression: 0.1394 (0.1506)  classification: 0.6590 (0.6645)  time: 0.3629  data: 0.1272  max mem: 3278
Epoch: [10]  [1900/3494]  eta: 0:09:30  lr: 0.0010000  loss: 0.7073 (0.8127)  bbox_regression: 0.1259 (0.1498)  classification: 0.5736 (0.6629)  time: 0.3677  data: 0.1325  max mem: 3278
Epoch: [10]  [2000/3494]  eta: 0:08:54  lr: 0.0010000  loss: 0.8147 (0.8129)  bbox_regression: 0.1435 (0.1500)  classification: 0.6605 (0.6629)  time: 0.3502  data: 0.1243  max mem: 3278
Epoch: [10]  [2100/3494]  eta: 0:08:19  lr: 0.0010000  loss: 0.8106 (0.8146)  bbox_regression: 0.1393 (0.1502)  classification: 0.6864 (0.6644)  time: 0.3585  data: 0.1295  max mem: 3278
Epoch: [10]  [2200/3494]  eta: 0:07:43  lr: 0.0010000  loss: 0.7817 (0.8148)  bbox_regression: 0.1539 (0.1504)  classification: 0.6410 (0.6644)  time: 0.3643  data: 0.1294  max mem: 3278
Epoch: [10]  [2300/3494]  eta: 0:07:08  lr: 0.0010000  loss: 0.7802 (0.8164)  bbox_regression: 0.1246 (0.1508)  classification: 0.6430 (0.6656)  time: 0.3614  data: 0.1300  max mem: 3278
Epoch: [10]  [2400/3494]  eta: 0:06:32  lr: 0.0010000  loss: 0.8262 (0.8152)  bbox_regression: 0.1366 (0.1506)  classification: 0.6771 (0.6646)  time: 0.3787  data: 0.1355  max mem: 3278
Epoch: [10]  [2500/3494]  eta: 0:05:56  lr: 0.0010000  loss: 0.7851 (0.8154)  bbox_regression: 0.1356 (0.1505)  classification: 0.6531 (0.6649)  time: 0.3551  data: 0.1245  max mem: 3278
Epoch: [10]  [2600/3494]  eta: 0:05:21  lr: 0.0010000  loss: 0.7916 (0.8151)  bbox_regression: 0.1364 (0.1504)  classification: 0.6510 (0.6647)  time: 0.3486  data: 0.1231  max mem: 3278
Epoch: [10]  [2700/3494]  eta: 0:04:45  lr: 0.0010000  loss: 0.7778 (0.8150)  bbox_regression: 0.1266 (0.1506)  classification: 0.6512 (0.6644)  time: 0.3590  data: 0.1323  max mem: 3278
Epoch: [10]  [2800/3494]  eta: 0:04:09  lr: 0.0010000  loss: 0.8351 (0.8160)  bbox_regression: 0.1528 (0.1505)  classification: 0.6803 (0.6655)  time: 0.3465  data: 0.1197  max mem: 3278
Epoch: [10]  [2900/3494]  eta: 0:03:33  lr: 0.0010000  loss: 0.7495 (0.8156)  bbox_regression: 0.1412 (0.1504)  classification: 0.6144 (0.6652)  time: 0.3461  data: 0.1224  max mem: 3278
Epoch: [10]  [3000/3494]  eta: 0:02:57  lr: 0.0010000  loss: 0.7899 (0.8159)  bbox_regression: 0.1393 (0.1504)  classification: 0.6377 (0.6655)  time: 0.3612  data: 0.1333  max mem: 3278
Epoch: [10]  [3100/3494]  eta: 0:02:21  lr: 0.0010000  loss: 0.7571 (0.8163)  bbox_regression: 0.1378 (0.1508)  classification: 0.6068 (0.6655)  time: 0.3549  data: 0.1234  max mem: 3278
Epoch: [10]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.7767 (0.8157)  bbox_regression: 0.1374 (0.1506)  classification: 0.6385 (0.6650)  time: 0.3660  data: 0.1357  max mem: 3278
Epoch: [10]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.7932 (0.8159)  bbox_regression: 0.1471 (0.1505)  classification: 0.6518 (0.6653)  time: 0.3594  data: 0.1254  max mem: 3278
Epoch: [10]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 0.8239 (0.8159)  bbox_regression: 0.1589 (0.1506)  classification: 0.6543 (0.6654)  time: 0.3606  data: 0.1290  max mem: 3278
Epoch: [10]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.7255 (0.8159)  bbox_regression: 0.1438 (0.1506)  classification: 0.6089 (0.6652)  time: 0.3608  data: 0.1268  max mem: 3278
Epoch: [10] Total time: 0:21:04 (0.3619 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:25  model_time: 0.1358 (0.1358)  loss: 1.0297 (1.0297)  bbox_regression: 0.1268 (0.1268)  classification: 0.9029 (0.9029)  time: 2.2550  data: 2.0954  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1138 (0.1196)  loss: 0.8941 (0.9846)  bbox_regression: 0.2034 (0.1915)  classification: 0.7254 (0.7931)  time: 0.2517  data: 0.1178  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1172 (0.1202)  loss: 0.9328 (0.9503)  bbox_regression: 0.1643 (0.1802)  classification: 0.7365 (0.7701)  time: 0.2741  data: 0.1362  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1217 (0.1213)  loss: 0.9333 (0.9466)  bbox_regression: 0.1608 (0.1766)  classification: 0.7803 (0.7700)  time: 0.2677  data: 0.1267  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1165 (0.1215)  loss: 0.8707 (0.9438)  bbox_regression: 0.1666 (0.1766)  classification: 0.7041 (0.7672)  time: 0.2609  data: 0.1222  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1178 (0.1213)  loss: 0.8716 (0.9434)  bbox_regression: 0.1484 (0.1767)  classification: 0.7279 (0.7667)  time: 0.2558  data: 0.1196  max mem: 3278
Validation: Total time: 0:01:56 (0.2666 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [11]  [   0/3494]  eta: 2:14:29  lr: 0.0010000  loss: 0.5247 (0.5247)  bbox_regression: 0.1011 (0.1011)  classification: 0.4236 (0.4236)  time: 2.3097  data: 2.0345  max mem: 3278
Epoch: [11]  [ 100/3494]  eta: 0:21:15  lr: 0.0010000  loss: 0.7790 (0.7653)  bbox_regression: 0.1363 (0.1444)  classification: 0.6201 (0.6209)  time: 0.3683  data: 0.1340  max mem: 3278
Epoch: [11]  [ 200/3494]  eta: 0:20:09  lr: 0.0010000  loss: 0.7969 (0.7869)  bbox_regression: 0.1362 (0.1483)  classification: 0.6618 (0.6386)  time: 0.3579  data: 0.1297  max mem: 3278
Epoch: [11]  [ 300/3494]  eta: 0:19:21  lr: 0.0010000  loss: 0.7803 (0.7839)  bbox_regression: 0.1224 (0.1467)  classification: 0.6517 (0.6372)  time: 0.3409  data: 0.1148  max mem: 3278
Epoch: [11]  [ 400/3494]  eta: 0:18:42  lr: 0.0010000  loss: 0.7962 (0.7885)  bbox_regression: 0.1576 (0.1470)  classification: 0.6117 (0.6415)  time: 0.3550  data: 0.1248  max mem: 3278
Epoch: [11]  [ 500/3494]  eta: 0:18:09  lr: 0.0010000  loss: 0.6998 (0.7871)  bbox_regression: 0.1209 (0.1469)  classification: 0.5945 (0.6402)  time: 0.3574  data: 0.1277  max mem: 3278
Epoch: [11]  [ 600/3494]  eta: 0:17:30  lr: 0.0010000  loss: 0.7859 (0.7942)  bbox_regression: 0.1408 (0.1479)  classification: 0.6404 (0.6463)  time: 0.3617  data: 0.1289  max mem: 3278
Epoch: [11]  [ 700/3494]  eta: 0:16:52  lr: 0.0010000  loss: 0.7440 (0.7899)  bbox_regression: 0.1190 (0.1468)  classification: 0.5954 (0.6431)  time: 0.3538  data: 0.1247  max mem: 3278
Epoch: [11]  [ 800/3494]  eta: 0:16:16  lr: 0.0010000  loss: 0.7133 (0.7894)  bbox_regression: 0.1306 (0.1464)  classification: 0.6195 (0.6430)  time: 0.3570  data: 0.1290  max mem: 3278
Epoch: [11]  [ 900/3494]  eta: 0:15:37  lr: 0.0010000  loss: 0.7640 (0.7910)  bbox_regression: 0.1366 (0.1468)  classification: 0.6340 (0.6442)  time: 0.3532  data: 0.1258  max mem: 3278
Epoch: [11]  [1000/3494]  eta: 0:15:01  lr: 0.0010000  loss: 0.7668 (0.7879)  bbox_regression: 0.1291 (0.1457)  classification: 0.6203 (0.6422)  time: 0.3654  data: 0.1343  max mem: 3278
Epoch: [11]  [1100/3494]  eta: 0:14:23  lr: 0.0010000  loss: 0.7696 (0.7887)  bbox_regression: 0.1321 (0.1455)  classification: 0.6370 (0.6432)  time: 0.3246  data: 0.1074  max mem: 3278
Epoch: [11]  [1200/3494]  eta: 0:13:47  lr: 0.0010000  loss: 0.9110 (0.7906)  bbox_regression: 0.1540 (0.1459)  classification: 0.7208 (0.6447)  time: 0.3568  data: 0.1277  max mem: 3278
Epoch: [11]  [1300/3494]  eta: 0:13:11  lr: 0.0010000  loss: 0.7400 (0.7922)  bbox_regression: 0.1324 (0.1460)  classification: 0.6034 (0.6462)  time: 0.3703  data: 0.1333  max mem: 3278
Epoch: [11]  [1400/3494]  eta: 0:12:35  lr: 0.0010000  loss: 0.7533 (0.7923)  bbox_regression: 0.1431 (0.1460)  classification: 0.5952 (0.6463)  time: 0.3607  data: 0.1274  max mem: 3278
Epoch: [11]  [1500/3494]  eta: 0:11:58  lr: 0.0010000  loss: 0.8045 (0.7961)  bbox_regression: 0.1517 (0.1467)  classification: 0.6562 (0.6493)  time: 0.3464  data: 0.1231  max mem: 3278
Epoch: [11]  [1600/3494]  eta: 0:11:23  lr: 0.0010000  loss: 0.8607 (0.7965)  bbox_regression: 0.1569 (0.1468)  classification: 0.6974 (0.6497)  time: 0.3551  data: 0.1265  max mem: 3278
Epoch: [11]  [1700/3494]  eta: 0:10:47  lr: 0.0010000  loss: 0.7262 (0.7964)  bbox_regression: 0.1318 (0.1468)  classification: 0.5856 (0.6496)  time: 0.3560  data: 0.1255  max mem: 3278
Epoch: [11]  [1800/3494]  eta: 0:10:11  lr: 0.0010000  loss: 0.7907 (0.7983)  bbox_regression: 0.1240 (0.1470)  classification: 0.6537 (0.6513)  time: 0.3634  data: 0.1318  max mem: 3278
Epoch: [11]  [1900/3494]  eta: 0:09:35  lr: 0.0010000  loss: 0.7643 (0.7977)  bbox_regression: 0.1379 (0.1468)  classification: 0.6221 (0.6509)  time: 0.3590  data: 0.1280  max mem: 3278
Epoch: [11]  [2000/3494]  eta: 0:08:59  lr: 0.0010000  loss: 0.7677 (0.7973)  bbox_regression: 0.1388 (0.1466)  classification: 0.6241 (0.6507)  time: 0.3629  data: 0.1278  max mem: 3278
Epoch: [11]  [2100/3494]  eta: 0:08:23  lr: 0.0010000  loss: 0.7821 (0.7977)  bbox_regression: 0.1484 (0.1466)  classification: 0.6526 (0.6511)  time: 0.3606  data: 0.1269  max mem: 3278
Epoch: [11]  [2200/3494]  eta: 0:07:47  lr: 0.0010000  loss: 0.7069 (0.7959)  bbox_regression: 0.1181 (0.1462)  classification: 0.5865 (0.6497)  time: 0.3761  data: 0.1350  max mem: 3278
Epoch: [11]  [2300/3494]  eta: 0:07:11  lr: 0.0010000  loss: 0.7105 (0.7959)  bbox_regression: 0.1346 (0.1463)  classification: 0.5917 (0.6495)  time: 0.3688  data: 0.1326  max mem: 3278
Epoch: [11]  [2400/3494]  eta: 0:06:35  lr: 0.0010000  loss: 0.8067 (0.7966)  bbox_regression: 0.1507 (0.1466)  classification: 0.6447 (0.6500)  time: 0.3646  data: 0.1332  max mem: 3278
Epoch: [11]  [2500/3494]  eta: 0:05:59  lr: 0.0010000  loss: 0.7615 (0.7965)  bbox_regression: 0.1437 (0.1468)  classification: 0.6237 (0.6497)  time: 0.3685  data: 0.1351  max mem: 3278
Epoch: [11]  [2600/3494]  eta: 0:05:23  lr: 0.0010000  loss: 0.8039 (0.7973)  bbox_regression: 0.1383 (0.1470)  classification: 0.6744 (0.6503)  time: 0.3682  data: 0.1343  max mem: 3278
Epoch: [11]  [2700/3494]  eta: 0:04:47  lr: 0.0010000  loss: 0.7836 (0.7972)  bbox_regression: 0.1343 (0.1467)  classification: 0.6461 (0.6505)  time: 0.3703  data: 0.1354  max mem: 3278
Epoch: [11]  [2800/3494]  eta: 0:04:11  lr: 0.0010000  loss: 0.8031 (0.7961)  bbox_regression: 0.1351 (0.1466)  classification: 0.6538 (0.6495)  time: 0.3533  data: 0.1235  max mem: 3278
Epoch: [11]  [2900/3494]  eta: 0:03:34  lr: 0.0010000  loss: 0.7950 (0.7965)  bbox_regression: 0.1434 (0.1465)  classification: 0.6446 (0.6500)  time: 0.3587  data: 0.1266  max mem: 3278
Epoch: [11]  [3000/3494]  eta: 0:02:58  lr: 0.0010000  loss: 0.7976 (0.7963)  bbox_regression: 0.1379 (0.1463)  classification: 0.6519 (0.6500)  time: 0.3593  data: 0.1354  max mem: 3278
Epoch: [11]  [3100/3494]  eta: 0:02:22  lr: 0.0010000  loss: 0.8337 (0.7969)  bbox_regression: 0.1525 (0.1465)  classification: 0.6774 (0.6503)  time: 0.3678  data: 0.1362  max mem: 3278
Epoch: [11]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 0.8057 (0.7975)  bbox_regression: 0.1273 (0.1466)  classification: 0.6433 (0.6509)  time: 0.3698  data: 0.1305  max mem: 3278
Epoch: [11]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 0.7234 (0.7977)  bbox_regression: 0.1354 (0.1467)  classification: 0.5880 (0.6510)  time: 0.3691  data: 0.1350  max mem: 3278
Epoch: [11]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 0.7995 (0.7981)  bbox_regression: 0.1331 (0.1466)  classification: 0.6589 (0.6515)  time: 0.3397  data: 0.1153  max mem: 3278
Epoch: [11]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.7331 (0.7992)  bbox_regression: 0.1329 (0.1468)  classification: 0.6091 (0.6525)  time: 0.3655  data: 0.1345  max mem: 3278
Epoch: [11] Total time: 0:21:14 (0.3647 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:54  model_time: 0.1455 (0.1455)  loss: 1.2240 (1.2240)  bbox_regression: 0.1638 (0.1638)  classification: 1.0602 (1.0602)  time: 2.0477  data: 1.8598  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1249 (0.1237)  loss: 0.9655 (1.0098)  bbox_regression: 0.1993 (0.1998)  classification: 0.7531 (0.8101)  time: 0.2725  data: 0.1286  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1156 (0.1228)  loss: 0.8744 (0.9758)  bbox_regression: 0.1788 (0.1895)  classification: 0.7064 (0.7863)  time: 0.2598  data: 0.1235  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1199 (0.1226)  loss: 0.9335 (0.9712)  bbox_regression: 0.1731 (0.1851)  classification: 0.7778 (0.7861)  time: 0.2663  data: 0.1238  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1259 (0.1230)  loss: 0.8695 (0.9661)  bbox_regression: 0.1808 (0.1851)  classification: 0.7066 (0.7810)  time: 0.2731  data: 0.1271  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1165 (0.1226)  loss: 0.8851 (0.9660)  bbox_regression: 0.1687 (0.1850)  classification: 0.7574 (0.7810)  time: 0.2547  data: 0.1218  max mem: 3278
Validation: Total time: 0:01:58 (0.2700 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [12]  [   0/3494]  eta: 2:22:20  lr: 0.0010000  loss: 1.4922 (1.4922)  bbox_regression: 0.2184 (0.2184)  classification: 1.2739 (1.2739)  time: 2.4443  data: 2.1961  max mem: 3278
Epoch: [12]  [ 100/3494]  eta: 0:21:45  lr: 0.0010000  loss: 0.7671 (0.7825)  bbox_regression: 0.1306 (0.1398)  classification: 0.6533 (0.6427)  time: 0.3573  data: 0.1260  max mem: 3278
Epoch: [12]  [ 200/3494]  eta: 0:20:26  lr: 0.0010000  loss: 0.7360 (0.7826)  bbox_regression: 0.1228 (0.1429)  classification: 0.5931 (0.6397)  time: 0.3713  data: 0.1352  max mem: 3278
Epoch: [12]  [ 300/3494]  eta: 0:19:39  lr: 0.0010000  loss: 0.7073 (0.7782)  bbox_regression: 0.1321 (0.1405)  classification: 0.5877 (0.6377)  time: 0.3657  data: 0.1326  max mem: 3278
Epoch: [12]  [ 400/3494]  eta: 0:18:54  lr: 0.0010000  loss: 0.7110 (0.7763)  bbox_regression: 0.1200 (0.1414)  classification: 0.5868 (0.6349)  time: 0.3420  data: 0.1201  max mem: 3278
Epoch: [12]  [ 500/3494]  eta: 0:18:14  lr: 0.0010000  loss: 0.7730 (0.7764)  bbox_regression: 0.1307 (0.1418)  classification: 0.6204 (0.6346)  time: 0.3469  data: 0.1166  max mem: 3278
Epoch: [12]  [ 600/3494]  eta: 0:17:36  lr: 0.0010000  loss: 0.7562 (0.7814)  bbox_regression: 0.1372 (0.1425)  classification: 0.6240 (0.6389)  time: 0.3589  data: 0.1256  max mem: 3278
Epoch: [12]  [ 700/3494]  eta: 0:16:59  lr: 0.0010000  loss: 0.7412 (0.7787)  bbox_regression: 0.1369 (0.1424)  classification: 0.6185 (0.6363)  time: 0.3653  data: 0.1322  max mem: 3278
Epoch: [12]  [ 800/3494]  eta: 0:16:20  lr: 0.0010000  loss: 0.7148 (0.7811)  bbox_regression: 0.1274 (0.1433)  classification: 0.5855 (0.6378)  time: 0.3556  data: 0.1295  max mem: 3278
Epoch: [12]  [ 900/3494]  eta: 0:15:43  lr: 0.0010000  loss: 0.7586 (0.7822)  bbox_regression: 0.1388 (0.1433)  classification: 0.6373 (0.6388)  time: 0.3604  data: 0.1283  max mem: 3278
Epoch: [12]  [1000/3494]  eta: 0:15:06  lr: 0.0010000  loss: 0.7387 (0.7811)  bbox_regression: 0.1234 (0.1431)  classification: 0.6149 (0.6379)  time: 0.3684  data: 0.1381  max mem: 3278
Epoch: [12]  [1100/3494]  eta: 0:14:29  lr: 0.0010000  loss: 0.6983 (0.7790)  bbox_regression: 0.1287 (0.1430)  classification: 0.5645 (0.6360)  time: 0.3587  data: 0.1272  max mem: 3278
Epoch: [12]  [1200/3494]  eta: 0:13:52  lr: 0.0010000  loss: 0.8235 (0.7788)  bbox_regression: 0.1274 (0.1429)  classification: 0.6855 (0.6360)  time: 0.3656  data: 0.1292  max mem: 3278
Epoch: [12]  [1300/3494]  eta: 0:13:16  lr: 0.0010000  loss: 0.7074 (0.7790)  bbox_regression: 0.1289 (0.1427)  classification: 0.6065 (0.6363)  time: 0.3647  data: 0.1276  max mem: 3278
Epoch: [12]  [1400/3494]  eta: 0:12:39  lr: 0.0010000  loss: 0.7782 (0.7804)  bbox_regression: 0.1323 (0.1430)  classification: 0.6226 (0.6373)  time: 0.3780  data: 0.1373  max mem: 3278
Epoch: [12]  [1500/3494]  eta: 0:12:04  lr: 0.0010000  loss: 0.8094 (0.7795)  bbox_regression: 0.1265 (0.1431)  classification: 0.6680 (0.6364)  time: 0.3682  data: 0.1296  max mem: 3278
Epoch: [12]  [1600/3494]  eta: 0:11:27  lr: 0.0010000  loss: 0.8067 (0.7793)  bbox_regression: 0.1402 (0.1427)  classification: 0.6802 (0.6365)  time: 0.3664  data: 0.1305  max mem: 3278
Epoch: [12]  [1700/3494]  eta: 0:10:51  lr: 0.0010000  loss: 0.7402 (0.7794)  bbox_regression: 0.1379 (0.1431)  classification: 0.6034 (0.6363)  time: 0.3672  data: 0.1301  max mem: 3278
Epoch: [12]  [1800/3494]  eta: 0:10:14  lr: 0.0010000  loss: 0.7130 (0.7794)  bbox_regression: 0.1266 (0.1431)  classification: 0.6081 (0.6362)  time: 0.3610  data: 0.1297  max mem: 3278
Epoch: [12]  [1900/3494]  eta: 0:09:38  lr: 0.0010000  loss: 0.7873 (0.7806)  bbox_regression: 0.1407 (0.1436)  classification: 0.6523 (0.6370)  time: 0.3537  data: 0.1252  max mem: 3278
Epoch: [12]  [2000/3494]  eta: 0:09:02  lr: 0.0010000  loss: 0.7677 (0.7790)  bbox_regression: 0.1277 (0.1431)  classification: 0.6380 (0.6360)  time: 0.3687  data: 0.1327  max mem: 3278
Epoch: [12]  [2100/3494]  eta: 0:08:25  lr: 0.0010000  loss: 0.6748 (0.7779)  bbox_regression: 0.1238 (0.1427)  classification: 0.5358 (0.6352)  time: 0.3601  data: 0.1293  max mem: 3278
Epoch: [12]  [2200/3494]  eta: 0:07:49  lr: 0.0010000  loss: 0.7922 (0.7786)  bbox_regression: 0.1334 (0.1428)  classification: 0.6565 (0.6358)  time: 0.3583  data: 0.1282  max mem: 3278
Epoch: [12]  [2300/3494]  eta: 0:07:13  lr: 0.0010000  loss: 0.7632 (0.7788)  bbox_regression: 0.1523 (0.1431)  classification: 0.6060 (0.6356)  time: 0.3558  data: 0.1271  max mem: 3278
Epoch: [12]  [2400/3494]  eta: 0:06:36  lr: 0.0010000  loss: 0.8209 (0.7798)  bbox_regression: 0.1280 (0.1433)  classification: 0.6903 (0.6365)  time: 0.3514  data: 0.1197  max mem: 3278
Epoch: [12]  [2500/3494]  eta: 0:06:00  lr: 0.0010000  loss: 0.7287 (0.7806)  bbox_regression: 0.1263 (0.1432)  classification: 0.6124 (0.6374)  time: 0.3652  data: 0.1314  max mem: 3278
Epoch: [12]  [2600/3494]  eta: 0:05:24  lr: 0.0010000  loss: 0.7664 (0.7805)  bbox_regression: 0.1266 (0.1432)  classification: 0.6394 (0.6373)  time: 0.3763  data: 0.1403  max mem: 3278
Epoch: [12]  [2700/3494]  eta: 0:04:48  lr: 0.0010000  loss: 0.7652 (0.7808)  bbox_regression: 0.1344 (0.1431)  classification: 0.6335 (0.6377)  time: 0.3485  data: 0.1175  max mem: 3278
Epoch: [12]  [2800/3494]  eta: 0:04:11  lr: 0.0010000  loss: 0.7936 (0.7811)  bbox_regression: 0.1417 (0.1431)  classification: 0.6415 (0.6380)  time: 0.3662  data: 0.1289  max mem: 3278
Epoch: [12]  [2900/3494]  eta: 0:03:35  lr: 0.0010000  loss: 0.7356 (0.7813)  bbox_regression: 0.1389 (0.1431)  classification: 0.6118 (0.6382)  time: 0.3527  data: 0.1249  max mem: 3278
Epoch: [12]  [3000/3494]  eta: 0:02:59  lr: 0.0010000  loss: 0.7382 (0.7818)  bbox_regression: 0.1468 (0.1432)  classification: 0.5905 (0.6386)  time: 0.3472  data: 0.1206  max mem: 3278
Epoch: [12]  [3100/3494]  eta: 0:02:22  lr: 0.0010000  loss: 0.7753 (0.7818)  bbox_regression: 0.1282 (0.1432)  classification: 0.6465 (0.6386)  time: 0.3582  data: 0.1280  max mem: 3278
Epoch: [12]  [3200/3494]  eta: 0:01:46  lr: 0.0010000  loss: 0.7390 (0.7824)  bbox_regression: 0.1385 (0.1434)  classification: 0.6053 (0.6391)  time: 0.3699  data: 0.1349  max mem: 3278
Epoch: [12]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 0.7118 (0.7820)  bbox_regression: 0.1125 (0.1433)  classification: 0.5848 (0.6387)  time: 0.3638  data: 0.1292  max mem: 3278
Epoch: [12]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 0.7293 (0.7823)  bbox_regression: 0.1351 (0.1433)  classification: 0.6088 (0.6390)  time: 0.3598  data: 0.1313  max mem: 3278
Epoch: [12]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.7670 (0.7826)  bbox_regression: 0.1391 (0.1433)  classification: 0.6279 (0.6393)  time: 0.3594  data: 0.1277  max mem: 3278
Epoch: [12] Total time: 0:21:16 (0.3654 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:54  model_time: 0.1419 (0.1419)  loss: 1.1125 (1.1125)  bbox_regression: 0.1310 (0.1310)  classification: 0.9815 (0.9815)  time: 2.3208  data: 2.1582  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1231 (0.1222)  loss: 0.8890 (0.9741)  bbox_regression: 0.1872 (0.1815)  classification: 0.6979 (0.7926)  time: 0.2669  data: 0.1257  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1243 (0.1226)  loss: 0.8649 (0.9408)  bbox_regression: 0.1759 (0.1729)  classification: 0.7028 (0.7679)  time: 0.2688  data: 0.1253  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1162 (0.1222)  loss: 0.9953 (0.9452)  bbox_regression: 0.1675 (0.1703)  classification: 0.8379 (0.7749)  time: 0.2586  data: 0.1229  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1228 (0.1227)  loss: 0.8493 (0.9400)  bbox_regression: 0.1630 (0.1698)  classification: 0.6682 (0.7702)  time: 0.2670  data: 0.1249  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1163 (0.1225)  loss: 0.8647 (0.9410)  bbox_regression: 0.1397 (0.1700)  classification: 0.7359 (0.7710)  time: 0.2551  data: 0.1210  max mem: 3278
Validation: Total time: 0:01:57 (0.2693 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [13]  [   0/3494]  eta: 2:01:29  lr: 0.0010000  loss: 0.5906 (0.5906)  bbox_regression: 0.1300 (0.1300)  classification: 0.4606 (0.4606)  time: 2.0862  data: 1.8264  max mem: 3278
Epoch: [13]  [ 100/3494]  eta: 0:21:40  lr: 0.0010000  loss: 0.6814 (0.7249)  bbox_regression: 0.1301 (0.1338)  classification: 0.5399 (0.5911)  time: 0.3812  data: 0.1467  max mem: 3278
Epoch: [13]  [ 200/3494]  eta: 0:20:34  lr: 0.0010000  loss: 0.7910 (0.7517)  bbox_regression: 0.1522 (0.1381)  classification: 0.5993 (0.6135)  time: 0.3729  data: 0.1393  max mem: 3278
Epoch: [13]  [ 300/3494]  eta: 0:19:37  lr: 0.0010000  loss: 0.7312 (0.7437)  bbox_regression: 0.1346 (0.1362)  classification: 0.5909 (0.6075)  time: 0.3385  data: 0.1191  max mem: 3278
Epoch: [13]  [ 400/3494]  eta: 0:18:53  lr: 0.0010000  loss: 0.7129 (0.7434)  bbox_regression: 0.1296 (0.1365)  classification: 0.5756 (0.6069)  time: 0.3516  data: 0.1260  max mem: 3278
Epoch: [13]  [ 500/3494]  eta: 0:18:12  lr: 0.0010000  loss: 0.7350 (0.7466)  bbox_regression: 0.1280 (0.1365)  classification: 0.5937 (0.6101)  time: 0.3553  data: 0.1274  max mem: 3278
Epoch: [13]  [ 600/3494]  eta: 0:17:35  lr: 0.0010000  loss: 0.7570 (0.7443)  bbox_regression: 0.1252 (0.1360)  classification: 0.6281 (0.6083)  time: 0.3558  data: 0.1241  max mem: 3278
Epoch: [13]  [ 700/3494]  eta: 0:16:57  lr: 0.0010000  loss: 0.6966 (0.7442)  bbox_regression: 0.1204 (0.1355)  classification: 0.5842 (0.6086)  time: 0.3700  data: 0.1321  max mem: 3278
Epoch: [13]  [ 800/3494]  eta: 0:16:20  lr: 0.0010000  loss: 0.7335 (0.7490)  bbox_regression: 0.1334 (0.1362)  classification: 0.5966 (0.6128)  time: 0.3465  data: 0.1197  max mem: 3278
Epoch: [13]  [ 900/3494]  eta: 0:15:41  lr: 0.0010000  loss: 0.7157 (0.7500)  bbox_regression: 0.1163 (0.1356)  classification: 0.6083 (0.6144)  time: 0.3555  data: 0.1260  max mem: 3278
Epoch: [13]  [1000/3494]  eta: 0:15:04  lr: 0.0010000  loss: 0.7266 (0.7500)  bbox_regression: 0.1283 (0.1358)  classification: 0.5862 (0.6142)  time: 0.3641  data: 0.1317  max mem: 3278
Epoch: [13]  [1100/3494]  eta: 0:14:28  lr: 0.0010000  loss: 0.7835 (0.7499)  bbox_regression: 0.1096 (0.1357)  classification: 0.6325 (0.6142)  time: 0.3618  data: 0.1283  max mem: 3278
Epoch: [13]  [1200/3494]  eta: 0:13:50  lr: 0.0010000  loss: 0.7303 (0.7524)  bbox_regression: 0.1287 (0.1366)  classification: 0.5992 (0.6158)  time: 0.3623  data: 0.1306  max mem: 3278
Epoch: [13]  [1300/3494]  eta: 0:13:14  lr: 0.0010000  loss: 0.7322 (0.7531)  bbox_regression: 0.1331 (0.1369)  classification: 0.6042 (0.6161)  time: 0.3529  data: 0.1230  max mem: 3278
Epoch: [13]  [1400/3494]  eta: 0:12:37  lr: 0.0010000  loss: 0.7475 (0.7532)  bbox_regression: 0.1365 (0.1371)  classification: 0.6285 (0.6162)  time: 0.3449  data: 0.1147  max mem: 3278
Epoch: [13]  [1500/3494]  eta: 0:12:01  lr: 0.0010000  loss: 0.7053 (0.7537)  bbox_regression: 0.1206 (0.1372)  classification: 0.5981 (0.6166)  time: 0.3729  data: 0.1366  max mem: 3278
Epoch: [13]  [1600/3494]  eta: 0:11:25  lr: 0.0010000  loss: 0.7170 (0.7540)  bbox_regression: 0.1250 (0.1374)  classification: 0.5964 (0.6167)  time: 0.3636  data: 0.1278  max mem: 3278
Epoch: [13]  [1700/3494]  eta: 0:10:48  lr: 0.0010000  loss: 0.7364 (0.7550)  bbox_regression: 0.1232 (0.1374)  classification: 0.6068 (0.6177)  time: 0.3590  data: 0.1278  max mem: 3278
Epoch: [13]  [1800/3494]  eta: 0:10:12  lr: 0.0010000  loss: 0.7038 (0.7553)  bbox_regression: 0.1370 (0.1373)  classification: 0.5707 (0.6180)  time: 0.3553  data: 0.1243  max mem: 3278
Epoch: [13]  [1900/3494]  eta: 0:09:36  lr: 0.0010000  loss: 0.6850 (0.7553)  bbox_regression: 0.1197 (0.1374)  classification: 0.5578 (0.6179)  time: 0.3610  data: 0.1267  max mem: 3278
Epoch: [13]  [2000/3494]  eta: 0:08:59  lr: 0.0010000  loss: 0.8046 (0.7591)  bbox_regression: 0.1300 (0.1382)  classification: 0.6746 (0.6209)  time: 0.3448  data: 0.1202  max mem: 3278
Epoch: [13]  [2100/3494]  eta: 0:08:22  lr: 0.0010000  loss: 0.7081 (0.7591)  bbox_regression: 0.1069 (0.1381)  classification: 0.5881 (0.6210)  time: 0.3539  data: 0.1238  max mem: 3278
Epoch: [13]  [2200/3494]  eta: 0:07:46  lr: 0.0010000  loss: 0.7283 (0.7595)  bbox_regression: 0.1292 (0.1381)  classification: 0.6024 (0.6213)  time: 0.3506  data: 0.1252  max mem: 3278
Epoch: [13]  [2300/3494]  eta: 0:07:10  lr: 0.0010000  loss: 0.7329 (0.7596)  bbox_regression: 0.1254 (0.1380)  classification: 0.5917 (0.6217)  time: 0.3498  data: 0.1218  max mem: 3278
Epoch: [13]  [2400/3494]  eta: 0:06:34  lr: 0.0010000  loss: 0.7587 (0.7603)  bbox_regression: 0.1428 (0.1383)  classification: 0.6104 (0.6221)  time: 0.3646  data: 0.1305  max mem: 3278
Epoch: [13]  [2500/3494]  eta: 0:05:58  lr: 0.0010000  loss: 0.7402 (0.7602)  bbox_regression: 0.1223 (0.1381)  classification: 0.6194 (0.6221)  time: 0.3478  data: 0.1195  max mem: 3278
Epoch: [13]  [2600/3494]  eta: 0:05:22  lr: 0.0010000  loss: 0.7317 (0.7603)  bbox_regression: 0.1357 (0.1381)  classification: 0.5956 (0.6222)  time: 0.3570  data: 0.1222  max mem: 3278
Epoch: [13]  [2700/3494]  eta: 0:04:46  lr: 0.0010000  loss: 0.7158 (0.7611)  bbox_regression: 0.1326 (0.1384)  classification: 0.5841 (0.6227)  time: 0.3632  data: 0.1275  max mem: 3278
Epoch: [13]  [2800/3494]  eta: 0:04:10  lr: 0.0010000  loss: 0.7818 (0.7616)  bbox_regression: 0.1438 (0.1386)  classification: 0.6833 (0.6230)  time: 0.3596  data: 0.1314  max mem: 3278
Epoch: [13]  [2900/3494]  eta: 0:03:34  lr: 0.0010000  loss: 0.7336 (0.7617)  bbox_regression: 0.1247 (0.1386)  classification: 0.6007 (0.6230)  time: 0.3546  data: 0.1251  max mem: 3278
Epoch: [13]  [3000/3494]  eta: 0:02:58  lr: 0.0010000  loss: 0.7267 (0.7622)  bbox_regression: 0.1286 (0.1388)  classification: 0.5809 (0.6234)  time: 0.3692  data: 0.1353  max mem: 3278
Epoch: [13]  [3100/3494]  eta: 0:02:21  lr: 0.0010000  loss: 0.7296 (0.7634)  bbox_regression: 0.1460 (0.1392)  classification: 0.6131 (0.6243)  time: 0.3573  data: 0.1277  max mem: 3278
Epoch: [13]  [3200/3494]  eta: 0:01:45  lr: 0.0010000  loss: 0.6676 (0.7631)  bbox_regression: 0.1125 (0.1390)  classification: 0.5551 (0.6241)  time: 0.3524  data: 0.1261  max mem: 3278
Epoch: [13]  [3300/3494]  eta: 0:01:09  lr: 0.0010000  loss: 0.7054 (0.7630)  bbox_regression: 0.1093 (0.1389)  classification: 0.6001 (0.6241)  time: 0.3608  data: 0.1290  max mem: 3278
Epoch: [13]  [3400/3494]  eta: 0:00:33  lr: 0.0010000  loss: 0.7480 (0.7645)  bbox_regression: 0.1328 (0.1391)  classification: 0.5949 (0.6254)  time: 0.3546  data: 0.1278  max mem: 3278
Epoch: [13]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.6969 (0.7646)  bbox_regression: 0.1220 (0.1390)  classification: 0.5599 (0.6256)  time: 0.3435  data: 0.1217  max mem: 3278
Epoch: [13] Total time: 0:21:09 (0.3632 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:11:43  model_time: 0.1254 (0.1254)  loss: 1.1524 (1.1524)  bbox_regression: 0.1621 (0.1621)  classification: 0.9902 (0.9902)  time: 1.6100  data: 1.4636  max mem: 3278
Validation:  [100/437]  eta: 0:01:31  model_time: 0.1185 (0.1200)  loss: 0.9242 (0.9812)  bbox_regression: 0.1913 (0.1937)  classification: 0.7594 (0.7875)  time: 0.2587  data: 0.1227  max mem: 3278
Validation:  [200/437]  eta: 0:01:02  model_time: 0.1199 (0.1200)  loss: 0.8654 (0.9479)  bbox_regression: 0.1620 (0.1822)  classification: 0.7137 (0.7657)  time: 0.2639  data: 0.1241  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1231 (0.1212)  loss: 0.9616 (0.9518)  bbox_regression: 0.1734 (0.1791)  classification: 0.8307 (0.7727)  time: 0.2738  data: 0.1298  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1220 (0.1215)  loss: 0.9159 (0.9461)  bbox_regression: 0.1818 (0.1790)  classification: 0.7259 (0.7671)  time: 0.2641  data: 0.1227  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1183 (0.1218)  loss: 0.8261 (0.9476)  bbox_regression: 0.1548 (0.1790)  classification: 0.7062 (0.7686)  time: 0.2542  data: 0.1181  max mem: 3278
Validation: Total time: 0:01:56 (0.2670 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [14]  [   0/3494]  eta: 2:22:55  lr: 0.0010000  loss: 0.7519 (0.7519)  bbox_regression: 0.1432 (0.1432)  classification: 0.6086 (0.6086)  time: 2.4543  data: 2.2228  max mem: 3278
Epoch: [14]  [ 100/3494]  eta: 0:21:36  lr: 0.0010000  loss: 0.7729 (0.7217)  bbox_regression: 0.1318 (0.1339)  classification: 0.6320 (0.5878)  time: 0.3750  data: 0.1442  max mem: 3278
Epoch: [14]  [ 200/3494]  eta: 0:20:23  lr: 0.0010000  loss: 0.6967 (0.7201)  bbox_regression: 0.1273 (0.1330)  classification: 0.5735 (0.5871)  time: 0.3754  data: 0.1267  max mem: 3278
Epoch: [14]  [ 300/3494]  eta: 0:19:35  lr: 0.0010000  loss: 0.6703 (0.7300)  bbox_regression: 0.1230 (0.1339)  classification: 0.5487 (0.5961)  time: 0.3809  data: 0.1329  max mem: 3278
Epoch: [14]  [ 400/3494]  eta: 0:18:46  lr: 0.0010000  loss: 0.6413 (0.7276)  bbox_regression: 0.1219 (0.1325)  classification: 0.5370 (0.5951)  time: 0.3695  data: 0.1414  max mem: 3278
Epoch: [14]  [ 500/3494]  eta: 0:18:06  lr: 0.0010000  loss: 0.7109 (0.7290)  bbox_regression: 0.1226 (0.1328)  classification: 0.5984 (0.5961)  time: 0.3555  data: 0.1262  max mem: 3278
Epoch: [14]  [ 600/3494]  eta: 0:17:27  lr: 0.0010000  loss: 0.7672 (0.7330)  bbox_regression: 0.1478 (0.1328)  classification: 0.6280 (0.6002)  time: 0.3578  data: 0.1276  max mem: 3278
Epoch: [14]  [ 700/3494]  eta: 0:16:51  lr: 0.0010000  loss: 0.7377 (0.7363)  bbox_regression: 0.1424 (0.1331)  classification: 0.5738 (0.6032)  time: 0.3738  data: 0.1349  max mem: 3278
Epoch: [14]  [ 800/3494]  eta: 0:16:14  lr: 0.0010000  loss: 0.6922 (0.7369)  bbox_regression: 0.1196 (0.1337)  classification: 0.5559 (0.6032)  time: 0.3597  data: 0.1274  max mem: 3278
Epoch: [14]  [ 900/3494]  eta: 0:15:37  lr: 0.0010000  loss: 0.7075 (0.7332)  bbox_regression: 0.1331 (0.1331)  classification: 0.5644 (0.6001)  time: 0.3626  data: 0.1280  max mem: 3278
Epoch: [14]  [1000/3494]  eta: 0:15:01  lr: 0.0010000  loss: 0.7482 (0.7343)  bbox_regression: 0.1289 (0.1327)  classification: 0.6111 (0.6016)  time: 0.3700  data: 0.1279  max mem: 3278
Epoch: [14]  [1100/3494]  eta: 0:14:26  lr: 0.0010000  loss: 0.6967 (0.7362)  bbox_regression: 0.1322 (0.1330)  classification: 0.5598 (0.6032)  time: 0.3723  data: 0.1296  max mem: 3278
Epoch: [14]  [1200/3494]  eta: 0:13:50  lr: 0.0010000  loss: 0.6744 (0.7373)  bbox_regression: 0.1164 (0.1335)  classification: 0.5579 (0.6038)  time: 0.3636  data: 0.1290  max mem: 3278
Epoch: [14]  [1300/3494]  eta: 0:13:14  lr: 0.0010000  loss: 0.7690 (0.7387)  bbox_regression: 0.1316 (0.1341)  classification: 0.6256 (0.6046)  time: 0.3660  data: 0.1360  max mem: 3278
Epoch: [14]  [1400/3494]  eta: 0:12:38  lr: 0.0010000  loss: 0.6722 (0.7396)  bbox_regression: 0.1182 (0.1341)  classification: 0.5614 (0.6055)  time: 0.3584  data: 0.1292  max mem: 3278
Epoch: [14]  [1500/3494]  eta: 0:12:02  lr: 0.0010000  loss: 0.7898 (0.7428)  bbox_regression: 0.1393 (0.1351)  classification: 0.6560 (0.6078)  time: 0.3654  data: 0.1273  max mem: 3278
Epoch: [14]  [1600/3494]  eta: 0:11:26  lr: 0.0010000  loss: 0.7754 (0.7446)  bbox_regression: 0.1256 (0.1358)  classification: 0.6430 (0.6088)  time: 0.3655  data: 0.1282  max mem: 3278
Epoch: [14]  [1700/3494]  eta: 0:10:50  lr: 0.0010000  loss: 0.7754 (0.7451)  bbox_regression: 0.1397 (0.1361)  classification: 0.6309 (0.6090)  time: 0.3744  data: 0.1340  max mem: 3278
Epoch: [14]  [1800/3494]  eta: 0:10:13  lr: 0.0010000  loss: 0.6638 (0.7480)  bbox_regression: 0.1303 (0.1369)  classification: 0.5438 (0.6110)  time: 0.3576  data: 0.1336  max mem: 3278
Epoch: [14]  [1900/3494]  eta: 0:09:37  lr: 0.0010000  loss: 0.6993 (0.7479)  bbox_regression: 0.1203 (0.1370)  classification: 0.5703 (0.6109)  time: 0.3601  data: 0.1282  max mem: 3278
Epoch: [14]  [2000/3494]  eta: 0:09:00  lr: 0.0010000  loss: 0.7255 (0.7480)  bbox_regression: 0.1258 (0.1368)  classification: 0.5846 (0.6112)  time: 0.3642  data: 0.1272  max mem: 3278
Epoch: [14]  [2100/3494]  eta: 0:08:24  lr: 0.0010000  loss: 0.6689 (0.7483)  bbox_regression: 0.1197 (0.1365)  classification: 0.5473 (0.6118)  time: 0.3643  data: 0.1289  max mem: 3278
Epoch: [14]  [2200/3494]  eta: 0:07:48  lr: 0.0010000  loss: 0.8303 (0.7488)  bbox_regression: 0.1422 (0.1367)  classification: 0.6674 (0.6121)  time: 0.3712  data: 0.1360  max mem: 3278
Epoch: [14]  [2300/3494]  eta: 0:07:11  lr: 0.0010000  loss: 0.8681 (0.7509)  bbox_regression: 0.1620 (0.1373)  classification: 0.7032 (0.6136)  time: 0.3634  data: 0.1307  max mem: 3278
Epoch: [14]  [2400/3494]  eta: 0:06:35  lr: 0.0010000  loss: 0.7950 (0.7506)  bbox_regression: 0.1457 (0.1373)  classification: 0.6333 (0.6133)  time: 0.3574  data: 0.1297  max mem: 3278
Epoch: [14]  [2500/3494]  eta: 0:05:59  lr: 0.0010000  loss: 0.7699 (0.7516)  bbox_regression: 0.1407 (0.1375)  classification: 0.6192 (0.6141)  time: 0.3770  data: 0.1363  max mem: 3278
Epoch: [14]  [2600/3494]  eta: 0:05:23  lr: 0.0010000  loss: 0.7123 (0.7514)  bbox_regression: 0.1248 (0.1372)  classification: 0.5783 (0.6142)  time: 0.3410  data: 0.1148  max mem: 3278
Epoch: [14]  [2700/3494]  eta: 0:04:47  lr: 0.0010000  loss: 0.6538 (0.7517)  bbox_regression: 0.1112 (0.1373)  classification: 0.5520 (0.6144)  time: 0.3717  data: 0.1334  max mem: 3278
Epoch: [14]  [2800/3494]  eta: 0:04:11  lr: 0.0010000  loss: 0.7558 (0.7522)  bbox_regression: 0.1296 (0.1372)  classification: 0.6251 (0.6149)  time: 0.3630  data: 0.1256  max mem: 3278
Epoch: [14]  [2900/3494]  eta: 0:03:35  lr: 0.0010000  loss: 0.7151 (0.7512)  bbox_regression: 0.1194 (0.1370)  classification: 0.5973 (0.6142)  time: 0.3721  data: 0.1261  max mem: 3278
Epoch: [14]  [3000/3494]  eta: 0:02:59  lr: 0.0010000  loss: 0.7414 (0.7519)  bbox_regression: 0.1276 (0.1370)  classification: 0.5754 (0.6149)  time: 0.3779  data: 0.1336  max mem: 3278
Epoch: [14]  [3100/3494]  eta: 0:02:23  lr: 0.0010000  loss: 0.7761 (0.7539)  bbox_regression: 0.1296 (0.1374)  classification: 0.6263 (0.6166)  time: 0.3686  data: 0.1303  max mem: 3278
Epoch: [14]  [3200/3494]  eta: 0:01:47  lr: 0.0010000  loss: 0.6904 (0.7554)  bbox_regression: 0.1320 (0.1375)  classification: 0.5796 (0.6179)  time: 0.3814  data: 0.1294  max mem: 3278
Epoch: [14]  [3300/3494]  eta: 0:01:10  lr: 0.0010000  loss: 0.6749 (0.7545)  bbox_regression: 0.1152 (0.1374)  classification: 0.5417 (0.6171)  time: 0.3776  data: 0.1432  max mem: 3278
Epoch: [14]  [3400/3494]  eta: 0:00:34  lr: 0.0010000  loss: 0.6718 (0.7548)  bbox_regression: 0.1169 (0.1376)  classification: 0.5512 (0.6172)  time: 0.3605  data: 0.1258  max mem: 3278
Epoch: [14]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.8384 (0.7554)  bbox_regression: 0.1313 (0.1375)  classification: 0.6825 (0.6179)  time: 0.3614  data: 0.1310  max mem: 3278
Epoch: [14] Total time: 0:21:26 (0.3681 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:00  model_time: 0.1728 (0.1728)  loss: 1.1830 (1.1830)  bbox_regression: 0.1764 (0.1764)  classification: 1.0066 (1.0066)  time: 2.0599  data: 1.8618  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1146 (0.1217)  loss: 0.8486 (0.9683)  bbox_regression: 0.1715 (0.1843)  classification: 0.6608 (0.7840)  time: 0.2591  data: 0.1234  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1175 (0.1232)  loss: 0.8317 (0.9338)  bbox_regression: 0.1510 (0.1747)  classification: 0.6835 (0.7591)  time: 0.2581  data: 0.1194  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1140 (0.1223)  loss: 0.9293 (0.9320)  bbox_regression: 0.1609 (0.1712)  classification: 0.7809 (0.7608)  time: 0.2503  data: 0.1172  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1187 (0.1219)  loss: 0.8242 (0.9297)  bbox_regression: 0.1492 (0.1713)  classification: 0.6572 (0.7585)  time: 0.2716  data: 0.1272  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1217 (0.1222)  loss: 0.8490 (0.9296)  bbox_regression: 0.1499 (0.1712)  classification: 0.7329 (0.7584)  time: 0.2758  data: 0.1334  max mem: 3278
Validation: Total time: 0:01:57 (0.2683 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [15]  [   0/3494]  eta: 2:08:27  lr: 0.0010000  loss: 0.7870 (0.7870)  bbox_regression: 0.1541 (0.1541)  classification: 0.6329 (0.6329)  time: 2.2058  data: 1.9356  max mem: 3278
Epoch: [15]  [ 100/3494]  eta: 0:22:07  lr: 0.0010000  loss: 0.6148 (0.7088)  bbox_regression: 0.1100 (0.1316)  classification: 0.4989 (0.5771)  time: 0.3635  data: 0.1319  max mem: 3278
Epoch: [15]  [ 200/3494]  eta: 0:20:42  lr: 0.0010000  loss: 0.7328 (0.7173)  bbox_regression: 0.1275 (0.1325)  classification: 0.5851 (0.5848)  time: 0.3643  data: 0.1309  max mem: 3278
Epoch: [15]  [ 300/3494]  eta: 0:19:51  lr: 0.0010000  loss: 0.7204 (0.7218)  bbox_regression: 0.1220 (0.1336)  classification: 0.6043 (0.5881)  time: 0.3772  data: 0.1319  max mem: 3278
Epoch: [15]  [ 400/3494]  eta: 0:19:13  lr: 0.0010000  loss: 0.7892 (0.7309)  bbox_regression: 0.1396 (0.1342)  classification: 0.6384 (0.5968)  time: 0.3742  data: 0.1344  max mem: 3278
Epoch: [15]  [ 500/3494]  eta: 0:18:31  lr: 0.0010000  loss: 0.6288 (0.7251)  bbox_regression: 0.1180 (0.1329)  classification: 0.5013 (0.5922)  time: 0.3660  data: 0.1306  max mem: 3278
Epoch: [15]  [ 600/3494]  eta: 0:17:58  lr: 0.0010000  loss: 0.6685 (0.7240)  bbox_regression: 0.1093 (0.1327)  classification: 0.5667 (0.5913)  time: 0.3786  data: 0.1313  max mem: 3278
Epoch: [15]  [ 700/3494]  eta: 0:17:24  lr: 0.0010000  loss: 0.6995 (0.7259)  bbox_regression: 0.1141 (0.1325)  classification: 0.5846 (0.5934)  time: 0.3926  data: 0.1319  max mem: 3278
Epoch: [15]  [ 800/3494]  eta: 0:16:48  lr: 0.0010000  loss: 0.6337 (0.7250)  bbox_regression: 0.1090 (0.1320)  classification: 0.5402 (0.5930)  time: 0.3751  data: 0.1297  max mem: 3278
Epoch: [15]  [ 900/3494]  eta: 0:16:11  lr: 0.0010000  loss: 0.6635 (0.7253)  bbox_regression: 0.1153 (0.1320)  classification: 0.5314 (0.5933)  time: 0.3919  data: 0.1349  max mem: 3278
Epoch: [15]  [1000/3494]  eta: 0:15:33  lr: 0.0010000  loss: 0.7029 (0.7273)  bbox_regression: 0.1186 (0.1323)  classification: 0.6045 (0.5950)  time: 0.3551  data: 0.1266  max mem: 3278
Epoch: [15]  [1100/3494]  eta: 0:14:54  lr: 0.0010000  loss: 0.6765 (0.7267)  bbox_regression: 0.1307 (0.1321)  classification: 0.5522 (0.5945)  time: 0.3773  data: 0.1322  max mem: 3278
Epoch: [15]  [1200/3494]  eta: 0:14:16  lr: 0.0010000  loss: 0.7784 (0.7284)  bbox_regression: 0.1257 (0.1320)  classification: 0.6022 (0.5964)  time: 0.3615  data: 0.1252  max mem: 3278
Epoch: [15]  [1300/3494]  eta: 0:13:39  lr: 0.0010000  loss: 0.6981 (0.7300)  bbox_regression: 0.1328 (0.1325)  classification: 0.5810 (0.5975)  time: 0.3827  data: 0.1335  max mem: 3278
Epoch: [15]  [1400/3494]  eta: 0:13:02  lr: 0.0010000  loss: 0.7402 (0.7303)  bbox_regression: 0.1317 (0.1326)  classification: 0.6191 (0.5977)  time: 0.3663  data: 0.1296  max mem: 3278
Epoch: [15]  [1500/3494]  eta: 0:12:26  lr: 0.0010000  loss: 0.7363 (0.7313)  bbox_regression: 0.1419 (0.1328)  classification: 0.5806 (0.5985)  time: 0.3619  data: 0.1289  max mem: 3278
Epoch: [15]  [1600/3494]  eta: 0:11:48  lr: 0.0010000  loss: 0.7442 (0.7315)  bbox_regression: 0.1358 (0.1326)  classification: 0.5900 (0.5989)  time: 0.3698  data: 0.1327  max mem: 3278
Epoch: [15]  [1700/3494]  eta: 0:11:11  lr: 0.0010000  loss: 0.7459 (0.7325)  bbox_regression: 0.1337 (0.1327)  classification: 0.6061 (0.5997)  time: 0.3734  data: 0.1282  max mem: 3278
Epoch: [15]  [1800/3494]  eta: 0:10:32  lr: 0.0010000  loss: 0.7614 (0.7321)  bbox_regression: 0.1368 (0.1326)  classification: 0.6252 (0.5995)  time: 0.3515  data: 0.1232  max mem: 3278
Epoch: [15]  [1900/3494]  eta: 0:09:54  lr: 0.0010000  loss: 0.7375 (0.7322)  bbox_regression: 0.1374 (0.1327)  classification: 0.6020 (0.5995)  time: 0.3576  data: 0.1243  max mem: 3278
Epoch: [15]  [2000/3494]  eta: 0:09:18  lr: 0.0010000  loss: 0.7242 (0.7334)  bbox_regression: 0.1263 (0.1329)  classification: 0.5991 (0.6005)  time: 0.3746  data: 0.1346  max mem: 3278
Epoch: [15]  [2100/3494]  eta: 0:08:41  lr: 0.0010000  loss: 0.7120 (0.7345)  bbox_regression: 0.1302 (0.1331)  classification: 0.5772 (0.6013)  time: 0.4031  data: 0.1508  max mem: 3278
Epoch: [15]  [2200/3494]  eta: 0:08:04  lr: 0.0010000  loss: 0.7945 (0.7350)  bbox_regression: 0.1353 (0.1331)  classification: 0.6561 (0.6019)  time: 0.3866  data: 0.1454  max mem: 3278
Epoch: [15]  [2300/3494]  eta: 0:07:27  lr: 0.0010000  loss: 0.7348 (0.7357)  bbox_regression: 0.1237 (0.1334)  classification: 0.6021 (0.6023)  time: 0.3686  data: 0.1325  max mem: 3278
Epoch: [15]  [2400/3494]  eta: 0:06:50  lr: 0.0010000  loss: 0.7105 (0.7368)  bbox_regression: 0.1221 (0.1335)  classification: 0.5677 (0.6034)  time: 0.3721  data: 0.1258  max mem: 3278
Epoch: [15]  [2500/3494]  eta: 0:06:12  lr: 0.0010000  loss: 0.6508 (0.7372)  bbox_regression: 0.1215 (0.1336)  classification: 0.5477 (0.6037)  time: 0.3693  data: 0.1367  max mem: 3278
Epoch: [15]  [2600/3494]  eta: 0:05:34  lr: 0.0010000  loss: 0.6857 (0.7377)  bbox_regression: 0.1172 (0.1334)  classification: 0.5833 (0.6043)  time: 0.3697  data: 0.1402  max mem: 3278
Epoch: [15]  [2700/3494]  eta: 0:04:57  lr: 0.0010000  loss: 0.7868 (0.7383)  bbox_regression: 0.1159 (0.1335)  classification: 0.6641 (0.6048)  time: 0.3563  data: 0.1217  max mem: 3278
Epoch: [15]  [2800/3494]  eta: 0:04:19  lr: 0.0010000  loss: 0.7403 (0.7395)  bbox_regression: 0.1390 (0.1336)  classification: 0.5941 (0.6059)  time: 0.3722  data: 0.1273  max mem: 3278
Epoch: [15]  [2900/3494]  eta: 0:03:42  lr: 0.0010000  loss: 0.7728 (0.7407)  bbox_regression: 0.1177 (0.1338)  classification: 0.6498 (0.6069)  time: 0.3784  data: 0.1363  max mem: 3278
Epoch: [15]  [3000/3494]  eta: 0:03:05  lr: 0.0010000  loss: 0.6530 (0.7407)  bbox_regression: 0.1094 (0.1337)  classification: 0.5523 (0.6070)  time: 0.3854  data: 0.1348  max mem: 3278
Epoch: [15]  [3100/3494]  eta: 0:02:27  lr: 0.0010000  loss: 0.7345 (0.7403)  bbox_regression: 0.1215 (0.1337)  classification: 0.5843 (0.6067)  time: 0.3866  data: 0.1421  max mem: 3278
Epoch: [15]  [3200/3494]  eta: 0:01:50  lr: 0.0010000  loss: 0.7289 (0.7415)  bbox_regression: 0.1568 (0.1341)  classification: 0.5799 (0.6074)  time: 0.3645  data: 0.1336  max mem: 3278
Epoch: [15]  [3300/3494]  eta: 0:01:12  lr: 0.0010000  loss: 0.7073 (0.7420)  bbox_regression: 0.1202 (0.1342)  classification: 0.5925 (0.6078)  time: 0.3601  data: 0.1242  max mem: 3278
Epoch: [15]  [3400/3494]  eta: 0:00:35  lr: 0.0010000  loss: 0.6894 (0.7417)  bbox_regression: 0.1328 (0.1341)  classification: 0.5936 (0.6076)  time: 0.3647  data: 0.1319  max mem: 3278
Epoch: [15]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.7184 (0.7417)  bbox_regression: 0.1150 (0.1341)  classification: 0.5624 (0.6076)  time: 0.3737  data: 0.1343  max mem: 3278
Epoch: [15] Total time: 0:21:58 (0.3773 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:09  model_time: 0.1536 (0.1536)  loss: 1.0547 (1.0547)  bbox_regression: 0.1473 (0.1473)  classification: 0.9074 (0.9074)  time: 2.0821  data: 1.8924  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1272 (0.1277)  loss: 0.8529 (0.9934)  bbox_regression: 0.1892 (0.1880)  classification: 0.7076 (0.8054)  time: 0.2684  data: 0.1233  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1331 (0.1281)  loss: 0.9385 (0.9604)  bbox_regression: 0.1678 (0.1788)  classification: 0.7426 (0.7816)  time: 0.2791  data: 0.1299  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1377 (0.1303)  loss: 0.9689 (0.9604)  bbox_regression: 0.1588 (0.1749)  classification: 0.8545 (0.7854)  time: 0.2786  data: 0.1227  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1245 (0.1299)  loss: 0.8581 (0.9548)  bbox_regression: 0.1625 (0.1751)  classification: 0.6722 (0.7797)  time: 0.2603  data: 0.1190  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1232 (0.1311)  loss: 0.8650 (0.9551)  bbox_regression: 0.1478 (0.1750)  classification: 0.7203 (0.7800)  time: 0.2955  data: 0.1205  max mem: 3278
Validation: Total time: 0:02:02 (0.2794 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [16]  [   0/3494]  eta: 2:19:04  lr: 0.0010000  loss: 0.5564 (0.5564)  bbox_regression: 0.0820 (0.0820)  classification: 0.4744 (0.4744)  time: 2.3882  data: 2.1461  max mem: 3278
Epoch: [16]  [ 100/3494]  eta: 0:22:05  lr: 0.0010000  loss: 0.6811 (0.6978)  bbox_regression: 0.1061 (0.1266)  classification: 0.5636 (0.5712)  time: 0.3636  data: 0.1253  max mem: 3278
Epoch: [16]  [ 200/3494]  eta: 0:21:01  lr: 0.0010000  loss: 0.6700 (0.6965)  bbox_regression: 0.1286 (0.1254)  classification: 0.5415 (0.5711)  time: 0.3865  data: 0.1472  max mem: 3278
Epoch: [16]  [ 300/3494]  eta: 0:20:03  lr: 0.0010000  loss: 0.7141 (0.7020)  bbox_regression: 0.1311 (0.1280)  classification: 0.5778 (0.5741)  time: 0.3518  data: 0.1204  max mem: 3278
Epoch: [16]  [ 400/3494]  eta: 0:19:13  lr: 0.0010000  loss: 0.7052 (0.7027)  bbox_regression: 0.1273 (0.1274)  classification: 0.5945 (0.5753)  time: 0.3834  data: 0.1383  max mem: 3278
Epoch: [16]  [ 500/3494]  eta: 0:18:40  lr: 0.0010000  loss: 0.6628 (0.7063)  bbox_regression: 0.1166 (0.1278)  classification: 0.5425 (0.5785)  time: 0.3784  data: 0.1306  max mem: 3278
Epoch: [16]  [ 600/3494]  eta: 0:18:04  lr: 0.0010000  loss: 0.6823 (0.7068)  bbox_regression: 0.1210 (0.1278)  classification: 0.5506 (0.5789)  time: 0.3890  data: 0.1446  max mem: 3278
Epoch: [16]  [ 700/3494]  eta: 0:17:29  lr: 0.0010000  loss: 0.6801 (0.7092)  bbox_regression: 0.1255 (0.1279)  classification: 0.5618 (0.5813)  time: 0.3948  data: 0.1215  max mem: 3278
Epoch: [16]  [ 800/3494]  eta: 0:16:51  lr: 0.0010000  loss: 0.6917 (0.7131)  bbox_regression: 0.1225 (0.1288)  classification: 0.5536 (0.5842)  time: 0.3747  data: 0.1308  max mem: 3278
Epoch: [16]  [ 900/3494]  eta: 0:16:15  lr: 0.0010000  loss: 0.7121 (0.7157)  bbox_regression: 0.1335 (0.1293)  classification: 0.5687 (0.5864)  time: 0.3578  data: 0.1276  max mem: 3278
Epoch: [16]  [1000/3494]  eta: 0:15:36  lr: 0.0010000  loss: 0.6921 (0.7161)  bbox_regression: 0.1257 (0.1295)  classification: 0.5699 (0.5866)  time: 0.3612  data: 0.1257  max mem: 3278
Epoch: [16]  [1100/3494]  eta: 0:14:57  lr: 0.0010000  loss: 0.7275 (0.7155)  bbox_regression: 0.1181 (0.1292)  classification: 0.5930 (0.5863)  time: 0.3637  data: 0.1320  max mem: 3278
Epoch: [16]  [1200/3494]  eta: 0:14:19  lr: 0.0010000  loss: 0.7188 (0.7178)  bbox_regression: 0.1046 (0.1293)  classification: 0.6181 (0.5885)  time: 0.3872  data: 0.1375  max mem: 3278
Epoch: [16]  [1300/3494]  eta: 0:13:41  lr: 0.0010000  loss: 0.6641 (0.7183)  bbox_regression: 0.1319 (0.1295)  classification: 0.5329 (0.5888)  time: 0.3682  data: 0.1299  max mem: 3278
Epoch: [16]  [1400/3494]  eta: 0:13:04  lr: 0.0010000  loss: 0.7350 (0.7189)  bbox_regression: 0.1327 (0.1295)  classification: 0.5855 (0.5893)  time: 0.3883  data: 0.1420  max mem: 3278
Epoch: [16]  [1500/3494]  eta: 0:12:28  lr: 0.0010000  loss: 0.7457 (0.7201)  bbox_regression: 0.1234 (0.1298)  classification: 0.6137 (0.5903)  time: 0.3962  data: 0.1295  max mem: 3278
Epoch: [16]  [1600/3494]  eta: 0:11:51  lr: 0.0010000  loss: 0.6919 (0.7213)  bbox_regression: 0.1177 (0.1299)  classification: 0.5931 (0.5914)  time: 0.3744  data: 0.1267  max mem: 3278
Epoch: [16]  [1700/3494]  eta: 0:11:13  lr: 0.0010000  loss: 0.7080 (0.7220)  bbox_regression: 0.1328 (0.1300)  classification: 0.5562 (0.5920)  time: 0.3771  data: 0.1292  max mem: 3278
Epoch: [16]  [1800/3494]  eta: 0:10:35  lr: 0.0010000  loss: 0.7633 (0.7231)  bbox_regression: 0.1155 (0.1301)  classification: 0.6488 (0.5930)  time: 0.3564  data: 0.1239  max mem: 3278
Epoch: [16]  [1900/3494]  eta: 0:09:57  lr: 0.0010000  loss: 0.7679 (0.7240)  bbox_regression: 0.1322 (0.1301)  classification: 0.6257 (0.5939)  time: 0.3679  data: 0.1312  max mem: 3278
Epoch: [16]  [2000/3494]  eta: 0:09:19  lr: 0.0010000  loss: 0.7631 (0.7260)  bbox_regression: 0.1539 (0.1306)  classification: 0.6084 (0.5954)  time: 0.3791  data: 0.1342  max mem: 3278
Epoch: [16]  [2100/3494]  eta: 0:08:42  lr: 0.0010000  loss: 0.6891 (0.7270)  bbox_regression: 0.1296 (0.1306)  classification: 0.5597 (0.5964)  time: 0.3612  data: 0.1282  max mem: 3278
Epoch: [16]  [2200/3494]  eta: 0:08:05  lr: 0.0010000  loss: 0.7994 (0.7265)  bbox_regression: 0.1314 (0.1306)  classification: 0.6511 (0.5960)  time: 0.3734  data: 0.1285  max mem: 3278
Epoch: [16]  [2300/3494]  eta: 0:07:28  lr: 0.0010000  loss: 0.7388 (0.7277)  bbox_regression: 0.1330 (0.1308)  classification: 0.5811 (0.5970)  time: 0.3852  data: 0.1391  max mem: 3278
Epoch: [16]  [2400/3494]  eta: 0:06:50  lr: 0.0010000  loss: 0.7030 (0.7282)  bbox_regression: 0.1084 (0.1307)  classification: 0.5921 (0.5975)  time: 0.3925  data: 0.1308  max mem: 3278
Epoch: [16]  [2500/3494]  eta: 0:06:13  lr: 0.0010000  loss: 0.7349 (0.7293)  bbox_regression: 0.1221 (0.1310)  classification: 0.5978 (0.5983)  time: 0.3605  data: 0.1228  max mem: 3278
Epoch: [16]  [2600/3494]  eta: 0:05:35  lr: 0.0010000  loss: 0.6825 (0.7291)  bbox_regression: 0.1397 (0.1313)  classification: 0.5671 (0.5978)  time: 0.3737  data: 0.1353  max mem: 3278
Epoch: [16]  [2700/3494]  eta: 0:04:57  lr: 0.0010000  loss: 0.6957 (0.7293)  bbox_regression: 0.1203 (0.1314)  classification: 0.5585 (0.5979)  time: 0.3763  data: 0.1319  max mem: 3278
Epoch: [16]  [2800/3494]  eta: 0:04:20  lr: 0.0010000  loss: 0.6761 (0.7290)  bbox_regression: 0.1288 (0.1313)  classification: 0.5307 (0.5977)  time: 0.3904  data: 0.1448  max mem: 3278
Epoch: [16]  [2900/3494]  eta: 0:03:42  lr: 0.0010000  loss: 0.6523 (0.7281)  bbox_regression: 0.1203 (0.1310)  classification: 0.5319 (0.5971)  time: 0.3664  data: 0.1289  max mem: 3278
Epoch: [16]  [3000/3494]  eta: 0:03:05  lr: 0.0010000  loss: 0.6958 (0.7281)  bbox_regression: 0.1278 (0.1311)  classification: 0.5742 (0.5970)  time: 0.3782  data: 0.1271  max mem: 3278
Epoch: [16]  [3100/3494]  eta: 0:02:27  lr: 0.0010000  loss: 0.7635 (0.7285)  bbox_regression: 0.1357 (0.1313)  classification: 0.6438 (0.5972)  time: 0.3904  data: 0.1467  max mem: 3278
Epoch: [16]  [3200/3494]  eta: 0:01:50  lr: 0.0010000  loss: 0.7160 (0.7284)  bbox_regression: 0.1224 (0.1314)  classification: 0.5913 (0.5971)  time: 0.3641  data: 0.1296  max mem: 3278
Epoch: [16]  [3300/3494]  eta: 0:01:12  lr: 0.0010000  loss: 0.7213 (0.7292)  bbox_regression: 0.1150 (0.1314)  classification: 0.5665 (0.5978)  time: 0.3666  data: 0.1330  max mem: 3278
Epoch: [16]  [3400/3494]  eta: 0:00:35  lr: 0.0010000  loss: 0.7376 (0.7298)  bbox_regression: 0.1323 (0.1316)  classification: 0.5930 (0.5982)  time: 0.3213  data: 0.0958  max mem: 3278
Epoch: [16]  [3493/3494]  eta: 0:00:00  lr: 0.0010000  loss: 0.6407 (0.7302)  bbox_regression: 0.1132 (0.1319)  classification: 0.5145 (0.5984)  time: 0.3646  data: 0.1359  max mem: 3278
Epoch: [16] Total time: 0:22:00 (0.3778 s / it)
Epoch 00017: reducing learning rate of group 0 to 1.0000e-04.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:19:14  model_time: 0.1238 (0.1238)  loss: 1.1033 (1.1033)  bbox_regression: 0.1435 (0.1435)  classification: 0.9598 (0.9598)  time: 2.6417  data: 2.4920  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1255 (0.1243)  loss: 0.8892 (0.9660)  bbox_regression: 0.1765 (0.1802)  classification: 0.7231 (0.7858)  time: 0.2710  data: 0.1283  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1329 (0.1250)  loss: 0.8653 (0.9267)  bbox_regression: 0.1585 (0.1688)  classification: 0.7069 (0.7579)  time: 0.2846  data: 0.1379  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1298 (0.1260)  loss: 0.9603 (0.9270)  bbox_regression: 0.1619 (0.1656)  classification: 0.7919 (0.7614)  time: 0.2700  data: 0.1230  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1262 (0.1279)  loss: 0.8406 (0.9218)  bbox_regression: 0.1621 (0.1654)  classification: 0.6638 (0.7565)  time: 0.2706  data: 0.1292  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1327 (0.1278)  loss: 0.7865 (0.9219)  bbox_regression: 0.1285 (0.1654)  classification: 0.6416 (0.7566)  time: 0.2649  data: 0.1192  max mem: 3278
Validation: Total time: 0:02:02 (0.2796 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [17]  [   0/3494]  eta: 1:57:07  lr: 0.0001000  loss: 0.6066 (0.6066)  bbox_regression: 0.1106 (0.1106)  classification: 0.4961 (0.4961)  time: 2.0113  data: 1.7279  max mem: 3278
Epoch: [17]  [ 100/3494]  eta: 0:22:40  lr: 0.0001000  loss: 0.6592 (0.6638)  bbox_regression: 0.1224 (0.1192)  classification: 0.5445 (0.5447)  time: 0.3850  data: 0.1360  max mem: 3278
Epoch: [17]  [ 200/3494]  eta: 0:21:34  lr: 0.0001000  loss: 0.6612 (0.6642)  bbox_regression: 0.1106 (0.1170)  classification: 0.5348 (0.5473)  time: 0.3725  data: 0.1277  max mem: 3278
Epoch: [17]  [ 300/3494]  eta: 0:20:37  lr: 0.0001000  loss: 0.6100 (0.6621)  bbox_regression: 0.1020 (0.1169)  classification: 0.4883 (0.5452)  time: 0.3776  data: 0.1341  max mem: 3278
Epoch: [17]  [ 400/3494]  eta: 0:19:46  lr: 0.0001000  loss: 0.6185 (0.6623)  bbox_regression: 0.0993 (0.1170)  classification: 0.5204 (0.5454)  time: 0.3721  data: 0.1285  max mem: 3278
Epoch: [17]  [ 500/3494]  eta: 0:19:00  lr: 0.0001000  loss: 0.6536 (0.6595)  bbox_regression: 0.1032 (0.1157)  classification: 0.5484 (0.5438)  time: 0.3793  data: 0.1362  max mem: 3278
Epoch: [17]  [ 600/3494]  eta: 0:18:26  lr: 0.0001000  loss: 0.6164 (0.6588)  bbox_regression: 0.1039 (0.1168)  classification: 0.5172 (0.5420)  time: 0.3767  data: 0.1315  max mem: 3278
Epoch: [17]  [ 700/3494]  eta: 0:17:48  lr: 0.0001000  loss: 0.6488 (0.6583)  bbox_regression: 0.1069 (0.1164)  classification: 0.5357 (0.5419)  time: 0.3933  data: 0.1453  max mem: 3278
Epoch: [17]  [ 800/3494]  eta: 0:17:08  lr: 0.0001000  loss: 0.5565 (0.6558)  bbox_regression: 0.0947 (0.1157)  classification: 0.4518 (0.5401)  time: 0.3731  data: 0.1289  max mem: 3278
Epoch: [17]  [ 900/3494]  eta: 0:16:29  lr: 0.0001000  loss: 0.6171 (0.6548)  bbox_regression: 0.0935 (0.1153)  classification: 0.5080 (0.5396)  time: 0.3838  data: 0.1326  max mem: 3278
Epoch: [17]  [1000/3494]  eta: 0:15:51  lr: 0.0001000  loss: 0.6440 (0.6518)  bbox_regression: 0.1120 (0.1149)  classification: 0.5194 (0.5369)  time: 0.3548  data: 0.1281  max mem: 3278
Epoch: [17]  [1100/3494]  eta: 0:15:12  lr: 0.0001000  loss: 0.6032 (0.6494)  bbox_regression: 0.0934 (0.1145)  classification: 0.4906 (0.5349)  time: 0.3780  data: 0.1305  max mem: 3278
Epoch: [17]  [1200/3494]  eta: 0:14:31  lr: 0.0001000  loss: 0.5679 (0.6479)  bbox_regression: 0.1081 (0.1143)  classification: 0.4781 (0.5336)  time: 0.3638  data: 0.1297  max mem: 3278
Epoch: [17]  [1300/3494]  eta: 0:13:50  lr: 0.0001000  loss: 0.5978 (0.6467)  bbox_regression: 0.1127 (0.1142)  classification: 0.4888 (0.5324)  time: 0.3752  data: 0.1328  max mem: 3278
Epoch: [17]  [1400/3494]  eta: 0:13:12  lr: 0.0001000  loss: 0.6180 (0.6445)  bbox_regression: 0.0973 (0.1136)  classification: 0.4874 (0.5309)  time: 0.3870  data: 0.1395  max mem: 3278
Epoch: [17]  [1500/3494]  eta: 0:12:34  lr: 0.0001000  loss: 0.6426 (0.6436)  bbox_regression: 0.1164 (0.1133)  classification: 0.5227 (0.5304)  time: 0.3804  data: 0.1289  max mem: 3278
Epoch: [17]  [1600/3494]  eta: 0:11:57  lr: 0.0001000  loss: 0.6354 (0.6445)  bbox_regression: 0.0964 (0.1133)  classification: 0.5033 (0.5312)  time: 0.3732  data: 0.1350  max mem: 3278
Epoch: [17]  [1700/3494]  eta: 0:11:19  lr: 0.0001000  loss: 0.5724 (0.6437)  bbox_regression: 0.1058 (0.1130)  classification: 0.4844 (0.5307)  time: 0.3702  data: 0.1298  max mem: 3278
Epoch: [17]  [1800/3494]  eta: 0:10:40  lr: 0.0001000  loss: 0.5929 (0.6430)  bbox_regression: 0.0903 (0.1130)  classification: 0.5048 (0.5300)  time: 0.3679  data: 0.1283  max mem: 3278
Epoch: [17]  [1900/3494]  eta: 0:10:02  lr: 0.0001000  loss: 0.6245 (0.6426)  bbox_regression: 0.1106 (0.1128)  classification: 0.5044 (0.5298)  time: 0.3621  data: 0.1281  max mem: 3278
Epoch: [17]  [2000/3494]  eta: 0:09:24  lr: 0.0001000  loss: 0.6408 (0.6420)  bbox_regression: 0.1126 (0.1126)  classification: 0.5266 (0.5293)  time: 0.3646  data: 0.1316  max mem: 3278
Epoch: [17]  [2100/3494]  eta: 0:08:45  lr: 0.0001000  loss: 0.5924 (0.6413)  bbox_regression: 0.1040 (0.1125)  classification: 0.4907 (0.5288)  time: 0.3606  data: 0.1249  max mem: 3278
Epoch: [17]  [2200/3494]  eta: 0:08:07  lr: 0.0001000  loss: 0.6092 (0.6408)  bbox_regression: 0.1093 (0.1126)  classification: 0.4925 (0.5282)  time: 0.3924  data: 0.1431  max mem: 3278
Epoch: [17]  [2300/3494]  eta: 0:07:30  lr: 0.0001000  loss: 0.5990 (0.6405)  bbox_regression: 0.0995 (0.1126)  classification: 0.4835 (0.5279)  time: 0.3975  data: 0.1502  max mem: 3278
Epoch: [17]  [2400/3494]  eta: 0:06:52  lr: 0.0001000  loss: 0.5818 (0.6393)  bbox_regression: 0.1084 (0.1124)  classification: 0.4679 (0.5269)  time: 0.3611  data: 0.1274  max mem: 3278
Epoch: [17]  [2500/3494]  eta: 0:06:14  lr: 0.0001000  loss: 0.5827 (0.6392)  bbox_regression: 0.0872 (0.1124)  classification: 0.4982 (0.5268)  time: 0.3525  data: 0.1243  max mem: 3278
Epoch: [17]  [2600/3494]  eta: 0:05:36  lr: 0.0001000  loss: 0.5937 (0.6383)  bbox_regression: 0.0977 (0.1122)  classification: 0.4994 (0.5261)  time: 0.3564  data: 0.1267  max mem: 3278
Epoch: [17]  [2700/3494]  eta: 0:04:58  lr: 0.0001000  loss: 0.6138 (0.6382)  bbox_regression: 0.1067 (0.1120)  classification: 0.4985 (0.5262)  time: 0.3580  data: 0.1246  max mem: 3278
Epoch: [17]  [2800/3494]  eta: 0:04:20  lr: 0.0001000  loss: 0.5927 (0.6374)  bbox_regression: 0.1025 (0.1119)  classification: 0.5024 (0.5255)  time: 0.3722  data: 0.1336  max mem: 3278
Epoch: [17]  [2900/3494]  eta: 0:03:43  lr: 0.0001000  loss: 0.6034 (0.6376)  bbox_regression: 0.1011 (0.1119)  classification: 0.4822 (0.5256)  time: 0.3703  data: 0.1269  max mem: 3278
Epoch: [17]  [3000/3494]  eta: 0:03:05  lr: 0.0001000  loss: 0.6063 (0.6377)  bbox_regression: 0.1080 (0.1121)  classification: 0.5048 (0.5256)  time: 0.3782  data: 0.1371  max mem: 3278
Epoch: [17]  [3100/3494]  eta: 0:02:27  lr: 0.0001000  loss: 0.5657 (0.6382)  bbox_regression: 0.1027 (0.1121)  classification: 0.4722 (0.5261)  time: 0.3794  data: 0.1376  max mem: 3278
Epoch: [17]  [3200/3494]  eta: 0:01:50  lr: 0.0001000  loss: 0.5734 (0.6372)  bbox_regression: 0.0899 (0.1118)  classification: 0.4811 (0.5254)  time: 0.4002  data: 0.1360  max mem: 3278
Epoch: [17]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.6088 (0.6370)  bbox_regression: 0.0976 (0.1119)  classification: 0.5088 (0.5252)  time: 0.3581  data: 0.1266  max mem: 3278
Epoch: [17]  [3400/3494]  eta: 0:00:35  lr: 0.0001000  loss: 0.6173 (0.6365)  bbox_regression: 0.0973 (0.1116)  classification: 0.5180 (0.5249)  time: 0.3540  data: 0.1255  max mem: 3278
Epoch: [17]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.6406 (0.6367)  bbox_regression: 0.1181 (0.1117)  classification: 0.5268 (0.5249)  time: 0.3423  data: 0.1233  max mem: 3278
Epoch: [17] Total time: 0:22:01 (0.3782 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:54  model_time: 0.1497 (0.1497)  loss: 1.0653 (1.0653)  bbox_regression: 0.1335 (0.1335)  classification: 0.9318 (0.9318)  time: 2.0468  data: 1.8579  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1247 (0.1272)  loss: 0.7885 (0.8952)  bbox_regression: 0.1654 (0.1640)  classification: 0.6306 (0.7312)  time: 0.2733  data: 0.1295  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1336 (0.1261)  loss: 0.7783 (0.8587)  bbox_regression: 0.1383 (0.1543)  classification: 0.6454 (0.7044)  time: 0.2757  data: 0.1263  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1217 (0.1257)  loss: 0.8854 (0.8613)  bbox_regression: 0.1442 (0.1510)  classification: 0.7338 (0.7104)  time: 0.2695  data: 0.1265  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1395 (0.1284)  loss: 0.7533 (0.8572)  bbox_regression: 0.1410 (0.1509)  classification: 0.6067 (0.7063)  time: 0.2849  data: 0.1286  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1229 (0.1284)  loss: 0.7425 (0.8577)  bbox_regression: 0.1223 (0.1510)  classification: 0.6447 (0.7067)  time: 0.2749  data: 0.1280  max mem: 3278
Validation: Total time: 0:02:01 (0.2776 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [18]  [   0/3494]  eta: 2:08:10  lr: 0.0001000  loss: 0.5102 (0.5102)  bbox_regression: 0.0988 (0.0988)  classification: 0.4114 (0.4114)  time: 2.2011  data: 1.8373  max mem: 3278
Epoch: [18]  [ 100/3494]  eta: 0:22:51  lr: 0.0001000  loss: 0.5923 (0.6115)  bbox_regression: 0.1072 (0.1061)  classification: 0.4840 (0.5055)  time: 0.3973  data: 0.1261  max mem: 3278
Epoch: [18]  [ 200/3494]  eta: 0:21:19  lr: 0.0001000  loss: 0.5812 (0.6169)  bbox_regression: 0.1041 (0.1093)  classification: 0.4763 (0.5076)  time: 0.3669  data: 0.1264  max mem: 3278
Epoch: [18]  [ 300/3494]  eta: 0:20:24  lr: 0.0001000  loss: 0.5886 (0.6184)  bbox_regression: 0.1024 (0.1108)  classification: 0.4666 (0.5076)  time: 0.3559  data: 0.1282  max mem: 3278
Epoch: [18]  [ 400/3494]  eta: 0:19:38  lr: 0.0001000  loss: 0.5856 (0.6187)  bbox_regression: 0.1010 (0.1118)  classification: 0.4692 (0.5070)  time: 0.3737  data: 0.1260  max mem: 3278
Epoch: [18]  [ 500/3494]  eta: 0:18:53  lr: 0.0001000  loss: 0.6466 (0.6194)  bbox_regression: 0.1029 (0.1112)  classification: 0.5169 (0.5082)  time: 0.3589  data: 0.1307  max mem: 3278
Epoch: [18]  [ 600/3494]  eta: 0:18:11  lr: 0.0001000  loss: 0.5547 (0.6184)  bbox_regression: 0.1028 (0.1110)  classification: 0.4602 (0.5074)  time: 0.3904  data: 0.1369  max mem: 3278
Epoch: [18]  [ 700/3494]  eta: 0:17:35  lr: 0.0001000  loss: 0.5548 (0.6191)  bbox_regression: 0.1123 (0.1105)  classification: 0.4638 (0.5086)  time: 0.3819  data: 0.1373  max mem: 3278
Epoch: [18]  [ 800/3494]  eta: 0:16:57  lr: 0.0001000  loss: 0.6210 (0.6196)  bbox_regression: 0.1123 (0.1105)  classification: 0.5007 (0.5092)  time: 0.3742  data: 0.1300  max mem: 3278
Epoch: [18]  [ 900/3494]  eta: 0:16:19  lr: 0.0001000  loss: 0.5715 (0.6187)  bbox_regression: 0.0933 (0.1101)  classification: 0.4782 (0.5086)  time: 0.3620  data: 0.1257  max mem: 3278
Epoch: [18]  [1000/3494]  eta: 0:15:41  lr: 0.0001000  loss: 0.6089 (0.6191)  bbox_regression: 0.0995 (0.1101)  classification: 0.4996 (0.5090)  time: 0.3645  data: 0.1257  max mem: 3278
Epoch: [18]  [1100/3494]  eta: 0:15:02  lr: 0.0001000  loss: 0.5866 (0.6201)  bbox_regression: 0.1028 (0.1103)  classification: 0.4784 (0.5098)  time: 0.3612  data: 0.1253  max mem: 3278
Epoch: [18]  [1200/3494]  eta: 0:14:21  lr: 0.0001000  loss: 0.6163 (0.6199)  bbox_regression: 0.0988 (0.1102)  classification: 0.5024 (0.5097)  time: 0.3578  data: 0.1255  max mem: 3278
Epoch: [18]  [1300/3494]  eta: 0:13:42  lr: 0.0001000  loss: 0.6269 (0.6187)  bbox_regression: 0.1038 (0.1098)  classification: 0.5172 (0.5088)  time: 0.3722  data: 0.1336  max mem: 3278
Epoch: [18]  [1400/3494]  eta: 0:13:04  lr: 0.0001000  loss: 0.5745 (0.6184)  bbox_regression: 0.1041 (0.1097)  classification: 0.4680 (0.5087)  time: 0.3728  data: 0.1275  max mem: 3278
Epoch: [18]  [1500/3494]  eta: 0:12:26  lr: 0.0001000  loss: 0.6543 (0.6203)  bbox_regression: 0.1088 (0.1100)  classification: 0.5197 (0.5104)  time: 0.3659  data: 0.1241  max mem: 3278
Epoch: [18]  [1600/3494]  eta: 0:11:49  lr: 0.0001000  loss: 0.5787 (0.6206)  bbox_regression: 0.0979 (0.1099)  classification: 0.4809 (0.5107)  time: 0.3718  data: 0.1318  max mem: 3278
Epoch: [18]  [1700/3494]  eta: 0:11:11  lr: 0.0001000  loss: 0.5870 (0.6203)  bbox_regression: 0.0970 (0.1097)  classification: 0.4919 (0.5106)  time: 0.3590  data: 0.1223  max mem: 3278
Epoch: [18]  [1800/3494]  eta: 0:10:35  lr: 0.0001000  loss: 0.6114 (0.6208)  bbox_regression: 0.0962 (0.1097)  classification: 0.4857 (0.5111)  time: 0.4090  data: 0.1530  max mem: 3278
Epoch: [18]  [1900/3494]  eta: 0:09:57  lr: 0.0001000  loss: 0.5560 (0.6209)  bbox_regression: 0.0928 (0.1096)  classification: 0.4601 (0.5113)  time: 0.3626  data: 0.1287  max mem: 3278
Epoch: [18]  [2000/3494]  eta: 0:09:19  lr: 0.0001000  loss: 0.5850 (0.6203)  bbox_regression: 0.1081 (0.1094)  classification: 0.4949 (0.5108)  time: 0.3593  data: 0.1302  max mem: 3278
Epoch: [18]  [2100/3494]  eta: 0:08:41  lr: 0.0001000  loss: 0.5640 (0.6196)  bbox_regression: 0.0826 (0.1092)  classification: 0.4695 (0.5104)  time: 0.3624  data: 0.1279  max mem: 3278
Epoch: [18]  [2200/3494]  eta: 0:08:04  lr: 0.0001000  loss: 0.6014 (0.6187)  bbox_regression: 0.1087 (0.1090)  classification: 0.5040 (0.5096)  time: 0.3837  data: 0.1410  max mem: 3278
Epoch: [18]  [2300/3494]  eta: 0:07:26  lr: 0.0001000  loss: 0.6282 (0.6187)  bbox_regression: 0.0988 (0.1090)  classification: 0.5137 (0.5097)  time: 0.3868  data: 0.1460  max mem: 3278
Epoch: [18]  [2400/3494]  eta: 0:06:49  lr: 0.0001000  loss: 0.5983 (0.6186)  bbox_regression: 0.0882 (0.1089)  classification: 0.5160 (0.5097)  time: 0.3955  data: 0.1353  max mem: 3278
Epoch: [18]  [2500/3494]  eta: 0:06:12  lr: 0.0001000  loss: 0.7104 (0.6188)  bbox_regression: 0.1111 (0.1089)  classification: 0.5634 (0.5099)  time: 0.3651  data: 0.1222  max mem: 3278
Epoch: [18]  [2600/3494]  eta: 0:05:34  lr: 0.0001000  loss: 0.5714 (0.6184)  bbox_regression: 0.1014 (0.1089)  classification: 0.4585 (0.5096)  time: 0.3779  data: 0.1291  max mem: 3278
Epoch: [18]  [2700/3494]  eta: 0:04:57  lr: 0.0001000  loss: 0.6065 (0.6186)  bbox_regression: 0.0960 (0.1089)  classification: 0.5119 (0.5097)  time: 0.3711  data: 0.1253  max mem: 3278
Epoch: [18]  [2800/3494]  eta: 0:04:19  lr: 0.0001000  loss: 0.6283 (0.6189)  bbox_regression: 0.0958 (0.1090)  classification: 0.4877 (0.5099)  time: 0.3699  data: 0.1344  max mem: 3278
Epoch: [18]  [2900/3494]  eta: 0:03:42  lr: 0.0001000  loss: 0.6050 (0.6184)  bbox_regression: 0.1066 (0.1089)  classification: 0.4860 (0.5096)  time: 0.3710  data: 0.1315  max mem: 3278
Epoch: [18]  [3000/3494]  eta: 0:03:04  lr: 0.0001000  loss: 0.5489 (0.6180)  bbox_regression: 0.0955 (0.1087)  classification: 0.4613 (0.5093)  time: 0.3749  data: 0.1310  max mem: 3278
Epoch: [18]  [3100/3494]  eta: 0:02:27  lr: 0.0001000  loss: 0.6160 (0.6186)  bbox_regression: 0.0987 (0.1089)  classification: 0.5098 (0.5096)  time: 0.3716  data: 0.1289  max mem: 3278
Epoch: [18]  [3200/3494]  eta: 0:01:50  lr: 0.0001000  loss: 0.5673 (0.6181)  bbox_regression: 0.1003 (0.1088)  classification: 0.4535 (0.5094)  time: 0.3930  data: 0.1446  max mem: 3278
Epoch: [18]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.6034 (0.6179)  bbox_regression: 0.0989 (0.1087)  classification: 0.5070 (0.5092)  time: 0.3684  data: 0.1246  max mem: 3278
Epoch: [18]  [3400/3494]  eta: 0:00:35  lr: 0.0001000  loss: 0.5649 (0.6181)  bbox_regression: 0.1050 (0.1087)  classification: 0.4572 (0.5094)  time: 0.3934  data: 0.1290  max mem: 3278
Epoch: [18]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.6599 (0.6182)  bbox_regression: 0.1020 (0.1087)  classification: 0.5589 (0.5095)  time: 0.3717  data: 0.1328  max mem: 3278
Epoch: [18] Total time: 0:21:59 (0.3778 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:22  model_time: 0.1411 (0.1411)  loss: 1.0531 (1.0531)  bbox_regression: 0.1359 (0.1359)  classification: 0.9171 (0.9171)  time: 1.6990  data: 1.5358  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1181 (0.1239)  loss: 0.7750 (0.8956)  bbox_regression: 0.1670 (0.1633)  classification: 0.6168 (0.7323)  time: 0.2662  data: 0.1231  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1128 (0.1223)  loss: 0.7685 (0.8589)  bbox_regression: 0.1432 (0.1543)  classification: 0.6440 (0.7046)  time: 0.2432  data: 0.1105  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1328 (0.1252)  loss: 0.9056 (0.8615)  bbox_regression: 0.1495 (0.1510)  classification: 0.7548 (0.7106)  time: 0.2682  data: 0.1205  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1313 (0.1261)  loss: 0.7256 (0.8582)  bbox_regression: 0.1369 (0.1511)  classification: 0.5974 (0.7071)  time: 0.2699  data: 0.1218  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1287 (0.1263)  loss: 0.7205 (0.8588)  bbox_regression: 0.1196 (0.1512)  classification: 0.6243 (0.7076)  time: 0.2663  data: 0.1222  max mem: 3278
Validation: Total time: 0:01:59 (0.2727 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [19]  [   0/3494]  eta: 2:32:07  lr: 0.0001000  loss: 0.4860 (0.4860)  bbox_regression: 0.0811 (0.0811)  classification: 0.4050 (0.4050)  time: 2.6123  data: 2.3640  max mem: 3278
Epoch: [19]  [ 100/3494]  eta: 0:23:01  lr: 0.0001000  loss: 0.5205 (0.6169)  bbox_regression: 0.0852 (0.1073)  classification: 0.4370 (0.5096)  time: 0.3830  data: 0.1380  max mem: 3278
Epoch: [19]  [ 200/3494]  eta: 0:21:28  lr: 0.0001000  loss: 0.5751 (0.6096)  bbox_regression: 0.0926 (0.1076)  classification: 0.4855 (0.5020)  time: 0.3634  data: 0.1247  max mem: 3278
Epoch: [19]  [ 300/3494]  eta: 0:20:26  lr: 0.0001000  loss: 0.5243 (0.6116)  bbox_regression: 0.1044 (0.1066)  classification: 0.4490 (0.5050)  time: 0.3537  data: 0.1238  max mem: 3278
Epoch: [19]  [ 400/3494]  eta: 0:19:40  lr: 0.0001000  loss: 0.5859 (0.6125)  bbox_regression: 0.1006 (0.1068)  classification: 0.5016 (0.5057)  time: 0.3860  data: 0.1441  max mem: 3278
Epoch: [19]  [ 500/3494]  eta: 0:18:52  lr: 0.0001000  loss: 0.5980 (0.6083)  bbox_regression: 0.1031 (0.1063)  classification: 0.4949 (0.5020)  time: 0.3607  data: 0.1280  max mem: 3278
Epoch: [19]  [ 600/3494]  eta: 0:18:03  lr: 0.0001000  loss: 0.6250 (0.6065)  bbox_regression: 0.1066 (0.1061)  classification: 0.4796 (0.5005)  time: 0.3496  data: 0.1187  max mem: 3278
Epoch: [19]  [ 700/3494]  eta: 0:17:29  lr: 0.0001000  loss: 0.5697 (0.6091)  bbox_regression: 0.0998 (0.1063)  classification: 0.4699 (0.5027)  time: 0.3688  data: 0.1262  max mem: 3278
Epoch: [19]  [ 800/3494]  eta: 0:16:56  lr: 0.0001000  loss: 0.5745 (0.6115)  bbox_regression: 0.1020 (0.1069)  classification: 0.4606 (0.5046)  time: 0.3986  data: 0.1465  max mem: 3278
Epoch: [19]  [ 900/3494]  eta: 0:16:18  lr: 0.0001000  loss: 0.5848 (0.6100)  bbox_regression: 0.0951 (0.1064)  classification: 0.4844 (0.5036)  time: 0.3787  data: 0.1323  max mem: 3278
Epoch: [19]  [1000/3494]  eta: 0:15:42  lr: 0.0001000  loss: 0.5733 (0.6097)  bbox_regression: 0.1056 (0.1066)  classification: 0.4615 (0.5031)  time: 0.3812  data: 0.1260  max mem: 3278
Epoch: [19]  [1100/3494]  eta: 0:15:04  lr: 0.0001000  loss: 0.5889 (0.6089)  bbox_regression: 0.0924 (0.1066)  classification: 0.4960 (0.5023)  time: 0.3891  data: 0.1357  max mem: 3278
Epoch: [19]  [1200/3494]  eta: 0:14:24  lr: 0.0001000  loss: 0.6132 (0.6084)  bbox_regression: 0.0928 (0.1064)  classification: 0.4904 (0.5020)  time: 0.3639  data: 0.1269  max mem: 3278
Epoch: [19]  [1300/3494]  eta: 0:13:44  lr: 0.0001000  loss: 0.5542 (0.6085)  bbox_regression: 0.0967 (0.1066)  classification: 0.4689 (0.5019)  time: 0.3683  data: 0.1364  max mem: 3278
Epoch: [19]  [1400/3494]  eta: 0:13:05  lr: 0.0001000  loss: 0.6212 (0.6085)  bbox_regression: 0.1113 (0.1066)  classification: 0.5014 (0.5019)  time: 0.3671  data: 0.1287  max mem: 3278
Epoch: [19]  [1500/3494]  eta: 0:12:28  lr: 0.0001000  loss: 0.6031 (0.6088)  bbox_regression: 0.1137 (0.1067)  classification: 0.4830 (0.5020)  time: 0.3669  data: 0.1308  max mem: 3278
Epoch: [19]  [1600/3494]  eta: 0:11:51  lr: 0.0001000  loss: 0.5900 (0.6085)  bbox_regression: 0.0976 (0.1068)  classification: 0.4870 (0.5017)  time: 0.3832  data: 0.1335  max mem: 3278
Epoch: [19]  [1700/3494]  eta: 0:11:13  lr: 0.0001000  loss: 0.6052 (0.6075)  bbox_regression: 0.0996 (0.1066)  classification: 0.4983 (0.5009)  time: 0.3728  data: 0.1286  max mem: 3278
Epoch: [19]  [1800/3494]  eta: 0:10:36  lr: 0.0001000  loss: 0.6117 (0.6069)  bbox_regression: 0.1076 (0.1066)  classification: 0.4906 (0.5004)  time: 0.3794  data: 0.1319  max mem: 3278
Epoch: [19]  [1900/3494]  eta: 0:09:58  lr: 0.0001000  loss: 0.5739 (0.6078)  bbox_regression: 0.1012 (0.1068)  classification: 0.4551 (0.5010)  time: 0.3716  data: 0.1340  max mem: 3278
Epoch: [19]  [2000/3494]  eta: 0:09:20  lr: 0.0001000  loss: 0.6366 (0.6088)  bbox_regression: 0.1120 (0.1070)  classification: 0.5268 (0.5017)  time: 0.3684  data: 0.1307  max mem: 3278
Epoch: [19]  [2100/3494]  eta: 0:08:41  lr: 0.0001000  loss: 0.5827 (0.6090)  bbox_regression: 0.1007 (0.1071)  classification: 0.4813 (0.5019)  time: 0.3678  data: 0.1334  max mem: 3278
Epoch: [19]  [2200/3494]  eta: 0:08:04  lr: 0.0001000  loss: 0.5779 (0.6089)  bbox_regression: 0.1042 (0.1070)  classification: 0.4752 (0.5019)  time: 0.3743  data: 0.1315  max mem: 3278
Epoch: [19]  [2300/3494]  eta: 0:07:27  lr: 0.0001000  loss: 0.5739 (0.6087)  bbox_regression: 0.0875 (0.1069)  classification: 0.4971 (0.5018)  time: 0.3694  data: 0.1283  max mem: 3278
Epoch: [19]  [2400/3494]  eta: 0:06:50  lr: 0.0001000  loss: 0.5848 (0.6089)  bbox_regression: 0.0989 (0.1069)  classification: 0.4809 (0.5020)  time: 0.3980  data: 0.1428  max mem: 3278
Epoch: [19]  [2500/3494]  eta: 0:06:13  lr: 0.0001000  loss: 0.6099 (0.6092)  bbox_regression: 0.1145 (0.1070)  classification: 0.5068 (0.5022)  time: 0.4038  data: 0.1395  max mem: 3278
Epoch: [19]  [2600/3494]  eta: 0:05:35  lr: 0.0001000  loss: 0.5362 (0.6087)  bbox_regression: 0.0898 (0.1069)  classification: 0.4497 (0.5017)  time: 0.3934  data: 0.1251  max mem: 3278
Epoch: [19]  [2700/3494]  eta: 0:04:58  lr: 0.0001000  loss: 0.6132 (0.6093)  bbox_regression: 0.0992 (0.1071)  classification: 0.5210 (0.5022)  time: 0.3724  data: 0.1254  max mem: 3278
Epoch: [19]  [2800/3494]  eta: 0:04:20  lr: 0.0001000  loss: 0.6170 (0.6098)  bbox_regression: 0.1158 (0.1072)  classification: 0.5098 (0.5027)  time: 0.3450  data: 0.1108  max mem: 3278
Epoch: [19]  [2900/3494]  eta: 0:03:42  lr: 0.0001000  loss: 0.5958 (0.6095)  bbox_regression: 0.0891 (0.1070)  classification: 0.4760 (0.5025)  time: 0.3674  data: 0.1316  max mem: 3278
Epoch: [19]  [3000/3494]  eta: 0:03:05  lr: 0.0001000  loss: 0.6334 (0.6104)  bbox_regression: 0.1044 (0.1072)  classification: 0.5411 (0.5032)  time: 0.3871  data: 0.1392  max mem: 3278
Epoch: [19]  [3100/3494]  eta: 0:02:27  lr: 0.0001000  loss: 0.6753 (0.6108)  bbox_regression: 0.1081 (0.1072)  classification: 0.5401 (0.5036)  time: 0.3720  data: 0.1272  max mem: 3278
Epoch: [19]  [3200/3494]  eta: 0:01:50  lr: 0.0001000  loss: 0.6093 (0.6109)  bbox_regression: 0.1034 (0.1072)  classification: 0.4900 (0.5037)  time: 0.3870  data: 0.1364  max mem: 3278
Epoch: [19]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.5615 (0.6113)  bbox_regression: 0.0952 (0.1073)  classification: 0.4683 (0.5040)  time: 0.3958  data: 0.1354  max mem: 3278
Epoch: [19]  [3400/3494]  eta: 0:00:35  lr: 0.0001000  loss: 0.5450 (0.6119)  bbox_regression: 0.1000 (0.1075)  classification: 0.4529 (0.5043)  time: 0.3682  data: 0.1285  max mem: 3278
Epoch: [19]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.5834 (0.6121)  bbox_regression: 0.0931 (0.1076)  classification: 0.4918 (0.5045)  time: 0.3703  data: 0.1375  max mem: 3278
Epoch: [19] Total time: 0:22:03 (0.3787 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:55  model_time: 0.1708 (0.1708)  loss: 1.0370 (1.0370)  bbox_regression: 0.1336 (0.1336)  classification: 0.9034 (0.9034)  time: 1.9130  data: 1.7203  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1157 (0.1214)  loss: 0.7755 (0.9013)  bbox_regression: 0.1614 (0.1641)  classification: 0.6242 (0.7372)  time: 0.2591  data: 0.1212  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1175 (0.1217)  loss: 0.7820 (0.8628)  bbox_regression: 0.1392 (0.1542)  classification: 0.6455 (0.7087)  time: 0.2646  data: 0.1223  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1187 (0.1235)  loss: 0.9020 (0.8649)  bbox_regression: 0.1452 (0.1506)  classification: 0.7402 (0.7143)  time: 0.2853  data: 0.1397  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1225 (0.1244)  loss: 0.7509 (0.8610)  bbox_regression: 0.1436 (0.1507)  classification: 0.6230 (0.7103)  time: 0.2614  data: 0.1213  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1327 (0.1247)  loss: 0.7222 (0.8617)  bbox_regression: 0.1205 (0.1508)  classification: 0.6272 (0.7109)  time: 0.2624  data: 0.1166  max mem: 3278
Validation: Total time: 0:01:58 (0.2721 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [20]  [   0/3494]  eta: 1:56:19  lr: 0.0001000  loss: 0.8958 (0.8958)  bbox_regression: 0.1164 (0.1164)  classification: 0.7794 (0.7794)  time: 1.9976  data: 1.7099  max mem: 3278
Epoch: [20]  [ 100/3494]  eta: 0:22:51  lr: 0.0001000  loss: 0.5409 (0.6113)  bbox_regression: 0.0959 (0.1061)  classification: 0.4477 (0.5052)  time: 0.3790  data: 0.1274  max mem: 3278
Epoch: [20]  [ 200/3494]  eta: 0:21:32  lr: 0.0001000  loss: 0.5377 (0.5987)  bbox_regression: 0.0889 (0.1046)  classification: 0.4585 (0.4941)  time: 0.3693  data: 0.1305  max mem: 3278
Epoch: [20]  [ 300/3494]  eta: 0:20:30  lr: 0.0001000  loss: 0.5797 (0.6011)  bbox_regression: 0.1055 (0.1056)  classification: 0.4733 (0.4954)  time: 0.3696  data: 0.1263  max mem: 3278
Epoch: [20]  [ 400/3494]  eta: 0:19:37  lr: 0.0001000  loss: 0.6106 (0.5964)  bbox_regression: 0.1021 (0.1056)  classification: 0.5096 (0.4909)  time: 0.3724  data: 0.1278  max mem: 3278
Epoch: [20]  [ 500/3494]  eta: 0:18:45  lr: 0.0001000  loss: 0.5556 (0.5979)  bbox_regression: 0.0960 (0.1057)  classification: 0.4368 (0.4922)  time: 0.3545  data: 0.1292  max mem: 3278
Epoch: [20]  [ 600/3494]  eta: 0:18:05  lr: 0.0001000  loss: 0.5338 (0.5954)  bbox_regression: 0.0948 (0.1055)  classification: 0.4593 (0.4899)  time: 0.3706  data: 0.1269  max mem: 3278
Epoch: [20]  [ 700/3494]  eta: 0:17:29  lr: 0.0001000  loss: 0.6155 (0.5973)  bbox_regression: 0.1057 (0.1057)  classification: 0.5097 (0.4917)  time: 0.3855  data: 0.1444  max mem: 3278
Epoch: [20]  [ 800/3494]  eta: 0:16:49  lr: 0.0001000  loss: 0.6168 (0.6002)  bbox_regression: 0.1194 (0.1068)  classification: 0.5041 (0.4934)  time: 0.3663  data: 0.1253  max mem: 3278
Epoch: [20]  [ 900/3494]  eta: 0:16:12  lr: 0.0001000  loss: 0.6264 (0.6002)  bbox_regression: 0.1079 (0.1069)  classification: 0.5119 (0.4933)  time: 0.3850  data: 0.1352  max mem: 3278
Epoch: [20]  [1000/3494]  eta: 0:15:34  lr: 0.0001000  loss: 0.5334 (0.6014)  bbox_regression: 0.0944 (0.1073)  classification: 0.4436 (0.4940)  time: 0.3675  data: 0.1328  max mem: 3278
Epoch: [20]  [1100/3494]  eta: 0:14:56  lr: 0.0001000  loss: 0.5885 (0.6022)  bbox_regression: 0.0989 (0.1073)  classification: 0.4838 (0.4949)  time: 0.3733  data: 0.1262  max mem: 3278
Epoch: [20]  [1200/3494]  eta: 0:14:18  lr: 0.0001000  loss: 0.5729 (0.6010)  bbox_regression: 0.0983 (0.1072)  classification: 0.4629 (0.4939)  time: 0.3654  data: 0.1386  max mem: 3278
Epoch: [20]  [1300/3494]  eta: 0:13:39  lr: 0.0001000  loss: 0.5937 (0.6017)  bbox_regression: 0.0973 (0.1071)  classification: 0.4917 (0.4946)  time: 0.3609  data: 0.1328  max mem: 3278
Epoch: [20]  [1400/3494]  eta: 0:13:01  lr: 0.0001000  loss: 0.5435 (0.6025)  bbox_regression: 0.0868 (0.1072)  classification: 0.4565 (0.4953)  time: 0.3794  data: 0.1355  max mem: 3278
Epoch: [20]  [1500/3494]  eta: 0:12:23  lr: 0.0001000  loss: 0.5594 (0.6027)  bbox_regression: 0.0905 (0.1070)  classification: 0.4632 (0.4957)  time: 0.3675  data: 0.1308  max mem: 3278
Epoch: [20]  [1600/3494]  eta: 0:11:45  lr: 0.0001000  loss: 0.6058 (0.6031)  bbox_regression: 0.0950 (0.1068)  classification: 0.5108 (0.4962)  time: 0.3616  data: 0.1216  max mem: 3278
Epoch: [20]  [1700/3494]  eta: 0:11:09  lr: 0.0001000  loss: 0.5687 (0.6028)  bbox_regression: 0.0950 (0.1064)  classification: 0.4751 (0.4964)  time: 0.3823  data: 0.1426  max mem: 3278
Epoch: [20]  [1800/3494]  eta: 0:10:31  lr: 0.0001000  loss: 0.5593 (0.6035)  bbox_regression: 0.1041 (0.1064)  classification: 0.4815 (0.4971)  time: 0.3517  data: 0.1203  max mem: 3278
Epoch: [20]  [1900/3494]  eta: 0:09:53  lr: 0.0001000  loss: 0.5754 (0.6058)  bbox_regression: 0.1091 (0.1072)  classification: 0.4650 (0.4986)  time: 0.3619  data: 0.1291  max mem: 3278
Epoch: [20]  [2000/3494]  eta: 0:09:15  lr: 0.0001000  loss: 0.5941 (0.6061)  bbox_regression: 0.0889 (0.1073)  classification: 0.4824 (0.4988)  time: 0.3657  data: 0.1299  max mem: 3278
Epoch: [20]  [2100/3494]  eta: 0:08:37  lr: 0.0001000  loss: 0.5546 (0.6071)  bbox_regression: 0.0949 (0.1072)  classification: 0.4727 (0.4999)  time: 0.3593  data: 0.1248  max mem: 3278
Epoch: [20]  [2200/3494]  eta: 0:08:00  lr: 0.0001000  loss: 0.5601 (0.6069)  bbox_regression: 0.0921 (0.1072)  classification: 0.4620 (0.4998)  time: 0.3689  data: 0.1274  max mem: 3278
Epoch: [20]  [2300/3494]  eta: 0:07:23  lr: 0.0001000  loss: 0.6042 (0.6073)  bbox_regression: 0.0992 (0.1072)  classification: 0.4938 (0.5001)  time: 0.3913  data: 0.1335  max mem: 3278
Epoch: [20]  [2400/3494]  eta: 0:06:46  lr: 0.0001000  loss: 0.5575 (0.6081)  bbox_regression: 0.1021 (0.1072)  classification: 0.4800 (0.5008)  time: 0.3862  data: 0.1271  max mem: 3278
Epoch: [20]  [2500/3494]  eta: 0:06:09  lr: 0.0001000  loss: 0.6434 (0.6078)  bbox_regression: 0.1220 (0.1070)  classification: 0.5246 (0.5007)  time: 0.3696  data: 0.1272  max mem: 3278
Epoch: [20]  [2600/3494]  eta: 0:05:32  lr: 0.0001000  loss: 0.6544 (0.6075)  bbox_regression: 0.0986 (0.1069)  classification: 0.5509 (0.5006)  time: 0.3930  data: 0.1277  max mem: 3278
Epoch: [20]  [2700/3494]  eta: 0:04:55  lr: 0.0001000  loss: 0.5823 (0.6076)  bbox_regression: 0.1030 (0.1068)  classification: 0.4738 (0.5007)  time: 0.3735  data: 0.1289  max mem: 3278
Epoch: [20]  [2800/3494]  eta: 0:04:17  lr: 0.0001000  loss: 0.5301 (0.6071)  bbox_regression: 0.1019 (0.1068)  classification: 0.4506 (0.5004)  time: 0.3654  data: 0.1313  max mem: 3278
Epoch: [20]  [2900/3494]  eta: 0:03:40  lr: 0.0001000  loss: 0.5667 (0.6071)  bbox_regression: 0.0968 (0.1067)  classification: 0.4661 (0.5005)  time: 0.3825  data: 0.1317  max mem: 3278
Epoch: [20]  [3000/3494]  eta: 0:03:03  lr: 0.0001000  loss: 0.6418 (0.6072)  bbox_regression: 0.1159 (0.1066)  classification: 0.5427 (0.5007)  time: 0.3704  data: 0.1263  max mem: 3278
Epoch: [20]  [3100/3494]  eta: 0:02:26  lr: 0.0001000  loss: 0.5711 (0.6071)  bbox_regression: 0.0949 (0.1066)  classification: 0.4536 (0.5005)  time: 0.3847  data: 0.1367  max mem: 3278
Epoch: [20]  [3200/3494]  eta: 0:01:49  lr: 0.0001000  loss: 0.6513 (0.6075)  bbox_regression: 0.1161 (0.1067)  classification: 0.5381 (0.5008)  time: 0.3640  data: 0.1287  max mem: 3278
Epoch: [20]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.6227 (0.6075)  bbox_regression: 0.0987 (0.1067)  classification: 0.4992 (0.5008)  time: 0.3787  data: 0.1365  max mem: 3278
Epoch: [20]  [3400/3494]  eta: 0:00:34  lr: 0.0001000  loss: 0.5735 (0.6074)  bbox_regression: 0.1023 (0.1068)  classification: 0.4755 (0.5006)  time: 0.3653  data: 0.1291  max mem: 3278
Epoch: [20]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.6517 (0.6079)  bbox_regression: 0.1090 (0.1069)  classification: 0.5267 (0.5010)  time: 0.3658  data: 0.1309  max mem: 3278
Epoch: [20] Total time: 0:21:49 (0.3748 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:07  model_time: 0.2102 (0.2102)  loss: 1.0125 (1.0125)  bbox_regression: 0.1277 (0.1277)  classification: 0.8848 (0.8848)  time: 2.3522  data: 2.1132  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1394 (0.1321)  loss: 0.8150 (0.9032)  bbox_regression: 0.1727 (0.1641)  classification: 0.6309 (0.7391)  time: 0.2829  data: 0.1257  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1173 (0.1274)  loss: 0.7604 (0.8645)  bbox_regression: 0.1402 (0.1543)  classification: 0.6407 (0.7102)  time: 0.2657  data: 0.1253  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1243 (0.1268)  loss: 0.9149 (0.8653)  bbox_regression: 0.1471 (0.1506)  classification: 0.7696 (0.7147)  time: 0.2617  data: 0.1209  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1278 (0.1275)  loss: 0.7468 (0.8611)  bbox_regression: 0.1419 (0.1506)  classification: 0.6245 (0.7104)  time: 0.2647  data: 0.1215  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1386 (0.1281)  loss: 0.7371 (0.8622)  bbox_regression: 0.1282 (0.1508)  classification: 0.6403 (0.7114)  time: 0.2757  data: 0.1214  max mem: 3278
Validation: Total time: 0:02:00 (0.2754 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [21]  [   0/3494]  eta: 2:47:44  lr: 0.0001000  loss: 0.3968 (0.3968)  bbox_regression: 0.0737 (0.0737)  classification: 0.3231 (0.3231)  time: 2.8805  data: 2.6451  max mem: 3278
Epoch: [21]  [ 100/3494]  eta: 0:22:19  lr: 0.0001000  loss: 0.6270 (0.6020)  bbox_regression: 0.1012 (0.1061)  classification: 0.5121 (0.4959)  time: 0.3615  data: 0.1300  max mem: 3278
Epoch: [21]  [ 200/3494]  eta: 0:21:14  lr: 0.0001000  loss: 0.5480 (0.5931)  bbox_regression: 0.0890 (0.1044)  classification: 0.4680 (0.4886)  time: 0.3787  data: 0.1365  max mem: 3278
Epoch: [21]  [ 300/3494]  eta: 0:20:29  lr: 0.0001000  loss: 0.6169 (0.6043)  bbox_regression: 0.0919 (0.1067)  classification: 0.5069 (0.4975)  time: 0.3956  data: 0.1269  max mem: 3278
Epoch: [21]  [ 400/3494]  eta: 0:19:42  lr: 0.0001000  loss: 0.5723 (0.6057)  bbox_regression: 0.1019 (0.1068)  classification: 0.4916 (0.4989)  time: 0.3585  data: 0.1233  max mem: 3278
Epoch: [21]  [ 500/3494]  eta: 0:18:57  lr: 0.0001000  loss: 0.5661 (0.6035)  bbox_regression: 0.0891 (0.1069)  classification: 0.4814 (0.4966)  time: 0.3751  data: 0.1346  max mem: 3278
Epoch: [21]  [ 600/3494]  eta: 0:18:12  lr: 0.0001000  loss: 0.6271 (0.6057)  bbox_regression: 0.1093 (0.1078)  classification: 0.4986 (0.4979)  time: 0.3584  data: 0.1233  max mem: 3278
Epoch: [21]  [ 700/3494]  eta: 0:17:36  lr: 0.0001000  loss: 0.5572 (0.6057)  bbox_regression: 0.0964 (0.1080)  classification: 0.4543 (0.4977)  time: 0.3856  data: 0.1463  max mem: 3278
Epoch: [21]  [ 800/3494]  eta: 0:16:56  lr: 0.0001000  loss: 0.6326 (0.6060)  bbox_regression: 0.1065 (0.1080)  classification: 0.5208 (0.4980)  time: 0.3806  data: 0.1364  max mem: 3278
Epoch: [21]  [ 900/3494]  eta: 0:16:19  lr: 0.0001000  loss: 0.5623 (0.6060)  bbox_regression: 0.1085 (0.1082)  classification: 0.4612 (0.4978)  time: 0.3709  data: 0.1268  max mem: 3278
Epoch: [21]  [1000/3494]  eta: 0:15:41  lr: 0.0001000  loss: 0.6336 (0.6052)  bbox_regression: 0.1032 (0.1076)  classification: 0.5320 (0.4976)  time: 0.3809  data: 0.1405  max mem: 3278
Epoch: [21]  [1100/3494]  eta: 0:15:04  lr: 0.0001000  loss: 0.5937 (0.6054)  bbox_regression: 0.1041 (0.1078)  classification: 0.5014 (0.4977)  time: 0.4063  data: 0.1272  max mem: 3278
Epoch: [21]  [1200/3494]  eta: 0:14:24  lr: 0.0001000  loss: 0.6020 (0.6062)  bbox_regression: 0.1056 (0.1078)  classification: 0.5099 (0.4983)  time: 0.3673  data: 0.1336  max mem: 3278
Epoch: [21]  [1300/3494]  eta: 0:13:43  lr: 0.0001000  loss: 0.6070 (0.6070)  bbox_regression: 0.0920 (0.1076)  classification: 0.5160 (0.4994)  time: 0.3456  data: 0.1139  max mem: 3278
Epoch: [21]  [1400/3494]  eta: 0:13:06  lr: 0.0001000  loss: 0.5687 (0.6065)  bbox_regression: 0.0902 (0.1072)  classification: 0.4787 (0.4994)  time: 0.3840  data: 0.1357  max mem: 3278
Epoch: [21]  [1500/3494]  eta: 0:12:27  lr: 0.0001000  loss: 0.5964 (0.6073)  bbox_regression: 0.0982 (0.1075)  classification: 0.4979 (0.4998)  time: 0.3632  data: 0.1276  max mem: 3278
Epoch: [21]  [1600/3494]  eta: 0:11:50  lr: 0.0001000  loss: 0.6204 (0.6089)  bbox_regression: 0.1051 (0.1078)  classification: 0.4944 (0.5012)  time: 0.3715  data: 0.1261  max mem: 3278
Epoch: [21]  [1700/3494]  eta: 0:11:14  lr: 0.0001000  loss: 0.5805 (0.6077)  bbox_regression: 0.0942 (0.1074)  classification: 0.4978 (0.5003)  time: 0.3910  data: 0.1412  max mem: 3278
Epoch: [21]  [1800/3494]  eta: 0:10:37  lr: 0.0001000  loss: 0.5979 (0.6085)  bbox_regression: 0.1083 (0.1075)  classification: 0.5013 (0.5010)  time: 0.3823  data: 0.1340  max mem: 3278
Epoch: [21]  [1900/3494]  eta: 0:10:00  lr: 0.0001000  loss: 0.5679 (0.6081)  bbox_regression: 0.0928 (0.1075)  classification: 0.4774 (0.5006)  time: 0.3866  data: 0.1372  max mem: 3278
Epoch: [21]  [2000/3494]  eta: 0:09:21  lr: 0.0001000  loss: 0.5973 (0.6081)  bbox_regression: 0.0994 (0.1076)  classification: 0.4898 (0.5006)  time: 0.3719  data: 0.1319  max mem: 3278
Epoch: [21]  [2100/3494]  eta: 0:08:43  lr: 0.0001000  loss: 0.5776 (0.6084)  bbox_regression: 0.1050 (0.1076)  classification: 0.4781 (0.5008)  time: 0.3597  data: 0.1265  max mem: 3278
Epoch: [21]  [2200/3494]  eta: 0:08:05  lr: 0.0001000  loss: 0.6214 (0.6073)  bbox_regression: 0.0980 (0.1074)  classification: 0.5128 (0.4998)  time: 0.3795  data: 0.1315  max mem: 3278
Epoch: [21]  [2300/3494]  eta: 0:07:27  lr: 0.0001000  loss: 0.5840 (0.6070)  bbox_regression: 0.1014 (0.1074)  classification: 0.4771 (0.4997)  time: 0.3699  data: 0.1342  max mem: 3278
Epoch: [21]  [2400/3494]  eta: 0:06:50  lr: 0.0001000  loss: 0.5910 (0.6069)  bbox_regression: 0.0918 (0.1072)  classification: 0.4970 (0.4997)  time: 0.3716  data: 0.1348  max mem: 3278
Epoch: [21]  [2500/3494]  eta: 0:06:13  lr: 0.0001000  loss: 0.5610 (0.6061)  bbox_regression: 0.0905 (0.1070)  classification: 0.4767 (0.4991)  time: 0.3860  data: 0.1402  max mem: 3278
Epoch: [21]  [2600/3494]  eta: 0:05:35  lr: 0.0001000  loss: 0.5648 (0.6055)  bbox_regression: 0.1133 (0.1070)  classification: 0.4602 (0.4985)  time: 0.3779  data: 0.1349  max mem: 3278
Epoch: [21]  [2700/3494]  eta: 0:04:58  lr: 0.0001000  loss: 0.5629 (0.6056)  bbox_regression: 0.0974 (0.1070)  classification: 0.4629 (0.4986)  time: 0.3594  data: 0.1267  max mem: 3278
Epoch: [21]  [2800/3494]  eta: 0:04:20  lr: 0.0001000  loss: 0.5938 (0.6053)  bbox_regression: 0.1090 (0.1071)  classification: 0.4876 (0.4982)  time: 0.3721  data: 0.1303  max mem: 3278
Epoch: [21]  [2900/3494]  eta: 0:03:42  lr: 0.0001000  loss: 0.5435 (0.6043)  bbox_regression: 0.0901 (0.1068)  classification: 0.4502 (0.4975)  time: 0.3836  data: 0.1372  max mem: 3278
Epoch: [21]  [3000/3494]  eta: 0:03:05  lr: 0.0001000  loss: 0.5460 (0.6039)  bbox_regression: 0.0896 (0.1067)  classification: 0.4457 (0.4973)  time: 0.3601  data: 0.1260  max mem: 3278
Epoch: [21]  [3100/3494]  eta: 0:02:27  lr: 0.0001000  loss: 0.5949 (0.6042)  bbox_regression: 0.0972 (0.1067)  classification: 0.4978 (0.4975)  time: 0.3763  data: 0.1322  max mem: 3278
Epoch: [21]  [3200/3494]  eta: 0:01:50  lr: 0.0001000  loss: 0.5498 (0.6041)  bbox_regression: 0.1006 (0.1066)  classification: 0.4567 (0.4975)  time: 0.3730  data: 0.1329  max mem: 3278
Epoch: [21]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.5977 (0.6040)  bbox_regression: 0.1020 (0.1065)  classification: 0.4908 (0.4975)  time: 0.3799  data: 0.1379  max mem: 3278
Epoch: [21]  [3400/3494]  eta: 0:00:35  lr: 0.0001000  loss: 0.5392 (0.6033)  bbox_regression: 0.0987 (0.1065)  classification: 0.4608 (0.4969)  time: 0.3763  data: 0.1330  max mem: 3278
Epoch: [21]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.5819 (0.6033)  bbox_regression: 0.0951 (0.1064)  classification: 0.4873 (0.4969)  time: 0.3767  data: 0.1303  max mem: 3278
Epoch: [21] Total time: 0:22:00 (0.3780 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:50  model_time: 0.1423 (0.1423)  loss: 1.0559 (1.0559)  bbox_regression: 0.1301 (0.1301)  classification: 0.9258 (0.9258)  time: 2.1746  data: 2.0019  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1208 (0.1218)  loss: 0.8039 (0.9037)  bbox_regression: 0.1619 (0.1643)  classification: 0.6176 (0.7394)  time: 0.2805  data: 0.1371  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1411 (0.1272)  loss: 0.7748 (0.8633)  bbox_regression: 0.1420 (0.1539)  classification: 0.6453 (0.7094)  time: 0.2833  data: 0.1244  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1196 (0.1258)  loss: 0.8934 (0.8665)  bbox_regression: 0.1412 (0.1507)  classification: 0.7572 (0.7158)  time: 0.2707  data: 0.1308  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1267 (0.1274)  loss: 0.7610 (0.8621)  bbox_regression: 0.1433 (0.1506)  classification: 0.6367 (0.7115)  time: 0.2765  data: 0.1344  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1338 (0.1279)  loss: 0.7372 (0.8631)  bbox_regression: 0.1224 (0.1508)  classification: 0.6395 (0.7123)  time: 0.2719  data: 0.1214  max mem: 3278
Validation: Total time: 0:02:01 (0.2772 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [22]  [   0/3494]  eta: 2:15:52  lr: 0.0001000  loss: 0.6767 (0.6767)  bbox_regression: 0.0800 (0.0800)  classification: 0.5967 (0.5967)  time: 2.3334  data: 2.0387  max mem: 3278
Epoch: [22]  [ 100/3494]  eta: 0:22:43  lr: 0.0001000  loss: 0.5740 (0.5682)  bbox_regression: 0.0885 (0.0991)  classification: 0.4796 (0.4691)  time: 0.3776  data: 0.1259  max mem: 3278
Epoch: [22]  [ 200/3494]  eta: 0:21:48  lr: 0.0001000  loss: 0.5840 (0.5740)  bbox_regression: 0.0915 (0.1003)  classification: 0.4656 (0.4737)  time: 0.3932  data: 0.1338  max mem: 3278
Epoch: [22]  [ 300/3494]  eta: 0:20:41  lr: 0.0001000  loss: 0.5383 (0.5817)  bbox_regression: 0.0996 (0.1013)  classification: 0.4428 (0.4804)  time: 0.3925  data: 0.1420  max mem: 3278
Epoch: [22]  [ 400/3494]  eta: 0:19:50  lr: 0.0001000  loss: 0.5336 (0.5864)  bbox_regression: 0.0905 (0.1027)  classification: 0.4475 (0.4837)  time: 0.3620  data: 0.1191  max mem: 3278
Epoch: [22]  [ 500/3494]  eta: 0:19:01  lr: 0.0001000  loss: 0.5417 (0.5861)  bbox_regression: 0.0935 (0.1025)  classification: 0.4500 (0.4836)  time: 0.3615  data: 0.1353  max mem: 3278
Epoch: [22]  [ 600/3494]  eta: 0:18:12  lr: 0.0001000  loss: 0.5408 (0.5858)  bbox_regression: 0.0967 (0.1023)  classification: 0.4503 (0.4834)  time: 0.3570  data: 0.1246  max mem: 3278
Epoch: [22]  [ 700/3494]  eta: 0:17:33  lr: 0.0001000  loss: 0.5647 (0.5904)  bbox_regression: 0.1061 (0.1038)  classification: 0.4477 (0.4866)  time: 0.3739  data: 0.1376  max mem: 3278
Epoch: [22]  [ 800/3494]  eta: 0:16:54  lr: 0.0001000  loss: 0.5656 (0.5915)  bbox_regression: 0.1048 (0.1042)  classification: 0.4541 (0.4873)  time: 0.3742  data: 0.1327  max mem: 3278
Epoch: [22]  [ 900/3494]  eta: 0:16:15  lr: 0.0001000  loss: 0.5870 (0.5911)  bbox_regression: 0.0944 (0.1039)  classification: 0.4735 (0.4872)  time: 0.3665  data: 0.1306  max mem: 3278
Epoch: [22]  [1000/3494]  eta: 0:15:38  lr: 0.0001000  loss: 0.6073 (0.5918)  bbox_regression: 0.1064 (0.1040)  classification: 0.4936 (0.4878)  time: 0.3841  data: 0.1346  max mem: 3278
Epoch: [22]  [1100/3494]  eta: 0:15:00  lr: 0.0001000  loss: 0.5456 (0.5919)  bbox_regression: 0.0861 (0.1038)  classification: 0.4679 (0.4881)  time: 0.3857  data: 0.1324  max mem: 3278
Epoch: [22]  [1200/3494]  eta: 0:14:22  lr: 0.0001000  loss: 0.6254 (0.5938)  bbox_regression: 0.1015 (0.1043)  classification: 0.5293 (0.4895)  time: 0.3815  data: 0.1347  max mem: 3278
Epoch: [22]  [1300/3494]  eta: 0:13:43  lr: 0.0001000  loss: 0.5373 (0.5942)  bbox_regression: 0.0862 (0.1046)  classification: 0.4511 (0.4896)  time: 0.3608  data: 0.1254  max mem: 3278
Epoch: [22]  [1400/3494]  eta: 0:13:04  lr: 0.0001000  loss: 0.5870 (0.5945)  bbox_regression: 0.0915 (0.1046)  classification: 0.4729 (0.4899)  time: 0.3714  data: 0.1365  max mem: 3278
Epoch: [22]  [1500/3494]  eta: 0:12:26  lr: 0.0001000  loss: 0.6251 (0.5967)  bbox_regression: 0.1280 (0.1052)  classification: 0.5176 (0.4914)  time: 0.3699  data: 0.1295  max mem: 3278
Epoch: [22]  [1600/3494]  eta: 0:11:48  lr: 0.0001000  loss: 0.5784 (0.5982)  bbox_regression: 0.0972 (0.1058)  classification: 0.4805 (0.4925)  time: 0.3706  data: 0.1254  max mem: 3278
Epoch: [22]  [1700/3494]  eta: 0:11:11  lr: 0.0001000  loss: 0.5977 (0.5987)  bbox_regression: 0.1016 (0.1056)  classification: 0.5024 (0.4931)  time: 0.3776  data: 0.1313  max mem: 3278
Epoch: [22]  [1800/3494]  eta: 0:10:35  lr: 0.0001000  loss: 0.5362 (0.5988)  bbox_regression: 0.0972 (0.1056)  classification: 0.4397 (0.4932)  time: 0.4032  data: 0.1416  max mem: 3278
Epoch: [22]  [1900/3494]  eta: 0:09:58  lr: 0.0001000  loss: 0.6035 (0.5996)  bbox_regression: 0.1059 (0.1056)  classification: 0.4936 (0.4940)  time: 0.3943  data: 0.1360  max mem: 3278
Epoch: [22]  [2000/3494]  eta: 0:09:21  lr: 0.0001000  loss: 0.5718 (0.5987)  bbox_regression: 0.0965 (0.1055)  classification: 0.4636 (0.4932)  time: 0.3638  data: 0.1300  max mem: 3278
Epoch: [22]  [2100/3494]  eta: 0:08:43  lr: 0.0001000  loss: 0.5380 (0.5990)  bbox_regression: 0.0968 (0.1055)  classification: 0.4614 (0.4935)  time: 0.3737  data: 0.1304  max mem: 3278
Epoch: [22]  [2200/3494]  eta: 0:08:05  lr: 0.0001000  loss: 0.6309 (0.5996)  bbox_regression: 0.1028 (0.1057)  classification: 0.5082 (0.4939)  time: 0.3748  data: 0.1337  max mem: 3278
Epoch: [22]  [2300/3494]  eta: 0:07:28  lr: 0.0001000  loss: 0.5214 (0.5991)  bbox_regression: 0.0893 (0.1056)  classification: 0.4360 (0.4935)  time: 0.3784  data: 0.1346  max mem: 3278
Epoch: [22]  [2400/3494]  eta: 0:06:51  lr: 0.0001000  loss: 0.5144 (0.5990)  bbox_regression: 0.0969 (0.1056)  classification: 0.4407 (0.4935)  time: 0.3948  data: 0.1370  max mem: 3278
Epoch: [22]  [2500/3494]  eta: 0:06:14  lr: 0.0001000  loss: 0.6229 (0.5999)  bbox_regression: 0.1053 (0.1056)  classification: 0.5176 (0.4943)  time: 0.3798  data: 0.1392  max mem: 3278
Epoch: [22]  [2600/3494]  eta: 0:05:36  lr: 0.0001000  loss: 0.5571 (0.5993)  bbox_regression: 0.0981 (0.1056)  classification: 0.4577 (0.4938)  time: 0.3688  data: 0.1388  max mem: 3278
Epoch: [22]  [2700/3494]  eta: 0:04:58  lr: 0.0001000  loss: 0.6087 (0.5991)  bbox_regression: 0.0966 (0.1057)  classification: 0.4832 (0.4935)  time: 0.3604  data: 0.1289  max mem: 3278
Epoch: [22]  [2800/3494]  eta: 0:04:20  lr: 0.0001000  loss: 0.6110 (0.5989)  bbox_regression: 0.1088 (0.1057)  classification: 0.4958 (0.4932)  time: 0.3610  data: 0.1321  max mem: 3278
Epoch: [22]  [2900/3494]  eta: 0:03:42  lr: 0.0001000  loss: 0.5277 (0.5992)  bbox_regression: 0.0883 (0.1057)  classification: 0.4355 (0.4936)  time: 0.3676  data: 0.1348  max mem: 3278
Epoch: [22]  [3000/3494]  eta: 0:03:05  lr: 0.0001000  loss: 0.5309 (0.5994)  bbox_regression: 0.1013 (0.1057)  classification: 0.4443 (0.4937)  time: 0.3719  data: 0.1269  max mem: 3278
Epoch: [22]  [3100/3494]  eta: 0:02:27  lr: 0.0001000  loss: 0.5739 (0.5994)  bbox_regression: 0.0863 (0.1057)  classification: 0.4835 (0.4937)  time: 0.3764  data: 0.1332  max mem: 3278
Epoch: [22]  [3200/3494]  eta: 0:01:50  lr: 0.0001000  loss: 0.6407 (0.5996)  bbox_regression: 0.1007 (0.1057)  classification: 0.5118 (0.4938)  time: 0.3815  data: 0.1337  max mem: 3278
Epoch: [22]  [3300/3494]  eta: 0:01:12  lr: 0.0001000  loss: 0.6006 (0.5997)  bbox_regression: 0.0973 (0.1058)  classification: 0.5153 (0.4940)  time: 0.3798  data: 0.1314  max mem: 3278
Epoch: [22]  [3400/3494]  eta: 0:00:35  lr: 0.0001000  loss: 0.6494 (0.6009)  bbox_regression: 0.1089 (0.1060)  classification: 0.5388 (0.4950)  time: 0.3969  data: 0.1406  max mem: 3278
Epoch: [22]  [3493/3494]  eta: 0:00:00  lr: 0.0001000  loss: 0.5583 (0.6006)  bbox_regression: 0.0975 (0.1059)  classification: 0.4548 (0.4947)  time: 0.3703  data: 0.1294  max mem: 3278
Epoch: [22] Total time: 0:22:03 (0.3788 s / it)
Epoch 00023: reducing learning rate of group 0 to 1.0000e-05.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:56  model_time: 0.1309 (0.1309)  loss: 1.0504 (1.0504)  bbox_regression: 0.1262 (0.1262)  classification: 0.9242 (0.9242)  time: 1.7764  data: 1.6020  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1171 (0.1205)  loss: 0.8066 (0.9071)  bbox_regression: 0.1684 (0.1640)  classification: 0.6382 (0.7431)  time: 0.2630  data: 0.1252  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1219 (0.1231)  loss: 0.7738 (0.8679)  bbox_regression: 0.1440 (0.1542)  classification: 0.6460 (0.7138)  time: 0.2703  data: 0.1286  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1266 (0.1254)  loss: 0.8752 (0.8693)  bbox_regression: 0.1466 (0.1508)  classification: 0.7727 (0.7185)  time: 0.2846  data: 0.1402  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1243 (0.1265)  loss: 0.7529 (0.8653)  bbox_regression: 0.1406 (0.1510)  classification: 0.6108 (0.7143)  time: 0.2761  data: 0.1313  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1322 (0.1264)  loss: 0.7418 (0.8662)  bbox_regression: 0.1281 (0.1511)  classification: 0.6440 (0.7151)  time: 0.2637  data: 0.1204  max mem: 3278
Validation: Total time: 0:01:59 (0.2739 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [23]  [   0/3494]  eta: 2:53:42  lr: 0.0000100  loss: 0.6476 (0.6476)  bbox_regression: 0.1283 (0.1283)  classification: 0.5194 (0.5194)  time: 2.9830  data: 2.7422  max mem: 3278
Epoch: [23]  [ 100/3494]  eta: 0:22:40  lr: 0.0000100  loss: 0.5092 (0.5918)  bbox_regression: 0.0847 (0.1020)  classification: 0.4267 (0.4898)  time: 0.3750  data: 0.1346  max mem: 3278
Epoch: [23]  [ 200/3494]  eta: 0:21:31  lr: 0.0000100  loss: 0.5674 (0.5899)  bbox_regression: 0.0942 (0.1031)  classification: 0.4622 (0.4868)  time: 0.3763  data: 0.1310  max mem: 3278
Epoch: [23]  [ 300/3494]  eta: 0:20:50  lr: 0.0000100  loss: 0.6114 (0.5946)  bbox_regression: 0.1089 (0.1051)  classification: 0.5123 (0.4895)  time: 0.3892  data: 0.1378  max mem: 3278
Epoch: [23]  [ 400/3494]  eta: 0:20:01  lr: 0.0000100  loss: 0.5316 (0.5906)  bbox_regression: 0.0909 (0.1041)  classification: 0.4399 (0.4865)  time: 0.3750  data: 0.1300  max mem: 3278
Epoch: [23]  [ 500/3494]  eta: 0:19:06  lr: 0.0000100  loss: 0.5853 (0.5922)  bbox_regression: 0.0915 (0.1053)  classification: 0.4981 (0.4869)  time: 0.3604  data: 0.1258  max mem: 3278
Epoch: [23]  [ 600/3494]  eta: 0:18:18  lr: 0.0000100  loss: 0.5486 (0.5920)  bbox_regression: 0.0939 (0.1054)  classification: 0.4626 (0.4866)  time: 0.3781  data: 0.1367  max mem: 3278
Epoch: [23]  [ 700/3494]  eta: 0:17:36  lr: 0.0000100  loss: 0.5531 (0.5908)  bbox_regression: 0.1016 (0.1055)  classification: 0.4538 (0.4853)  time: 0.3721  data: 0.1395  max mem: 3278
Epoch: [23]  [ 800/3494]  eta: 0:16:56  lr: 0.0000100  loss: 0.5526 (0.5896)  bbox_regression: 0.0958 (0.1051)  classification: 0.4452 (0.4845)  time: 0.3598  data: 0.1250  max mem: 3278
Epoch: [23]  [ 900/3494]  eta: 0:16:17  lr: 0.0000100  loss: 0.5764 (0.5896)  bbox_regression: 0.0972 (0.1048)  classification: 0.4747 (0.4847)  time: 0.3606  data: 0.1255  max mem: 3278
Epoch: [23]  [1000/3494]  eta: 0:15:41  lr: 0.0000100  loss: 0.6152 (0.5896)  bbox_regression: 0.1006 (0.1050)  classification: 0.4955 (0.4846)  time: 0.3725  data: 0.1269  max mem: 3278
Epoch: [23]  [1100/3494]  eta: 0:15:03  lr: 0.0000100  loss: 0.5299 (0.5904)  bbox_regression: 0.0951 (0.1051)  classification: 0.4445 (0.4853)  time: 0.3608  data: 0.1291  max mem: 3278
Epoch: [23]  [1200/3494]  eta: 0:14:25  lr: 0.0000100  loss: 0.5723 (0.5896)  bbox_regression: 0.0852 (0.1049)  classification: 0.4767 (0.4847)  time: 0.3704  data: 0.1322  max mem: 3278
Epoch: [23]  [1300/3494]  eta: 0:13:45  lr: 0.0000100  loss: 0.5487 (0.5899)  bbox_regression: 0.0869 (0.1048)  classification: 0.4585 (0.4851)  time: 0.3655  data: 0.1365  max mem: 3278
Epoch: [23]  [1400/3494]  eta: 0:13:05  lr: 0.0000100  loss: 0.5798 (0.5898)  bbox_regression: 0.1024 (0.1047)  classification: 0.4964 (0.4852)  time: 0.3598  data: 0.1233  max mem: 3278
Epoch: [23]  [1500/3494]  eta: 0:12:28  lr: 0.0000100  loss: 0.5331 (0.5894)  bbox_regression: 0.0927 (0.1046)  classification: 0.4615 (0.4848)  time: 0.3989  data: 0.1405  max mem: 3278
Epoch: [23]  [1600/3494]  eta: 0:11:51  lr: 0.0000100  loss: 0.5446 (0.5895)  bbox_regression: 0.0955 (0.1045)  classification: 0.4526 (0.4850)  time: 0.3776  data: 0.1319  max mem: 3278
Epoch: [23]  [1700/3494]  eta: 0:11:14  lr: 0.0000100  loss: 0.6109 (0.5903)  bbox_regression: 0.0952 (0.1045)  classification: 0.5217 (0.4858)  time: 0.3715  data: 0.1307  max mem: 3278
Epoch: [23]  [1800/3494]  eta: 0:10:36  lr: 0.0000100  loss: 0.5927 (0.5900)  bbox_regression: 0.0986 (0.1043)  classification: 0.5015 (0.4857)  time: 0.3577  data: 0.1237  max mem: 3278
Epoch: [23]  [1900/3494]  eta: 0:09:59  lr: 0.0000100  loss: 0.5887 (0.5901)  bbox_regression: 0.0931 (0.1043)  classification: 0.5091 (0.4857)  time: 0.3884  data: 0.1302  max mem: 3278
Epoch: [23]  [2000/3494]  eta: 0:09:20  lr: 0.0000100  loss: 0.5787 (0.5899)  bbox_regression: 0.0960 (0.1043)  classification: 0.4863 (0.4856)  time: 0.3564  data: 0.1244  max mem: 3278
Epoch: [23]  [2100/3494]  eta: 0:08:41  lr: 0.0000100  loss: 0.5766 (0.5894)  bbox_regression: 0.0947 (0.1041)  classification: 0.4856 (0.4853)  time: 0.3667  data: 0.1295  max mem: 3278
Epoch: [23]  [2200/3494]  eta: 0:08:03  lr: 0.0000100  loss: 0.5730 (0.5899)  bbox_regression: 0.0882 (0.1042)  classification: 0.4791 (0.4858)  time: 0.3779  data: 0.1337  max mem: 3278
Epoch: [23]  [2300/3494]  eta: 0:07:26  lr: 0.0000100  loss: 0.5394 (0.5898)  bbox_regression: 0.0910 (0.1042)  classification: 0.4614 (0.4857)  time: 0.3774  data: 0.1272  max mem: 3278
Epoch: [23]  [2400/3494]  eta: 0:06:49  lr: 0.0000100  loss: 0.6382 (0.5899)  bbox_regression: 0.1080 (0.1042)  classification: 0.5104 (0.4857)  time: 0.3806  data: 0.1356  max mem: 3278
Epoch: [23]  [2500/3494]  eta: 0:06:12  lr: 0.0000100  loss: 0.5522 (0.5890)  bbox_regression: 0.1007 (0.1040)  classification: 0.4494 (0.4850)  time: 0.3944  data: 0.1308  max mem: 3278
Epoch: [23]  [2600/3494]  eta: 0:05:35  lr: 0.0000100  loss: 0.5393 (0.5893)  bbox_regression: 0.1004 (0.1041)  classification: 0.4510 (0.4852)  time: 0.3575  data: 0.1223  max mem: 3278
Epoch: [23]  [2700/3494]  eta: 0:04:57  lr: 0.0000100  loss: 0.6051 (0.5894)  bbox_regression: 0.1008 (0.1042)  classification: 0.4778 (0.4852)  time: 0.3634  data: 0.1320  max mem: 3278
Epoch: [23]  [2800/3494]  eta: 0:04:19  lr: 0.0000100  loss: 0.5545 (0.5890)  bbox_regression: 0.0921 (0.1040)  classification: 0.4776 (0.4849)  time: 0.3585  data: 0.1303  max mem: 3278
Epoch: [23]  [2900/3494]  eta: 0:03:42  lr: 0.0000100  loss: 0.5968 (0.5893)  bbox_regression: 0.0908 (0.1040)  classification: 0.4886 (0.4853)  time: 0.3657  data: 0.1259  max mem: 3278
Epoch: [23]  [3000/3494]  eta: 0:03:04  lr: 0.0000100  loss: 0.5469 (0.5894)  bbox_regression: 0.0989 (0.1041)  classification: 0.4504 (0.4853)  time: 0.3714  data: 0.1290  max mem: 3278
Epoch: [23]  [3100/3494]  eta: 0:02:27  lr: 0.0000100  loss: 0.5657 (0.5891)  bbox_regression: 0.0929 (0.1041)  classification: 0.4742 (0.4851)  time: 0.3733  data: 0.1304  max mem: 3278
Epoch: [23]  [3200/3494]  eta: 0:01:49  lr: 0.0000100  loss: 0.5925 (0.5892)  bbox_regression: 0.0992 (0.1041)  classification: 0.4789 (0.4851)  time: 0.3587  data: 0.1218  max mem: 3278
Epoch: [23]  [3300/3494]  eta: 0:01:12  lr: 0.0000100  loss: 0.5922 (0.5890)  bbox_regression: 0.1018 (0.1040)  classification: 0.4901 (0.4850)  time: 0.3958  data: 0.1341  max mem: 3278
Epoch: [23]  [3400/3494]  eta: 0:00:35  lr: 0.0000100  loss: 0.5431 (0.5891)  bbox_regression: 0.0979 (0.1041)  classification: 0.4350 (0.4850)  time: 0.3881  data: 0.1433  max mem: 3278
Epoch: [23]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5466 (0.5891)  bbox_regression: 0.0934 (0.1041)  classification: 0.4517 (0.4850)  time: 0.3734  data: 0.1350  max mem: 3278
Epoch: [23] Total time: 0:21:55 (0.3766 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:52  model_time: 0.1348 (0.1348)  loss: 1.0469 (1.0469)  bbox_regression: 0.1277 (0.1277)  classification: 0.9192 (0.9192)  time: 2.4536  data: 2.2942  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1128 (0.1203)  loss: 0.7786 (0.8995)  bbox_regression: 0.1673 (0.1626)  classification: 0.6187 (0.7369)  time: 0.2528  data: 0.1193  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1170 (0.1199)  loss: 0.7631 (0.8620)  bbox_regression: 0.1420 (0.1533)  classification: 0.6504 (0.7087)  time: 0.2555  data: 0.1208  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1148 (0.1210)  loss: 0.8899 (0.8641)  bbox_regression: 0.1446 (0.1500)  classification: 0.7623 (0.7142)  time: 0.2648  data: 0.1225  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1394 (0.1233)  loss: 0.7342 (0.8601)  bbox_regression: 0.1392 (0.1500)  classification: 0.6098 (0.7101)  time: 0.2731  data: 0.1236  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1365 (0.1238)  loss: 0.7308 (0.8611)  bbox_regression: 0.1230 (0.1502)  classification: 0.6335 (0.7109)  time: 0.2798  data: 0.1333  max mem: 3278
Validation: Total time: 0:01:58 (0.2720 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [24]  [   0/3494]  eta: 2:45:44  lr: 0.0000100  loss: 0.5240 (0.5240)  bbox_regression: 0.0779 (0.0779)  classification: 0.4462 (0.4462)  time: 2.8461  data: 2.5392  max mem: 3278
Epoch: [24]  [ 100/3494]  eta: 0:22:36  lr: 0.0000100  loss: 0.5372 (0.5897)  bbox_regression: 0.0910 (0.1069)  classification: 0.4524 (0.4828)  time: 0.3620  data: 0.1263  max mem: 3278
Epoch: [24]  [ 200/3494]  eta: 0:21:24  lr: 0.0000100  loss: 0.5068 (0.5881)  bbox_regression: 0.0928 (0.1060)  classification: 0.4110 (0.4821)  time: 0.3779  data: 0.1310  max mem: 3278
Epoch: [24]  [ 300/3494]  eta: 0:20:36  lr: 0.0000100  loss: 0.5306 (0.5935)  bbox_regression: 0.0934 (0.1075)  classification: 0.4586 (0.4861)  time: 0.3785  data: 0.1351  max mem: 3278
Epoch: [24]  [ 400/3494]  eta: 0:19:50  lr: 0.0000100  loss: 0.5330 (0.5871)  bbox_regression: 0.0908 (0.1057)  classification: 0.4430 (0.4814)  time: 0.3879  data: 0.1267  max mem: 3278
Epoch: [24]  [ 500/3494]  eta: 0:19:04  lr: 0.0000100  loss: 0.6209 (0.5880)  bbox_regression: 0.1018 (0.1050)  classification: 0.4892 (0.4831)  time: 0.3667  data: 0.1338  max mem: 3278
Epoch: [24]  [ 600/3494]  eta: 0:18:17  lr: 0.0000100  loss: 0.5812 (0.5876)  bbox_regression: 0.0978 (0.1051)  classification: 0.4609 (0.4825)  time: 0.3728  data: 0.1315  max mem: 3278
Epoch: [24]  [ 700/3494]  eta: 0:17:39  lr: 0.0000100  loss: 0.5715 (0.5878)  bbox_regression: 0.0968 (0.1048)  classification: 0.4649 (0.4831)  time: 0.3983  data: 0.1508  max mem: 3278
Epoch: [24]  [ 800/3494]  eta: 0:17:03  lr: 0.0000100  loss: 0.5289 (0.5873)  bbox_regression: 0.0916 (0.1046)  classification: 0.4372 (0.4827)  time: 0.3680  data: 0.1233  max mem: 3278
Epoch: [24]  [ 900/3494]  eta: 0:16:23  lr: 0.0000100  loss: 0.5957 (0.5874)  bbox_regression: 0.0948 (0.1045)  classification: 0.5046 (0.4829)  time: 0.3487  data: 0.1193  max mem: 3278
Epoch: [24]  [1000/3494]  eta: 0:15:45  lr: 0.0000100  loss: 0.5498 (0.5882)  bbox_regression: 0.0931 (0.1047)  classification: 0.4630 (0.4835)  time: 0.4005  data: 0.1246  max mem: 3278
Epoch: [24]  [1100/3494]  eta: 0:15:04  lr: 0.0000100  loss: 0.5978 (0.5859)  bbox_regression: 0.0995 (0.1043)  classification: 0.5063 (0.4817)  time: 0.3656  data: 0.1356  max mem: 3278
Epoch: [24]  [1200/3494]  eta: 0:14:25  lr: 0.0000100  loss: 0.6185 (0.5875)  bbox_regression: 0.1019 (0.1043)  classification: 0.4812 (0.4832)  time: 0.3824  data: 0.1338  max mem: 3278
Epoch: [24]  [1300/3494]  eta: 0:13:46  lr: 0.0000100  loss: 0.6072 (0.5892)  bbox_regression: 0.0977 (0.1043)  classification: 0.4701 (0.4849)  time: 0.3777  data: 0.1460  max mem: 3278
Epoch: [24]  [1400/3494]  eta: 0:13:06  lr: 0.0000100  loss: 0.5365 (0.5881)  bbox_regression: 0.0963 (0.1042)  classification: 0.4381 (0.4839)  time: 0.3798  data: 0.1351  max mem: 3278
Epoch: [24]  [1500/3494]  eta: 0:12:29  lr: 0.0000100  loss: 0.5490 (0.5885)  bbox_regression: 0.1036 (0.1044)  classification: 0.4551 (0.4841)  time: 0.3562  data: 0.1224  max mem: 3278
Epoch: [24]  [1600/3494]  eta: 0:11:51  lr: 0.0000100  loss: 0.5448 (0.5890)  bbox_regression: 0.0996 (0.1045)  classification: 0.4454 (0.4845)  time: 0.3697  data: 0.1276  max mem: 3278
Epoch: [24]  [1700/3494]  eta: 0:11:14  lr: 0.0000100  loss: 0.5535 (0.5899)  bbox_regression: 0.0927 (0.1046)  classification: 0.4701 (0.4853)  time: 0.3820  data: 0.1371  max mem: 3278
Epoch: [24]  [1800/3494]  eta: 0:10:37  lr: 0.0000100  loss: 0.5695 (0.5897)  bbox_regression: 0.0970 (0.1044)  classification: 0.4462 (0.4853)  time: 0.3854  data: 0.1388  max mem: 3278
Epoch: [24]  [1900/3494]  eta: 0:10:00  lr: 0.0000100  loss: 0.5692 (0.5891)  bbox_regression: 0.0952 (0.1043)  classification: 0.4588 (0.4848)  time: 0.3896  data: 0.1261  max mem: 3278
Epoch: [24]  [2000/3494]  eta: 0:09:21  lr: 0.0000100  loss: 0.4905 (0.5878)  bbox_regression: 0.0969 (0.1041)  classification: 0.4099 (0.4837)  time: 0.3668  data: 0.1292  max mem: 3278
Epoch: [24]  [2100/3494]  eta: 0:08:43  lr: 0.0000100  loss: 0.5701 (0.5875)  bbox_regression: 0.0977 (0.1041)  classification: 0.4724 (0.4834)  time: 0.3657  data: 0.1342  max mem: 3278
Epoch: [24]  [2200/3494]  eta: 0:08:05  lr: 0.0000100  loss: 0.5418 (0.5871)  bbox_regression: 0.0878 (0.1039)  classification: 0.4595 (0.4832)  time: 0.3826  data: 0.1313  max mem: 3278
Epoch: [24]  [2300/3494]  eta: 0:07:28  lr: 0.0000100  loss: 0.4802 (0.5870)  bbox_regression: 0.0763 (0.1039)  classification: 0.3838 (0.4832)  time: 0.3682  data: 0.1352  max mem: 3278
Epoch: [24]  [2400/3494]  eta: 0:06:51  lr: 0.0000100  loss: 0.5705 (0.5872)  bbox_regression: 0.1002 (0.1039)  classification: 0.4899 (0.4833)  time: 0.3851  data: 0.1377  max mem: 3278
Epoch: [24]  [2500/3494]  eta: 0:06:14  lr: 0.0000100  loss: 0.5978 (0.5868)  bbox_regression: 0.0933 (0.1038)  classification: 0.5010 (0.4830)  time: 0.3946  data: 0.1420  max mem: 3278
Epoch: [24]  [2600/3494]  eta: 0:05:36  lr: 0.0000100  loss: 0.6108 (0.5866)  bbox_regression: 0.0936 (0.1037)  classification: 0.5079 (0.4829)  time: 0.3716  data: 0.1337  max mem: 3278
Epoch: [24]  [2700/3494]  eta: 0:04:58  lr: 0.0000100  loss: 0.5452 (0.5863)  bbox_regression: 0.0905 (0.1036)  classification: 0.4421 (0.4827)  time: 0.3825  data: 0.1411  max mem: 3278
Epoch: [24]  [2800/3494]  eta: 0:04:20  lr: 0.0000100  loss: 0.5638 (0.5869)  bbox_regression: 0.1017 (0.1037)  classification: 0.4604 (0.4832)  time: 0.3457  data: 0.1178  max mem: 3278
Epoch: [24]  [2900/3494]  eta: 0:03:42  lr: 0.0000100  loss: 0.5568 (0.5862)  bbox_regression: 0.0927 (0.1036)  classification: 0.4530 (0.4825)  time: 0.3747  data: 0.1347  max mem: 3278
Epoch: [24]  [3000/3494]  eta: 0:03:05  lr: 0.0000100  loss: 0.5818 (0.5866)  bbox_regression: 0.0913 (0.1036)  classification: 0.4769 (0.4830)  time: 0.3705  data: 0.1288  max mem: 3278
Epoch: [24]  [3100/3494]  eta: 0:02:27  lr: 0.0000100  loss: 0.6027 (0.5873)  bbox_regression: 0.0883 (0.1038)  classification: 0.5077 (0.4835)  time: 0.3779  data: 0.1335  max mem: 3278
Epoch: [24]  [3200/3494]  eta: 0:01:50  lr: 0.0000100  loss: 0.5953 (0.5875)  bbox_regression: 0.1027 (0.1039)  classification: 0.4919 (0.4836)  time: 0.3759  data: 0.1330  max mem: 3278
Epoch: [24]  [3300/3494]  eta: 0:01:12  lr: 0.0000100  loss: 0.5546 (0.5873)  bbox_regression: 0.1008 (0.1037)  classification: 0.4643 (0.4836)  time: 0.4130  data: 0.1389  max mem: 3278
Epoch: [24]  [3400/3494]  eta: 0:00:35  lr: 0.0000100  loss: 0.5650 (0.5874)  bbox_regression: 0.0927 (0.1038)  classification: 0.4650 (0.4836)  time: 0.3524  data: 0.1209  max mem: 3278
Epoch: [24]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5424 (0.5871)  bbox_regression: 0.0942 (0.1037)  classification: 0.4465 (0.4834)  time: 0.3585  data: 0.1316  max mem: 3278
Epoch: [24] Total time: 0:21:58 (0.3774 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:45  model_time: 0.1267 (0.1267)  loss: 1.0479 (1.0479)  bbox_regression: 0.1275 (0.1275)  classification: 0.9204 (0.9204)  time: 2.3017  data: 2.1546  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1233 (0.1221)  loss: 0.7615 (0.8997)  bbox_regression: 0.1652 (0.1625)  classification: 0.6065 (0.7372)  time: 0.2681  data: 0.1254  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1197 (0.1233)  loss: 0.7712 (0.8620)  bbox_regression: 0.1413 (0.1531)  classification: 0.6496 (0.7089)  time: 0.2675  data: 0.1266  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1232 (0.1238)  loss: 0.8947 (0.8646)  bbox_regression: 0.1445 (0.1499)  classification: 0.7629 (0.7147)  time: 0.2723  data: 0.1278  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1330 (0.1260)  loss: 0.7335 (0.8605)  bbox_regression: 0.1416 (0.1499)  classification: 0.6138 (0.7106)  time: 0.2743  data: 0.1259  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1275 (0.1267)  loss: 0.7348 (0.8615)  bbox_regression: 0.1216 (0.1501)  classification: 0.6374 (0.7114)  time: 0.2747  data: 0.1249  max mem: 3278
Validation: Total time: 0:01:59 (0.2740 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [25]  [   0/3494]  eta: 2:42:15  lr: 0.0000100  loss: 0.5513 (0.5513)  bbox_regression: 0.1030 (0.1030)  classification: 0.4483 (0.4483)  time: 2.7863  data: 2.5333  max mem: 3278
Epoch: [25]  [ 100/3494]  eta: 0:22:19  lr: 0.0000100  loss: 0.6211 (0.5799)  bbox_regression: 0.0922 (0.1021)  classification: 0.5189 (0.4778)  time: 0.3752  data: 0.1341  max mem: 3278
Epoch: [25]  [ 200/3494]  eta: 0:21:12  lr: 0.0000100  loss: 0.5433 (0.5774)  bbox_regression: 0.0999 (0.1036)  classification: 0.4592 (0.4738)  time: 0.3714  data: 0.1241  max mem: 3278
Epoch: [25]  [ 300/3494]  eta: 0:20:32  lr: 0.0000100  loss: 0.5678 (0.5787)  bbox_regression: 0.0977 (0.1035)  classification: 0.4578 (0.4752)  time: 0.3768  data: 0.1299  max mem: 3278
Epoch: [25]  [ 400/3494]  eta: 0:19:43  lr: 0.0000100  loss: 0.5656 (0.5808)  bbox_regression: 0.1070 (0.1032)  classification: 0.4733 (0.4776)  time: 0.3857  data: 0.1322  max mem: 3278
Epoch: [25]  [ 500/3494]  eta: 0:19:01  lr: 0.0000100  loss: 0.4861 (0.5798)  bbox_regression: 0.0873 (0.1030)  classification: 0.4169 (0.4769)  time: 0.3763  data: 0.1340  max mem: 3278
Epoch: [25]  [ 600/3494]  eta: 0:18:16  lr: 0.0000100  loss: 0.5347 (0.5845)  bbox_regression: 0.0836 (0.1041)  classification: 0.4171 (0.4803)  time: 0.3678  data: 0.1323  max mem: 3278
Epoch: [25]  [ 700/3494]  eta: 0:17:34  lr: 0.0000100  loss: 0.5738 (0.5852)  bbox_regression: 0.1014 (0.1042)  classification: 0.4633 (0.4810)  time: 0.3845  data: 0.1473  max mem: 3278
Epoch: [25]  [ 800/3494]  eta: 0:17:00  lr: 0.0000100  loss: 0.5914 (0.5875)  bbox_regression: 0.1075 (0.1045)  classification: 0.4658 (0.4830)  time: 0.4031  data: 0.1531  max mem: 3278
Epoch: [25]  [ 900/3494]  eta: 0:16:21  lr: 0.0000100  loss: 0.5615 (0.5895)  bbox_regression: 0.0904 (0.1046)  classification: 0.4832 (0.4848)  time: 0.3737  data: 0.1282  max mem: 3278
Epoch: [25]  [1000/3494]  eta: 0:15:46  lr: 0.0000100  loss: 0.5498 (0.5875)  bbox_regression: 0.0985 (0.1040)  classification: 0.4448 (0.4835)  time: 0.3852  data: 0.1355  max mem: 3278
Epoch: [25]  [1100/3494]  eta: 0:15:08  lr: 0.0000100  loss: 0.5653 (0.5879)  bbox_regression: 0.1043 (0.1042)  classification: 0.4722 (0.4838)  time: 0.4157  data: 0.1499  max mem: 3278
Epoch: [25]  [1200/3494]  eta: 0:14:28  lr: 0.0000100  loss: 0.5793 (0.5889)  bbox_regression: 0.1070 (0.1045)  classification: 0.4756 (0.4844)  time: 0.3757  data: 0.1320  max mem: 3278
Epoch: [25]  [1300/3494]  eta: 0:13:49  lr: 0.0000100  loss: 0.5979 (0.5894)  bbox_regression: 0.0916 (0.1047)  classification: 0.5088 (0.4847)  time: 0.3742  data: 0.1328  max mem: 3278
Epoch: [25]  [1400/3494]  eta: 0:13:08  lr: 0.0000100  loss: 0.5490 (0.5892)  bbox_regression: 0.0944 (0.1046)  classification: 0.4499 (0.4845)  time: 0.3779  data: 0.1299  max mem: 3278
Epoch: [25]  [1500/3494]  eta: 0:12:31  lr: 0.0000100  loss: 0.5317 (0.5897)  bbox_regression: 0.0926 (0.1046)  classification: 0.4533 (0.4851)  time: 0.3735  data: 0.1247  max mem: 3278
Epoch: [25]  [1600/3494]  eta: 0:11:53  lr: 0.0000100  loss: 0.6028 (0.5891)  bbox_regression: 0.1010 (0.1043)  classification: 0.4770 (0.4848)  time: 0.3799  data: 0.1375  max mem: 3278
Epoch: [25]  [1700/3494]  eta: 0:11:16  lr: 0.0000100  loss: 0.5175 (0.5889)  bbox_regression: 0.0843 (0.1043)  classification: 0.4316 (0.4846)  time: 0.4041  data: 0.1425  max mem: 3278
Epoch: [25]  [1800/3494]  eta: 0:10:39  lr: 0.0000100  loss: 0.5474 (0.5885)  bbox_regression: 0.1024 (0.1039)  classification: 0.4464 (0.4845)  time: 0.4090  data: 0.1348  max mem: 3278
Epoch: [25]  [1900/3494]  eta: 0:10:01  lr: 0.0000100  loss: 0.5869 (0.5892)  bbox_regression: 0.1030 (0.1042)  classification: 0.4786 (0.4850)  time: 0.3928  data: 0.1237  max mem: 3278
Epoch: [25]  [2000/3494]  eta: 0:09:23  lr: 0.0000100  loss: 0.6089 (0.5884)  bbox_regression: 0.1030 (0.1040)  classification: 0.5134 (0.4845)  time: 0.3630  data: 0.1272  max mem: 3278
Epoch: [25]  [2100/3494]  eta: 0:08:45  lr: 0.0000100  loss: 0.5783 (0.5888)  bbox_regression: 0.1007 (0.1042)  classification: 0.4546 (0.4846)  time: 0.3623  data: 0.1312  max mem: 3278
Epoch: [25]  [2200/3494]  eta: 0:08:06  lr: 0.0000100  loss: 0.6019 (0.5888)  bbox_regression: 0.0975 (0.1044)  classification: 0.4828 (0.4844)  time: 0.3705  data: 0.1324  max mem: 3278
Epoch: [25]  [2300/3494]  eta: 0:07:29  lr: 0.0000100  loss: 0.5909 (0.5883)  bbox_regression: 0.1011 (0.1043)  classification: 0.4925 (0.4840)  time: 0.3739  data: 0.1263  max mem: 3278
Epoch: [25]  [2400/3494]  eta: 0:06:51  lr: 0.0000100  loss: 0.5727 (0.5881)  bbox_regression: 0.1041 (0.1042)  classification: 0.4793 (0.4839)  time: 0.3939  data: 0.1406  max mem: 3278
Epoch: [25]  [2500/3494]  eta: 0:06:14  lr: 0.0000100  loss: 0.5496 (0.5872)  bbox_regression: 0.1011 (0.1042)  classification: 0.4486 (0.4830)  time: 0.3902  data: 0.1393  max mem: 3278
Epoch: [25]  [2600/3494]  eta: 0:05:36  lr: 0.0000100  loss: 0.5961 (0.5875)  bbox_regression: 0.0926 (0.1040)  classification: 0.4880 (0.4835)  time: 0.3810  data: 0.1286  max mem: 3278
Epoch: [25]  [2700/3494]  eta: 0:04:58  lr: 0.0000100  loss: 0.5487 (0.5873)  bbox_regression: 0.0859 (0.1039)  classification: 0.4618 (0.4834)  time: 0.3601  data: 0.1257  max mem: 3278
Epoch: [25]  [2800/3494]  eta: 0:04:21  lr: 0.0000100  loss: 0.6263 (0.5876)  bbox_regression: 0.1050 (0.1040)  classification: 0.4895 (0.4837)  time: 0.3680  data: 0.1284  max mem: 3278
Epoch: [25]  [2900/3494]  eta: 0:03:43  lr: 0.0000100  loss: 0.6088 (0.5880)  bbox_regression: 0.1125 (0.1040)  classification: 0.4862 (0.4839)  time: 0.3377  data: 0.1145  max mem: 3278
Epoch: [25]  [3000/3494]  eta: 0:03:05  lr: 0.0000100  loss: 0.5028 (0.5874)  bbox_regression: 0.0953 (0.1039)  classification: 0.4006 (0.4835)  time: 0.3707  data: 0.1295  max mem: 3278
Epoch: [25]  [3100/3494]  eta: 0:02:28  lr: 0.0000100  loss: 0.5552 (0.5874)  bbox_regression: 0.1044 (0.1038)  classification: 0.4592 (0.4836)  time: 0.3731  data: 0.1324  max mem: 3278
Epoch: [25]  [3200/3494]  eta: 0:01:50  lr: 0.0000100  loss: 0.5559 (0.5866)  bbox_regression: 0.0920 (0.1036)  classification: 0.4450 (0.4831)  time: 0.3785  data: 0.1296  max mem: 3278
Epoch: [25]  [3300/3494]  eta: 0:01:12  lr: 0.0000100  loss: 0.5049 (0.5863)  bbox_regression: 0.0881 (0.1036)  classification: 0.4192 (0.4827)  time: 0.3920  data: 0.1302  max mem: 3278
Epoch: [25]  [3400/3494]  eta: 0:00:35  lr: 0.0000100  loss: 0.5594 (0.5863)  bbox_regression: 0.0912 (0.1036)  classification: 0.4456 (0.4827)  time: 0.3795  data: 0.1357  max mem: 3278
Epoch: [25]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5859 (0.5864)  bbox_regression: 0.1029 (0.1036)  classification: 0.4805 (0.4828)  time: 0.3592  data: 0.1328  max mem: 3278
Epoch: [25] Total time: 0:22:04 (0.3790 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:47  model_time: 0.1410 (0.1410)  loss: 1.0489 (1.0489)  bbox_regression: 0.1270 (0.1270)  classification: 0.9219 (0.9219)  time: 2.3044  data: 2.1298  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1163 (0.1257)  loss: 0.7643 (0.9003)  bbox_regression: 0.1668 (0.1625)  classification: 0.6084 (0.7378)  time: 0.2588  data: 0.1218  max mem: 3278
Validation:  [200/437]  eta: 0:01:02  model_time: 0.1170 (0.1203)  loss: 0.7690 (0.8621)  bbox_regression: 0.1410 (0.1532)  classification: 0.6524 (0.7089)  time: 0.2487  data: 0.1140  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1219 (0.1223)  loss: 0.8972 (0.8643)  bbox_regression: 0.1440 (0.1499)  classification: 0.7644 (0.7145)  time: 0.2792  data: 0.1319  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1221 (0.1228)  loss: 0.7345 (0.8606)  bbox_regression: 0.1411 (0.1500)  classification: 0.6137 (0.7106)  time: 0.2696  data: 0.1290  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1120 (0.1225)  loss: 0.7356 (0.8615)  bbox_regression: 0.1229 (0.1501)  classification: 0.6382 (0.7114)  time: 0.2439  data: 0.1135  max mem: 3278
Validation: Total time: 0:01:57 (0.2680 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [26]  [   0/3494]  eta: 2:10:51  lr: 0.0000100  loss: 0.5619 (0.5619)  bbox_regression: 0.1067 (0.1067)  classification: 0.4552 (0.4552)  time: 2.2472  data: 1.9810  max mem: 3278
Epoch: [26]  [ 100/3494]  eta: 0:21:56  lr: 0.0000100  loss: 0.5438 (0.5793)  bbox_regression: 0.0993 (0.1022)  classification: 0.4487 (0.4771)  time: 0.3854  data: 0.1340  max mem: 3278
Epoch: [26]  [ 200/3494]  eta: 0:21:08  lr: 0.0000100  loss: 0.5893 (0.5894)  bbox_regression: 0.1084 (0.1036)  classification: 0.5113 (0.4859)  time: 0.4036  data: 0.1279  max mem: 3278
Epoch: [26]  [ 300/3494]  eta: 0:20:04  lr: 0.0000100  loss: 0.5611 (0.5844)  bbox_regression: 0.1056 (0.1036)  classification: 0.4820 (0.4809)  time: 0.3615  data: 0.1247  max mem: 3278
Epoch: [26]  [ 400/3494]  eta: 0:19:23  lr: 0.0000100  loss: 0.5765 (0.5832)  bbox_regression: 0.0940 (0.1040)  classification: 0.4578 (0.4791)  time: 0.3649  data: 0.1304  max mem: 3278
Epoch: [26]  [ 500/3494]  eta: 0:18:45  lr: 0.0000100  loss: 0.6575 (0.5880)  bbox_regression: 0.1180 (0.1052)  classification: 0.5222 (0.4828)  time: 0.3701  data: 0.1286  max mem: 3278
Epoch: [26]  [ 600/3494]  eta: 0:18:01  lr: 0.0000100  loss: 0.5501 (0.5907)  bbox_regression: 0.0942 (0.1050)  classification: 0.4562 (0.4857)  time: 0.3704  data: 0.1305  max mem: 3278
Epoch: [26]  [ 700/3494]  eta: 0:17:23  lr: 0.0000100  loss: 0.5615 (0.5891)  bbox_regression: 0.0934 (0.1041)  classification: 0.4655 (0.4850)  time: 0.3670  data: 0.1275  max mem: 3278
Epoch: [26]  [ 800/3494]  eta: 0:16:47  lr: 0.0000100  loss: 0.5196 (0.5873)  bbox_regression: 0.1035 (0.1038)  classification: 0.4102 (0.4835)  time: 0.3618  data: 0.1239  max mem: 3278
Epoch: [26]  [ 900/3494]  eta: 0:16:09  lr: 0.0000100  loss: 0.5743 (0.5846)  bbox_regression: 0.0895 (0.1034)  classification: 0.4678 (0.4812)  time: 0.3767  data: 0.1387  max mem: 3278
Epoch: [26]  [1000/3494]  eta: 0:15:32  lr: 0.0000100  loss: 0.5575 (0.5843)  bbox_regression: 0.0952 (0.1031)  classification: 0.4653 (0.4812)  time: 0.3819  data: 0.1293  max mem: 3278
Epoch: [26]  [1100/3494]  eta: 0:14:57  lr: 0.0000100  loss: 0.6009 (0.5858)  bbox_regression: 0.0982 (0.1033)  classification: 0.4875 (0.4825)  time: 0.3775  data: 0.1364  max mem: 3278
Epoch: [26]  [1200/3494]  eta: 0:14:20  lr: 0.0000100  loss: 0.5764 (0.5858)  bbox_regression: 0.0943 (0.1034)  classification: 0.4625 (0.4824)  time: 0.3696  data: 0.1345  max mem: 3278
Epoch: [26]  [1300/3494]  eta: 0:13:40  lr: 0.0000100  loss: 0.5964 (0.5860)  bbox_regression: 0.1038 (0.1036)  classification: 0.4826 (0.4824)  time: 0.3572  data: 0.1292  max mem: 3278
Epoch: [26]  [1400/3494]  eta: 0:13:01  lr: 0.0000100  loss: 0.5333 (0.5851)  bbox_regression: 0.0936 (0.1036)  classification: 0.4259 (0.4815)  time: 0.3697  data: 0.1300  max mem: 3278
Epoch: [26]  [1500/3494]  eta: 0:12:22  lr: 0.0000100  loss: 0.5463 (0.5849)  bbox_regression: 0.0838 (0.1034)  classification: 0.4756 (0.4815)  time: 0.3658  data: 0.1301  max mem: 3278
Epoch: [26]  [1600/3494]  eta: 0:11:43  lr: 0.0000100  loss: 0.5638 (0.5853)  bbox_regression: 0.1030 (0.1037)  classification: 0.4598 (0.4816)  time: 0.3805  data: 0.1428  max mem: 3278
Epoch: [26]  [1700/3494]  eta: 0:11:05  lr: 0.0000100  loss: 0.5883 (0.5852)  bbox_regression: 0.0970 (0.1036)  classification: 0.4844 (0.4816)  time: 0.3606  data: 0.1252  max mem: 3278
Epoch: [26]  [1800/3494]  eta: 0:10:27  lr: 0.0000100  loss: 0.5940 (0.5857)  bbox_regression: 0.1004 (0.1035)  classification: 0.4966 (0.4822)  time: 0.3642  data: 0.1324  max mem: 3278
Epoch: [26]  [1900/3494]  eta: 0:09:48  lr: 0.0000100  loss: 0.5360 (0.5854)  bbox_regression: 0.1052 (0.1035)  classification: 0.4468 (0.4819)  time: 0.3691  data: 0.1366  max mem: 3278
Epoch: [26]  [2000/3494]  eta: 0:09:11  lr: 0.0000100  loss: 0.5529 (0.5846)  bbox_regression: 0.0974 (0.1033)  classification: 0.4619 (0.4813)  time: 0.3618  data: 0.1294  max mem: 3278
Epoch: [26]  [2100/3494]  eta: 0:08:33  lr: 0.0000100  loss: 0.5690 (0.5851)  bbox_regression: 0.0973 (0.1034)  classification: 0.4630 (0.4817)  time: 0.3352  data: 0.1097  max mem: 3278
Epoch: [26]  [2200/3494]  eta: 0:07:56  lr: 0.0000100  loss: 0.5905 (0.5846)  bbox_regression: 0.1090 (0.1033)  classification: 0.4785 (0.4813)  time: 0.3595  data: 0.1297  max mem: 3278
Epoch: [26]  [2300/3494]  eta: 0:07:18  lr: 0.0000100  loss: 0.5607 (0.5855)  bbox_regression: 0.0962 (0.1034)  classification: 0.4715 (0.4820)  time: 0.3567  data: 0.1296  max mem: 3278
Epoch: [26]  [2400/3494]  eta: 0:06:41  lr: 0.0000100  loss: 0.6168 (0.5854)  bbox_regression: 0.0924 (0.1034)  classification: 0.5061 (0.4820)  time: 0.3604  data: 0.1287  max mem: 3278
Epoch: [26]  [2500/3494]  eta: 0:06:04  lr: 0.0000100  loss: 0.6009 (0.5863)  bbox_regression: 0.1060 (0.1035)  classification: 0.4859 (0.4827)  time: 0.3595  data: 0.1274  max mem: 3278
Epoch: [26]  [2600/3494]  eta: 0:05:27  lr: 0.0000100  loss: 0.5521 (0.5865)  bbox_regression: 0.0884 (0.1034)  classification: 0.4728 (0.4832)  time: 0.3549  data: 0.1280  max mem: 3278
Epoch: [26]  [2700/3494]  eta: 0:04:50  lr: 0.0000100  loss: 0.5336 (0.5855)  bbox_regression: 0.0979 (0.1034)  classification: 0.4238 (0.4822)  time: 0.3645  data: 0.1329  max mem: 3278
Epoch: [26]  [2800/3494]  eta: 0:04:14  lr: 0.0000100  loss: 0.6051 (0.5859)  bbox_regression: 0.1053 (0.1034)  classification: 0.5091 (0.4825)  time: 0.3557  data: 0.1253  max mem: 3278
Epoch: [26]  [2900/3494]  eta: 0:03:37  lr: 0.0000100  loss: 0.5704 (0.5859)  bbox_regression: 0.0898 (0.1034)  classification: 0.4674 (0.4825)  time: 0.3666  data: 0.1288  max mem: 3278
Epoch: [26]  [3000/3494]  eta: 0:03:00  lr: 0.0000100  loss: 0.5496 (0.5858)  bbox_regression: 0.1010 (0.1034)  classification: 0.4486 (0.4824)  time: 0.3610  data: 0.1283  max mem: 3278
Epoch: [26]  [3100/3494]  eta: 0:02:23  lr: 0.0000100  loss: 0.5263 (0.5858)  bbox_regression: 0.0958 (0.1035)  classification: 0.4260 (0.4823)  time: 0.3613  data: 0.1264  max mem: 3278
Epoch: [26]  [3200/3494]  eta: 0:01:47  lr: 0.0000100  loss: 0.5631 (0.5863)  bbox_regression: 0.0938 (0.1036)  classification: 0.4722 (0.4827)  time: 0.3295  data: 0.1118  max mem: 3278
Epoch: [26]  [3300/3494]  eta: 0:01:10  lr: 0.0000100  loss: 0.5652 (0.5862)  bbox_regression: 0.1042 (0.1036)  classification: 0.4572 (0.4826)  time: 0.3752  data: 0.1453  max mem: 3278
Epoch: [26]  [3400/3494]  eta: 0:00:34  lr: 0.0000100  loss: 0.5461 (0.5863)  bbox_regression: 0.0918 (0.1036)  classification: 0.4416 (0.4827)  time: 0.3536  data: 0.1229  max mem: 3278
Epoch: [26]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5627 (0.5865)  bbox_regression: 0.0873 (0.1035)  classification: 0.4698 (0.4830)  time: 0.3494  data: 0.1250  max mem: 3278
Epoch: [26] Total time: 0:21:25 (0.3678 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:37  model_time: 0.1448 (0.1448)  loss: 1.0432 (1.0432)  bbox_regression: 0.1272 (0.1272)  classification: 0.9160 (0.9160)  time: 2.4208  data: 2.2554  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1172 (0.1199)  loss: 0.7672 (0.8998)  bbox_regression: 0.1665 (0.1626)  classification: 0.6100 (0.7372)  time: 0.2634  data: 0.1263  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1176 (0.1202)  loss: 0.7600 (0.8622)  bbox_regression: 0.1406 (0.1533)  classification: 0.6481 (0.7089)  time: 0.2673  data: 0.1278  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1186 (0.1210)  loss: 0.8936 (0.8645)  bbox_regression: 0.1454 (0.1500)  classification: 0.7607 (0.7146)  time: 0.2644  data: 0.1263  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1180 (0.1213)  loss: 0.7381 (0.8607)  bbox_regression: 0.1411 (0.1501)  classification: 0.6184 (0.7107)  time: 0.2698  data: 0.1283  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1175 (0.1212)  loss: 0.7313 (0.8617)  bbox_regression: 0.1214 (0.1502)  classification: 0.6338 (0.7115)  time: 0.2610  data: 0.1231  max mem: 3278
Validation: Total time: 0:01:56 (0.2676 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [27]  [   0/3494]  eta: 2:06:56  lr: 0.0000100  loss: 0.5054 (0.5054)  bbox_regression: 0.0853 (0.0853)  classification: 0.4201 (0.4201)  time: 2.1798  data: 1.9038  max mem: 3278
Epoch: [27]  [ 100/3494]  eta: 0:21:13  lr: 0.0000100  loss: 0.5801 (0.6146)  bbox_regression: 0.0986 (0.1095)  classification: 0.4896 (0.5052)  time: 0.3599  data: 0.1295  max mem: 3278
Epoch: [27]  [ 200/3494]  eta: 0:20:05  lr: 0.0000100  loss: 0.5631 (0.5991)  bbox_regression: 0.1122 (0.1063)  classification: 0.4534 (0.4928)  time: 0.3313  data: 0.1101  max mem: 3278
Epoch: [27]  [ 300/3494]  eta: 0:19:23  lr: 0.0000100  loss: 0.5531 (0.5981)  bbox_regression: 0.0982 (0.1058)  classification: 0.4597 (0.4922)  time: 0.3581  data: 0.1257  max mem: 3278
Epoch: [27]  [ 400/3494]  eta: 0:18:44  lr: 0.0000100  loss: 0.5683 (0.5962)  bbox_regression: 0.0919 (0.1054)  classification: 0.4669 (0.4908)  time: 0.3545  data: 0.1270  max mem: 3278
Epoch: [27]  [ 500/3494]  eta: 0:18:04  lr: 0.0000100  loss: 0.5914 (0.5956)  bbox_regression: 0.1127 (0.1051)  classification: 0.4428 (0.4905)  time: 0.3619  data: 0.1297  max mem: 3278
Epoch: [27]  [ 600/3494]  eta: 0:17:24  lr: 0.0000100  loss: 0.5503 (0.5915)  bbox_regression: 0.0998 (0.1052)  classification: 0.4307 (0.4863)  time: 0.3348  data: 0.1167  max mem: 3278
Epoch: [27]  [ 700/3494]  eta: 0:16:47  lr: 0.0000100  loss: 0.5612 (0.5905)  bbox_regression: 0.0945 (0.1052)  classification: 0.4646 (0.4852)  time: 0.3594  data: 0.1291  max mem: 3278
Epoch: [27]  [ 800/3494]  eta: 0:16:11  lr: 0.0000100  loss: 0.5563 (0.5901)  bbox_regression: 0.1002 (0.1044)  classification: 0.4529 (0.4857)  time: 0.3654  data: 0.1383  max mem: 3278
Epoch: [27]  [ 900/3494]  eta: 0:15:36  lr: 0.0000100  loss: 0.5626 (0.5909)  bbox_regression: 0.0848 (0.1047)  classification: 0.4840 (0.4862)  time: 0.3537  data: 0.1229  max mem: 3278
Epoch: [27]  [1000/3494]  eta: 0:14:59  lr: 0.0000100  loss: 0.5657 (0.5906)  bbox_regression: 0.1062 (0.1055)  classification: 0.4400 (0.4851)  time: 0.3560  data: 0.1247  max mem: 3278
Epoch: [27]  [1100/3494]  eta: 0:14:23  lr: 0.0000100  loss: 0.5391 (0.5886)  bbox_regression: 0.1018 (0.1051)  classification: 0.4373 (0.4835)  time: 0.3593  data: 0.1305  max mem: 3278
Epoch: [27]  [1200/3494]  eta: 0:13:46  lr: 0.0000100  loss: 0.5674 (0.5879)  bbox_regression: 0.0953 (0.1048)  classification: 0.4809 (0.4831)  time: 0.3499  data: 0.1245  max mem: 3278
Epoch: [27]  [1300/3494]  eta: 0:13:10  lr: 0.0000100  loss: 0.5180 (0.5871)  bbox_regression: 0.0984 (0.1048)  classification: 0.4281 (0.4823)  time: 0.3740  data: 0.1330  max mem: 3278
Epoch: [27]  [1400/3494]  eta: 0:12:34  lr: 0.0000100  loss: 0.5254 (0.5856)  bbox_regression: 0.0931 (0.1046)  classification: 0.4292 (0.4810)  time: 0.3684  data: 0.1340  max mem: 3278
Epoch: [27]  [1500/3494]  eta: 0:11:58  lr: 0.0000100  loss: 0.5464 (0.5861)  bbox_regression: 0.0986 (0.1045)  classification: 0.4495 (0.4816)  time: 0.3577  data: 0.1246  max mem: 3278
Epoch: [27]  [1600/3494]  eta: 0:11:22  lr: 0.0000100  loss: 0.5362 (0.5853)  bbox_regression: 0.0861 (0.1044)  classification: 0.4341 (0.4809)  time: 0.3528  data: 0.1238  max mem: 3278
Epoch: [27]  [1700/3494]  eta: 0:10:46  lr: 0.0000100  loss: 0.5326 (0.5851)  bbox_regression: 0.0928 (0.1042)  classification: 0.4415 (0.4809)  time: 0.3616  data: 0.1300  max mem: 3278
Epoch: [27]  [1800/3494]  eta: 0:10:09  lr: 0.0000100  loss: 0.5951 (0.5856)  bbox_regression: 0.1070 (0.1042)  classification: 0.4881 (0.4814)  time: 0.3311  data: 0.1099  max mem: 3278
Epoch: [27]  [1900/3494]  eta: 0:09:33  lr: 0.0000100  loss: 0.5917 (0.5852)  bbox_regression: 0.0971 (0.1042)  classification: 0.4760 (0.4810)  time: 0.3571  data: 0.1305  max mem: 3278
Epoch: [27]  [2000/3494]  eta: 0:08:57  lr: 0.0000100  loss: 0.5567 (0.5852)  bbox_regression: 0.0934 (0.1042)  classification: 0.4578 (0.4810)  time: 0.3613  data: 0.1274  max mem: 3278
Epoch: [27]  [2100/3494]  eta: 0:08:21  lr: 0.0000100  loss: 0.5125 (0.5843)  bbox_regression: 0.0955 (0.1040)  classification: 0.4181 (0.4803)  time: 0.3658  data: 0.1371  max mem: 3278
Epoch: [27]  [2200/3494]  eta: 0:07:45  lr: 0.0000100  loss: 0.5467 (0.5846)  bbox_regression: 0.0930 (0.1039)  classification: 0.4554 (0.4806)  time: 0.3612  data: 0.1327  max mem: 3278
Epoch: [27]  [2300/3494]  eta: 0:07:09  lr: 0.0000100  loss: 0.5466 (0.5847)  bbox_regression: 0.0967 (0.1039)  classification: 0.4596 (0.4808)  time: 0.3549  data: 0.1268  max mem: 3278
Epoch: [27]  [2400/3494]  eta: 0:06:33  lr: 0.0000100  loss: 0.5250 (0.5846)  bbox_regression: 0.1029 (0.1039)  classification: 0.4239 (0.4807)  time: 0.3679  data: 0.1372  max mem: 3278
Epoch: [27]  [2500/3494]  eta: 0:05:57  lr: 0.0000100  loss: 0.6217 (0.5846)  bbox_regression: 0.0931 (0.1038)  classification: 0.5217 (0.4809)  time: 0.3578  data: 0.1267  max mem: 3278
Epoch: [27]  [2600/3494]  eta: 0:05:21  lr: 0.0000100  loss: 0.5589 (0.5848)  bbox_regression: 0.1011 (0.1038)  classification: 0.4535 (0.4809)  time: 0.3651  data: 0.1308  max mem: 3278
Epoch: [27]  [2700/3494]  eta: 0:04:45  lr: 0.0000100  loss: 0.5527 (0.5846)  bbox_regression: 0.1026 (0.1039)  classification: 0.4503 (0.4808)  time: 0.3569  data: 0.1285  max mem: 3278
Epoch: [27]  [2800/3494]  eta: 0:04:09  lr: 0.0000100  loss: 0.5744 (0.5849)  bbox_regression: 0.0958 (0.1039)  classification: 0.4740 (0.4811)  time: 0.3623  data: 0.1282  max mem: 3278
Epoch: [27]  [2900/3494]  eta: 0:03:33  lr: 0.0000100  loss: 0.5379 (0.5849)  bbox_regression: 0.0961 (0.1038)  classification: 0.4527 (0.4812)  time: 0.3513  data: 0.1223  max mem: 3278
Epoch: [27]  [3000/3494]  eta: 0:02:57  lr: 0.0000100  loss: 0.5583 (0.5852)  bbox_regression: 0.0932 (0.1037)  classification: 0.4651 (0.4814)  time: 0.3747  data: 0.1378  max mem: 3278
Epoch: [27]  [3100/3494]  eta: 0:02:21  lr: 0.0000100  loss: 0.5051 (0.5851)  bbox_regression: 0.0912 (0.1037)  classification: 0.4260 (0.4815)  time: 0.3656  data: 0.1312  max mem: 3278
Epoch: [27]  [3200/3494]  eta: 0:01:45  lr: 0.0000100  loss: 0.5448 (0.5856)  bbox_regression: 0.0863 (0.1037)  classification: 0.4469 (0.4819)  time: 0.3734  data: 0.1370  max mem: 3278
Epoch: [27]  [3300/3494]  eta: 0:01:09  lr: 0.0000100  loss: 0.6075 (0.5859)  bbox_regression: 0.0965 (0.1036)  classification: 0.5105 (0.4822)  time: 0.3575  data: 0.1282  max mem: 3278
Epoch: [27]  [3400/3494]  eta: 0:00:33  lr: 0.0000100  loss: 0.5685 (0.5846)  bbox_regression: 0.0921 (0.1034)  classification: 0.4767 (0.4812)  time: 0.3619  data: 0.1273  max mem: 3278
Epoch: [27]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5997 (0.5853)  bbox_regression: 0.1198 (0.1036)  classification: 0.4595 (0.4817)  time: 0.3555  data: 0.1312  max mem: 3278
Epoch: [27] Total time: 0:21:08 (0.3630 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:15  model_time: 0.1271 (0.1271)  loss: 1.0433 (1.0433)  bbox_regression: 0.1277 (0.1277)  classification: 0.9157 (0.9157)  time: 1.8213  data: 1.6562  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1229 (0.1228)  loss: 0.7686 (0.9000)  bbox_regression: 0.1658 (0.1626)  classification: 0.6126 (0.7374)  time: 0.2778  data: 0.1310  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1219 (0.1219)  loss: 0.7628 (0.8623)  bbox_regression: 0.1410 (0.1533)  classification: 0.6506 (0.7090)  time: 0.2809  data: 0.1380  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1178 (0.1215)  loss: 0.8926 (0.8646)  bbox_regression: 0.1449 (0.1500)  classification: 0.7599 (0.7147)  time: 0.2617  data: 0.1255  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1228 (0.1222)  loss: 0.7377 (0.8609)  bbox_regression: 0.1418 (0.1500)  classification: 0.6177 (0.7108)  time: 0.2702  data: 0.1284  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1197 (0.1220)  loss: 0.7313 (0.8619)  bbox_regression: 0.1220 (0.1502)  classification: 0.6340 (0.7117)  time: 0.2626  data: 0.1237  max mem: 3278
Validation: Total time: 0:01:57 (0.2683 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [28]  [   0/3494]  eta: 2:02:37  lr: 0.0000100  loss: 0.7043 (0.7043)  bbox_regression: 0.1027 (0.1027)  classification: 0.6016 (0.6016)  time: 2.1059  data: 1.8692  max mem: 3278
Epoch: [28]  [ 100/3494]  eta: 0:21:26  lr: 0.0000100  loss: 0.5628 (0.6051)  bbox_regression: 0.0902 (0.1046)  classification: 0.4726 (0.5005)  time: 0.3570  data: 0.1277  max mem: 3278
Epoch: [28]  [ 200/3494]  eta: 0:20:19  lr: 0.0000100  loss: 0.5550 (0.5917)  bbox_regression: 0.0924 (0.1015)  classification: 0.4540 (0.4902)  time: 0.3541  data: 0.1241  max mem: 3278
Epoch: [28]  [ 300/3494]  eta: 0:19:34  lr: 0.0000100  loss: 0.5761 (0.5911)  bbox_regression: 0.1107 (0.1027)  classification: 0.4703 (0.4885)  time: 0.3732  data: 0.1334  max mem: 3278
Epoch: [28]  [ 400/3494]  eta: 0:18:46  lr: 0.0000100  loss: 0.5300 (0.5872)  bbox_regression: 0.1010 (0.1031)  classification: 0.4289 (0.4842)  time: 0.3596  data: 0.1317  max mem: 3278
Epoch: [28]  [ 500/3494]  eta: 0:18:04  lr: 0.0000100  loss: 0.5410 (0.5863)  bbox_regression: 0.0922 (0.1027)  classification: 0.4516 (0.4835)  time: 0.3491  data: 0.1176  max mem: 3278
Epoch: [28]  [ 600/3494]  eta: 0:17:27  lr: 0.0000100  loss: 0.5827 (0.5852)  bbox_regression: 0.0965 (0.1020)  classification: 0.4685 (0.4832)  time: 0.3570  data: 0.1275  max mem: 3278
Epoch: [28]  [ 700/3494]  eta: 0:16:50  lr: 0.0000100  loss: 0.5521 (0.5851)  bbox_regression: 0.1019 (0.1029)  classification: 0.4478 (0.4822)  time: 0.3668  data: 0.1290  max mem: 3278
Epoch: [28]  [ 800/3494]  eta: 0:16:13  lr: 0.0000100  loss: 0.5655 (0.5869)  bbox_regression: 0.0965 (0.1033)  classification: 0.4648 (0.4836)  time: 0.3596  data: 0.1296  max mem: 3278
Epoch: [28]  [ 900/3494]  eta: 0:15:37  lr: 0.0000100  loss: 0.5872 (0.5875)  bbox_regression: 0.0926 (0.1034)  classification: 0.5108 (0.4840)  time: 0.3554  data: 0.1282  max mem: 3278
Epoch: [28]  [1000/3494]  eta: 0:15:03  lr: 0.0000100  loss: 0.5768 (0.5873)  bbox_regression: 0.0915 (0.1029)  classification: 0.4747 (0.4843)  time: 0.3723  data: 0.1344  max mem: 3278
Epoch: [28]  [1100/3494]  eta: 0:14:25  lr: 0.0000100  loss: 0.5840 (0.5872)  bbox_regression: 0.0918 (0.1027)  classification: 0.4922 (0.4846)  time: 0.3602  data: 0.1268  max mem: 3278
Epoch: [28]  [1200/3494]  eta: 0:13:49  lr: 0.0000100  loss: 0.5237 (0.5865)  bbox_regression: 0.0900 (0.1028)  classification: 0.4390 (0.4837)  time: 0.3532  data: 0.1267  max mem: 3278
Epoch: [28]  [1300/3494]  eta: 0:13:12  lr: 0.0000100  loss: 0.5986 (0.5881)  bbox_regression: 0.0986 (0.1031)  classification: 0.4845 (0.4850)  time: 0.3454  data: 0.1245  max mem: 3278
Epoch: [28]  [1400/3494]  eta: 0:12:36  lr: 0.0000100  loss: 0.6368 (0.5886)  bbox_regression: 0.1031 (0.1033)  classification: 0.4957 (0.4852)  time: 0.3575  data: 0.1260  max mem: 3278
Epoch: [28]  [1500/3494]  eta: 0:12:00  lr: 0.0000100  loss: 0.6220 (0.5890)  bbox_regression: 0.0916 (0.1032)  classification: 0.5252 (0.4858)  time: 0.3550  data: 0.1284  max mem: 3278
Epoch: [28]  [1600/3494]  eta: 0:11:23  lr: 0.0000100  loss: 0.5521 (0.5889)  bbox_regression: 0.0921 (0.1033)  classification: 0.4449 (0.4856)  time: 0.3546  data: 0.1254  max mem: 3278
Epoch: [28]  [1700/3494]  eta: 0:10:46  lr: 0.0000100  loss: 0.5369 (0.5880)  bbox_regression: 0.1005 (0.1033)  classification: 0.4361 (0.4848)  time: 0.3454  data: 0.1207  max mem: 3278
Epoch: [28]  [1800/3494]  eta: 0:10:10  lr: 0.0000100  loss: 0.5693 (0.5885)  bbox_regression: 0.0995 (0.1036)  classification: 0.4604 (0.4849)  time: 0.3550  data: 0.1227  max mem: 3278
Epoch: [28]  [1900/3494]  eta: 0:09:34  lr: 0.0000100  loss: 0.5383 (0.5889)  bbox_regression: 0.0945 (0.1037)  classification: 0.4445 (0.4853)  time: 0.3688  data: 0.1317  max mem: 3278
Epoch: [28]  [2000/3494]  eta: 0:08:58  lr: 0.0000100  loss: 0.5644 (0.5893)  bbox_regression: 0.1001 (0.1038)  classification: 0.4616 (0.4855)  time: 0.3585  data: 0.1305  max mem: 3278
Epoch: [28]  [2100/3494]  eta: 0:08:21  lr: 0.0000100  loss: 0.5750 (0.5887)  bbox_regression: 0.1103 (0.1038)  classification: 0.4577 (0.4849)  time: 0.3564  data: 0.1275  max mem: 3278
Epoch: [28]  [2200/3494]  eta: 0:07:45  lr: 0.0000100  loss: 0.6258 (0.5892)  bbox_regression: 0.1084 (0.1038)  classification: 0.5148 (0.4854)  time: 0.3537  data: 0.1279  max mem: 3278
Epoch: [28]  [2300/3494]  eta: 0:07:09  lr: 0.0000100  loss: 0.5687 (0.5894)  bbox_regression: 0.0940 (0.1038)  classification: 0.4671 (0.4856)  time: 0.3557  data: 0.1236  max mem: 3278
Epoch: [28]  [2400/3494]  eta: 0:06:33  lr: 0.0000100  loss: 0.5441 (0.5892)  bbox_regression: 0.0917 (0.1037)  classification: 0.4322 (0.4855)  time: 0.3346  data: 0.1165  max mem: 3278
Epoch: [28]  [2500/3494]  eta: 0:05:57  lr: 0.0000100  loss: 0.5844 (0.5889)  bbox_regression: 0.0948 (0.1037)  classification: 0.4910 (0.4852)  time: 0.3578  data: 0.1281  max mem: 3278
Epoch: [28]  [2600/3494]  eta: 0:05:21  lr: 0.0000100  loss: 0.4999 (0.5877)  bbox_regression: 0.0883 (0.1036)  classification: 0.4208 (0.4842)  time: 0.3738  data: 0.1385  max mem: 3278
Epoch: [28]  [2700/3494]  eta: 0:04:45  lr: 0.0000100  loss: 0.5375 (0.5875)  bbox_regression: 0.0964 (0.1036)  classification: 0.4390 (0.4839)  time: 0.3700  data: 0.1398  max mem: 3278
Epoch: [28]  [2800/3494]  eta: 0:04:09  lr: 0.0000100  loss: 0.5807 (0.5870)  bbox_regression: 0.1008 (0.1036)  classification: 0.4770 (0.4835)  time: 0.3572  data: 0.1298  max mem: 3278
Epoch: [28]  [2900/3494]  eta: 0:03:33  lr: 0.0000100  loss: 0.5118 (0.5867)  bbox_regression: 0.0831 (0.1035)  classification: 0.4406 (0.4832)  time: 0.3596  data: 0.1256  max mem: 3278
Epoch: [28]  [3000/3494]  eta: 0:02:57  lr: 0.0000100  loss: 0.5380 (0.5867)  bbox_regression: 0.1023 (0.1035)  classification: 0.4468 (0.4833)  time: 0.3592  data: 0.1286  max mem: 3278
Epoch: [28]  [3100/3494]  eta: 0:02:21  lr: 0.0000100  loss: 0.5628 (0.5861)  bbox_regression: 0.0884 (0.1033)  classification: 0.4512 (0.4828)  time: 0.3703  data: 0.1365  max mem: 3278
Epoch: [28]  [3200/3494]  eta: 0:01:45  lr: 0.0000100  loss: 0.5774 (0.5861)  bbox_regression: 0.0936 (0.1033)  classification: 0.4821 (0.4828)  time: 0.3266  data: 0.1087  max mem: 3278
Epoch: [28]  [3300/3494]  eta: 0:01:09  lr: 0.0000100  loss: 0.5943 (0.5860)  bbox_regression: 0.1033 (0.1034)  classification: 0.4886 (0.4826)  time: 0.3534  data: 0.1269  max mem: 3278
Epoch: [28]  [3400/3494]  eta: 0:00:33  lr: 0.0000100  loss: 0.5230 (0.5856)  bbox_regression: 0.0924 (0.1034)  classification: 0.4236 (0.4823)  time: 0.3554  data: 0.1264  max mem: 3278
Epoch: [28]  [3493/3494]  eta: 0:00:00  lr: 0.0000100  loss: 0.5802 (0.5853)  bbox_regression: 0.1002 (0.1034)  classification: 0.4562 (0.4819)  time: 0.3481  data: 0.1217  max mem: 3278
Epoch: [28] Total time: 0:21:07 (0.3628 s / it)
Epoch 00029: reducing learning rate of group 0 to 1.0000e-06.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:17  model_time: 0.1256 (0.1256)  loss: 1.0476 (1.0476)  bbox_regression: 0.1259 (0.1259)  classification: 0.9217 (0.9217)  time: 2.3742  data: 2.2288  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1181 (0.1263)  loss: 0.7729 (0.9009)  bbox_regression: 0.1674 (0.1627)  classification: 0.6151 (0.7382)  time: 0.2601  data: 0.1217  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1261 (0.1248)  loss: 0.7644 (0.8628)  bbox_regression: 0.1425 (0.1533)  classification: 0.6502 (0.7095)  time: 0.2742  data: 0.1273  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1196 (0.1238)  loss: 0.8939 (0.8651)  bbox_regression: 0.1455 (0.1500)  classification: 0.7657 (0.7151)  time: 0.2686  data: 0.1272  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1222 (0.1232)  loss: 0.7391 (0.8613)  bbox_regression: 0.1426 (0.1501)  classification: 0.6174 (0.7112)  time: 0.2637  data: 0.1236  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1167 (0.1230)  loss: 0.7336 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6367 (0.7120)  time: 0.2593  data: 0.1228  max mem: 3278
Validation: Total time: 0:01:58 (0.2706 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [29]  [   0/3494]  eta: 2:11:36  lr: 0.0000010  loss: 0.6637 (0.6637)  bbox_regression: 0.1555 (0.1555)  classification: 0.5082 (0.5082)  time: 2.2599  data: 2.0192  max mem: 3278
Epoch: [29]  [ 100/3494]  eta: 0:21:34  lr: 0.0000010  loss: 0.5267 (0.5799)  bbox_regression: 0.0843 (0.1018)  classification: 0.4425 (0.4781)  time: 0.3734  data: 0.1356  max mem: 3278
Epoch: [29]  [ 200/3494]  eta: 0:20:15  lr: 0.0000010  loss: 0.5420 (0.5854)  bbox_regression: 0.0894 (0.1044)  classification: 0.4467 (0.4810)  time: 0.3482  data: 0.1197  max mem: 3278
Epoch: [29]  [ 300/3494]  eta: 0:19:27  lr: 0.0000010  loss: 0.5055 (0.5826)  bbox_regression: 0.0887 (0.1038)  classification: 0.4226 (0.4787)  time: 0.3504  data: 0.1269  max mem: 3278
Epoch: [29]  [ 400/3494]  eta: 0:18:50  lr: 0.0000010  loss: 0.5943 (0.5837)  bbox_regression: 0.1071 (0.1042)  classification: 0.4934 (0.4795)  time: 0.3611  data: 0.1308  max mem: 3278
Epoch: [29]  [ 500/3494]  eta: 0:18:06  lr: 0.0000010  loss: 0.6026 (0.5830)  bbox_regression: 0.0948 (0.1034)  classification: 0.4980 (0.4796)  time: 0.3678  data: 0.1309  max mem: 3278
Epoch: [29]  [ 600/3494]  eta: 0:17:28  lr: 0.0000010  loss: 0.4979 (0.5820)  bbox_regression: 0.0762 (0.1022)  classification: 0.4146 (0.4797)  time: 0.3575  data: 0.1274  max mem: 3278
Epoch: [29]  [ 700/3494]  eta: 0:16:50  lr: 0.0000010  loss: 0.5627 (0.5819)  bbox_regression: 0.0922 (0.1026)  classification: 0.4610 (0.4793)  time: 0.3621  data: 0.1300  max mem: 3278
Epoch: [29]  [ 800/3494]  eta: 0:16:14  lr: 0.0000010  loss: 0.5405 (0.5815)  bbox_regression: 0.1021 (0.1028)  classification: 0.4354 (0.4787)  time: 0.3747  data: 0.1360  max mem: 3278
Epoch: [29]  [ 900/3494]  eta: 0:15:37  lr: 0.0000010  loss: 0.5412 (0.5835)  bbox_regression: 0.0887 (0.1031)  classification: 0.4334 (0.4803)  time: 0.3559  data: 0.1325  max mem: 3278
Epoch: [29]  [1000/3494]  eta: 0:14:59  lr: 0.0000010  loss: 0.5672 (0.5835)  bbox_regression: 0.1038 (0.1031)  classification: 0.4766 (0.4805)  time: 0.3548  data: 0.1254  max mem: 3278
Epoch: [29]  [1100/3494]  eta: 0:14:22  lr: 0.0000010  loss: 0.5735 (0.5830)  bbox_regression: 0.1019 (0.1031)  classification: 0.4718 (0.4799)  time: 0.3759  data: 0.1398  max mem: 3278
Epoch: [29]  [1200/3494]  eta: 0:13:46  lr: 0.0000010  loss: 0.5506 (0.5825)  bbox_regression: 0.0970 (0.1030)  classification: 0.4635 (0.4795)  time: 0.3632  data: 0.1337  max mem: 3278
Epoch: [29]  [1300/3494]  eta: 0:13:09  lr: 0.0000010  loss: 0.5597 (0.5822)  bbox_regression: 0.1057 (0.1032)  classification: 0.4667 (0.4790)  time: 0.3512  data: 0.1252  max mem: 3278
Epoch: [29]  [1400/3494]  eta: 0:12:33  lr: 0.0000010  loss: 0.5778 (0.5816)  bbox_regression: 0.0985 (0.1030)  classification: 0.4732 (0.4786)  time: 0.3606  data: 0.1262  max mem: 3278
Epoch: [29]  [1500/3494]  eta: 0:11:57  lr: 0.0000010  loss: 0.5745 (0.5820)  bbox_regression: 0.0996 (0.1032)  classification: 0.4822 (0.4788)  time: 0.3670  data: 0.1316  max mem: 3278
Epoch: [29]  [1600/3494]  eta: 0:11:21  lr: 0.0000010  loss: 0.5359 (0.5818)  bbox_regression: 0.0964 (0.1030)  classification: 0.4494 (0.4788)  time: 0.3547  data: 0.1295  max mem: 3278
Epoch: [29]  [1700/3494]  eta: 0:10:45  lr: 0.0000010  loss: 0.5890 (0.5813)  bbox_regression: 0.0922 (0.1028)  classification: 0.4955 (0.4785)  time: 0.3537  data: 0.1243  max mem: 3278
Epoch: [29]  [1800/3494]  eta: 0:10:09  lr: 0.0000010  loss: 0.5485 (0.5823)  bbox_regression: 0.0935 (0.1029)  classification: 0.4548 (0.4793)  time: 0.3568  data: 0.1276  max mem: 3278
Epoch: [29]  [1900/3494]  eta: 0:09:33  lr: 0.0000010  loss: 0.5654 (0.5822)  bbox_regression: 0.1032 (0.1028)  classification: 0.4830 (0.4794)  time: 0.3567  data: 0.1263  max mem: 3278
Epoch: [29]  [2000/3494]  eta: 0:08:56  lr: 0.0000010  loss: 0.5905 (0.5826)  bbox_regression: 0.1055 (0.1028)  classification: 0.4919 (0.4798)  time: 0.3501  data: 0.1252  max mem: 3278
Epoch: [29]  [2100/3494]  eta: 0:08:20  lr: 0.0000010  loss: 0.5542 (0.5831)  bbox_regression: 0.1087 (0.1028)  classification: 0.4581 (0.4803)  time: 0.3495  data: 0.1241  max mem: 3278
Epoch: [29]  [2200/3494]  eta: 0:07:44  lr: 0.0000010  loss: 0.5598 (0.5831)  bbox_regression: 0.0912 (0.1027)  classification: 0.4797 (0.4804)  time: 0.3591  data: 0.1285  max mem: 3278
Epoch: [29]  [2300/3494]  eta: 0:07:08  lr: 0.0000010  loss: 0.5885 (0.5837)  bbox_regression: 0.0963 (0.1027)  classification: 0.4727 (0.4810)  time: 0.3513  data: 0.1269  max mem: 3278
Epoch: [29]  [2400/3494]  eta: 0:06:32  lr: 0.0000010  loss: 0.5833 (0.5848)  bbox_regression: 0.1006 (0.1030)  classification: 0.4696 (0.4818)  time: 0.3199  data: 0.1025  max mem: 3278
Epoch: [29]  [2500/3494]  eta: 0:05:56  lr: 0.0000010  loss: 0.5971 (0.5848)  bbox_regression: 0.1052 (0.1031)  classification: 0.4943 (0.4817)  time: 0.3585  data: 0.1304  max mem: 3278
Epoch: [29]  [2600/3494]  eta: 0:05:20  lr: 0.0000010  loss: 0.5359 (0.5847)  bbox_regression: 0.0870 (0.1031)  classification: 0.4433 (0.4817)  time: 0.3621  data: 0.1298  max mem: 3278
Epoch: [29]  [2700/3494]  eta: 0:04:44  lr: 0.0000010  loss: 0.5892 (0.5846)  bbox_regression: 0.1081 (0.1031)  classification: 0.4859 (0.4815)  time: 0.3517  data: 0.1255  max mem: 3278
Epoch: [29]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.6088 (0.5844)  bbox_regression: 0.0976 (0.1032)  classification: 0.4775 (0.4812)  time: 0.3600  data: 0.1309  max mem: 3278
Epoch: [29]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5675 (0.5842)  bbox_regression: 0.0973 (0.1032)  classification: 0.4739 (0.4810)  time: 0.3688  data: 0.1302  max mem: 3278
Epoch: [29]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.5389 (0.5842)  bbox_regression: 0.0994 (0.1033)  classification: 0.4516 (0.4809)  time: 0.3677  data: 0.1351  max mem: 3278
Epoch: [29]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5544 (0.5841)  bbox_regression: 0.0871 (0.1032)  classification: 0.4593 (0.4809)  time: 0.3591  data: 0.1282  max mem: 3278
Epoch: [29]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5526 (0.5834)  bbox_regression: 0.1019 (0.1031)  classification: 0.4503 (0.4804)  time: 0.3620  data: 0.1287  max mem: 3278
Epoch: [29]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5527 (0.5835)  bbox_regression: 0.0970 (0.1030)  classification: 0.4539 (0.4804)  time: 0.3685  data: 0.1304  max mem: 3278
Epoch: [29]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.6241 (0.5836)  bbox_regression: 0.1014 (0.1030)  classification: 0.4945 (0.4805)  time: 0.3751  data: 0.1318  max mem: 3278
Epoch: [29]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5644 (0.5834)  bbox_regression: 0.1001 (0.1031)  classification: 0.4538 (0.4803)  time: 0.3314  data: 0.1123  max mem: 3278
Epoch: [29] Total time: 0:21:05 (0.3622 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:11:50  model_time: 0.1355 (0.1355)  loss: 1.0471 (1.0471)  bbox_regression: 0.1264 (0.1264)  classification: 0.9207 (0.9207)  time: 1.6268  data: 1.4673  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1190 (0.1214)  loss: 0.7719 (0.9006)  bbox_regression: 0.1666 (0.1627)  classification: 0.6144 (0.7380)  time: 0.2651  data: 0.1246  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1144 (0.1218)  loss: 0.7648 (0.8626)  bbox_regression: 0.1422 (0.1533)  classification: 0.6510 (0.7094)  time: 0.2548  data: 0.1193  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1257 (0.1221)  loss: 0.8970 (0.8649)  bbox_regression: 0.1451 (0.1499)  classification: 0.7651 (0.7150)  time: 0.2771  data: 0.1312  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1174 (0.1221)  loss: 0.7393 (0.8611)  bbox_regression: 0.1420 (0.1500)  classification: 0.6167 (0.7111)  time: 0.2577  data: 0.1213  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1174 (0.1221)  loss: 0.7326 (0.8621)  bbox_regression: 0.1217 (0.1502)  classification: 0.6358 (0.7119)  time: 0.2591  data: 0.1212  max mem: 3278
Validation: Total time: 0:01:57 (0.2681 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [30]  [   0/3494]  eta: 1:49:13  lr: 0.0000010  loss: 1.0785 (1.0785)  bbox_regression: 0.1856 (0.1856)  classification: 0.8929 (0.8929)  time: 1.8757  data: 1.6437  max mem: 3278
Epoch: [30]  [ 100/3494]  eta: 0:21:22  lr: 0.0000010  loss: 0.5383 (0.5954)  bbox_regression: 0.0977 (0.1048)  classification: 0.4407 (0.4907)  time: 0.3694  data: 0.1363  max mem: 3278
Epoch: [30]  [ 200/3494]  eta: 0:20:20  lr: 0.0000010  loss: 0.5628 (0.5785)  bbox_regression: 0.0875 (0.0996)  classification: 0.4726 (0.4788)  time: 0.3635  data: 0.1282  max mem: 3278
Epoch: [30]  [ 300/3494]  eta: 0:19:28  lr: 0.0000010  loss: 0.5602 (0.5777)  bbox_regression: 0.0896 (0.1015)  classification: 0.4766 (0.4762)  time: 0.3658  data: 0.1351  max mem: 3278
Epoch: [30]  [ 400/3494]  eta: 0:18:53  lr: 0.0000010  loss: 0.5697 (0.5756)  bbox_regression: 0.0926 (0.1025)  classification: 0.4771 (0.4731)  time: 0.3555  data: 0.1244  max mem: 3278
Epoch: [30]  [ 500/3494]  eta: 0:18:11  lr: 0.0000010  loss: 0.5196 (0.5757)  bbox_regression: 0.0907 (0.1028)  classification: 0.4322 (0.4728)  time: 0.3585  data: 0.1271  max mem: 3278
Epoch: [30]  [ 600/3494]  eta: 0:17:34  lr: 0.0000010  loss: 0.5379 (0.5740)  bbox_regression: 0.0988 (0.1025)  classification: 0.4374 (0.4714)  time: 0.3610  data: 0.1355  max mem: 3278
Epoch: [30]  [ 700/3494]  eta: 0:16:55  lr: 0.0000010  loss: 0.5951 (0.5801)  bbox_regression: 0.1056 (0.1036)  classification: 0.4799 (0.4765)  time: 0.3509  data: 0.1256  max mem: 3278
Epoch: [30]  [ 800/3494]  eta: 0:16:16  lr: 0.0000010  loss: 0.5752 (0.5803)  bbox_regression: 0.1029 (0.1030)  classification: 0.4688 (0.4773)  time: 0.3660  data: 0.1330  max mem: 3278
Epoch: [30]  [ 900/3494]  eta: 0:15:39  lr: 0.0000010  loss: 0.5233 (0.5802)  bbox_regression: 0.0905 (0.1025)  classification: 0.4429 (0.4777)  time: 0.3530  data: 0.1267  max mem: 3278
Epoch: [30]  [1000/3494]  eta: 0:15:03  lr: 0.0000010  loss: 0.6233 (0.5834)  bbox_regression: 0.0980 (0.1030)  classification: 0.5100 (0.4804)  time: 0.3768  data: 0.1349  max mem: 3278
Epoch: [30]  [1100/3494]  eta: 0:14:24  lr: 0.0000010  loss: 0.5136 (0.5835)  bbox_regression: 0.0897 (0.1033)  classification: 0.4284 (0.4802)  time: 0.3643  data: 0.1315  max mem: 3278
Epoch: [30]  [1200/3494]  eta: 0:13:48  lr: 0.0000010  loss: 0.5649 (0.5831)  bbox_regression: 0.0941 (0.1033)  classification: 0.4743 (0.4798)  time: 0.3493  data: 0.1233  max mem: 3278
Epoch: [30]  [1300/3494]  eta: 0:13:13  lr: 0.0000010  loss: 0.5672 (0.5851)  bbox_regression: 0.1030 (0.1038)  classification: 0.4667 (0.4813)  time: 0.3519  data: 0.1256  max mem: 3278
Epoch: [30]  [1400/3494]  eta: 0:12:37  lr: 0.0000010  loss: 0.5719 (0.5855)  bbox_regression: 0.0892 (0.1040)  classification: 0.4829 (0.4815)  time: 0.3520  data: 0.1252  max mem: 3278
Epoch: [30]  [1500/3494]  eta: 0:12:01  lr: 0.0000010  loss: 0.5435 (0.5847)  bbox_regression: 0.0868 (0.1037)  classification: 0.4612 (0.4811)  time: 0.3627  data: 0.1287  max mem: 3278
Epoch: [30]  [1600/3494]  eta: 0:11:25  lr: 0.0000010  loss: 0.5856 (0.5850)  bbox_regression: 0.0945 (0.1038)  classification: 0.4913 (0.4811)  time: 0.3640  data: 0.1319  max mem: 3278
Epoch: [30]  [1700/3494]  eta: 0:10:49  lr: 0.0000010  loss: 0.5660 (0.5845)  bbox_regression: 0.0874 (0.1035)  classification: 0.4736 (0.4809)  time: 0.3610  data: 0.1325  max mem: 3278
Epoch: [30]  [1800/3494]  eta: 0:10:12  lr: 0.0000010  loss: 0.6087 (0.5848)  bbox_regression: 0.1038 (0.1037)  classification: 0.4993 (0.4811)  time: 0.3660  data: 0.1289  max mem: 3278
Epoch: [30]  [1900/3494]  eta: 0:09:36  lr: 0.0000010  loss: 0.5756 (0.5848)  bbox_regression: 0.0892 (0.1038)  classification: 0.4655 (0.4810)  time: 0.3698  data: 0.1372  max mem: 3278
Epoch: [30]  [2000/3494]  eta: 0:09:00  lr: 0.0000010  loss: 0.5522 (0.5856)  bbox_regression: 0.0925 (0.1040)  classification: 0.4484 (0.4816)  time: 0.3552  data: 0.1253  max mem: 3278
Epoch: [30]  [2100/3494]  eta: 0:08:23  lr: 0.0000010  loss: 0.5506 (0.5853)  bbox_regression: 0.1030 (0.1039)  classification: 0.4461 (0.4814)  time: 0.3492  data: 0.1214  max mem: 3278
Epoch: [30]  [2200/3494]  eta: 0:07:47  lr: 0.0000010  loss: 0.5608 (0.5839)  bbox_regression: 0.0967 (0.1036)  classification: 0.4640 (0.4803)  time: 0.3618  data: 0.1283  max mem: 3278
Epoch: [30]  [2300/3494]  eta: 0:07:11  lr: 0.0000010  loss: 0.5745 (0.5842)  bbox_regression: 0.0943 (0.1036)  classification: 0.4959 (0.4806)  time: 0.3623  data: 0.1311  max mem: 3278
Epoch: [30]  [2400/3494]  eta: 0:06:34  lr: 0.0000010  loss: 0.5684 (0.5837)  bbox_regression: 0.0977 (0.1035)  classification: 0.4793 (0.4802)  time: 0.3461  data: 0.1209  max mem: 3278
Epoch: [30]  [2500/3494]  eta: 0:05:58  lr: 0.0000010  loss: 0.5662 (0.5840)  bbox_regression: 0.0957 (0.1036)  classification: 0.4434 (0.4804)  time: 0.3645  data: 0.1283  max mem: 3278
Epoch: [30]  [2600/3494]  eta: 0:05:22  lr: 0.0000010  loss: 0.5442 (0.5837)  bbox_regression: 0.0897 (0.1036)  classification: 0.4615 (0.4801)  time: 0.3614  data: 0.1325  max mem: 3278
Epoch: [30]  [2700/3494]  eta: 0:04:46  lr: 0.0000010  loss: 0.5728 (0.5843)  bbox_regression: 0.0999 (0.1037)  classification: 0.4784 (0.4806)  time: 0.3683  data: 0.1326  max mem: 3278
Epoch: [30]  [2800/3494]  eta: 0:04:10  lr: 0.0000010  loss: 0.5900 (0.5840)  bbox_regression: 0.1034 (0.1037)  classification: 0.4750 (0.4803)  time: 0.3638  data: 0.1348  max mem: 3278
Epoch: [30]  [2900/3494]  eta: 0:03:34  lr: 0.0000010  loss: 0.5919 (0.5836)  bbox_regression: 0.1059 (0.1037)  classification: 0.4894 (0.4799)  time: 0.3668  data: 0.1365  max mem: 3278
Epoch: [30]  [3000/3494]  eta: 0:02:58  lr: 0.0000010  loss: 0.5093 (0.5832)  bbox_regression: 0.0894 (0.1037)  classification: 0.4245 (0.4795)  time: 0.3572  data: 0.1264  max mem: 3278
Epoch: [30]  [3100/3494]  eta: 0:02:22  lr: 0.0000010  loss: 0.5412 (0.5830)  bbox_regression: 0.0897 (0.1035)  classification: 0.4716 (0.4795)  time: 0.3604  data: 0.1295  max mem: 3278
Epoch: [30]  [3200/3494]  eta: 0:01:46  lr: 0.0000010  loss: 0.5578 (0.5829)  bbox_regression: 0.0961 (0.1034)  classification: 0.4628 (0.4795)  time: 0.3486  data: 0.1170  max mem: 3278
Epoch: [30]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.6041 (0.5831)  bbox_regression: 0.0997 (0.1034)  classification: 0.5070 (0.4797)  time: 0.3636  data: 0.1322  max mem: 3278
Epoch: [30]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5345 (0.5834)  bbox_regression: 0.0903 (0.1034)  classification: 0.4431 (0.4800)  time: 0.3607  data: 0.1305  max mem: 3278
Epoch: [30]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5016 (0.5831)  bbox_regression: 0.0877 (0.1033)  classification: 0.4251 (0.4798)  time: 0.3549  data: 0.1344  max mem: 3278
Epoch: [30] Total time: 0:21:11 (0.3638 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:54  model_time: 0.1255 (0.1255)  loss: 1.0472 (1.0472)  bbox_regression: 0.1266 (0.1266)  classification: 0.9206 (0.9206)  time: 1.7726  data: 1.6127  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1183 (0.1224)  loss: 0.7712 (0.9006)  bbox_regression: 0.1666 (0.1627)  classification: 0.6138 (0.7380)  time: 0.2674  data: 0.1264  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1207 (0.1216)  loss: 0.7649 (0.8626)  bbox_regression: 0.1422 (0.1533)  classification: 0.6510 (0.7094)  time: 0.2647  data: 0.1259  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1185 (0.1222)  loss: 0.8978 (0.8649)  bbox_regression: 0.1451 (0.1499)  classification: 0.7649 (0.7150)  time: 0.2619  data: 0.1240  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1166 (0.1220)  loss: 0.7397 (0.8611)  bbox_regression: 0.1419 (0.1500)  classification: 0.6162 (0.7111)  time: 0.2651  data: 0.1248  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1172 (0.1220)  loss: 0.7324 (0.8621)  bbox_regression: 0.1219 (0.1502)  classification: 0.6356 (0.7119)  time: 0.2594  data: 0.1266  max mem: 3278
Validation: Total time: 0:01:56 (0.2669 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [31]  [   0/3494]  eta: 1:55:32  lr: 0.0000010  loss: 0.5708 (0.5708)  bbox_regression: 0.0897 (0.0897)  classification: 0.4811 (0.4811)  time: 1.9841  data: 1.7279  max mem: 3278
Epoch: [31]  [ 100/3494]  eta: 0:21:29  lr: 0.0000010  loss: 0.5489 (0.5807)  bbox_regression: 0.0944 (0.0996)  classification: 0.4517 (0.4810)  time: 0.3587  data: 0.1300  max mem: 3278
Epoch: [31]  [ 200/3494]  eta: 0:20:18  lr: 0.0000010  loss: 0.5622 (0.5819)  bbox_regression: 0.0921 (0.1019)  classification: 0.4733 (0.4800)  time: 0.3651  data: 0.1320  max mem: 3278
Epoch: [31]  [ 300/3494]  eta: 0:19:23  lr: 0.0000010  loss: 0.5422 (0.5753)  bbox_regression: 0.0959 (0.1009)  classification: 0.4341 (0.4744)  time: 0.3565  data: 0.1274  max mem: 3278
Epoch: [31]  [ 400/3494]  eta: 0:18:49  lr: 0.0000010  loss: 0.5466 (0.5747)  bbox_regression: 0.0857 (0.1007)  classification: 0.4611 (0.4739)  time: 0.3629  data: 0.1305  max mem: 3278
Epoch: [31]  [ 500/3494]  eta: 0:18:09  lr: 0.0000010  loss: 0.5200 (0.5773)  bbox_regression: 0.0905 (0.1010)  classification: 0.4207 (0.4763)  time: 0.3658  data: 0.1319  max mem: 3278
Epoch: [31]  [ 600/3494]  eta: 0:17:27  lr: 0.0000010  loss: 0.5012 (0.5749)  bbox_regression: 0.0894 (0.1010)  classification: 0.4014 (0.4738)  time: 0.3539  data: 0.1271  max mem: 3278
Epoch: [31]  [ 700/3494]  eta: 0:16:51  lr: 0.0000010  loss: 0.5270 (0.5762)  bbox_regression: 0.0890 (0.1015)  classification: 0.4293 (0.4747)  time: 0.3569  data: 0.1278  max mem: 3278
Epoch: [31]  [ 800/3494]  eta: 0:16:13  lr: 0.0000010  loss: 0.5499 (0.5779)  bbox_regression: 0.1056 (0.1023)  classification: 0.4611 (0.4756)  time: 0.3688  data: 0.1343  max mem: 3278
Epoch: [31]  [ 900/3494]  eta: 0:15:34  lr: 0.0000010  loss: 0.5507 (0.5776)  bbox_regression: 0.0980 (0.1023)  classification: 0.4398 (0.4753)  time: 0.3541  data: 0.1294  max mem: 3278
Epoch: [31]  [1000/3494]  eta: 0:14:59  lr: 0.0000010  loss: 0.5235 (0.5760)  bbox_regression: 0.0988 (0.1022)  classification: 0.4247 (0.4738)  time: 0.3550  data: 0.1267  max mem: 3278
Epoch: [31]  [1100/3494]  eta: 0:14:22  lr: 0.0000010  loss: 0.5641 (0.5773)  bbox_regression: 0.0935 (0.1024)  classification: 0.4687 (0.4749)  time: 0.3642  data: 0.1272  max mem: 3278
Epoch: [31]  [1200/3494]  eta: 0:13:48  lr: 0.0000010  loss: 0.5444 (0.5779)  bbox_regression: 0.0899 (0.1023)  classification: 0.4535 (0.4756)  time: 0.3861  data: 0.1419  max mem: 3278
Epoch: [31]  [1300/3494]  eta: 0:13:12  lr: 0.0000010  loss: 0.5632 (0.5778)  bbox_regression: 0.1093 (0.1024)  classification: 0.4509 (0.4754)  time: 0.3399  data: 0.1182  max mem: 3278
Epoch: [31]  [1400/3494]  eta: 0:12:36  lr: 0.0000010  loss: 0.5502 (0.5787)  bbox_regression: 0.0896 (0.1023)  classification: 0.4375 (0.4763)  time: 0.3644  data: 0.1360  max mem: 3278
Epoch: [31]  [1500/3494]  eta: 0:12:00  lr: 0.0000010  loss: 0.6240 (0.5803)  bbox_regression: 0.1001 (0.1026)  classification: 0.5121 (0.4777)  time: 0.3498  data: 0.1222  max mem: 3278
Epoch: [31]  [1600/3494]  eta: 0:11:24  lr: 0.0000010  loss: 0.6140 (0.5822)  bbox_regression: 0.1016 (0.1030)  classification: 0.5005 (0.4792)  time: 0.3675  data: 0.1280  max mem: 3278
Epoch: [31]  [1700/3494]  eta: 0:10:48  lr: 0.0000010  loss: 0.5661 (0.5823)  bbox_regression: 0.1002 (0.1031)  classification: 0.4682 (0.4792)  time: 0.3611  data: 0.1318  max mem: 3278
Epoch: [31]  [1800/3494]  eta: 0:10:11  lr: 0.0000010  loss: 0.5674 (0.5817)  bbox_regression: 0.0933 (0.1030)  classification: 0.4454 (0.4787)  time: 0.3513  data: 0.1216  max mem: 3278
Epoch: [31]  [1900/3494]  eta: 0:09:35  lr: 0.0000010  loss: 0.5823 (0.5820)  bbox_regression: 0.1021 (0.1033)  classification: 0.4782 (0.4787)  time: 0.3666  data: 0.1297  max mem: 3278
Epoch: [31]  [2000/3494]  eta: 0:09:00  lr: 0.0000010  loss: 0.5546 (0.5813)  bbox_regression: 0.0887 (0.1032)  classification: 0.4472 (0.4781)  time: 0.3706  data: 0.1319  max mem: 3278
Epoch: [31]  [2100/3494]  eta: 0:08:23  lr: 0.0000010  loss: 0.5714 (0.5827)  bbox_regression: 0.0949 (0.1035)  classification: 0.4664 (0.4792)  time: 0.3247  data: 0.1079  max mem: 3278
Epoch: [31]  [2200/3494]  eta: 0:07:47  lr: 0.0000010  loss: 0.5238 (0.5822)  bbox_regression: 0.0976 (0.1033)  classification: 0.4361 (0.4788)  time: 0.3572  data: 0.1290  max mem: 3278
Epoch: [31]  [2300/3494]  eta: 0:07:11  lr: 0.0000010  loss: 0.5485 (0.5825)  bbox_regression: 0.0869 (0.1032)  classification: 0.4639 (0.4793)  time: 0.3604  data: 0.1315  max mem: 3278
Epoch: [31]  [2400/3494]  eta: 0:06:34  lr: 0.0000010  loss: 0.5496 (0.5829)  bbox_regression: 0.1005 (0.1034)  classification: 0.4453 (0.4796)  time: 0.3682  data: 0.1323  max mem: 3278
Epoch: [31]  [2500/3494]  eta: 0:05:58  lr: 0.0000010  loss: 0.5679 (0.5827)  bbox_regression: 0.0845 (0.1033)  classification: 0.4803 (0.4794)  time: 0.3673  data: 0.1336  max mem: 3278
Epoch: [31]  [2600/3494]  eta: 0:05:22  lr: 0.0000010  loss: 0.5435 (0.5833)  bbox_regression: 0.1010 (0.1033)  classification: 0.4365 (0.4799)  time: 0.3553  data: 0.1249  max mem: 3278
Epoch: [31]  [2700/3494]  eta: 0:04:46  lr: 0.0000010  loss: 0.5174 (0.5830)  bbox_regression: 0.0890 (0.1034)  classification: 0.4352 (0.4796)  time: 0.3639  data: 0.1272  max mem: 3278
Epoch: [31]  [2800/3494]  eta: 0:04:10  lr: 0.0000010  loss: 0.5442 (0.5830)  bbox_regression: 0.0942 (0.1033)  classification: 0.4308 (0.4797)  time: 0.3699  data: 0.1331  max mem: 3278
Epoch: [31]  [2900/3494]  eta: 0:03:34  lr: 0.0000010  loss: 0.5504 (0.5827)  bbox_regression: 0.0890 (0.1033)  classification: 0.4543 (0.4793)  time: 0.3680  data: 0.1354  max mem: 3278
Epoch: [31]  [3000/3494]  eta: 0:02:58  lr: 0.0000010  loss: 0.5545 (0.5833)  bbox_regression: 0.0962 (0.1034)  classification: 0.4700 (0.4799)  time: 0.3601  data: 0.1317  max mem: 3278
Epoch: [31]  [3100/3494]  eta: 0:02:22  lr: 0.0000010  loss: 0.6268 (0.5832)  bbox_regression: 0.1026 (0.1034)  classification: 0.5354 (0.4799)  time: 0.3579  data: 0.1251  max mem: 3278
Epoch: [31]  [3200/3494]  eta: 0:01:46  lr: 0.0000010  loss: 0.5290 (0.5832)  bbox_regression: 0.0994 (0.1034)  classification: 0.4296 (0.4797)  time: 0.3460  data: 0.1186  max mem: 3278
Epoch: [31]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5703 (0.5832)  bbox_regression: 0.1048 (0.1034)  classification: 0.4729 (0.4798)  time: 0.3589  data: 0.1288  max mem: 3278
Epoch: [31]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5703 (0.5831)  bbox_regression: 0.0968 (0.1033)  classification: 0.4567 (0.4798)  time: 0.3557  data: 0.1251  max mem: 3278
Epoch: [31]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5475 (0.5834)  bbox_regression: 0.0872 (0.1034)  classification: 0.4583 (0.4801)  time: 0.3482  data: 0.1249  max mem: 3278
Epoch: [31] Total time: 0:21:09 (0.3634 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:20  model_time: 0.1404 (0.1404)  loss: 1.0475 (1.0475)  bbox_regression: 0.1266 (0.1266)  classification: 0.9209 (0.9209)  time: 2.1059  data: 1.9371  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1163 (0.1204)  loss: 0.7710 (0.9008)  bbox_regression: 0.1666 (0.1627)  classification: 0.6138 (0.7382)  time: 0.2558  data: 0.1208  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1181 (0.1201)  loss: 0.7659 (0.8627)  bbox_regression: 0.1421 (0.1532)  classification: 0.6515 (0.7095)  time: 0.2628  data: 0.1228  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1222 (0.1203)  loss: 0.8978 (0.8650)  bbox_regression: 0.1450 (0.1499)  classification: 0.7649 (0.7151)  time: 0.2622  data: 0.1202  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1163 (0.1204)  loss: 0.7396 (0.8612)  bbox_regression: 0.1418 (0.1500)  classification: 0.6160 (0.7112)  time: 0.2584  data: 0.1209  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1137 (0.1201)  loss: 0.7325 (0.8622)  bbox_regression: 0.1221 (0.1502)  classification: 0.6357 (0.7120)  time: 0.2524  data: 0.1186  max mem: 3278
Validation: Total time: 0:01:55 (0.2639 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [32]  [   0/3494]  eta: 2:07:43  lr: 0.0000010  loss: 0.4355 (0.4355)  bbox_regression: 0.0764 (0.0764)  classification: 0.3592 (0.3592)  time: 2.1934  data: 1.9431  max mem: 3278
Epoch: [32]  [ 100/3494]  eta: 0:21:11  lr: 0.0000010  loss: 0.5504 (0.5905)  bbox_regression: 0.0926 (0.1093)  classification: 0.4455 (0.4811)  time: 0.3641  data: 0.1328  max mem: 3278
Epoch: [32]  [ 200/3494]  eta: 0:20:04  lr: 0.0000010  loss: 0.5475 (0.5828)  bbox_regression: 0.0958 (0.1058)  classification: 0.4486 (0.4770)  time: 0.3616  data: 0.1293  max mem: 3278
Epoch: [32]  [ 300/3494]  eta: 0:19:28  lr: 0.0000010  loss: 0.5493 (0.5814)  bbox_regression: 0.0957 (0.1048)  classification: 0.4558 (0.4765)  time: 0.3576  data: 0.1251  max mem: 3278
Epoch: [32]  [ 400/3494]  eta: 0:18:52  lr: 0.0000010  loss: 0.5259 (0.5851)  bbox_regression: 0.0947 (0.1054)  classification: 0.4137 (0.4797)  time: 0.3700  data: 0.1383  max mem: 3278
Epoch: [32]  [ 500/3494]  eta: 0:18:10  lr: 0.0000010  loss: 0.5828 (0.5846)  bbox_regression: 0.0917 (0.1047)  classification: 0.4910 (0.4799)  time: 0.3652  data: 0.1305  max mem: 3278
Epoch: [32]  [ 600/3494]  eta: 0:17:32  lr: 0.0000010  loss: 0.5718 (0.5824)  bbox_regression: 0.1011 (0.1038)  classification: 0.4671 (0.4786)  time: 0.3620  data: 0.1291  max mem: 3278
Epoch: [32]  [ 700/3494]  eta: 0:16:56  lr: 0.0000010  loss: 0.5362 (0.5818)  bbox_regression: 0.0967 (0.1037)  classification: 0.4246 (0.4782)  time: 0.3642  data: 0.1289  max mem: 3278
Epoch: [32]  [ 800/3494]  eta: 0:16:18  lr: 0.0000010  loss: 0.5837 (0.5799)  bbox_regression: 0.1034 (0.1036)  classification: 0.4612 (0.4764)  time: 0.3611  data: 0.1316  max mem: 3278
Epoch: [32]  [ 900/3494]  eta: 0:15:41  lr: 0.0000010  loss: 0.6155 (0.5812)  bbox_regression: 0.0908 (0.1038)  classification: 0.5097 (0.4774)  time: 0.3784  data: 0.1420  max mem: 3278
Epoch: [32]  [1000/3494]  eta: 0:15:05  lr: 0.0000010  loss: 0.5755 (0.5825)  bbox_regression: 0.0945 (0.1042)  classification: 0.4680 (0.4783)  time: 0.3554  data: 0.1229  max mem: 3278
Epoch: [32]  [1100/3494]  eta: 0:14:27  lr: 0.0000010  loss: 0.5629 (0.5817)  bbox_regression: 0.0983 (0.1042)  classification: 0.4686 (0.4774)  time: 0.3519  data: 0.1244  max mem: 3278
Epoch: [32]  [1200/3494]  eta: 0:13:51  lr: 0.0000010  loss: 0.5505 (0.5822)  bbox_regression: 0.1017 (0.1043)  classification: 0.4626 (0.4780)  time: 0.3584  data: 0.1256  max mem: 3278
Epoch: [32]  [1300/3494]  eta: 0:13:13  lr: 0.0000010  loss: 0.5689 (0.5826)  bbox_regression: 0.1038 (0.1043)  classification: 0.4814 (0.4783)  time: 0.3627  data: 0.1297  max mem: 3278
Epoch: [32]  [1400/3494]  eta: 0:12:37  lr: 0.0000010  loss: 0.5794 (0.5836)  bbox_regression: 0.0937 (0.1042)  classification: 0.4556 (0.4794)  time: 0.3614  data: 0.1297  max mem: 3278
Epoch: [32]  [1500/3494]  eta: 0:12:01  lr: 0.0000010  loss: 0.5779 (0.5846)  bbox_regression: 0.0965 (0.1042)  classification: 0.4834 (0.4804)  time: 0.3722  data: 0.1380  max mem: 3278
Epoch: [32]  [1600/3494]  eta: 0:11:23  lr: 0.0000010  loss: 0.5545 (0.5851)  bbox_regression: 0.1019 (0.1041)  classification: 0.4591 (0.4810)  time: 0.3658  data: 0.1335  max mem: 3278
Epoch: [32]  [1700/3494]  eta: 0:10:47  lr: 0.0000010  loss: 0.5703 (0.5857)  bbox_regression: 0.0932 (0.1041)  classification: 0.4640 (0.4816)  time: 0.3530  data: 0.1280  max mem: 3278
Epoch: [32]  [1800/3494]  eta: 0:10:10  lr: 0.0000010  loss: 0.5494 (0.5848)  bbox_regression: 0.0833 (0.1039)  classification: 0.4635 (0.4809)  time: 0.3583  data: 0.1276  max mem: 3278
Epoch: [32]  [1900/3494]  eta: 0:09:34  lr: 0.0000010  loss: 0.5983 (0.5838)  bbox_regression: 0.0908 (0.1036)  classification: 0.4918 (0.4802)  time: 0.3690  data: 0.1405  max mem: 3278
Epoch: [32]  [2000/3494]  eta: 0:08:58  lr: 0.0000010  loss: 0.5248 (0.5832)  bbox_regression: 0.0868 (0.1033)  classification: 0.4243 (0.4798)  time: 0.3675  data: 0.1315  max mem: 3278
Epoch: [32]  [2100/3494]  eta: 0:08:22  lr: 0.0000010  loss: 0.5258 (0.5830)  bbox_regression: 0.0988 (0.1033)  classification: 0.4270 (0.4798)  time: 0.3540  data: 0.1232  max mem: 3278
Epoch: [32]  [2200/3494]  eta: 0:07:45  lr: 0.0000010  loss: 0.6064 (0.5827)  bbox_regression: 0.1066 (0.1032)  classification: 0.4892 (0.4795)  time: 0.3573  data: 0.1290  max mem: 3278
Epoch: [32]  [2300/3494]  eta: 0:07:09  lr: 0.0000010  loss: 0.5847 (0.5828)  bbox_regression: 0.0977 (0.1032)  classification: 0.4917 (0.4796)  time: 0.3545  data: 0.1303  max mem: 3278
Epoch: [32]  [2400/3494]  eta: 0:06:33  lr: 0.0000010  loss: 0.5469 (0.5825)  bbox_regression: 0.0934 (0.1032)  classification: 0.4536 (0.4793)  time: 0.3473  data: 0.1206  max mem: 3278
Epoch: [32]  [2500/3494]  eta: 0:05:57  lr: 0.0000010  loss: 0.5957 (0.5829)  bbox_regression: 0.1059 (0.1033)  classification: 0.4756 (0.4796)  time: 0.3652  data: 0.1282  max mem: 3278
Epoch: [32]  [2600/3494]  eta: 0:05:21  lr: 0.0000010  loss: 0.5289 (0.5823)  bbox_regression: 0.0863 (0.1031)  classification: 0.4450 (0.4792)  time: 0.3668  data: 0.1333  max mem: 3278
Epoch: [32]  [2700/3494]  eta: 0:04:45  lr: 0.0000010  loss: 0.5475 (0.5828)  bbox_regression: 0.0994 (0.1032)  classification: 0.4442 (0.4796)  time: 0.3579  data: 0.1255  max mem: 3278
Epoch: [32]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.5611 (0.5833)  bbox_regression: 0.0964 (0.1031)  classification: 0.4648 (0.4801)  time: 0.3650  data: 0.1338  max mem: 3278
Epoch: [32]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5769 (0.5833)  bbox_regression: 0.0893 (0.1032)  classification: 0.4892 (0.4801)  time: 0.3547  data: 0.1256  max mem: 3278
Epoch: [32]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.5942 (0.5832)  bbox_regression: 0.1035 (0.1032)  classification: 0.4667 (0.4800)  time: 0.3597  data: 0.1241  max mem: 3278
Epoch: [32]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5600 (0.5830)  bbox_regression: 0.1005 (0.1032)  classification: 0.4656 (0.4798)  time: 0.3578  data: 0.1271  max mem: 3278
Epoch: [32]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5785 (0.5834)  bbox_regression: 0.0915 (0.1033)  classification: 0.4848 (0.4801)  time: 0.3689  data: 0.1303  max mem: 3278
Epoch: [32]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5472 (0.5832)  bbox_regression: 0.0962 (0.1032)  classification: 0.4453 (0.4800)  time: 0.3631  data: 0.1376  max mem: 3278
Epoch: [32]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5131 (0.5834)  bbox_regression: 0.0946 (0.1033)  classification: 0.4204 (0.4801)  time: 0.3640  data: 0.1313  max mem: 3278
Epoch: [32]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5477 (0.5832)  bbox_regression: 0.0928 (0.1032)  classification: 0.4351 (0.4800)  time: 0.3494  data: 0.1202  max mem: 3278
Epoch: [32] Total time: 0:21:07 (0.3627 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:03  model_time: 0.1224 (0.1224)  loss: 1.0479 (1.0479)  bbox_regression: 0.1267 (0.1267)  classification: 0.9211 (0.9211)  time: 2.0674  data: 1.9138  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1214 (0.1223)  loss: 0.7699 (0.9009)  bbox_regression: 0.1664 (0.1626)  classification: 0.6129 (0.7382)  time: 0.2626  data: 0.1246  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1176 (0.1226)  loss: 0.7666 (0.8628)  bbox_regression: 0.1420 (0.1532)  classification: 0.6518 (0.7095)  time: 0.2640  data: 0.1253  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1167 (0.1224)  loss: 0.8979 (0.8651)  bbox_regression: 0.1450 (0.1499)  classification: 0.7651 (0.7152)  time: 0.2583  data: 0.1204  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1210 (0.1221)  loss: 0.7396 (0.8612)  bbox_regression: 0.1419 (0.1500)  classification: 0.6159 (0.7112)  time: 0.2838  data: 0.1382  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1163 (0.1221)  loss: 0.7325 (0.8622)  bbox_regression: 0.1220 (0.1502)  classification: 0.6358 (0.7120)  time: 0.2550  data: 0.1189  max mem: 3278
Validation: Total time: 0:01:57 (0.2685 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [33]  [   0/3494]  eta: 2:08:22  lr: 0.0000010  loss: 0.5452 (0.5452)  bbox_regression: 0.0644 (0.0644)  classification: 0.4808 (0.4808)  time: 2.2045  data: 1.9561  max mem: 3278
Epoch: [33]  [ 100/3494]  eta: 0:21:32  lr: 0.0000010  loss: 0.5378 (0.5689)  bbox_regression: 0.0868 (0.1013)  classification: 0.4496 (0.4677)  time: 0.3680  data: 0.1446  max mem: 3278
Epoch: [33]  [ 200/3494]  eta: 0:20:15  lr: 0.0000010  loss: 0.5612 (0.5908)  bbox_regression: 0.1066 (0.1054)  classification: 0.4670 (0.4854)  time: 0.3542  data: 0.1263  max mem: 3278
Epoch: [33]  [ 300/3494]  eta: 0:19:25  lr: 0.0000010  loss: 0.6017 (0.5863)  bbox_regression: 0.1007 (0.1030)  classification: 0.5164 (0.4833)  time: 0.3702  data: 0.1352  max mem: 3278
Epoch: [33]  [ 400/3494]  eta: 0:18:44  lr: 0.0000010  loss: 0.5981 (0.5858)  bbox_regression: 0.0924 (0.1030)  classification: 0.5006 (0.4829)  time: 0.3526  data: 0.1250  max mem: 3278
Epoch: [33]  [ 500/3494]  eta: 0:18:02  lr: 0.0000010  loss: 0.5376 (0.5858)  bbox_regression: 0.0955 (0.1024)  classification: 0.4426 (0.4834)  time: 0.3390  data: 0.1138  max mem: 3278
Epoch: [33]  [ 600/3494]  eta: 0:17:27  lr: 0.0000010  loss: 0.5394 (0.5863)  bbox_regression: 0.0908 (0.1028)  classification: 0.4486 (0.4835)  time: 0.3583  data: 0.1297  max mem: 3278
Epoch: [33]  [ 700/3494]  eta: 0:16:50  lr: 0.0000010  loss: 0.5644 (0.5894)  bbox_regression: 0.0995 (0.1033)  classification: 0.4671 (0.4860)  time: 0.3579  data: 0.1265  max mem: 3278
Epoch: [33]  [ 800/3494]  eta: 0:16:11  lr: 0.0000010  loss: 0.5544 (0.5889)  bbox_regression: 0.0967 (0.1029)  classification: 0.4613 (0.4860)  time: 0.3614  data: 0.1284  max mem: 3278
Epoch: [33]  [ 900/3494]  eta: 0:15:35  lr: 0.0000010  loss: 0.5969 (0.5904)  bbox_regression: 0.1101 (0.1035)  classification: 0.4927 (0.4870)  time: 0.3657  data: 0.1324  max mem: 3278
Epoch: [33]  [1000/3494]  eta: 0:14:59  lr: 0.0000010  loss: 0.5590 (0.5909)  bbox_regression: 0.1034 (0.1034)  classification: 0.4580 (0.4875)  time: 0.3684  data: 0.1341  max mem: 3278
Epoch: [33]  [1100/3494]  eta: 0:14:23  lr: 0.0000010  loss: 0.6374 (0.5911)  bbox_regression: 0.1020 (0.1035)  classification: 0.5365 (0.4876)  time: 0.3686  data: 0.1296  max mem: 3278
Epoch: [33]  [1200/3494]  eta: 0:13:46  lr: 0.0000010  loss: 0.5327 (0.5892)  bbox_regression: 0.0920 (0.1031)  classification: 0.4462 (0.4861)  time: 0.3617  data: 0.1293  max mem: 3278
Epoch: [33]  [1300/3494]  eta: 0:13:09  lr: 0.0000010  loss: 0.5684 (0.5888)  bbox_regression: 0.1009 (0.1031)  classification: 0.4516 (0.4858)  time: 0.3219  data: 0.1068  max mem: 3278
Epoch: [33]  [1400/3494]  eta: 0:12:33  lr: 0.0000010  loss: 0.5347 (0.5872)  bbox_regression: 0.0896 (0.1027)  classification: 0.4481 (0.4845)  time: 0.3585  data: 0.1312  max mem: 3278
Epoch: [33]  [1500/3494]  eta: 0:11:57  lr: 0.0000010  loss: 0.5684 (0.5877)  bbox_regression: 0.0977 (0.1029)  classification: 0.4739 (0.4848)  time: 0.3577  data: 0.1245  max mem: 3278
Epoch: [33]  [1600/3494]  eta: 0:11:22  lr: 0.0000010  loss: 0.5881 (0.5881)  bbox_regression: 0.0982 (0.1032)  classification: 0.4766 (0.4848)  time: 0.3752  data: 0.1398  max mem: 3278
Epoch: [33]  [1700/3494]  eta: 0:10:46  lr: 0.0000010  loss: 0.5322 (0.5861)  bbox_regression: 0.0964 (0.1028)  classification: 0.4180 (0.4833)  time: 0.3424  data: 0.1218  max mem: 3278
Epoch: [33]  [1800/3494]  eta: 0:10:09  lr: 0.0000010  loss: 0.5352 (0.5859)  bbox_regression: 0.0800 (0.1030)  classification: 0.4546 (0.4829)  time: 0.3507  data: 0.1233  max mem: 3278
Epoch: [33]  [1900/3494]  eta: 0:09:33  lr: 0.0000010  loss: 0.5614 (0.5843)  bbox_regression: 0.0974 (0.1027)  classification: 0.4769 (0.4816)  time: 0.3658  data: 0.1301  max mem: 3278
Epoch: [33]  [2000/3494]  eta: 0:08:57  lr: 0.0000010  loss: 0.5872 (0.5841)  bbox_regression: 0.1025 (0.1027)  classification: 0.4665 (0.4814)  time: 0.3642  data: 0.1318  max mem: 3278
Epoch: [33]  [2100/3494]  eta: 0:08:22  lr: 0.0000010  loss: 0.5535 (0.5851)  bbox_regression: 0.0981 (0.1029)  classification: 0.4698 (0.4821)  time: 0.3605  data: 0.1292  max mem: 3278
Epoch: [33]  [2200/3494]  eta: 0:07:45  lr: 0.0000010  loss: 0.5549 (0.5842)  bbox_regression: 0.0894 (0.1030)  classification: 0.4588 (0.4812)  time: 0.3637  data: 0.1313  max mem: 3278
Epoch: [33]  [2300/3494]  eta: 0:07:09  lr: 0.0000010  loss: 0.5442 (0.5840)  bbox_regression: 0.1003 (0.1029)  classification: 0.4453 (0.4811)  time: 0.3730  data: 0.1382  max mem: 3278
Epoch: [33]  [2400/3494]  eta: 0:06:33  lr: 0.0000010  loss: 0.5619 (0.5834)  bbox_regression: 0.0955 (0.1027)  classification: 0.4682 (0.4807)  time: 0.3468  data: 0.1239  max mem: 3278
Epoch: [33]  [2500/3494]  eta: 0:05:57  lr: 0.0000010  loss: 0.5533 (0.5836)  bbox_regression: 0.0948 (0.1028)  classification: 0.4701 (0.4808)  time: 0.3654  data: 0.1371  max mem: 3278
Epoch: [33]  [2600/3494]  eta: 0:05:21  lr: 0.0000010  loss: 0.5951 (0.5841)  bbox_regression: 0.0991 (0.1029)  classification: 0.4705 (0.4812)  time: 0.3712  data: 0.1371  max mem: 3278
Epoch: [33]  [2700/3494]  eta: 0:04:45  lr: 0.0000010  loss: 0.5709 (0.5844)  bbox_regression: 0.0887 (0.1032)  classification: 0.4868 (0.4813)  time: 0.3660  data: 0.1311  max mem: 3278
Epoch: [33]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.5536 (0.5844)  bbox_regression: 0.0969 (0.1033)  classification: 0.4657 (0.4812)  time: 0.3539  data: 0.1266  max mem: 3278
Epoch: [33]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5251 (0.5835)  bbox_regression: 0.0961 (0.1032)  classification: 0.4452 (0.4803)  time: 0.3678  data: 0.1324  max mem: 3278
Epoch: [33]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.6237 (0.5835)  bbox_regression: 0.0936 (0.1032)  classification: 0.4986 (0.4803)  time: 0.3720  data: 0.1379  max mem: 3278
Epoch: [33]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5954 (0.5840)  bbox_regression: 0.1085 (0.1032)  classification: 0.4933 (0.4808)  time: 0.3510  data: 0.1244  max mem: 3278
Epoch: [33]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5816 (0.5842)  bbox_regression: 0.1062 (0.1032)  classification: 0.4648 (0.4810)  time: 0.3459  data: 0.1212  max mem: 3278
Epoch: [33]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5431 (0.5842)  bbox_regression: 0.1019 (0.1032)  classification: 0.4410 (0.4810)  time: 0.3567  data: 0.1265  max mem: 3278
Epoch: [33]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5455 (0.5842)  bbox_regression: 0.1020 (0.1033)  classification: 0.4398 (0.4809)  time: 0.3709  data: 0.1386  max mem: 3278
Epoch: [33]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.4930 (0.5837)  bbox_regression: 0.0915 (0.1032)  classification: 0.4134 (0.4805)  time: 0.3566  data: 0.1271  max mem: 3278
Epoch: [33] Total time: 0:21:05 (0.3623 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:57  model_time: 0.1258 (0.1258)  loss: 1.0478 (1.0478)  bbox_regression: 0.1269 (0.1269)  classification: 0.9209 (0.9209)  time: 1.9163  data: 1.7694  max mem: 3278
Validation:  [100/437]  eta: 0:01:31  model_time: 0.1215 (0.1196)  loss: 0.7720 (0.9009)  bbox_regression: 0.1663 (0.1627)  classification: 0.6146 (0.7382)  time: 0.2628  data: 0.1227  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1137 (0.1202)  loss: 0.7661 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6519 (0.7095)  time: 0.2624  data: 0.1279  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1239 (0.1206)  loss: 0.8974 (0.8651)  bbox_regression: 0.1450 (0.1499)  classification: 0.7646 (0.7152)  time: 0.2690  data: 0.1263  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1194 (0.1210)  loss: 0.7400 (0.8613)  bbox_regression: 0.1419 (0.1500)  classification: 0.6166 (0.7112)  time: 0.2601  data: 0.1240  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1168 (0.1209)  loss: 0.7316 (0.8622)  bbox_regression: 0.1220 (0.1502)  classification: 0.6349 (0.7121)  time: 0.2540  data: 0.1176  max mem: 3278
Validation: Total time: 0:01:55 (0.2643 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [34]  [   0/3494]  eta: 2:09:28  lr: 0.0000010  loss: 0.4609 (0.4609)  bbox_regression: 0.0791 (0.0791)  classification: 0.3818 (0.3818)  time: 2.2234  data: 1.9430  max mem: 3278
Epoch: [34]  [ 100/3494]  eta: 0:21:35  lr: 0.0000010  loss: 0.5690 (0.5821)  bbox_regression: 0.0920 (0.1011)  classification: 0.4533 (0.4810)  time: 0.3576  data: 0.1279  max mem: 3278
Epoch: [34]  [ 200/3494]  eta: 0:20:18  lr: 0.0000010  loss: 0.5274 (0.5924)  bbox_regression: 0.0945 (0.1026)  classification: 0.4438 (0.4899)  time: 0.3566  data: 0.1233  max mem: 3278
Epoch: [34]  [ 300/3494]  eta: 0:19:31  lr: 0.0000010  loss: 0.5904 (0.5929)  bbox_regression: 0.0895 (0.1029)  classification: 0.4859 (0.4900)  time: 0.3507  data: 0.1248  max mem: 3278
Epoch: [34]  [ 400/3494]  eta: 0:18:45  lr: 0.0000010  loss: 0.5729 (0.5901)  bbox_regression: 0.1023 (0.1031)  classification: 0.4671 (0.4869)  time: 0.3501  data: 0.1203  max mem: 3278
Epoch: [34]  [ 500/3494]  eta: 0:18:04  lr: 0.0000010  loss: 0.5691 (0.5880)  bbox_regression: 0.0992 (0.1031)  classification: 0.4641 (0.4849)  time: 0.3526  data: 0.1310  max mem: 3278
Epoch: [34]  [ 600/3494]  eta: 0:17:21  lr: 0.0000010  loss: 0.5591 (0.5850)  bbox_regression: 0.0916 (0.1029)  classification: 0.4716 (0.4821)  time: 0.3620  data: 0.1265  max mem: 3278
Epoch: [34]  [ 700/3494]  eta: 0:16:48  lr: 0.0000010  loss: 0.5699 (0.5830)  bbox_regression: 0.0989 (0.1025)  classification: 0.4695 (0.4805)  time: 0.3670  data: 0.1367  max mem: 3278
Epoch: [34]  [ 800/3494]  eta: 0:16:11  lr: 0.0000010  loss: 0.5551 (0.5823)  bbox_regression: 0.0914 (0.1022)  classification: 0.4683 (0.4800)  time: 0.3567  data: 0.1270  max mem: 3278
Epoch: [34]  [ 900/3494]  eta: 0:15:35  lr: 0.0000010  loss: 0.5544 (0.5830)  bbox_regression: 0.1043 (0.1021)  classification: 0.4533 (0.4810)  time: 0.3621  data: 0.1287  max mem: 3278
Epoch: [34]  [1000/3494]  eta: 0:14:59  lr: 0.0000010  loss: 0.5796 (0.5828)  bbox_regression: 0.0992 (0.1023)  classification: 0.4804 (0.4806)  time: 0.3466  data: 0.1237  max mem: 3278
Epoch: [34]  [1100/3494]  eta: 0:14:22  lr: 0.0000010  loss: 0.5436 (0.5828)  bbox_regression: 0.0928 (0.1022)  classification: 0.4556 (0.4806)  time: 0.3564  data: 0.1257  max mem: 3278
Epoch: [34]  [1200/3494]  eta: 0:13:47  lr: 0.0000010  loss: 0.5478 (0.5838)  bbox_regression: 0.0974 (0.1024)  classification: 0.4479 (0.4813)  time: 0.3751  data: 0.1376  max mem: 3278
Epoch: [34]  [1300/3494]  eta: 0:13:11  lr: 0.0000010  loss: 0.5876 (0.5836)  bbox_regression: 0.0880 (0.1022)  classification: 0.4593 (0.4814)  time: 0.3617  data: 0.1302  max mem: 3278
Epoch: [34]  [1400/3494]  eta: 0:12:33  lr: 0.0000010  loss: 0.5362 (0.5835)  bbox_regression: 0.1008 (0.1022)  classification: 0.4434 (0.4813)  time: 0.3582  data: 0.1257  max mem: 3278
Epoch: [34]  [1500/3494]  eta: 0:11:58  lr: 0.0000010  loss: 0.5304 (0.5838)  bbox_regression: 0.0901 (0.1023)  classification: 0.4405 (0.4815)  time: 0.3559  data: 0.1273  max mem: 3278
Epoch: [34]  [1600/3494]  eta: 0:11:21  lr: 0.0000010  loss: 0.5684 (0.5841)  bbox_regression: 0.0959 (0.1024)  classification: 0.4732 (0.4817)  time: 0.3510  data: 0.1255  max mem: 3278
Epoch: [34]  [1700/3494]  eta: 0:10:45  lr: 0.0000010  loss: 0.5563 (0.5839)  bbox_regression: 0.0928 (0.1022)  classification: 0.4617 (0.4817)  time: 0.3539  data: 0.1243  max mem: 3278
Epoch: [34]  [1800/3494]  eta: 0:10:09  lr: 0.0000010  loss: 0.5370 (0.5831)  bbox_regression: 0.0915 (0.1023)  classification: 0.4324 (0.4808)  time: 0.3576  data: 0.1255  max mem: 3278
Epoch: [34]  [1900/3494]  eta: 0:09:33  lr: 0.0000010  loss: 0.5556 (0.5832)  bbox_regression: 0.0934 (0.1025)  classification: 0.4493 (0.4808)  time: 0.3380  data: 0.1239  max mem: 3278
Epoch: [34]  [2000/3494]  eta: 0:08:57  lr: 0.0000010  loss: 0.5929 (0.5827)  bbox_regression: 0.1153 (0.1025)  classification: 0.4696 (0.4802)  time: 0.3564  data: 0.1301  max mem: 3278
Epoch: [34]  [2100/3494]  eta: 0:08:21  lr: 0.0000010  loss: 0.5559 (0.5819)  bbox_regression: 0.0915 (0.1025)  classification: 0.4530 (0.4794)  time: 0.3507  data: 0.1242  max mem: 3278
Epoch: [34]  [2200/3494]  eta: 0:07:45  lr: 0.0000010  loss: 0.5341 (0.5820)  bbox_regression: 0.0975 (0.1027)  classification: 0.4316 (0.4793)  time: 0.3524  data: 0.1241  max mem: 3278
Epoch: [34]  [2300/3494]  eta: 0:07:09  lr: 0.0000010  loss: 0.5800 (0.5822)  bbox_regression: 0.0917 (0.1027)  classification: 0.4757 (0.4795)  time: 0.3472  data: 0.1243  max mem: 3278
Epoch: [34]  [2400/3494]  eta: 0:06:33  lr: 0.0000010  loss: 0.5455 (0.5831)  bbox_regression: 0.0934 (0.1029)  classification: 0.4579 (0.4802)  time: 0.3575  data: 0.1288  max mem: 3278
Epoch: [34]  [2500/3494]  eta: 0:05:57  lr: 0.0000010  loss: 0.5420 (0.5830)  bbox_regression: 0.0971 (0.1030)  classification: 0.4397 (0.4800)  time: 0.3605  data: 0.1294  max mem: 3278
Epoch: [34]  [2600/3494]  eta: 0:05:21  lr: 0.0000010  loss: 0.5652 (0.5820)  bbox_regression: 0.1011 (0.1029)  classification: 0.4565 (0.4791)  time: 0.3654  data: 0.1326  max mem: 3278
Epoch: [34]  [2700/3494]  eta: 0:04:45  lr: 0.0000010  loss: 0.5630 (0.5826)  bbox_regression: 0.1063 (0.1031)  classification: 0.4739 (0.4795)  time: 0.3592  data: 0.1293  max mem: 3278
Epoch: [34]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.5483 (0.5828)  bbox_regression: 0.0925 (0.1032)  classification: 0.4353 (0.4796)  time: 0.3596  data: 0.1273  max mem: 3278
Epoch: [34]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5560 (0.5828)  bbox_regression: 0.0985 (0.1033)  classification: 0.4533 (0.4795)  time: 0.3557  data: 0.1261  max mem: 3278
Epoch: [34]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.5223 (0.5831)  bbox_regression: 0.0877 (0.1032)  classification: 0.4356 (0.4798)  time: 0.3565  data: 0.1251  max mem: 3278
Epoch: [34]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5537 (0.5833)  bbox_regression: 0.0894 (0.1032)  classification: 0.4574 (0.4801)  time: 0.3691  data: 0.1337  max mem: 3278
Epoch: [34]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5902 (0.5838)  bbox_regression: 0.0935 (0.1034)  classification: 0.5044 (0.4804)  time: 0.3600  data: 0.1328  max mem: 3278
Epoch: [34]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5863 (0.5833)  bbox_regression: 0.0972 (0.1033)  classification: 0.4785 (0.4800)  time: 0.3634  data: 0.1289  max mem: 3278
Epoch: [34]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5361 (0.5833)  bbox_regression: 0.0897 (0.1033)  classification: 0.4382 (0.4800)  time: 0.3635  data: 0.1310  max mem: 3278
Epoch: [34]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.6214 (0.5834)  bbox_regression: 0.0998 (0.1032)  classification: 0.4701 (0.4802)  time: 0.3535  data: 0.1273  max mem: 3278
Epoch: [34] Total time: 0:21:06 (0.3625 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:44  model_time: 0.1285 (0.1285)  loss: 1.0470 (1.0470)  bbox_regression: 0.1267 (0.1267)  classification: 0.9202 (0.9202)  time: 2.1618  data: 2.0126  max mem: 3278
Validation:  [100/437]  eta: 0:01:32  model_time: 0.1242 (0.1201)  loss: 0.7719 (0.9009)  bbox_regression: 0.1663 (0.1627)  classification: 0.6146 (0.7382)  time: 0.2851  data: 0.1416  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1190 (0.1207)  loss: 0.7652 (0.8628)  bbox_regression: 0.1418 (0.1532)  classification: 0.6506 (0.7095)  time: 0.2639  data: 0.1255  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1153 (0.1217)  loss: 0.8969 (0.8651)  bbox_regression: 0.1452 (0.1499)  classification: 0.7640 (0.7152)  time: 0.2585  data: 0.1216  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1240 (0.1216)  loss: 0.7398 (0.8613)  bbox_regression: 0.1420 (0.1500)  classification: 0.6168 (0.7113)  time: 0.2682  data: 0.1274  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1249 (0.1214)  loss: 0.7314 (0.8622)  bbox_regression: 0.1219 (0.1502)  classification: 0.6347 (0.7121)  time: 0.2606  data: 0.1226  max mem: 3278
Validation: Total time: 0:01:56 (0.2660 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [35]  [   0/3494]  eta: 2:04:32  lr: 0.0000010  loss: 0.6302 (0.6302)  bbox_regression: 0.1330 (0.1330)  classification: 0.4972 (0.4972)  time: 2.1386  data: 1.8938  max mem: 3278
Epoch: [35]  [ 100/3494]  eta: 0:21:27  lr: 0.0000010  loss: 0.5369 (0.5895)  bbox_regression: 0.0972 (0.1059)  classification: 0.4571 (0.4836)  time: 0.3610  data: 0.1293  max mem: 3278
Epoch: [35]  [ 200/3494]  eta: 0:20:25  lr: 0.0000010  loss: 0.5498 (0.5816)  bbox_regression: 0.1003 (0.1044)  classification: 0.4482 (0.4772)  time: 0.3493  data: 0.1248  max mem: 3278
Epoch: [35]  [ 300/3494]  eta: 0:19:34  lr: 0.0000010  loss: 0.5668 (0.5802)  bbox_regression: 0.0919 (0.1030)  classification: 0.4728 (0.4773)  time: 0.3596  data: 0.1285  max mem: 3278
Epoch: [35]  [ 400/3494]  eta: 0:18:56  lr: 0.0000010  loss: 0.5588 (0.5778)  bbox_regression: 0.1017 (0.1024)  classification: 0.4583 (0.4754)  time: 0.3682  data: 0.1313  max mem: 3278
Epoch: [35]  [ 500/3494]  eta: 0:18:16  lr: 0.0000010  loss: 0.5892 (0.5777)  bbox_regression: 0.0972 (0.1025)  classification: 0.4865 (0.4752)  time: 0.3668  data: 0.1287  max mem: 3278
Epoch: [35]  [ 600/3494]  eta: 0:17:38  lr: 0.0000010  loss: 0.5672 (0.5809)  bbox_regression: 0.1001 (0.1035)  classification: 0.4540 (0.4774)  time: 0.3675  data: 0.1298  max mem: 3278
Epoch: [35]  [ 700/3494]  eta: 0:16:59  lr: 0.0000010  loss: 0.5880 (0.5821)  bbox_regression: 0.1037 (0.1034)  classification: 0.4847 (0.4786)  time: 0.3515  data: 0.1224  max mem: 3278
Epoch: [35]  [ 800/3494]  eta: 0:16:19  lr: 0.0000010  loss: 0.5330 (0.5816)  bbox_regression: 0.0989 (0.1034)  classification: 0.4341 (0.4782)  time: 0.3360  data: 0.1089  max mem: 3278
Epoch: [35]  [ 900/3494]  eta: 0:15:41  lr: 0.0000010  loss: 0.5487 (0.5830)  bbox_regression: 0.0905 (0.1036)  classification: 0.4674 (0.4793)  time: 0.3544  data: 0.1327  max mem: 3278
Epoch: [35]  [1000/3494]  eta: 0:15:03  lr: 0.0000010  loss: 0.5689 (0.5843)  bbox_regression: 0.0974 (0.1038)  classification: 0.4764 (0.4805)  time: 0.3610  data: 0.1271  max mem: 3278
Epoch: [35]  [1100/3494]  eta: 0:14:25  lr: 0.0000010  loss: 0.6050 (0.5845)  bbox_regression: 0.0942 (0.1041)  classification: 0.5078 (0.4804)  time: 0.3413  data: 0.1159  max mem: 3278
Epoch: [35]  [1200/3494]  eta: 0:13:49  lr: 0.0000010  loss: 0.5879 (0.5830)  bbox_regression: 0.0787 (0.1036)  classification: 0.4863 (0.4793)  time: 0.3637  data: 0.1295  max mem: 3278
Epoch: [35]  [1300/3494]  eta: 0:13:12  lr: 0.0000010  loss: 0.5951 (0.5830)  bbox_regression: 0.0977 (0.1035)  classification: 0.4588 (0.4795)  time: 0.3507  data: 0.1260  max mem: 3278
Epoch: [35]  [1400/3494]  eta: 0:12:33  lr: 0.0000010  loss: 0.5819 (0.5835)  bbox_regression: 0.1067 (0.1034)  classification: 0.4571 (0.4801)  time: 0.3582  data: 0.1283  max mem: 3278
Epoch: [35]  [1500/3494]  eta: 0:11:58  lr: 0.0000010  loss: 0.5451 (0.5820)  bbox_regression: 0.0883 (0.1031)  classification: 0.4367 (0.4790)  time: 0.3643  data: 0.1304  max mem: 3278
Epoch: [35]  [1600/3494]  eta: 0:11:23  lr: 0.0000010  loss: 0.5824 (0.5819)  bbox_regression: 0.0951 (0.1029)  classification: 0.4878 (0.4790)  time: 0.3564  data: 0.1290  max mem: 3278
Epoch: [35]  [1700/3494]  eta: 0:10:46  lr: 0.0000010  loss: 0.5498 (0.5810)  bbox_regression: 0.1020 (0.1028)  classification: 0.4389 (0.4782)  time: 0.3635  data: 0.1304  max mem: 3278
Epoch: [35]  [1800/3494]  eta: 0:10:10  lr: 0.0000010  loss: 0.5991 (0.5809)  bbox_regression: 0.0958 (0.1025)  classification: 0.5011 (0.4783)  time: 0.3682  data: 0.1287  max mem: 3278
Epoch: [35]  [1900/3494]  eta: 0:09:34  lr: 0.0000010  loss: 0.5354 (0.5826)  bbox_regression: 0.0924 (0.1030)  classification: 0.4430 (0.4796)  time: 0.3664  data: 0.1300  max mem: 3278
Epoch: [35]  [2000/3494]  eta: 0:08:58  lr: 0.0000010  loss: 0.5931 (0.5829)  bbox_regression: 0.0965 (0.1029)  classification: 0.5021 (0.4800)  time: 0.3724  data: 0.1364  max mem: 3278
Epoch: [35]  [2100/3494]  eta: 0:08:22  lr: 0.0000010  loss: 0.5490 (0.5829)  bbox_regression: 0.0924 (0.1032)  classification: 0.4386 (0.4798)  time: 0.3786  data: 0.1373  max mem: 3278
Epoch: [35]  [2200/3494]  eta: 0:07:45  lr: 0.0000010  loss: 0.5864 (0.5833)  bbox_regression: 0.0858 (0.1032)  classification: 0.4914 (0.4800)  time: 0.2932  data: 0.0910  max mem: 3278
Epoch: [35]  [2300/3494]  eta: 0:07:10  lr: 0.0000010  loss: 0.5712 (0.5829)  bbox_regression: 0.0967 (0.1030)  classification: 0.4687 (0.4799)  time: 0.3724  data: 0.1337  max mem: 3278
Epoch: [35]  [2400/3494]  eta: 0:06:34  lr: 0.0000010  loss: 0.5350 (0.5822)  bbox_regression: 0.0905 (0.1030)  classification: 0.4297 (0.4792)  time: 0.3650  data: 0.1367  max mem: 3278
Epoch: [35]  [2500/3494]  eta: 0:05:58  lr: 0.0000010  loss: 0.6167 (0.5818)  bbox_regression: 0.1049 (0.1030)  classification: 0.4840 (0.4788)  time: 0.3562  data: 0.1276  max mem: 3278
Epoch: [35]  [2600/3494]  eta: 0:05:22  lr: 0.0000010  loss: 0.5576 (0.5820)  bbox_regression: 0.1050 (0.1031)  classification: 0.4710 (0.4788)  time: 0.3513  data: 0.1267  max mem: 3278
Epoch: [35]  [2700/3494]  eta: 0:04:46  lr: 0.0000010  loss: 0.5586 (0.5822)  bbox_regression: 0.1041 (0.1032)  classification: 0.4623 (0.4790)  time: 0.3705  data: 0.1347  max mem: 3278
Epoch: [35]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.5480 (0.5822)  bbox_regression: 0.0878 (0.1031)  classification: 0.4776 (0.4791)  time: 0.3494  data: 0.1231  max mem: 3278
Epoch: [35]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5723 (0.5825)  bbox_regression: 0.0948 (0.1030)  classification: 0.4756 (0.4795)  time: 0.3638  data: 0.1336  max mem: 3278
Epoch: [35]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.5535 (0.5826)  bbox_regression: 0.1003 (0.1031)  classification: 0.4464 (0.4794)  time: 0.3538  data: 0.1256  max mem: 3278
Epoch: [35]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5673 (0.5829)  bbox_regression: 0.0842 (0.1032)  classification: 0.4706 (0.4797)  time: 0.3550  data: 0.1274  max mem: 3278
Epoch: [35]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5815 (0.5834)  bbox_regression: 0.0988 (0.1032)  classification: 0.4957 (0.4802)  time: 0.3623  data: 0.1314  max mem: 3278
Epoch: [35]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5678 (0.5830)  bbox_regression: 0.1081 (0.1031)  classification: 0.4525 (0.4799)  time: 0.3332  data: 0.1109  max mem: 3278
Epoch: [35]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5396 (0.5831)  bbox_regression: 0.0989 (0.1032)  classification: 0.4357 (0.4799)  time: 0.3523  data: 0.1253  max mem: 3278
Epoch: [35]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5543 (0.5831)  bbox_regression: 0.0929 (0.1031)  classification: 0.4442 (0.4800)  time: 0.3574  data: 0.1294  max mem: 3278
Epoch: [35] Total time: 0:21:07 (0.3628 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:43  model_time: 0.1217 (0.1217)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.2966  data: 2.1482  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1158 (0.1200)  loss: 0.7720 (0.9010)  bbox_regression: 0.1663 (0.1627)  classification: 0.6146 (0.7383)  time: 0.2504  data: 0.1152  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1266 (0.1221)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6511 (0.7095)  time: 0.2744  data: 0.1288  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1187 (0.1221)  loss: 0.8972 (0.8651)  bbox_regression: 0.1451 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2663  data: 0.1257  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1227 (0.1216)  loss: 0.7399 (0.8613)  bbox_regression: 0.1417 (0.1500)  classification: 0.6164 (0.7113)  time: 0.2646  data: 0.1261  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1189 (0.1218)  loss: 0.7317 (0.8623)  bbox_regression: 0.1220 (0.1502)  classification: 0.6350 (0.7121)  time: 0.2600  data: 0.1216  max mem: 3278
Validation: Total time: 0:01:57 (0.2694 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [36]  [   0/3494]  eta: 2:01:51  lr: 0.0000010  loss: 0.4304 (0.4304)  bbox_regression: 0.0925 (0.0925)  classification: 0.3378 (0.3378)  time: 2.0927  data: 1.8541  max mem: 3278
Epoch: [36]  [ 100/3494]  eta: 0:21:06  lr: 0.0000010  loss: 0.5404 (0.5732)  bbox_regression: 0.0874 (0.1029)  classification: 0.4402 (0.4703)  time: 0.3466  data: 0.1237  max mem: 3278
Epoch: [36]  [ 200/3494]  eta: 0:20:14  lr: 0.0000010  loss: 0.5278 (0.5800)  bbox_regression: 0.0965 (0.1036)  classification: 0.4529 (0.4764)  time: 0.3598  data: 0.1250  max mem: 3278
Epoch: [36]  [ 300/3494]  eta: 0:19:21  lr: 0.0000010  loss: 0.5632 (0.5781)  bbox_regression: 0.0845 (0.1030)  classification: 0.4729 (0.4751)  time: 0.3282  data: 0.1118  max mem: 3278
Epoch: [36]  [ 400/3494]  eta: 0:18:42  lr: 0.0000010  loss: 0.5496 (0.5741)  bbox_regression: 0.0927 (0.1015)  classification: 0.4545 (0.4726)  time: 0.3598  data: 0.1300  max mem: 3278
Epoch: [36]  [ 500/3494]  eta: 0:18:01  lr: 0.0000010  loss: 0.5752 (0.5754)  bbox_regression: 0.0898 (0.1012)  classification: 0.4874 (0.4741)  time: 0.3508  data: 0.1203  max mem: 3278
Epoch: [36]  [ 600/3494]  eta: 0:17:20  lr: 0.0000010  loss: 0.5600 (0.5779)  bbox_regression: 0.0922 (0.1015)  classification: 0.4568 (0.4763)  time: 0.3344  data: 0.1119  max mem: 3278
Epoch: [36]  [ 700/3494]  eta: 0:16:45  lr: 0.0000010  loss: 0.5543 (0.5820)  bbox_regression: 0.0921 (0.1018)  classification: 0.4569 (0.4802)  time: 0.3571  data: 0.1273  max mem: 3278
Epoch: [36]  [ 800/3494]  eta: 0:16:10  lr: 0.0000010  loss: 0.5470 (0.5811)  bbox_regression: 0.0843 (0.1020)  classification: 0.4431 (0.4791)  time: 0.3609  data: 0.1287  max mem: 3278
Epoch: [36]  [ 900/3494]  eta: 0:15:32  lr: 0.0000010  loss: 0.5731 (0.5828)  bbox_regression: 0.1049 (0.1025)  classification: 0.4845 (0.4803)  time: 0.3622  data: 0.1306  max mem: 3278
Epoch: [36]  [1000/3494]  eta: 0:14:57  lr: 0.0000010  loss: 0.5598 (0.5823)  bbox_regression: 0.1108 (0.1026)  classification: 0.4471 (0.4796)  time: 0.3584  data: 0.1288  max mem: 3278
Epoch: [36]  [1100/3494]  eta: 0:14:21  lr: 0.0000010  loss: 0.5546 (0.5824)  bbox_regression: 0.1014 (0.1025)  classification: 0.4643 (0.4799)  time: 0.3564  data: 0.1260  max mem: 3278
Epoch: [36]  [1200/3494]  eta: 0:13:45  lr: 0.0000010  loss: 0.5365 (0.5820)  bbox_regression: 0.1000 (0.1026)  classification: 0.4568 (0.4794)  time: 0.3706  data: 0.1315  max mem: 3278
Epoch: [36]  [1300/3494]  eta: 0:13:10  lr: 0.0000010  loss: 0.5649 (0.5819)  bbox_regression: 0.0909 (0.1024)  classification: 0.4741 (0.4795)  time: 0.3625  data: 0.1299  max mem: 3278
Epoch: [36]  [1400/3494]  eta: 0:12:33  lr: 0.0000010  loss: 0.5708 (0.5828)  bbox_regression: 0.1032 (0.1026)  classification: 0.4662 (0.4802)  time: 0.3678  data: 0.1326  max mem: 3278
Epoch: [36]  [1500/3494]  eta: 0:11:57  lr: 0.0000010  loss: 0.5385 (0.5826)  bbox_regression: 0.1037 (0.1027)  classification: 0.4495 (0.4799)  time: 0.3555  data: 0.1242  max mem: 3278
Epoch: [36]  [1600/3494]  eta: 0:11:21  lr: 0.0000010  loss: 0.5593 (0.5833)  bbox_regression: 0.0978 (0.1030)  classification: 0.4589 (0.4803)  time: 0.3538  data: 0.1273  max mem: 3278
Epoch: [36]  [1700/3494]  eta: 0:10:45  lr: 0.0000010  loss: 0.5225 (0.5829)  bbox_regression: 0.1035 (0.1029)  classification: 0.4375 (0.4800)  time: 0.3589  data: 0.1311  max mem: 3278
Epoch: [36]  [1800/3494]  eta: 0:10:09  lr: 0.0000010  loss: 0.5547 (0.5823)  bbox_regression: 0.0942 (0.1030)  classification: 0.4584 (0.4793)  time: 0.3499  data: 0.1262  max mem: 3278
Epoch: [36]  [1900/3494]  eta: 0:09:33  lr: 0.0000010  loss: 0.5652 (0.5811)  bbox_regression: 0.0991 (0.1029)  classification: 0.4730 (0.4782)  time: 0.3644  data: 0.1341  max mem: 3278
Epoch: [36]  [2000/3494]  eta: 0:08:57  lr: 0.0000010  loss: 0.5310 (0.5807)  bbox_regression: 0.0986 (0.1028)  classification: 0.4205 (0.4779)  time: 0.3521  data: 0.1231  max mem: 3278
Epoch: [36]  [2100/3494]  eta: 0:08:20  lr: 0.0000010  loss: 0.5589 (0.5805)  bbox_regression: 0.1005 (0.1028)  classification: 0.4643 (0.4777)  time: 0.3692  data: 0.1333  max mem: 3278
Epoch: [36]  [2200/3494]  eta: 0:07:45  lr: 0.0000010  loss: 0.5403 (0.5802)  bbox_regression: 0.0953 (0.1024)  classification: 0.4352 (0.4778)  time: 0.3591  data: 0.1289  max mem: 3278
Epoch: [36]  [2300/3494]  eta: 0:07:09  lr: 0.0000010  loss: 0.5790 (0.5801)  bbox_regression: 0.0949 (0.1025)  classification: 0.4682 (0.4776)  time: 0.3748  data: 0.1372  max mem: 3278
Epoch: [36]  [2400/3494]  eta: 0:06:33  lr: 0.0000010  loss: 0.5764 (0.5801)  bbox_regression: 0.0942 (0.1026)  classification: 0.4821 (0.4775)  time: 0.3509  data: 0.1265  max mem: 3278
Epoch: [36]  [2500/3494]  eta: 0:05:57  lr: 0.0000010  loss: 0.5593 (0.5805)  bbox_regression: 0.0923 (0.1027)  classification: 0.4459 (0.4778)  time: 0.3479  data: 0.1229  max mem: 3278
Epoch: [36]  [2600/3494]  eta: 0:05:21  lr: 0.0000010  loss: 0.5345 (0.5812)  bbox_regression: 0.0917 (0.1028)  classification: 0.4292 (0.4784)  time: 0.3650  data: 0.1368  max mem: 3278
Epoch: [36]  [2700/3494]  eta: 0:04:45  lr: 0.0000010  loss: 0.5521 (0.5816)  bbox_regression: 0.0869 (0.1028)  classification: 0.4561 (0.4787)  time: 0.3646  data: 0.1313  max mem: 3278
Epoch: [36]  [2800/3494]  eta: 0:04:09  lr: 0.0000010  loss: 0.5214 (0.5825)  bbox_regression: 0.0819 (0.1030)  classification: 0.4395 (0.4794)  time: 0.3619  data: 0.1351  max mem: 3278
Epoch: [36]  [2900/3494]  eta: 0:03:33  lr: 0.0000010  loss: 0.5416 (0.5829)  bbox_regression: 0.0940 (0.1031)  classification: 0.4335 (0.4799)  time: 0.3615  data: 0.1302  max mem: 3278
Epoch: [36]  [3000/3494]  eta: 0:02:57  lr: 0.0000010  loss: 0.5766 (0.5831)  bbox_regression: 0.0966 (0.1031)  classification: 0.4907 (0.4800)  time: 0.3640  data: 0.1340  max mem: 3278
Epoch: [36]  [3100/3494]  eta: 0:02:21  lr: 0.0000010  loss: 0.5932 (0.5831)  bbox_regression: 0.0919 (0.1031)  classification: 0.4888 (0.4800)  time: 0.3695  data: 0.1367  max mem: 3278
Epoch: [36]  [3200/3494]  eta: 0:01:45  lr: 0.0000010  loss: 0.5495 (0.5833)  bbox_regression: 0.0876 (0.1030)  classification: 0.4576 (0.4803)  time: 0.3614  data: 0.1311  max mem: 3278
Epoch: [36]  [3300/3494]  eta: 0:01:09  lr: 0.0000010  loss: 0.5641 (0.5834)  bbox_regression: 0.0940 (0.1032)  classification: 0.4783 (0.4803)  time: 0.3636  data: 0.1269  max mem: 3278
Epoch: [36]  [3400/3494]  eta: 0:00:33  lr: 0.0000010  loss: 0.5043 (0.5829)  bbox_regression: 0.0871 (0.1030)  classification: 0.4367 (0.4799)  time: 0.3614  data: 0.1318  max mem: 3278
Epoch: [36]  [3493/3494]  eta: 0:00:00  lr: 0.0000010  loss: 0.5370 (0.5831)  bbox_regression: 0.0941 (0.1031)  classification: 0.4494 (0.4800)  time: 0.3462  data: 0.1241  max mem: 3278
Epoch: [36] Total time: 0:21:05 (0.3623 s / it)
Epoch 00037: reducing learning rate of group 0 to 1.0000e-07.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:45  model_time: 0.1323 (0.1323)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9206 (0.9206)  time: 2.1628  data: 2.0122  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1223 (0.1232)  loss: 0.7708 (0.9009)  bbox_regression: 0.1662 (0.1626)  classification: 0.6137 (0.7383)  time: 0.2824  data: 0.1405  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1174 (0.1218)  loss: 0.7655 (0.8628)  bbox_regression: 0.1418 (0.1532)  classification: 0.6513 (0.7095)  time: 0.2614  data: 0.1238  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1169 (0.1232)  loss: 0.8972 (0.8651)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2646  data: 0.1267  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1162 (0.1237)  loss: 0.7399 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2609  data: 0.1232  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1175 (0.1238)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2582  data: 0.1194  max mem: 3278
Validation: Total time: 0:01:59 (0.2742 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [37]  [   0/3494]  eta: 2:03:28  lr: 0.0000001  loss: 0.6454 (0.6454)  bbox_regression: 0.0825 (0.0825)  classification: 0.5629 (0.5629)  time: 2.1204  data: 1.8331  max mem: 3278
Epoch: [37]  [ 100/3494]  eta: 0:20:58  lr: 0.0000001  loss: 0.6503 (0.5928)  bbox_regression: 0.1088 (0.1062)  classification: 0.5259 (0.4866)  time: 0.3636  data: 0.1277  max mem: 3278
Epoch: [37]  [ 200/3494]  eta: 0:20:05  lr: 0.0000001  loss: 0.5881 (0.5844)  bbox_regression: 0.0967 (0.1043)  classification: 0.4555 (0.4801)  time: 0.3710  data: 0.1355  max mem: 3278
Epoch: [37]  [ 300/3494]  eta: 0:19:22  lr: 0.0000001  loss: 0.5631 (0.5856)  bbox_regression: 0.0924 (0.1054)  classification: 0.4520 (0.4802)  time: 0.3606  data: 0.1261  max mem: 3278
Epoch: [37]  [ 400/3494]  eta: 0:18:45  lr: 0.0000001  loss: 0.5625 (0.5831)  bbox_regression: 0.0917 (0.1041)  classification: 0.4679 (0.4790)  time: 0.3646  data: 0.1360  max mem: 3278
Epoch: [37]  [ 500/3494]  eta: 0:18:07  lr: 0.0000001  loss: 0.5346 (0.5778)  bbox_regression: 0.0981 (0.1034)  classification: 0.4509 (0.4744)  time: 0.3642  data: 0.1308  max mem: 3278
Epoch: [37]  [ 600/3494]  eta: 0:17:26  lr: 0.0000001  loss: 0.5124 (0.5760)  bbox_regression: 0.0837 (0.1029)  classification: 0.4127 (0.4731)  time: 0.3314  data: 0.1123  max mem: 3278
Epoch: [37]  [ 700/3494]  eta: 0:16:49  lr: 0.0000001  loss: 0.5461 (0.5790)  bbox_regression: 0.0939 (0.1029)  classification: 0.4284 (0.4761)  time: 0.3678  data: 0.1291  max mem: 3278
Epoch: [37]  [ 800/3494]  eta: 0:16:12  lr: 0.0000001  loss: 0.6104 (0.5804)  bbox_regression: 0.1069 (0.1031)  classification: 0.5032 (0.4773)  time: 0.3562  data: 0.1263  max mem: 3278
Epoch: [37]  [ 900/3494]  eta: 0:15:35  lr: 0.0000001  loss: 0.5399 (0.5798)  bbox_regression: 0.0901 (0.1027)  classification: 0.4562 (0.4771)  time: 0.3583  data: 0.1288  max mem: 3278
Epoch: [37]  [1000/3494]  eta: 0:14:59  lr: 0.0000001  loss: 0.5517 (0.5809)  bbox_regression: 0.0946 (0.1026)  classification: 0.4518 (0.4783)  time: 0.3565  data: 0.1284  max mem: 3278
Epoch: [37]  [1100/3494]  eta: 0:14:22  lr: 0.0000001  loss: 0.5705 (0.5806)  bbox_regression: 0.0915 (0.1025)  classification: 0.4711 (0.4781)  time: 0.3463  data: 0.1177  max mem: 3278
Epoch: [37]  [1200/3494]  eta: 0:13:45  lr: 0.0000001  loss: 0.5345 (0.5815)  bbox_regression: 0.0880 (0.1026)  classification: 0.4314 (0.4789)  time: 0.3571  data: 0.1273  max mem: 3278
Epoch: [37]  [1300/3494]  eta: 0:13:10  lr: 0.0000001  loss: 0.4882 (0.5809)  bbox_regression: 0.0869 (0.1025)  classification: 0.4092 (0.4784)  time: 0.3696  data: 0.1376  max mem: 3278
Epoch: [37]  [1400/3494]  eta: 0:12:34  lr: 0.0000001  loss: 0.5144 (0.5802)  bbox_regression: 0.0842 (0.1025)  classification: 0.4386 (0.4777)  time: 0.3595  data: 0.1285  max mem: 3278
Epoch: [37]  [1500/3494]  eta: 0:11:57  lr: 0.0000001  loss: 0.5490 (0.5810)  bbox_regression: 0.1011 (0.1031)  classification: 0.4553 (0.4779)  time: 0.3643  data: 0.1335  max mem: 3278
Epoch: [37]  [1600/3494]  eta: 0:11:21  lr: 0.0000001  loss: 0.5819 (0.5819)  bbox_regression: 0.1048 (0.1033)  classification: 0.4558 (0.4786)  time: 0.3591  data: 0.1290  max mem: 3278
Epoch: [37]  [1700/3494]  eta: 0:10:45  lr: 0.0000001  loss: 0.5717 (0.5818)  bbox_regression: 0.1035 (0.1034)  classification: 0.4789 (0.4784)  time: 0.3603  data: 0.1232  max mem: 3278
Epoch: [37]  [1800/3494]  eta: 0:10:09  lr: 0.0000001  loss: 0.5377 (0.5814)  bbox_regression: 0.0941 (0.1034)  classification: 0.4342 (0.4780)  time: 0.3663  data: 0.1341  max mem: 3278
Epoch: [37]  [1900/3494]  eta: 0:09:33  lr: 0.0000001  loss: 0.5424 (0.5822)  bbox_regression: 0.0942 (0.1036)  classification: 0.4482 (0.4787)  time: 0.3630  data: 0.1298  max mem: 3278
Epoch: [37]  [2000/3494]  eta: 0:08:57  lr: 0.0000001  loss: 0.5763 (0.5831)  bbox_regression: 0.1036 (0.1038)  classification: 0.4908 (0.4793)  time: 0.3784  data: 0.1401  max mem: 3278
Epoch: [37]  [2100/3494]  eta: 0:08:21  lr: 0.0000001  loss: 0.6517 (0.5836)  bbox_regression: 0.1004 (0.1038)  classification: 0.5421 (0.4798)  time: 0.3580  data: 0.1273  max mem: 3278
Epoch: [37]  [2200/3494]  eta: 0:07:45  lr: 0.0000001  loss: 0.5931 (0.5841)  bbox_regression: 0.0928 (0.1038)  classification: 0.5056 (0.4803)  time: 0.3615  data: 0.1296  max mem: 3278
Epoch: [37]  [2300/3494]  eta: 0:07:08  lr: 0.0000001  loss: 0.5301 (0.5844)  bbox_regression: 0.1012 (0.1039)  classification: 0.4316 (0.4805)  time: 0.3673  data: 0.1298  max mem: 3278
Epoch: [37]  [2400/3494]  eta: 0:06:32  lr: 0.0000001  loss: 0.5713 (0.5845)  bbox_regression: 0.0930 (0.1039)  classification: 0.4674 (0.4806)  time: 0.3545  data: 0.1277  max mem: 3278
Epoch: [37]  [2500/3494]  eta: 0:05:56  lr: 0.0000001  loss: 0.5445 (0.5843)  bbox_regression: 0.1037 (0.1037)  classification: 0.4486 (0.4806)  time: 0.3598  data: 0.1271  max mem: 3278
Epoch: [37]  [2600/3494]  eta: 0:05:21  lr: 0.0000001  loss: 0.5407 (0.5831)  bbox_regression: 0.0929 (0.1035)  classification: 0.4515 (0.4796)  time: 0.3641  data: 0.1328  max mem: 3278
Epoch: [37]  [2700/3494]  eta: 0:04:45  lr: 0.0000001  loss: 0.5442 (0.5830)  bbox_regression: 0.1108 (0.1034)  classification: 0.4770 (0.4795)  time: 0.3566  data: 0.1253  max mem: 3278
Epoch: [37]  [2800/3494]  eta: 0:04:09  lr: 0.0000001  loss: 0.5423 (0.5833)  bbox_regression: 0.0958 (0.1035)  classification: 0.4612 (0.4798)  time: 0.3574  data: 0.1274  max mem: 3278
Epoch: [37]  [2900/3494]  eta: 0:03:33  lr: 0.0000001  loss: 0.5856 (0.5827)  bbox_regression: 0.0977 (0.1031)  classification: 0.4973 (0.4795)  time: 0.3583  data: 0.1280  max mem: 3278
Epoch: [37]  [3000/3494]  eta: 0:02:57  lr: 0.0000001  loss: 0.5511 (0.5831)  bbox_regression: 0.0973 (0.1031)  classification: 0.4639 (0.4801)  time: 0.3668  data: 0.1326  max mem: 3278
Epoch: [37]  [3100/3494]  eta: 0:02:21  lr: 0.0000001  loss: 0.5708 (0.5827)  bbox_regression: 0.0932 (0.1031)  classification: 0.4619 (0.4797)  time: 0.3609  data: 0.1308  max mem: 3278
Epoch: [37]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5275 (0.5826)  bbox_regression: 0.0801 (0.1030)  classification: 0.4457 (0.4796)  time: 0.3554  data: 0.1267  max mem: 3278
Epoch: [37]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5944 (0.5824)  bbox_regression: 0.0919 (0.1030)  classification: 0.4983 (0.4794)  time: 0.3488  data: 0.1238  max mem: 3278
Epoch: [37]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5603 (0.5824)  bbox_regression: 0.1015 (0.1031)  classification: 0.4524 (0.4793)  time: 0.3605  data: 0.1273  max mem: 3278
Epoch: [37]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5480 (0.5823)  bbox_regression: 0.1053 (0.1032)  classification: 0.4392 (0.4791)  time: 0.3474  data: 0.1241  max mem: 3278
Epoch: [37] Total time: 0:21:05 (0.3622 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:07  model_time: 0.1414 (0.1414)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8027  data: 1.6347  max mem: 3278
Validation:  [100/437]  eta: 0:01:31  model_time: 0.1134 (0.1194)  loss: 0.7708 (0.9009)  bbox_regression: 0.1662 (0.1626)  classification: 0.6137 (0.7383)  time: 0.2552  data: 0.1225  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1136 (0.1212)  loss: 0.7656 (0.8628)  bbox_regression: 0.1418 (0.1532)  classification: 0.6513 (0.7095)  time: 0.2550  data: 0.1202  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1169 (0.1214)  loss: 0.8972 (0.8651)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2593  data: 0.1192  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1132 (0.1212)  loss: 0.7399 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2516  data: 0.1187  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1127 (0.1209)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2483  data: 0.1171  max mem: 3278
Validation: Total time: 0:01:55 (0.2638 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [38]  [   0/3494]  eta: 2:09:26  lr: 0.0000001  loss: 0.5884 (0.5884)  bbox_regression: 0.1175 (0.1175)  classification: 0.4708 (0.4708)  time: 2.2227  data: 1.9512  max mem: 3278
Epoch: [38]  [ 100/3494]  eta: 0:21:30  lr: 0.0000001  loss: 0.5316 (0.5712)  bbox_regression: 0.0866 (0.1037)  classification: 0.4445 (0.4675)  time: 0.3604  data: 0.1277  max mem: 3278
Epoch: [38]  [ 200/3494]  eta: 0:20:28  lr: 0.0000001  loss: 0.5992 (0.5814)  bbox_regression: 0.0888 (0.1046)  classification: 0.5111 (0.4768)  time: 0.3567  data: 0.1286  max mem: 3278
Epoch: [38]  [ 300/3494]  eta: 0:19:34  lr: 0.0000001  loss: 0.5279 (0.5770)  bbox_regression: 0.0883 (0.1031)  classification: 0.4455 (0.4740)  time: 0.3654  data: 0.1285  max mem: 3278
Epoch: [38]  [ 400/3494]  eta: 0:18:57  lr: 0.0000001  loss: 0.5737 (0.5787)  bbox_regression: 0.1042 (0.1032)  classification: 0.4694 (0.4755)  time: 0.3710  data: 0.1403  max mem: 3278
Epoch: [38]  [ 500/3494]  eta: 0:18:17  lr: 0.0000001  loss: 0.5364 (0.5783)  bbox_regression: 0.1050 (0.1029)  classification: 0.4542 (0.4754)  time: 0.3598  data: 0.1254  max mem: 3278
Epoch: [38]  [ 600/3494]  eta: 0:17:37  lr: 0.0000001  loss: 0.5757 (0.5780)  bbox_regression: 0.0946 (0.1029)  classification: 0.4938 (0.4750)  time: 0.3704  data: 0.1335  max mem: 3278
Epoch: [38]  [ 700/3494]  eta: 0:17:01  lr: 0.0000001  loss: 0.6335 (0.5825)  bbox_regression: 0.1046 (0.1038)  classification: 0.5015 (0.4787)  time: 0.3643  data: 0.1285  max mem: 3278
Epoch: [38]  [ 800/3494]  eta: 0:16:21  lr: 0.0000001  loss: 0.5575 (0.5838)  bbox_regression: 0.0920 (0.1039)  classification: 0.4435 (0.4799)  time: 0.3636  data: 0.1315  max mem: 3278
Epoch: [38]  [ 900/3494]  eta: 0:15:42  lr: 0.0000001  loss: 0.5938 (0.5838)  bbox_regression: 0.0982 (0.1037)  classification: 0.4819 (0.4801)  time: 0.3681  data: 0.1342  max mem: 3278
Epoch: [38]  [1000/3494]  eta: 0:15:05  lr: 0.0000001  loss: 0.5942 (0.5841)  bbox_regression: 0.0946 (0.1035)  classification: 0.5029 (0.4806)  time: 0.3669  data: 0.1333  max mem: 3278
Epoch: [38]  [1100/3494]  eta: 0:14:28  lr: 0.0000001  loss: 0.5442 (0.5846)  bbox_regression: 0.1029 (0.1035)  classification: 0.4487 (0.4812)  time: 0.3686  data: 0.1356  max mem: 3278
Epoch: [38]  [1200/3494]  eta: 0:13:50  lr: 0.0000001  loss: 0.5029 (0.5840)  bbox_regression: 0.0908 (0.1032)  classification: 0.4212 (0.4808)  time: 0.3537  data: 0.1254  max mem: 3278
Epoch: [38]  [1300/3494]  eta: 0:13:13  lr: 0.0000001  loss: 0.5652 (0.5843)  bbox_regression: 0.0915 (0.1034)  classification: 0.4660 (0.4809)  time: 0.3620  data: 0.1282  max mem: 3278
Epoch: [38]  [1400/3494]  eta: 0:12:35  lr: 0.0000001  loss: 0.5499 (0.5848)  bbox_regression: 0.0901 (0.1034)  classification: 0.4654 (0.4814)  time: 0.3609  data: 0.1315  max mem: 3278
Epoch: [38]  [1500/3494]  eta: 0:11:59  lr: 0.0000001  loss: 0.5480 (0.5837)  bbox_regression: 0.0896 (0.1032)  classification: 0.4639 (0.4805)  time: 0.3600  data: 0.1256  max mem: 3278
Epoch: [38]  [1600/3494]  eta: 0:11:24  lr: 0.0000001  loss: 0.5541 (0.5845)  bbox_regression: 0.1068 (0.1034)  classification: 0.4609 (0.4812)  time: 0.3702  data: 0.1316  max mem: 3278
Epoch: [38]  [1700/3494]  eta: 0:10:47  lr: 0.0000001  loss: 0.5834 (0.5833)  bbox_regression: 0.1053 (0.1031)  classification: 0.4546 (0.4802)  time: 0.3602  data: 0.1299  max mem: 3278
Epoch: [38]  [1800/3494]  eta: 0:10:11  lr: 0.0000001  loss: 0.5766 (0.5834)  bbox_regression: 0.0978 (0.1031)  classification: 0.4709 (0.4803)  time: 0.3533  data: 0.1258  max mem: 3278
Epoch: [38]  [1900/3494]  eta: 0:09:34  lr: 0.0000001  loss: 0.5874 (0.5837)  bbox_regression: 0.1009 (0.1034)  classification: 0.4752 (0.4803)  time: 0.3315  data: 0.1100  max mem: 3278
Epoch: [38]  [2000/3494]  eta: 0:08:59  lr: 0.0000001  loss: 0.5661 (0.5837)  bbox_regression: 0.0895 (0.1033)  classification: 0.4687 (0.4804)  time: 0.3614  data: 0.1290  max mem: 3278
Epoch: [38]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.6176 (0.5838)  bbox_regression: 0.1182 (0.1033)  classification: 0.5098 (0.4806)  time: 0.3494  data: 0.1220  max mem: 3278
Epoch: [38]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5805 (0.5832)  bbox_regression: 0.0956 (0.1031)  classification: 0.4666 (0.4800)  time: 0.3678  data: 0.1269  max mem: 3278
Epoch: [38]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5704 (0.5834)  bbox_regression: 0.0907 (0.1031)  classification: 0.4734 (0.4804)  time: 0.3530  data: 0.1231  max mem: 3278
Epoch: [38]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5139 (0.5833)  bbox_regression: 0.0932 (0.1033)  classification: 0.4318 (0.4800)  time: 0.3573  data: 0.1257  max mem: 3278
Epoch: [38]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5864 (0.5838)  bbox_regression: 0.1080 (0.1033)  classification: 0.4921 (0.4804)  time: 0.3607  data: 0.1310  max mem: 3278
Epoch: [38]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5765 (0.5838)  bbox_regression: 0.0871 (0.1034)  classification: 0.4677 (0.4804)  time: 0.3674  data: 0.1314  max mem: 3278
Epoch: [38]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5291 (0.5841)  bbox_regression: 0.0976 (0.1035)  classification: 0.4264 (0.4806)  time: 0.3691  data: 0.1293  max mem: 3278
Epoch: [38]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5807 (0.5844)  bbox_regression: 0.0919 (0.1035)  classification: 0.4696 (0.4809)  time: 0.3756  data: 0.1381  max mem: 3278
Epoch: [38]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5672 (0.5844)  bbox_regression: 0.1032 (0.1035)  classification: 0.4611 (0.4809)  time: 0.3731  data: 0.1329  max mem: 3278
Epoch: [38]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5600 (0.5844)  bbox_regression: 0.1019 (0.1035)  classification: 0.4625 (0.4810)  time: 0.3537  data: 0.1234  max mem: 3278
Epoch: [38]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5526 (0.5842)  bbox_regression: 0.0884 (0.1034)  classification: 0.4519 (0.4808)  time: 0.3654  data: 0.1328  max mem: 3278
Epoch: [38]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5917 (0.5842)  bbox_regression: 0.1072 (0.1034)  classification: 0.4729 (0.4808)  time: 0.3589  data: 0.1316  max mem: 3278
Epoch: [38]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5428 (0.5838)  bbox_regression: 0.1051 (0.1034)  classification: 0.4464 (0.4804)  time: 0.3489  data: 0.1224  max mem: 3278
Epoch: [38]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5428 (0.5837)  bbox_regression: 0.0956 (0.1033)  classification: 0.4468 (0.4804)  time: 0.3640  data: 0.1344  max mem: 3278
Epoch: [38]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.6057 (0.5833)  bbox_regression: 0.0907 (0.1031)  classification: 0.4958 (0.4802)  time: 0.3614  data: 0.1301  max mem: 3278
Epoch: [38] Total time: 0:21:09 (0.3633 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:00  model_time: 0.1275 (0.1275)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.6496  data: 1.4981  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1251 (0.1213)  loss: 0.7708 (0.9009)  bbox_regression: 0.1662 (0.1626)  classification: 0.6137 (0.7383)  time: 0.2673  data: 0.1250  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1136 (0.1212)  loss: 0.7656 (0.8628)  bbox_regression: 0.1418 (0.1532)  classification: 0.6513 (0.7095)  time: 0.2644  data: 0.1310  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1148 (0.1216)  loss: 0.8971 (0.8651)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2591  data: 0.1233  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1165 (0.1213)  loss: 0.7399 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2693  data: 0.1288  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1180 (0.1211)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2426  data: 0.1110  max mem: 3278
Validation: Total time: 0:01:56 (0.2662 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [39]  [   0/3494]  eta: 2:14:12  lr: 0.0000001  loss: 0.4908 (0.4908)  bbox_regression: 0.0993 (0.0993)  classification: 0.3915 (0.3915)  time: 2.3046  data: 2.0241  max mem: 3278
Epoch: [39]  [ 100/3494]  eta: 0:21:37  lr: 0.0000001  loss: 0.5504 (0.5723)  bbox_regression: 0.1069 (0.1049)  classification: 0.4278 (0.4674)  time: 0.3632  data: 0.1339  max mem: 3278
Epoch: [39]  [ 200/3494]  eta: 0:20:28  lr: 0.0000001  loss: 0.5300 (0.5655)  bbox_regression: 0.0958 (0.1026)  classification: 0.4524 (0.4628)  time: 0.3719  data: 0.1322  max mem: 3278
Epoch: [39]  [ 300/3494]  eta: 0:19:30  lr: 0.0000001  loss: 0.5827 (0.5740)  bbox_regression: 0.1045 (0.1043)  classification: 0.4790 (0.4697)  time: 0.3633  data: 0.1333  max mem: 3278
Epoch: [39]  [ 400/3494]  eta: 0:18:47  lr: 0.0000001  loss: 0.5656 (0.5794)  bbox_regression: 0.1098 (0.1048)  classification: 0.4772 (0.4746)  time: 0.3600  data: 0.1284  max mem: 3278
Epoch: [39]  [ 500/3494]  eta: 0:18:12  lr: 0.0000001  loss: 0.5565 (0.5805)  bbox_regression: 0.0874 (0.1041)  classification: 0.4672 (0.4765)  time: 0.3852  data: 0.1457  max mem: 3278
Epoch: [39]  [ 600/3494]  eta: 0:17:34  lr: 0.0000001  loss: 0.5847 (0.5816)  bbox_regression: 0.0922 (0.1037)  classification: 0.4847 (0.4779)  time: 0.3570  data: 0.1256  max mem: 3278
Epoch: [39]  [ 700/3494]  eta: 0:16:55  lr: 0.0000001  loss: 0.5360 (0.5818)  bbox_regression: 0.0924 (0.1037)  classification: 0.4457 (0.4782)  time: 0.3646  data: 0.1305  max mem: 3278
Epoch: [39]  [ 800/3494]  eta: 0:16:16  lr: 0.0000001  loss: 0.5398 (0.5792)  bbox_regression: 0.0980 (0.1025)  classification: 0.4415 (0.4766)  time: 0.3435  data: 0.1224  max mem: 3278
Epoch: [39]  [ 900/3494]  eta: 0:15:39  lr: 0.0000001  loss: 0.5538 (0.5808)  bbox_regression: 0.0912 (0.1030)  classification: 0.4632 (0.4778)  time: 0.3618  data: 0.1279  max mem: 3278
Epoch: [39]  [1000/3494]  eta: 0:15:04  lr: 0.0000001  loss: 0.5324 (0.5807)  bbox_regression: 0.0898 (0.1028)  classification: 0.4212 (0.4779)  time: 0.3823  data: 0.1451  max mem: 3278
Epoch: [39]  [1100/3494]  eta: 0:14:27  lr: 0.0000001  loss: 0.5963 (0.5803)  bbox_regression: 0.1138 (0.1029)  classification: 0.4776 (0.4775)  time: 0.3583  data: 0.1269  max mem: 3278
Epoch: [39]  [1200/3494]  eta: 0:13:51  lr: 0.0000001  loss: 0.4949 (0.5800)  bbox_regression: 0.0894 (0.1027)  classification: 0.4059 (0.4773)  time: 0.3639  data: 0.1304  max mem: 3278
Epoch: [39]  [1300/3494]  eta: 0:13:14  lr: 0.0000001  loss: 0.5394 (0.5797)  bbox_regression: 0.0905 (0.1029)  classification: 0.4428 (0.4769)  time: 0.3611  data: 0.1267  max mem: 3278
Epoch: [39]  [1400/3494]  eta: 0:12:36  lr: 0.0000001  loss: 0.5242 (0.5801)  bbox_regression: 0.0901 (0.1031)  classification: 0.4270 (0.4771)  time: 0.3559  data: 0.1261  max mem: 3278
Epoch: [39]  [1500/3494]  eta: 0:12:01  lr: 0.0000001  loss: 0.5710 (0.5816)  bbox_regression: 0.0966 (0.1034)  classification: 0.4841 (0.4782)  time: 0.3629  data: 0.1324  max mem: 3278
Epoch: [39]  [1600/3494]  eta: 0:11:23  lr: 0.0000001  loss: 0.5407 (0.5820)  bbox_regression: 0.1019 (0.1035)  classification: 0.4388 (0.4785)  time: 0.3590  data: 0.1269  max mem: 3278
Epoch: [39]  [1700/3494]  eta: 0:10:48  lr: 0.0000001  loss: 0.5751 (0.5827)  bbox_regression: 0.0962 (0.1038)  classification: 0.4797 (0.4789)  time: 0.3561  data: 0.1309  max mem: 3278
Epoch: [39]  [1800/3494]  eta: 0:10:11  lr: 0.0000001  loss: 0.5303 (0.5829)  bbox_regression: 0.0839 (0.1039)  classification: 0.4416 (0.4790)  time: 0.3581  data: 0.1264  max mem: 3278
Epoch: [39]  [1900/3494]  eta: 0:09:35  lr: 0.0000001  loss: 0.5446 (0.5827)  bbox_regression: 0.0928 (0.1038)  classification: 0.4489 (0.4789)  time: 0.3709  data: 0.1302  max mem: 3278
Epoch: [39]  [2000/3494]  eta: 0:08:59  lr: 0.0000001  loss: 0.6206 (0.5825)  bbox_regression: 0.1128 (0.1039)  classification: 0.5070 (0.4786)  time: 0.3513  data: 0.1272  max mem: 3278
Epoch: [39]  [2100/3494]  eta: 0:08:23  lr: 0.0000001  loss: 0.5320 (0.5824)  bbox_regression: 0.0907 (0.1038)  classification: 0.4358 (0.4786)  time: 0.3578  data: 0.1273  max mem: 3278
Epoch: [39]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5899 (0.5831)  bbox_regression: 0.1085 (0.1040)  classification: 0.4800 (0.4791)  time: 0.3522  data: 0.1245  max mem: 3278
Epoch: [39]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5668 (0.5833)  bbox_regression: 0.0953 (0.1038)  classification: 0.4883 (0.4795)  time: 0.3594  data: 0.1282  max mem: 3278
Epoch: [39]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5464 (0.5832)  bbox_regression: 0.1015 (0.1038)  classification: 0.4500 (0.4795)  time: 0.3564  data: 0.1292  max mem: 3278
Epoch: [39]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5442 (0.5829)  bbox_regression: 0.0898 (0.1036)  classification: 0.4583 (0.4793)  time: 0.3631  data: 0.1301  max mem: 3278
Epoch: [39]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.6197 (0.5834)  bbox_regression: 0.1041 (0.1036)  classification: 0.5236 (0.4799)  time: 0.3577  data: 0.1259  max mem: 3278
Epoch: [39]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5603 (0.5835)  bbox_regression: 0.0982 (0.1035)  classification: 0.4649 (0.4800)  time: 0.3640  data: 0.1296  max mem: 3278
Epoch: [39]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5110 (0.5835)  bbox_regression: 0.0867 (0.1034)  classification: 0.4265 (0.4800)  time: 0.3664  data: 0.1295  max mem: 3278
Epoch: [39]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5424 (0.5837)  bbox_regression: 0.0934 (0.1035)  classification: 0.4660 (0.4802)  time: 0.3714  data: 0.1344  max mem: 3278
Epoch: [39]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5110 (0.5831)  bbox_regression: 0.0966 (0.1033)  classification: 0.4306 (0.4798)  time: 0.3637  data: 0.1342  max mem: 3278
Epoch: [39]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5740 (0.5831)  bbox_regression: 0.0999 (0.1033)  classification: 0.4761 (0.4798)  time: 0.3692  data: 0.1341  max mem: 3278
Epoch: [39]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5210 (0.5827)  bbox_regression: 0.0958 (0.1031)  classification: 0.4092 (0.4796)  time: 0.3664  data: 0.1309  max mem: 3278
Epoch: [39]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5690 (0.5826)  bbox_regression: 0.0967 (0.1032)  classification: 0.4275 (0.4795)  time: 0.3543  data: 0.1287  max mem: 3278
Epoch: [39]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5727 (0.5828)  bbox_regression: 0.0962 (0.1032)  classification: 0.4774 (0.4796)  time: 0.3375  data: 0.1175  max mem: 3278
Epoch: [39]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5674 (0.5825)  bbox_regression: 0.0927 (0.1030)  classification: 0.4661 (0.4795)  time: 0.3451  data: 0.1270  max mem: 3278
Epoch: [39] Total time: 0:21:09 (0.3635 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:14  model_time: 0.1247 (0.1247)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.6814  data: 1.5338  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1174 (0.1212)  loss: 0.7709 (0.9009)  bbox_regression: 0.1663 (0.1626)  classification: 0.6138 (0.7383)  time: 0.2633  data: 0.1239  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1133 (0.1215)  loss: 0.7655 (0.8628)  bbox_regression: 0.1418 (0.1532)  classification: 0.6513 (0.7095)  time: 0.2557  data: 0.1212  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1180 (0.1204)  loss: 0.8971 (0.8651)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2599  data: 0.1222  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1171 (0.1203)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2747  data: 0.1359  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1162 (0.1202)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2546  data: 0.1200  max mem: 3278
Validation: Total time: 0:01:55 (0.2645 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [40]  [   0/3494]  eta: 1:47:37  lr: 0.0000001  loss: 0.6792 (0.6792)  bbox_regression: 0.1067 (0.1067)  classification: 0.5724 (0.5724)  time: 1.8481  data: 1.5777  max mem: 3278
Epoch: [40]  [ 100/3494]  eta: 0:21:29  lr: 0.0000001  loss: 0.5462 (0.5961)  bbox_regression: 0.0984 (0.1085)  classification: 0.4411 (0.4876)  time: 0.3586  data: 0.1293  max mem: 3278
Epoch: [40]  [ 200/3494]  eta: 0:20:11  lr: 0.0000001  loss: 0.5517 (0.5858)  bbox_regression: 0.0987 (0.1056)  classification: 0.4575 (0.4801)  time: 0.3715  data: 0.1406  max mem: 3278
Epoch: [40]  [ 300/3494]  eta: 0:19:29  lr: 0.0000001  loss: 0.6018 (0.5902)  bbox_regression: 0.0979 (0.1066)  classification: 0.4764 (0.4836)  time: 0.3667  data: 0.1328  max mem: 3278
Epoch: [40]  [ 400/3494]  eta: 0:18:51  lr: 0.0000001  loss: 0.5311 (0.5883)  bbox_regression: 0.1007 (0.1055)  classification: 0.4209 (0.4827)  time: 0.3619  data: 0.1295  max mem: 3278
Epoch: [40]  [ 500/3494]  eta: 0:18:10  lr: 0.0000001  loss: 0.6186 (0.5901)  bbox_regression: 0.1242 (0.1060)  classification: 0.5082 (0.4841)  time: 0.3641  data: 0.1383  max mem: 3278
Epoch: [40]  [ 600/3494]  eta: 0:17:34  lr: 0.0000001  loss: 0.5675 (0.5883)  bbox_regression: 0.0882 (0.1050)  classification: 0.4821 (0.4833)  time: 0.3588  data: 0.1256  max mem: 3278
Epoch: [40]  [ 700/3494]  eta: 0:16:56  lr: 0.0000001  loss: 0.5987 (0.5876)  bbox_regression: 0.1030 (0.1050)  classification: 0.4895 (0.4826)  time: 0.3451  data: 0.1222  max mem: 3278
Epoch: [40]  [ 800/3494]  eta: 0:16:18  lr: 0.0000001  loss: 0.5477 (0.5870)  bbox_regression: 0.1050 (0.1054)  classification: 0.4467 (0.4816)  time: 0.3647  data: 0.1295  max mem: 3278
Epoch: [40]  [ 900/3494]  eta: 0:15:41  lr: 0.0000001  loss: 0.5277 (0.5873)  bbox_regression: 0.0907 (0.1053)  classification: 0.4371 (0.4821)  time: 0.3603  data: 0.1291  max mem: 3278
Epoch: [40]  [1000/3494]  eta: 0:15:03  lr: 0.0000001  loss: 0.5236 (0.5866)  bbox_regression: 0.0957 (0.1050)  classification: 0.4249 (0.4816)  time: 0.3646  data: 0.1322  max mem: 3278
Epoch: [40]  [1100/3494]  eta: 0:14:26  lr: 0.0000001  loss: 0.6282 (0.5884)  bbox_regression: 0.1017 (0.1051)  classification: 0.5231 (0.4833)  time: 0.3540  data: 0.1273  max mem: 3278
Epoch: [40]  [1200/3494]  eta: 0:13:50  lr: 0.0000001  loss: 0.5359 (0.5891)  bbox_regression: 0.0895 (0.1049)  classification: 0.4431 (0.4842)  time: 0.3549  data: 0.1258  max mem: 3278
Epoch: [40]  [1300/3494]  eta: 0:13:13  lr: 0.0000001  loss: 0.5227 (0.5901)  bbox_regression: 0.0979 (0.1055)  classification: 0.4407 (0.4846)  time: 0.3581  data: 0.1287  max mem: 3278
Epoch: [40]  [1400/3494]  eta: 0:12:37  lr: 0.0000001  loss: 0.6178 (0.5900)  bbox_regression: 0.1075 (0.1053)  classification: 0.5140 (0.4847)  time: 0.3647  data: 0.1283  max mem: 3278
Epoch: [40]  [1500/3494]  eta: 0:12:01  lr: 0.0000001  loss: 0.6048 (0.5900)  bbox_regression: 0.0968 (0.1051)  classification: 0.4856 (0.4849)  time: 0.3478  data: 0.1221  max mem: 3278
Epoch: [40]  [1600/3494]  eta: 0:11:24  lr: 0.0000001  loss: 0.5435 (0.5895)  bbox_regression: 0.0957 (0.1049)  classification: 0.4595 (0.4846)  time: 0.3623  data: 0.1294  max mem: 3278
Epoch: [40]  [1700/3494]  eta: 0:10:48  lr: 0.0000001  loss: 0.5664 (0.5888)  bbox_regression: 0.0917 (0.1046)  classification: 0.4721 (0.4841)  time: 0.3655  data: 0.1338  max mem: 3278
Epoch: [40]  [1800/3494]  eta: 0:10:11  lr: 0.0000001  loss: 0.5774 (0.5882)  bbox_regression: 0.0929 (0.1045)  classification: 0.4680 (0.4838)  time: 0.3573  data: 0.1253  max mem: 3278
Epoch: [40]  [1900/3494]  eta: 0:09:35  lr: 0.0000001  loss: 0.5778 (0.5880)  bbox_regression: 0.1008 (0.1044)  classification: 0.4625 (0.4835)  time: 0.3637  data: 0.1322  max mem: 3278
Epoch: [40]  [2000/3494]  eta: 0:08:59  lr: 0.0000001  loss: 0.5212 (0.5870)  bbox_regression: 0.0897 (0.1042)  classification: 0.4332 (0.4828)  time: 0.3546  data: 0.1258  max mem: 3278
Epoch: [40]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.5781 (0.5865)  bbox_regression: 0.1077 (0.1041)  classification: 0.4762 (0.4824)  time: 0.3334  data: 0.1136  max mem: 3278
Epoch: [40]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5273 (0.5858)  bbox_regression: 0.0970 (0.1040)  classification: 0.4486 (0.4819)  time: 0.3556  data: 0.1244  max mem: 3278
Epoch: [40]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5594 (0.5855)  bbox_regression: 0.0873 (0.1040)  classification: 0.4778 (0.4815)  time: 0.3575  data: 0.1284  max mem: 3278
Epoch: [40]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5682 (0.5852)  bbox_regression: 0.0936 (0.1039)  classification: 0.4528 (0.4813)  time: 0.3620  data: 0.1302  max mem: 3278
Epoch: [40]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.6148 (0.5848)  bbox_regression: 0.1120 (0.1039)  classification: 0.4983 (0.4810)  time: 0.3631  data: 0.1327  max mem: 3278
Epoch: [40]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5615 (0.5844)  bbox_regression: 0.0969 (0.1037)  classification: 0.4550 (0.4807)  time: 0.3533  data: 0.1238  max mem: 3278
Epoch: [40]  [2700/3494]  eta: 0:04:45  lr: 0.0000001  loss: 0.5434 (0.5841)  bbox_regression: 0.0870 (0.1037)  classification: 0.4463 (0.4804)  time: 0.3494  data: 0.1253  max mem: 3278
Epoch: [40]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5538 (0.5834)  bbox_regression: 0.0856 (0.1035)  classification: 0.4592 (0.4799)  time: 0.3659  data: 0.1358  max mem: 3278
Epoch: [40]  [2900/3494]  eta: 0:03:33  lr: 0.0000001  loss: 0.6241 (0.5837)  bbox_regression: 0.1037 (0.1036)  classification: 0.5175 (0.4801)  time: 0.3543  data: 0.1242  max mem: 3278
Epoch: [40]  [3000/3494]  eta: 0:02:57  lr: 0.0000001  loss: 0.5892 (0.5834)  bbox_regression: 0.0980 (0.1034)  classification: 0.4818 (0.4799)  time: 0.3683  data: 0.1302  max mem: 3278
Epoch: [40]  [3100/3494]  eta: 0:02:21  lr: 0.0000001  loss: 0.5354 (0.5828)  bbox_regression: 0.0970 (0.1033)  classification: 0.4417 (0.4794)  time: 0.3617  data: 0.1312  max mem: 3278
Epoch: [40]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5564 (0.5830)  bbox_regression: 0.0993 (0.1033)  classification: 0.4668 (0.4797)  time: 0.3376  data: 0.1118  max mem: 3278
Epoch: [40]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5785 (0.5831)  bbox_regression: 0.0976 (0.1032)  classification: 0.4809 (0.4798)  time: 0.3638  data: 0.1287  max mem: 3278
Epoch: [40]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5490 (0.5830)  bbox_regression: 0.1061 (0.1033)  classification: 0.4494 (0.4798)  time: 0.3681  data: 0.1403  max mem: 3278
Epoch: [40]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5304 (0.5830)  bbox_regression: 0.0825 (0.1032)  classification: 0.4471 (0.4797)  time: 0.3246  data: 0.1121  max mem: 3278
Epoch: [40] Total time: 0:21:08 (0.3629 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:00  model_time: 0.1211 (0.1211)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9206 (0.9206)  time: 2.1978  data: 2.0564  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1171 (0.1208)  loss: 0.7710 (0.9009)  bbox_regression: 0.1663 (0.1626)  classification: 0.6138 (0.7383)  time: 0.2651  data: 0.1260  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1325 (0.1227)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7095)  time: 0.2768  data: 0.1293  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1160 (0.1220)  loss: 0.8971 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2555  data: 0.1215  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1191 (0.1216)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2688  data: 0.1272  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1177 (0.1215)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2641  data: 0.1300  max mem: 3278
Validation: Total time: 0:01:57 (0.2687 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [41]  [   0/3494]  eta: 1:50:15  lr: 0.0000001  loss: 0.6246 (0.6246)  bbox_regression: 0.1054 (0.1054)  classification: 0.5192 (0.5192)  time: 1.8934  data: 1.6413  max mem: 3278
Epoch: [41]  [ 100/3494]  eta: 0:21:10  lr: 0.0000001  loss: 0.5363 (0.5730)  bbox_regression: 0.0993 (0.1080)  classification: 0.4434 (0.4650)  time: 0.3614  data: 0.1286  max mem: 3278
Epoch: [41]  [ 200/3494]  eta: 0:20:15  lr: 0.0000001  loss: 0.5505 (0.5769)  bbox_regression: 0.0930 (0.1047)  classification: 0.4725 (0.4722)  time: 0.3761  data: 0.1432  max mem: 3278
Epoch: [41]  [ 300/3494]  eta: 0:19:18  lr: 0.0000001  loss: 0.5452 (0.5825)  bbox_regression: 0.0867 (0.1062)  classification: 0.4303 (0.4763)  time: 0.3609  data: 0.1304  max mem: 3278
Epoch: [41]  [ 400/3494]  eta: 0:18:37  lr: 0.0000001  loss: 0.5536 (0.5896)  bbox_regression: 0.1015 (0.1068)  classification: 0.4671 (0.4828)  time: 0.3618  data: 0.1297  max mem: 3278
Epoch: [41]  [ 500/3494]  eta: 0:17:59  lr: 0.0000001  loss: 0.5683 (0.5924)  bbox_regression: 0.1014 (0.1066)  classification: 0.4496 (0.4858)  time: 0.3500  data: 0.1234  max mem: 3278
Epoch: [41]  [ 600/3494]  eta: 0:17:24  lr: 0.0000001  loss: 0.5933 (0.5921)  bbox_regression: 0.1020 (0.1061)  classification: 0.5051 (0.4860)  time: 0.3592  data: 0.1307  max mem: 3278
Epoch: [41]  [ 700/3494]  eta: 0:16:49  lr: 0.0000001  loss: 0.6389 (0.5939)  bbox_regression: 0.1039 (0.1058)  classification: 0.5195 (0.4882)  time: 0.3652  data: 0.1337  max mem: 3278
Epoch: [41]  [ 800/3494]  eta: 0:16:15  lr: 0.0000001  loss: 0.5859 (0.5951)  bbox_regression: 0.0912 (0.1059)  classification: 0.4719 (0.4892)  time: 0.3620  data: 0.1275  max mem: 3278
Epoch: [41]  [ 900/3494]  eta: 0:15:39  lr: 0.0000001  loss: 0.6076 (0.5950)  bbox_regression: 0.1000 (0.1060)  classification: 0.5045 (0.4890)  time: 0.3548  data: 0.1269  max mem: 3278
Epoch: [41]  [1000/3494]  eta: 0:15:01  lr: 0.0000001  loss: 0.5197 (0.5934)  bbox_regression: 0.0858 (0.1054)  classification: 0.4266 (0.4880)  time: 0.3595  data: 0.1305  max mem: 3278
Epoch: [41]  [1100/3494]  eta: 0:14:24  lr: 0.0000001  loss: 0.5466 (0.5917)  bbox_regression: 0.1076 (0.1050)  classification: 0.4566 (0.4867)  time: 0.3499  data: 0.1223  max mem: 3278
Epoch: [41]  [1200/3494]  eta: 0:13:47  lr: 0.0000001  loss: 0.5414 (0.5910)  bbox_regression: 0.0914 (0.1046)  classification: 0.4334 (0.4864)  time: 0.3412  data: 0.1128  max mem: 3278
Epoch: [41]  [1300/3494]  eta: 0:13:12  lr: 0.0000001  loss: 0.5636 (0.5896)  bbox_regression: 0.0960 (0.1044)  classification: 0.4455 (0.4852)  time: 0.3638  data: 0.1282  max mem: 3278
Epoch: [41]  [1400/3494]  eta: 0:12:35  lr: 0.0000001  loss: 0.5715 (0.5892)  bbox_regression: 0.0939 (0.1044)  classification: 0.4765 (0.4849)  time: 0.3640  data: 0.1306  max mem: 3278
Epoch: [41]  [1500/3494]  eta: 0:11:58  lr: 0.0000001  loss: 0.5516 (0.5891)  bbox_regression: 0.0924 (0.1041)  classification: 0.4564 (0.4850)  time: 0.3587  data: 0.1318  max mem: 3278
Epoch: [41]  [1600/3494]  eta: 0:11:22  lr: 0.0000001  loss: 0.5592 (0.5901)  bbox_regression: 0.0945 (0.1042)  classification: 0.4463 (0.4859)  time: 0.3496  data: 0.1235  max mem: 3278
Epoch: [41]  [1700/3494]  eta: 0:10:45  lr: 0.0000001  loss: 0.5661 (0.5895)  bbox_regression: 0.0962 (0.1040)  classification: 0.4552 (0.4855)  time: 0.3568  data: 0.1301  max mem: 3278
Epoch: [41]  [1800/3494]  eta: 0:10:09  lr: 0.0000001  loss: 0.5648 (0.5901)  bbox_regression: 0.0880 (0.1043)  classification: 0.4797 (0.4858)  time: 0.3498  data: 0.1227  max mem: 3278
Epoch: [41]  [1900/3494]  eta: 0:09:33  lr: 0.0000001  loss: 0.5659 (0.5886)  bbox_regression: 0.0993 (0.1041)  classification: 0.4837 (0.4845)  time: 0.3613  data: 0.1319  max mem: 3278
Epoch: [41]  [2000/3494]  eta: 0:08:57  lr: 0.0000001  loss: 0.5375 (0.5871)  bbox_regression: 0.0899 (0.1038)  classification: 0.4668 (0.4833)  time: 0.3585  data: 0.1306  max mem: 3278
Epoch: [41]  [2100/3494]  eta: 0:08:21  lr: 0.0000001  loss: 0.5698 (0.5870)  bbox_regression: 0.0936 (0.1038)  classification: 0.4567 (0.4833)  time: 0.3551  data: 0.1268  max mem: 3278
Epoch: [41]  [2200/3494]  eta: 0:07:45  lr: 0.0000001  loss: 0.5369 (0.5868)  bbox_regression: 0.1001 (0.1038)  classification: 0.4360 (0.4831)  time: 0.3685  data: 0.1326  max mem: 3278
Epoch: [41]  [2300/3494]  eta: 0:07:09  lr: 0.0000001  loss: 0.5513 (0.5867)  bbox_regression: 0.0997 (0.1037)  classification: 0.4611 (0.4830)  time: 0.3624  data: 0.1307  max mem: 3278
Epoch: [41]  [2400/3494]  eta: 0:06:33  lr: 0.0000001  loss: 0.6172 (0.5868)  bbox_regression: 0.0904 (0.1036)  classification: 0.5249 (0.4832)  time: 0.3787  data: 0.1395  max mem: 3278
Epoch: [41]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5569 (0.5870)  bbox_regression: 0.0966 (0.1037)  classification: 0.4795 (0.4833)  time: 0.3653  data: 0.1293  max mem: 3278
Epoch: [41]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5548 (0.5864)  bbox_regression: 0.0972 (0.1037)  classification: 0.4576 (0.4827)  time: 0.3623  data: 0.1346  max mem: 3278
Epoch: [41]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.6321 (0.5871)  bbox_regression: 0.1209 (0.1037)  classification: 0.5209 (0.4833)  time: 0.3691  data: 0.1310  max mem: 3278
Epoch: [41]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5391 (0.5863)  bbox_regression: 0.1033 (0.1036)  classification: 0.4406 (0.4827)  time: 0.3617  data: 0.1306  max mem: 3278
Epoch: [41]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.6193 (0.5864)  bbox_regression: 0.0956 (0.1036)  classification: 0.5024 (0.4827)  time: 0.3707  data: 0.1372  max mem: 3278
Epoch: [41]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5709 (0.5861)  bbox_regression: 0.1046 (0.1037)  classification: 0.4552 (0.4824)  time: 0.3575  data: 0.1256  max mem: 3278
Epoch: [41]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5185 (0.5861)  bbox_regression: 0.0930 (0.1038)  classification: 0.4200 (0.4823)  time: 0.3273  data: 0.1127  max mem: 3278
Epoch: [41]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5566 (0.5852)  bbox_regression: 0.0991 (0.1036)  classification: 0.4510 (0.4816)  time: 0.3514  data: 0.1236  max mem: 3278
Epoch: [41]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5201 (0.5850)  bbox_regression: 0.0864 (0.1036)  classification: 0.4289 (0.4814)  time: 0.3525  data: 0.1260  max mem: 3278
Epoch: [41]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5649 (0.5845)  bbox_regression: 0.0979 (0.1034)  classification: 0.4528 (0.4810)  time: 0.3529  data: 0.1259  max mem: 3278
Epoch: [41]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5741 (0.5836)  bbox_regression: 0.0965 (0.1033)  classification: 0.4727 (0.4804)  time: 0.3529  data: 0.1232  max mem: 3278
Epoch: [41] Total time: 0:21:09 (0.3635 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:37  model_time: 0.1490 (0.1490)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9206 (0.9206)  time: 2.0072  data: 1.8292  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1168 (0.1191)  loss: 0.7711 (0.9009)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2599  data: 0.1230  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1150 (0.1194)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2587  data: 0.1237  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1167 (0.1192)  loss: 0.8971 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2595  data: 0.1220  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1129 (0.1198)  loss: 0.7399 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2507  data: 0.1180  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1148 (0.1198)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2555  data: 0.1218  max mem: 3278
Validation: Total time: 0:01:55 (0.2637 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [42]  [   0/3494]  eta: 2:17:14  lr: 0.0000001  loss: 0.4842 (0.4842)  bbox_regression: 0.0809 (0.0809)  classification: 0.4033 (0.4033)  time: 2.3567  data: 2.1171  max mem: 3278
Epoch: [42]  [ 100/3494]  eta: 0:21:45  lr: 0.0000001  loss: 0.5761 (0.5787)  bbox_regression: 0.0997 (0.1008)  classification: 0.4800 (0.4779)  time: 0.3667  data: 0.1322  max mem: 3278
Epoch: [42]  [ 200/3494]  eta: 0:20:17  lr: 0.0000001  loss: 0.6066 (0.5894)  bbox_regression: 0.0899 (0.1045)  classification: 0.5113 (0.4848)  time: 0.3596  data: 0.1272  max mem: 3278
Epoch: [42]  [ 300/3494]  eta: 0:19:31  lr: 0.0000001  loss: 0.5451 (0.5858)  bbox_regression: 0.0899 (0.1036)  classification: 0.4599 (0.4822)  time: 0.3746  data: 0.1317  max mem: 3278
Epoch: [42]  [ 400/3494]  eta: 0:18:44  lr: 0.0000001  loss: 0.5597 (0.5851)  bbox_regression: 0.0943 (0.1028)  classification: 0.4502 (0.4823)  time: 0.3304  data: 0.1124  max mem: 3278
Epoch: [42]  [ 500/3494]  eta: 0:18:09  lr: 0.0000001  loss: 0.5455 (0.5829)  bbox_regression: 0.0962 (0.1021)  classification: 0.4460 (0.4808)  time: 0.3610  data: 0.1289  max mem: 3278
Epoch: [42]  [ 600/3494]  eta: 0:17:33  lr: 0.0000001  loss: 0.5987 (0.5851)  bbox_regression: 0.0972 (0.1025)  classification: 0.4866 (0.4826)  time: 0.3747  data: 0.1385  max mem: 3278
Epoch: [42]  [ 700/3494]  eta: 0:16:54  lr: 0.0000001  loss: 0.5254 (0.5842)  bbox_regression: 0.1058 (0.1028)  classification: 0.4244 (0.4814)  time: 0.3675  data: 0.1379  max mem: 3278
Epoch: [42]  [ 800/3494]  eta: 0:16:15  lr: 0.0000001  loss: 0.5680 (0.5827)  bbox_regression: 0.0961 (0.1025)  classification: 0.4628 (0.4802)  time: 0.3421  data: 0.1202  max mem: 3278
Epoch: [42]  [ 900/3494]  eta: 0:15:37  lr: 0.0000001  loss: 0.5880 (0.5834)  bbox_regression: 0.0993 (0.1023)  classification: 0.4761 (0.4811)  time: 0.3469  data: 0.1230  max mem: 3278
Epoch: [42]  [1000/3494]  eta: 0:14:58  lr: 0.0000001  loss: 0.5862 (0.5835)  bbox_regression: 0.1075 (0.1023)  classification: 0.4650 (0.4812)  time: 0.3544  data: 0.1251  max mem: 3278
Epoch: [42]  [1100/3494]  eta: 0:14:23  lr: 0.0000001  loss: 0.5429 (0.5848)  bbox_regression: 0.1044 (0.1026)  classification: 0.4452 (0.4822)  time: 0.3699  data: 0.1331  max mem: 3278
Epoch: [42]  [1200/3494]  eta: 0:13:47  lr: 0.0000001  loss: 0.5311 (0.5860)  bbox_regression: 0.0879 (0.1031)  classification: 0.4364 (0.4829)  time: 0.3554  data: 0.1249  max mem: 3278
Epoch: [42]  [1300/3494]  eta: 0:13:11  lr: 0.0000001  loss: 0.5385 (0.5872)  bbox_regression: 0.1021 (0.1033)  classification: 0.4521 (0.4840)  time: 0.3584  data: 0.1308  max mem: 3278
Epoch: [42]  [1400/3494]  eta: 0:12:35  lr: 0.0000001  loss: 0.5802 (0.5867)  bbox_regression: 0.0944 (0.1029)  classification: 0.4698 (0.4838)  time: 0.3803  data: 0.1403  max mem: 3278
Epoch: [42]  [1500/3494]  eta: 0:11:59  lr: 0.0000001  loss: 0.5572 (0.5856)  bbox_regression: 0.1043 (0.1030)  classification: 0.4547 (0.4826)  time: 0.3651  data: 0.1333  max mem: 3278
Epoch: [42]  [1600/3494]  eta: 0:11:23  lr: 0.0000001  loss: 0.5661 (0.5853)  bbox_regression: 0.0963 (0.1031)  classification: 0.4773 (0.4823)  time: 0.3649  data: 0.1369  max mem: 3278
Epoch: [42]  [1700/3494]  eta: 0:10:46  lr: 0.0000001  loss: 0.5684 (0.5845)  bbox_regression: 0.0899 (0.1029)  classification: 0.4569 (0.4816)  time: 0.3583  data: 0.1267  max mem: 3278
Epoch: [42]  [1800/3494]  eta: 0:10:10  lr: 0.0000001  loss: 0.5877 (0.5847)  bbox_regression: 0.0980 (0.1031)  classification: 0.4816 (0.4816)  time: 0.3753  data: 0.1343  max mem: 3278
Epoch: [42]  [1900/3494]  eta: 0:09:33  lr: 0.0000001  loss: 0.5757 (0.5853)  bbox_regression: 0.0962 (0.1033)  classification: 0.4893 (0.4820)  time: 0.3562  data: 0.1278  max mem: 3278
Epoch: [42]  [2000/3494]  eta: 0:08:58  lr: 0.0000001  loss: 0.6152 (0.5855)  bbox_regression: 0.1051 (0.1033)  classification: 0.4979 (0.4822)  time: 0.3442  data: 0.1151  max mem: 3278
Epoch: [42]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.5587 (0.5838)  bbox_regression: 0.0970 (0.1032)  classification: 0.4385 (0.4806)  time: 0.3569  data: 0.1305  max mem: 3278
Epoch: [42]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5768 (0.5842)  bbox_regression: 0.0915 (0.1032)  classification: 0.4806 (0.4810)  time: 0.3759  data: 0.1416  max mem: 3278
Epoch: [42]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5789 (0.5842)  bbox_regression: 0.0965 (0.1033)  classification: 0.4929 (0.4809)  time: 0.3570  data: 0.1279  max mem: 3278
Epoch: [42]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5607 (0.5849)  bbox_regression: 0.0934 (0.1034)  classification: 0.4663 (0.4815)  time: 0.3585  data: 0.1270  max mem: 3278
Epoch: [42]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5834 (0.5840)  bbox_regression: 0.1012 (0.1033)  classification: 0.4900 (0.4808)  time: 0.3524  data: 0.1265  max mem: 3278
Epoch: [42]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5602 (0.5841)  bbox_regression: 0.0982 (0.1033)  classification: 0.4743 (0.4808)  time: 0.3611  data: 0.1292  max mem: 3278
Epoch: [42]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5537 (0.5843)  bbox_regression: 0.1033 (0.1035)  classification: 0.4170 (0.4809)  time: 0.3729  data: 0.1314  max mem: 3278
Epoch: [42]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5281 (0.5836)  bbox_regression: 0.0949 (0.1034)  classification: 0.4287 (0.4802)  time: 0.3593  data: 0.1292  max mem: 3278
Epoch: [42]  [2900/3494]  eta: 0:03:33  lr: 0.0000001  loss: 0.5038 (0.5831)  bbox_regression: 0.0875 (0.1033)  classification: 0.4179 (0.4798)  time: 0.3559  data: 0.1254  max mem: 3278
Epoch: [42]  [3000/3494]  eta: 0:02:57  lr: 0.0000001  loss: 0.5647 (0.5829)  bbox_regression: 0.1001 (0.1033)  classification: 0.4652 (0.4796)  time: 0.3546  data: 0.1268  max mem: 3278
Epoch: [42]  [3100/3494]  eta: 0:02:21  lr: 0.0000001  loss: 0.5702 (0.5837)  bbox_regression: 0.0941 (0.1033)  classification: 0.4637 (0.4804)  time: 0.3369  data: 0.1113  max mem: 3278
Epoch: [42]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5600 (0.5834)  bbox_regression: 0.1021 (0.1033)  classification: 0.4571 (0.4801)  time: 0.3583  data: 0.1331  max mem: 3278
Epoch: [42]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5596 (0.5833)  bbox_regression: 0.1053 (0.1032)  classification: 0.4637 (0.4800)  time: 0.3576  data: 0.1263  max mem: 3278
Epoch: [42]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5180 (0.5827)  bbox_regression: 0.0937 (0.1032)  classification: 0.4415 (0.4796)  time: 0.3620  data: 0.1294  max mem: 3278
Epoch: [42]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5639 (0.5832)  bbox_regression: 0.0959 (0.1033)  classification: 0.4680 (0.4799)  time: 0.3692  data: 0.1339  max mem: 3278
Epoch: [42] Total time: 0:21:09 (0.3634 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:57  model_time: 0.1295 (0.1295)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.1920  data: 2.0386  max mem: 3278
Validation:  [100/437]  eta: 0:01:32  model_time: 0.1207 (0.1188)  loss: 0.7711 (0.9009)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2598  data: 0.1203  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1140 (0.1193)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2617  data: 0.1234  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1221 (0.1204)  loss: 0.8971 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7152)  time: 0.2637  data: 0.1218  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1162 (0.1208)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2569  data: 0.1228  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1233 (0.1211)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2689  data: 0.1248  max mem: 3278
Validation: Total time: 0:01:56 (0.2655 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [43]  [   0/3494]  eta: 2:29:57  lr: 0.0000001  loss: 0.6288 (0.6288)  bbox_regression: 0.1053 (0.1053)  classification: 0.5235 (0.5235)  time: 2.5750  data: 2.3341  max mem: 3278
Epoch: [43]  [ 100/3494]  eta: 0:21:03  lr: 0.0000001  loss: 0.5886 (0.5848)  bbox_regression: 0.1055 (0.1059)  classification: 0.4840 (0.4789)  time: 0.3581  data: 0.1249  max mem: 3278
Epoch: [43]  [ 200/3494]  eta: 0:20:10  lr: 0.0000001  loss: 0.5652 (0.5859)  bbox_regression: 0.0844 (0.1045)  classification: 0.4761 (0.4814)  time: 0.3631  data: 0.1298  max mem: 3278
Epoch: [43]  [ 300/3494]  eta: 0:19:23  lr: 0.0000001  loss: 0.5432 (0.5866)  bbox_regression: 0.1066 (0.1032)  classification: 0.4535 (0.4834)  time: 0.3527  data: 0.1247  max mem: 3278
Epoch: [43]  [ 400/3494]  eta: 0:18:41  lr: 0.0000001  loss: 0.6066 (0.5848)  bbox_regression: 0.1020 (0.1030)  classification: 0.4926 (0.4817)  time: 0.3663  data: 0.1295  max mem: 3278
Epoch: [43]  [ 500/3494]  eta: 0:18:03  lr: 0.0000001  loss: 0.5985 (0.5862)  bbox_regression: 0.1152 (0.1037)  classification: 0.4804 (0.4825)  time: 0.3553  data: 0.1291  max mem: 3278
Epoch: [43]  [ 600/3494]  eta: 0:17:25  lr: 0.0000001  loss: 0.5618 (0.5865)  bbox_regression: 0.1071 (0.1039)  classification: 0.4628 (0.4826)  time: 0.3626  data: 0.1295  max mem: 3278
Epoch: [43]  [ 700/3494]  eta: 0:16:44  lr: 0.0000001  loss: 0.5078 (0.5844)  bbox_regression: 0.0846 (0.1037)  classification: 0.4145 (0.4807)  time: 0.3448  data: 0.1243  max mem: 3278
Epoch: [43]  [ 800/3494]  eta: 0:16:10  lr: 0.0000001  loss: 0.6031 (0.5831)  bbox_regression: 0.1061 (0.1035)  classification: 0.4867 (0.4796)  time: 0.3613  data: 0.1313  max mem: 3278
Epoch: [43]  [ 900/3494]  eta: 0:15:35  lr: 0.0000001  loss: 0.5713 (0.5829)  bbox_regression: 0.0942 (0.1030)  classification: 0.4800 (0.4799)  time: 0.3601  data: 0.1274  max mem: 3278
Epoch: [43]  [1000/3494]  eta: 0:14:59  lr: 0.0000001  loss: 0.5295 (0.5820)  bbox_regression: 0.0910 (0.1030)  classification: 0.4488 (0.4791)  time: 0.3701  data: 0.1328  max mem: 3278
Epoch: [43]  [1100/3494]  eta: 0:14:23  lr: 0.0000001  loss: 0.5672 (0.5808)  bbox_regression: 0.0860 (0.1026)  classification: 0.4817 (0.4782)  time: 0.3552  data: 0.1280  max mem: 3278
Epoch: [43]  [1200/3494]  eta: 0:13:46  lr: 0.0000001  loss: 0.5631 (0.5799)  bbox_regression: 0.1014 (0.1026)  classification: 0.4616 (0.4773)  time: 0.3352  data: 0.1147  max mem: 3278
Epoch: [43]  [1300/3494]  eta: 0:13:09  lr: 0.0000001  loss: 0.5778 (0.5806)  bbox_regression: 0.1020 (0.1030)  classification: 0.4886 (0.4775)  time: 0.3495  data: 0.1210  max mem: 3278
Epoch: [43]  [1400/3494]  eta: 0:12:33  lr: 0.0000001  loss: 0.5733 (0.5815)  bbox_regression: 0.0966 (0.1032)  classification: 0.4679 (0.4784)  time: 0.3583  data: 0.1278  max mem: 3278
Epoch: [43]  [1500/3494]  eta: 0:11:57  lr: 0.0000001  loss: 0.5947 (0.5807)  bbox_regression: 0.0937 (0.1030)  classification: 0.5005 (0.4778)  time: 0.3302  data: 0.1126  max mem: 3278
Epoch: [43]  [1600/3494]  eta: 0:11:21  lr: 0.0000001  loss: 0.5800 (0.5807)  bbox_regression: 0.0975 (0.1030)  classification: 0.4824 (0.4778)  time: 0.3613  data: 0.1258  max mem: 3278
Epoch: [43]  [1700/3494]  eta: 0:10:45  lr: 0.0000001  loss: 0.5801 (0.5805)  bbox_regression: 0.0909 (0.1028)  classification: 0.4845 (0.4777)  time: 0.3548  data: 0.1256  max mem: 3278
Epoch: [43]  [1800/3494]  eta: 0:10:09  lr: 0.0000001  loss: 0.5833 (0.5796)  bbox_regression: 0.0953 (0.1026)  classification: 0.4862 (0.4770)  time: 0.3648  data: 0.1277  max mem: 3278
Epoch: [43]  [1900/3494]  eta: 0:09:33  lr: 0.0000001  loss: 0.5706 (0.5795)  bbox_regression: 0.0929 (0.1028)  classification: 0.4464 (0.4767)  time: 0.3571  data: 0.1306  max mem: 3278
Epoch: [43]  [2000/3494]  eta: 0:08:58  lr: 0.0000001  loss: 0.5277 (0.5799)  bbox_regression: 0.0905 (0.1026)  classification: 0.4501 (0.4773)  time: 0.3772  data: 0.1391  max mem: 3278
Epoch: [43]  [2100/3494]  eta: 0:08:21  lr: 0.0000001  loss: 0.6002 (0.5812)  bbox_regression: 0.1053 (0.1030)  classification: 0.4916 (0.4782)  time: 0.3672  data: 0.1375  max mem: 3278
Epoch: [43]  [2200/3494]  eta: 0:07:45  lr: 0.0000001  loss: 0.5883 (0.5815)  bbox_regression: 0.0975 (0.1029)  classification: 0.4779 (0.4787)  time: 0.3630  data: 0.1326  max mem: 3278
Epoch: [43]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5277 (0.5817)  bbox_regression: 0.0934 (0.1029)  classification: 0.4348 (0.4789)  time: 0.3692  data: 0.1328  max mem: 3278
Epoch: [43]  [2400/3494]  eta: 0:06:33  lr: 0.0000001  loss: 0.4951 (0.5815)  bbox_regression: 0.0896 (0.1029)  classification: 0.4141 (0.4786)  time: 0.3537  data: 0.1266  max mem: 3278
Epoch: [43]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5369 (0.5818)  bbox_regression: 0.0872 (0.1030)  classification: 0.4477 (0.4788)  time: 0.3575  data: 0.1252  max mem: 3278
Epoch: [43]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5630 (0.5820)  bbox_regression: 0.0887 (0.1030)  classification: 0.4725 (0.4790)  time: 0.3848  data: 0.1499  max mem: 3278
Epoch: [43]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5382 (0.5823)  bbox_regression: 0.0871 (0.1031)  classification: 0.4560 (0.4792)  time: 0.3764  data: 0.1391  max mem: 3278
Epoch: [43]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5458 (0.5827)  bbox_regression: 0.0954 (0.1031)  classification: 0.4765 (0.4796)  time: 0.3567  data: 0.1254  max mem: 3278
Epoch: [43]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5167 (0.5826)  bbox_regression: 0.0909 (0.1032)  classification: 0.4465 (0.4794)  time: 0.3470  data: 0.1232  max mem: 3278
Epoch: [43]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5828 (0.5824)  bbox_regression: 0.1031 (0.1032)  classification: 0.4741 (0.4792)  time: 0.3576  data: 0.1280  max mem: 3278
Epoch: [43]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5648 (0.5826)  bbox_regression: 0.0932 (0.1032)  classification: 0.4622 (0.4794)  time: 0.3660  data: 0.1302  max mem: 3278
Epoch: [43]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5654 (0.5830)  bbox_regression: 0.1003 (0.1033)  classification: 0.4538 (0.4797)  time: 0.3742  data: 0.1325  max mem: 3278
Epoch: [43]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5976 (0.5831)  bbox_regression: 0.0963 (0.1032)  classification: 0.4892 (0.4799)  time: 0.3638  data: 0.1295  max mem: 3278
Epoch: [43]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5619 (0.5835)  bbox_regression: 0.0991 (0.1033)  classification: 0.4704 (0.4803)  time: 0.3680  data: 0.1327  max mem: 3278
Epoch: [43]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5486 (0.5833)  bbox_regression: 0.0979 (0.1032)  classification: 0.4621 (0.4801)  time: 0.3522  data: 0.1259  max mem: 3278
Epoch: [43] Total time: 0:21:10 (0.3636 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:37  model_time: 0.1319 (0.1319)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.2832  data: 2.1253  max mem: 3278
Validation:  [100/437]  eta: 0:01:29  model_time: 0.1171 (0.1184)  loss: 0.7711 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2555  data: 0.1198  max mem: 3278
Validation:  [200/437]  eta: 0:01:02  model_time: 0.1137 (0.1198)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2562  data: 0.1214  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1182 (0.1200)  loss: 0.8971 (0.8652)  bbox_regression: 0.1451 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2597  data: 0.1250  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1183 (0.1202)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2808  data: 0.1403  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1211 (0.1202)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2571  data: 0.1187  max mem: 3278
Validation: Total time: 0:01:55 (0.2654 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [44]  [   0/3494]  eta: 2:16:48  lr: 0.0000001  loss: 0.4943 (0.4943)  bbox_regression: 0.0682 (0.0682)  classification: 0.4260 (0.4260)  time: 2.3494  data: 2.0986  max mem: 3278
Epoch: [44]  [ 100/3494]  eta: 0:20:54  lr: 0.0000001  loss: 0.6030 (0.5639)  bbox_regression: 0.0928 (0.1003)  classification: 0.5081 (0.4636)  time: 0.3558  data: 0.1304  max mem: 3278
Epoch: [44]  [ 200/3494]  eta: 0:20:12  lr: 0.0000001  loss: 0.5555 (0.5691)  bbox_regression: 0.1010 (0.1022)  classification: 0.4545 (0.4669)  time: 0.3709  data: 0.1350  max mem: 3278
Epoch: [44]  [ 300/3494]  eta: 0:19:24  lr: 0.0000001  loss: 0.5624 (0.5776)  bbox_regression: 0.1036 (0.1039)  classification: 0.4729 (0.4737)  time: 0.3276  data: 0.1082  max mem: 3278
Epoch: [44]  [ 400/3494]  eta: 0:18:46  lr: 0.0000001  loss: 0.5799 (0.5826)  bbox_regression: 0.0930 (0.1035)  classification: 0.4944 (0.4791)  time: 0.3760  data: 0.1372  max mem: 3278
Epoch: [44]  [ 500/3494]  eta: 0:18:08  lr: 0.0000001  loss: 0.5429 (0.5799)  bbox_regression: 0.0989 (0.1025)  classification: 0.4433 (0.4774)  time: 0.3660  data: 0.1346  max mem: 3278
Epoch: [44]  [ 600/3494]  eta: 0:17:30  lr: 0.0000001  loss: 0.5704 (0.5849)  bbox_regression: 0.0950 (0.1031)  classification: 0.4700 (0.4818)  time: 0.3426  data: 0.1211  max mem: 3278
Epoch: [44]  [ 700/3494]  eta: 0:16:56  lr: 0.0000001  loss: 0.5935 (0.5868)  bbox_regression: 0.1019 (0.1033)  classification: 0.5088 (0.4835)  time: 0.3692  data: 0.1353  max mem: 3278
Epoch: [44]  [ 800/3494]  eta: 0:16:21  lr: 0.0000001  loss: 0.5522 (0.5870)  bbox_regression: 0.0987 (0.1032)  classification: 0.4386 (0.4838)  time: 0.3679  data: 0.1381  max mem: 3278
Epoch: [44]  [ 900/3494]  eta: 0:15:44  lr: 0.0000001  loss: 0.5205 (0.5855)  bbox_regression: 0.0930 (0.1028)  classification: 0.4276 (0.4827)  time: 0.3694  data: 0.1355  max mem: 3278
Epoch: [44]  [1000/3494]  eta: 0:15:06  lr: 0.0000001  loss: 0.5335 (0.5851)  bbox_regression: 0.0971 (0.1027)  classification: 0.4389 (0.4824)  time: 0.3650  data: 0.1359  max mem: 3278
Epoch: [44]  [1100/3494]  eta: 0:14:29  lr: 0.0000001  loss: 0.5621 (0.5873)  bbox_regression: 0.0946 (0.1032)  classification: 0.4694 (0.4841)  time: 0.3612  data: 0.1321  max mem: 3278
Epoch: [44]  [1200/3494]  eta: 0:13:51  lr: 0.0000001  loss: 0.6035 (0.5876)  bbox_regression: 0.1080 (0.1036)  classification: 0.4801 (0.4840)  time: 0.3571  data: 0.1331  max mem: 3278
Epoch: [44]  [1300/3494]  eta: 0:13:15  lr: 0.0000001  loss: 0.5482 (0.5856)  bbox_regression: 0.0898 (0.1032)  classification: 0.4385 (0.4824)  time: 0.3513  data: 0.1225  max mem: 3278
Epoch: [44]  [1400/3494]  eta: 0:12:38  lr: 0.0000001  loss: 0.5959 (0.5855)  bbox_regression: 0.0970 (0.1031)  classification: 0.4886 (0.4824)  time: 0.3658  data: 0.1289  max mem: 3278
Epoch: [44]  [1500/3494]  eta: 0:12:02  lr: 0.0000001  loss: 0.5486 (0.5867)  bbox_regression: 0.1011 (0.1033)  classification: 0.4643 (0.4835)  time: 0.3786  data: 0.1314  max mem: 3278
Epoch: [44]  [1600/3494]  eta: 0:11:26  lr: 0.0000001  loss: 0.5574 (0.5867)  bbox_regression: 0.0976 (0.1034)  classification: 0.4678 (0.4832)  time: 0.3555  data: 0.1234  max mem: 3278
Epoch: [44]  [1700/3494]  eta: 0:10:50  lr: 0.0000001  loss: 0.5353 (0.5859)  bbox_regression: 0.0915 (0.1034)  classification: 0.4526 (0.4825)  time: 0.3646  data: 0.1345  max mem: 3278
Epoch: [44]  [1800/3494]  eta: 0:10:13  lr: 0.0000001  loss: 0.5125 (0.5853)  bbox_regression: 0.0941 (0.1034)  classification: 0.4283 (0.4819)  time: 0.3693  data: 0.1332  max mem: 3278
Epoch: [44]  [1900/3494]  eta: 0:09:37  lr: 0.0000001  loss: 0.5775 (0.5850)  bbox_regression: 0.1004 (0.1034)  classification: 0.4629 (0.4816)  time: 0.3594  data: 0.1326  max mem: 3278
Epoch: [44]  [2000/3494]  eta: 0:09:01  lr: 0.0000001  loss: 0.5435 (0.5853)  bbox_regression: 0.0868 (0.1036)  classification: 0.4486 (0.4817)  time: 0.3641  data: 0.1313  max mem: 3278
Epoch: [44]  [2100/3494]  eta: 0:08:25  lr: 0.0000001  loss: 0.5604 (0.5846)  bbox_regression: 0.1016 (0.1033)  classification: 0.4629 (0.4812)  time: 0.3690  data: 0.1366  max mem: 3278
Epoch: [44]  [2200/3494]  eta: 0:07:49  lr: 0.0000001  loss: 0.5226 (0.5850)  bbox_regression: 0.0901 (0.1035)  classification: 0.4417 (0.4814)  time: 0.3676  data: 0.1370  max mem: 3278
Epoch: [44]  [2300/3494]  eta: 0:07:12  lr: 0.0000001  loss: 0.5869 (0.5849)  bbox_regression: 0.1006 (0.1036)  classification: 0.5021 (0.4813)  time: 0.3550  data: 0.1261  max mem: 3278
Epoch: [44]  [2400/3494]  eta: 0:06:36  lr: 0.0000001  loss: 0.5483 (0.5835)  bbox_regression: 0.0969 (0.1035)  classification: 0.4480 (0.4800)  time: 0.3675  data: 0.1362  max mem: 3278
Epoch: [44]  [2500/3494]  eta: 0:06:00  lr: 0.0000001  loss: 0.5066 (0.5834)  bbox_regression: 0.0896 (0.1033)  classification: 0.4316 (0.4800)  time: 0.3664  data: 0.1287  max mem: 3278
Epoch: [44]  [2600/3494]  eta: 0:05:23  lr: 0.0000001  loss: 0.5490 (0.5831)  bbox_regression: 0.1002 (0.1034)  classification: 0.4432 (0.4797)  time: 0.3397  data: 0.1176  max mem: 3278
Epoch: [44]  [2700/3494]  eta: 0:04:47  lr: 0.0000001  loss: 0.5484 (0.5830)  bbox_regression: 0.0936 (0.1034)  classification: 0.4608 (0.4797)  time: 0.3725  data: 0.1351  max mem: 3278
Epoch: [44]  [2800/3494]  eta: 0:04:11  lr: 0.0000001  loss: 0.5801 (0.5831)  bbox_regression: 0.1112 (0.1033)  classification: 0.4705 (0.4798)  time: 0.3594  data: 0.1296  max mem: 3278
Epoch: [44]  [2900/3494]  eta: 0:03:35  lr: 0.0000001  loss: 0.5369 (0.5825)  bbox_regression: 0.0900 (0.1032)  classification: 0.4582 (0.4793)  time: 0.3589  data: 0.1218  max mem: 3278
Epoch: [44]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5530 (0.5827)  bbox_regression: 0.0964 (0.1032)  classification: 0.4497 (0.4794)  time: 0.3661  data: 0.1312  max mem: 3278
Epoch: [44]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5515 (0.5831)  bbox_regression: 0.0906 (0.1033)  classification: 0.4820 (0.4797)  time: 0.3647  data: 0.1281  max mem: 3278
Epoch: [44]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5511 (0.5823)  bbox_regression: 0.0921 (0.1032)  classification: 0.4667 (0.4792)  time: 0.3472  data: 0.1239  max mem: 3278
Epoch: [44]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.6043 (0.5824)  bbox_regression: 0.0956 (0.1032)  classification: 0.4862 (0.4792)  time: 0.3598  data: 0.1304  max mem: 3278
Epoch: [44]  [3400/3494]  eta: 0:00:34  lr: 0.0000001  loss: 0.5363 (0.5828)  bbox_regression: 0.0894 (0.1032)  classification: 0.4328 (0.4795)  time: 0.3628  data: 0.1341  max mem: 3278
Epoch: [44]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5786 (0.5828)  bbox_regression: 0.1033 (0.1032)  classification: 0.4746 (0.4796)  time: 0.3622  data: 0.1328  max mem: 3278
Epoch: [44] Total time: 0:21:15 (0.3650 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:10  model_time: 0.1313 (0.1313)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.6710  data: 1.4983  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1126 (0.1214)  loss: 0.7710 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6138 (0.7383)  time: 0.2637  data: 0.1247  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1204 (0.1215)  loss: 0.7657 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2651  data: 0.1240  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1196 (0.1214)  loss: 0.8971 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7152)  time: 0.2645  data: 0.1265  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1239 (0.1208)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2754  data: 0.1325  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1143 (0.1209)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2523  data: 0.1171  max mem: 3278
Validation: Total time: 0:01:56 (0.2671 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [45]  [   0/3494]  eta: 2:00:27  lr: 0.0000001  loss: 0.8040 (0.8040)  bbox_regression: 0.1357 (0.1357)  classification: 0.6683 (0.6683)  time: 2.0685  data: 1.7956  max mem: 3278
Epoch: [45]  [ 100/3494]  eta: 0:21:38  lr: 0.0000001  loss: 0.5498 (0.5847)  bbox_regression: 0.0984 (0.1005)  classification: 0.4585 (0.4842)  time: 0.3781  data: 0.1437  max mem: 3278
Epoch: [45]  [ 200/3494]  eta: 0:20:17  lr: 0.0000001  loss: 0.5533 (0.5786)  bbox_regression: 0.0997 (0.0998)  classification: 0.4367 (0.4788)  time: 0.3565  data: 0.1264  max mem: 3278
Epoch: [45]  [ 300/3494]  eta: 0:19:23  lr: 0.0000001  loss: 0.5293 (0.5748)  bbox_regression: 0.0906 (0.0995)  classification: 0.4336 (0.4753)  time: 0.3532  data: 0.1244  max mem: 3278
Epoch: [45]  [ 400/3494]  eta: 0:18:45  lr: 0.0000001  loss: 0.5196 (0.5742)  bbox_regression: 0.0953 (0.1001)  classification: 0.4482 (0.4741)  time: 0.3753  data: 0.1377  max mem: 3278
Epoch: [45]  [ 500/3494]  eta: 0:18:03  lr: 0.0000001  loss: 0.5781 (0.5788)  bbox_regression: 0.0976 (0.1008)  classification: 0.4510 (0.4780)  time: 0.3500  data: 0.1236  max mem: 3278
Epoch: [45]  [ 600/3494]  eta: 0:17:26  lr: 0.0000001  loss: 0.6242 (0.5780)  bbox_regression: 0.1049 (0.1004)  classification: 0.5098 (0.4776)  time: 0.3654  data: 0.1314  max mem: 3278
Epoch: [45]  [ 700/3494]  eta: 0:16:48  lr: 0.0000001  loss: 0.5301 (0.5799)  bbox_regression: 0.0955 (0.1004)  classification: 0.4413 (0.4795)  time: 0.3622  data: 0.1265  max mem: 3278
Epoch: [45]  [ 800/3494]  eta: 0:16:12  lr: 0.0000001  loss: 0.5162 (0.5782)  bbox_regression: 0.0905 (0.1008)  classification: 0.4263 (0.4774)  time: 0.3689  data: 0.1341  max mem: 3278
Epoch: [45]  [ 900/3494]  eta: 0:15:36  lr: 0.0000001  loss: 0.5658 (0.5798)  bbox_regression: 0.1035 (0.1016)  classification: 0.4637 (0.4782)  time: 0.3484  data: 0.1241  max mem: 3278
Epoch: [45]  [1000/3494]  eta: 0:15:00  lr: 0.0000001  loss: 0.5365 (0.5805)  bbox_regression: 0.0853 (0.1019)  classification: 0.4669 (0.4786)  time: 0.3782  data: 0.1375  max mem: 3278
Epoch: [45]  [1100/3494]  eta: 0:14:24  lr: 0.0000001  loss: 0.5655 (0.5806)  bbox_regression: 0.0980 (0.1019)  classification: 0.4734 (0.4787)  time: 0.3695  data: 0.1301  max mem: 3278
Epoch: [45]  [1200/3494]  eta: 0:13:47  lr: 0.0000001  loss: 0.5583 (0.5811)  bbox_regression: 0.0950 (0.1022)  classification: 0.4527 (0.4789)  time: 0.3478  data: 0.1211  max mem: 3278
Epoch: [45]  [1300/3494]  eta: 0:13:10  lr: 0.0000001  loss: 0.5579 (0.5806)  bbox_regression: 0.0936 (0.1023)  classification: 0.4596 (0.4783)  time: 0.3598  data: 0.1301  max mem: 3278
Epoch: [45]  [1400/3494]  eta: 0:12:34  lr: 0.0000001  loss: 0.5741 (0.5814)  bbox_regression: 0.0997 (0.1023)  classification: 0.4883 (0.4790)  time: 0.3588  data: 0.1297  max mem: 3278
Epoch: [45]  [1500/3494]  eta: 0:11:59  lr: 0.0000001  loss: 0.5871 (0.5821)  bbox_regression: 0.0995 (0.1026)  classification: 0.4770 (0.4795)  time: 0.3676  data: 0.1311  max mem: 3278
Epoch: [45]  [1600/3494]  eta: 0:11:23  lr: 0.0000001  loss: 0.5288 (0.5818)  bbox_regression: 0.0887 (0.1027)  classification: 0.4518 (0.4791)  time: 0.3450  data: 0.1189  max mem: 3278
Epoch: [45]  [1700/3494]  eta: 0:10:47  lr: 0.0000001  loss: 0.5759 (0.5821)  bbox_regression: 0.1014 (0.1026)  classification: 0.4928 (0.4795)  time: 0.3662  data: 0.1297  max mem: 3278
Epoch: [45]  [1800/3494]  eta: 0:10:11  lr: 0.0000001  loss: 0.5321 (0.5812)  bbox_regression: 0.0857 (0.1024)  classification: 0.4577 (0.4788)  time: 0.3599  data: 0.1277  max mem: 3278
Epoch: [45]  [1900/3494]  eta: 0:09:35  lr: 0.0000001  loss: 0.5340 (0.5807)  bbox_regression: 0.0866 (0.1022)  classification: 0.4351 (0.4785)  time: 0.3565  data: 0.1286  max mem: 3278
Epoch: [45]  [2000/3494]  eta: 0:08:59  lr: 0.0000001  loss: 0.5561 (0.5806)  bbox_regression: 0.0861 (0.1022)  classification: 0.4680 (0.4785)  time: 0.3661  data: 0.1358  max mem: 3278
Epoch: [45]  [2100/3494]  eta: 0:08:23  lr: 0.0000001  loss: 0.5905 (0.5817)  bbox_regression: 0.0912 (0.1024)  classification: 0.5020 (0.4793)  time: 0.3507  data: 0.1238  max mem: 3278
Epoch: [45]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.6147 (0.5825)  bbox_regression: 0.1001 (0.1026)  classification: 0.4893 (0.4798)  time: 0.3671  data: 0.1312  max mem: 3278
Epoch: [45]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.4974 (0.5824)  bbox_regression: 0.0848 (0.1027)  classification: 0.4215 (0.4797)  time: 0.3710  data: 0.1397  max mem: 3278
Epoch: [45]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5678 (0.5830)  bbox_regression: 0.1041 (0.1028)  classification: 0.4803 (0.4802)  time: 0.3328  data: 0.1124  max mem: 3278
Epoch: [45]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5356 (0.5831)  bbox_regression: 0.0913 (0.1028)  classification: 0.4543 (0.4803)  time: 0.3692  data: 0.1361  max mem: 3278
Epoch: [45]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5831 (0.5827)  bbox_regression: 0.0868 (0.1028)  classification: 0.4801 (0.4799)  time: 0.3617  data: 0.1287  max mem: 3278
Epoch: [45]  [2700/3494]  eta: 0:04:45  lr: 0.0000001  loss: 0.5450 (0.5826)  bbox_regression: 0.0948 (0.1028)  classification: 0.4509 (0.4798)  time: 0.3549  data: 0.1268  max mem: 3278
Epoch: [45]  [2800/3494]  eta: 0:04:09  lr: 0.0000001  loss: 0.6276 (0.5830)  bbox_regression: 0.1133 (0.1029)  classification: 0.5247 (0.4801)  time: 0.3530  data: 0.1251  max mem: 3278
Epoch: [45]  [2900/3494]  eta: 0:03:33  lr: 0.0000001  loss: 0.5175 (0.5825)  bbox_regression: 0.0889 (0.1028)  classification: 0.4188 (0.4797)  time: 0.3659  data: 0.1299  max mem: 3278
Epoch: [45]  [3000/3494]  eta: 0:02:57  lr: 0.0000001  loss: 0.5483 (0.5824)  bbox_regression: 0.0938 (0.1027)  classification: 0.4564 (0.4797)  time: 0.3710  data: 0.1388  max mem: 3278
Epoch: [45]  [3100/3494]  eta: 0:02:21  lr: 0.0000001  loss: 0.5462 (0.5825)  bbox_regression: 0.0961 (0.1029)  classification: 0.4441 (0.4797)  time: 0.3686  data: 0.1336  max mem: 3278
Epoch: [45]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5684 (0.5830)  bbox_regression: 0.0923 (0.1029)  classification: 0.4761 (0.4801)  time: 0.3452  data: 0.1192  max mem: 3278
Epoch: [45]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5434 (0.5830)  bbox_regression: 0.0913 (0.1030)  classification: 0.4498 (0.4800)  time: 0.3541  data: 0.1279  max mem: 3278
Epoch: [45]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5812 (0.5835)  bbox_regression: 0.0944 (0.1031)  classification: 0.4799 (0.4804)  time: 0.3580  data: 0.1327  max mem: 3278
Epoch: [45]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5749 (0.5833)  bbox_regression: 0.1086 (0.1032)  classification: 0.4711 (0.4801)  time: 0.3451  data: 0.1181  max mem: 3278
Epoch: [45] Total time: 0:21:07 (0.3626 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:13  model_time: 0.1485 (0.1485)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0897  data: 1.9129  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1265 (0.1218)  loss: 0.7711 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2689  data: 0.1254  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1176 (0.1212)  loss: 0.7657 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2713  data: 0.1320  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1180 (0.1219)  loss: 0.8971 (0.8652)  bbox_regression: 0.1451 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2603  data: 0.1227  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1185 (0.1214)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2646  data: 0.1252  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1163 (0.1211)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2611  data: 0.1246  max mem: 3278
Validation: Total time: 0:01:56 (0.2658 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [46]  [   0/3494]  eta: 2:28:27  lr: 0.0000001  loss: 0.5692 (0.5692)  bbox_regression: 0.1097 (0.1097)  classification: 0.4595 (0.4595)  time: 2.5494  data: 2.3210  max mem: 3278
Epoch: [46]  [ 100/3494]  eta: 0:21:26  lr: 0.0000001  loss: 0.5273 (0.5921)  bbox_regression: 0.0960 (0.1037)  classification: 0.4379 (0.4884)  time: 0.3645  data: 0.1302  max mem: 3278
Epoch: [46]  [ 200/3494]  eta: 0:20:23  lr: 0.0000001  loss: 0.5795 (0.5878)  bbox_regression: 0.0855 (0.1029)  classification: 0.4840 (0.4850)  time: 0.3627  data: 0.1377  max mem: 3278
Epoch: [46]  [ 300/3494]  eta: 0:19:31  lr: 0.0000001  loss: 0.6092 (0.5901)  bbox_regression: 0.1026 (0.1036)  classification: 0.4968 (0.4865)  time: 0.3706  data: 0.1332  max mem: 3278
Epoch: [46]  [ 400/3494]  eta: 0:18:47  lr: 0.0000001  loss: 0.5523 (0.5883)  bbox_regression: 0.0880 (0.1032)  classification: 0.4602 (0.4850)  time: 0.3524  data: 0.1255  max mem: 3278
Epoch: [46]  [ 500/3494]  eta: 0:18:07  lr: 0.0000001  loss: 0.6028 (0.5870)  bbox_regression: 0.1054 (0.1030)  classification: 0.4920 (0.4839)  time: 0.3562  data: 0.1265  max mem: 3278
Epoch: [46]  [ 600/3494]  eta: 0:17:33  lr: 0.0000001  loss: 0.5185 (0.5850)  bbox_regression: 0.0995 (0.1031)  classification: 0.4134 (0.4819)  time: 0.3694  data: 0.1298  max mem: 3278
Epoch: [46]  [ 700/3494]  eta: 0:16:55  lr: 0.0000001  loss: 0.5608 (0.5820)  bbox_regression: 0.1023 (0.1024)  classification: 0.4751 (0.4796)  time: 0.3655  data: 0.1379  max mem: 3278
Epoch: [46]  [ 800/3494]  eta: 0:16:16  lr: 0.0000001  loss: 0.5510 (0.5805)  bbox_regression: 0.0979 (0.1026)  classification: 0.4608 (0.4779)  time: 0.3722  data: 0.1397  max mem: 3278
Epoch: [46]  [ 900/3494]  eta: 0:15:39  lr: 0.0000001  loss: 0.5325 (0.5809)  bbox_regression: 0.0957 (0.1022)  classification: 0.4364 (0.4786)  time: 0.3557  data: 0.1252  max mem: 3278
Epoch: [46]  [1000/3494]  eta: 0:15:06  lr: 0.0000001  loss: 0.5553 (0.5819)  bbox_regression: 0.0976 (0.1022)  classification: 0.4531 (0.4797)  time: 0.3726  data: 0.1332  max mem: 3278
Epoch: [46]  [1100/3494]  eta: 0:14:28  lr: 0.0000001  loss: 0.5875 (0.5825)  bbox_regression: 0.0983 (0.1024)  classification: 0.4728 (0.4801)  time: 0.3580  data: 0.1273  max mem: 3278
Epoch: [46]  [1200/3494]  eta: 0:13:52  lr: 0.0000001  loss: 0.5466 (0.5815)  bbox_regression: 0.0952 (0.1026)  classification: 0.4468 (0.4789)  time: 0.3593  data: 0.1301  max mem: 3278
Epoch: [46]  [1300/3494]  eta: 0:13:16  lr: 0.0000001  loss: 0.5609 (0.5812)  bbox_regression: 0.0896 (0.1026)  classification: 0.4673 (0.4786)  time: 0.3552  data: 0.1255  max mem: 3278
Epoch: [46]  [1400/3494]  eta: 0:12:39  lr: 0.0000001  loss: 0.5481 (0.5812)  bbox_regression: 0.0972 (0.1028)  classification: 0.4559 (0.4784)  time: 0.3593  data: 0.1298  max mem: 3278
Epoch: [46]  [1500/3494]  eta: 0:12:03  lr: 0.0000001  loss: 0.5210 (0.5806)  bbox_regression: 0.0880 (0.1026)  classification: 0.4454 (0.4780)  time: 0.3589  data: 0.1272  max mem: 3278
Epoch: [46]  [1600/3494]  eta: 0:11:26  lr: 0.0000001  loss: 0.5953 (0.5818)  bbox_regression: 0.1023 (0.1027)  classification: 0.4930 (0.4791)  time: 0.3612  data: 0.1292  max mem: 3278
Epoch: [46]  [1700/3494]  eta: 0:10:50  lr: 0.0000001  loss: 0.5310 (0.5814)  bbox_regression: 0.1038 (0.1027)  classification: 0.4266 (0.4787)  time: 0.3662  data: 0.1327  max mem: 3278
Epoch: [46]  [1800/3494]  eta: 0:10:14  lr: 0.0000001  loss: 0.5713 (0.5812)  bbox_regression: 0.0902 (0.1027)  classification: 0.4751 (0.4786)  time: 0.3518  data: 0.1241  max mem: 3278
Epoch: [46]  [1900/3494]  eta: 0:09:37  lr: 0.0000001  loss: 0.6770 (0.5827)  bbox_regression: 0.0977 (0.1028)  classification: 0.5518 (0.4799)  time: 0.3628  data: 0.1263  max mem: 3278
Epoch: [46]  [2000/3494]  eta: 0:09:01  lr: 0.0000001  loss: 0.5617 (0.5826)  bbox_regression: 0.0954 (0.1029)  classification: 0.4568 (0.4797)  time: 0.3534  data: 0.1221  max mem: 3278
Epoch: [46]  [2100/3494]  eta: 0:08:24  lr: 0.0000001  loss: 0.5489 (0.5838)  bbox_regression: 0.0969 (0.1031)  classification: 0.4676 (0.4807)  time: 0.3632  data: 0.1316  max mem: 3278
Epoch: [46]  [2200/3494]  eta: 0:07:48  lr: 0.0000001  loss: 0.5555 (0.5830)  bbox_regression: 0.0959 (0.1030)  classification: 0.4555 (0.4800)  time: 0.3626  data: 0.1338  max mem: 3278
Epoch: [46]  [2300/3494]  eta: 0:07:12  lr: 0.0000001  loss: 0.5728 (0.5832)  bbox_regression: 0.1025 (0.1029)  classification: 0.4690 (0.4803)  time: 0.3517  data: 0.1247  max mem: 3278
Epoch: [46]  [2400/3494]  eta: 0:06:35  lr: 0.0000001  loss: 0.5300 (0.5828)  bbox_regression: 0.0906 (0.1029)  classification: 0.4226 (0.4799)  time: 0.3492  data: 0.1229  max mem: 3278
Epoch: [46]  [2500/3494]  eta: 0:05:59  lr: 0.0000001  loss: 0.5591 (0.5831)  bbox_regression: 0.1004 (0.1029)  classification: 0.4721 (0.4802)  time: 0.3562  data: 0.1238  max mem: 3278
Epoch: [46]  [2600/3494]  eta: 0:05:23  lr: 0.0000001  loss: 0.5952 (0.5833)  bbox_regression: 0.1037 (0.1031)  classification: 0.4808 (0.4802)  time: 0.3666  data: 0.1350  max mem: 3278
Epoch: [46]  [2700/3494]  eta: 0:04:47  lr: 0.0000001  loss: 0.5328 (0.5829)  bbox_regression: 0.0783 (0.1031)  classification: 0.4373 (0.4798)  time: 0.3762  data: 0.1421  max mem: 3278
Epoch: [46]  [2800/3494]  eta: 0:04:11  lr: 0.0000001  loss: 0.5655 (0.5835)  bbox_regression: 0.1045 (0.1031)  classification: 0.4609 (0.4804)  time: 0.3832  data: 0.1365  max mem: 3278
Epoch: [46]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5903 (0.5835)  bbox_regression: 0.1103 (0.1032)  classification: 0.4727 (0.4804)  time: 0.3642  data: 0.1315  max mem: 3278
Epoch: [46]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5782 (0.5833)  bbox_regression: 0.1073 (0.1032)  classification: 0.4872 (0.4801)  time: 0.3713  data: 0.1333  max mem: 3278
Epoch: [46]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5727 (0.5834)  bbox_regression: 0.0959 (0.1031)  classification: 0.4817 (0.4803)  time: 0.3602  data: 0.1320  max mem: 3278
Epoch: [46]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.6088 (0.5837)  bbox_regression: 0.0957 (0.1030)  classification: 0.4937 (0.4807)  time: 0.3514  data: 0.1276  max mem: 3278
Epoch: [46]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5884 (0.5836)  bbox_regression: 0.0973 (0.1031)  classification: 0.4869 (0.4805)  time: 0.3625  data: 0.1351  max mem: 3278
Epoch: [46]  [3400/3494]  eta: 0:00:34  lr: 0.0000001  loss: 0.5541 (0.5833)  bbox_regression: 0.0966 (0.1032)  classification: 0.4530 (0.4801)  time: 0.3600  data: 0.1269  max mem: 3278
Epoch: [46]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5916 (0.5834)  bbox_regression: 0.1101 (0.1031)  classification: 0.4750 (0.4803)  time: 0.3316  data: 0.1135  max mem: 3278
Epoch: [46] Total time: 0:21:13 (0.3645 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:30  model_time: 0.1354 (0.1354)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9912  data: 1.8303  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1130 (0.1216)  loss: 0.7711 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2503  data: 0.1185  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1182 (0.1208)  loss: 0.7657 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6515 (0.7096)  time: 0.2626  data: 0.1246  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1188 (0.1214)  loss: 0.8971 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7643 (0.7153)  time: 0.2590  data: 0.1191  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1177 (0.1210)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2577  data: 0.1206  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1158 (0.1211)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2680  data: 0.1263  max mem: 3278
Validation: Total time: 0:01:56 (0.2663 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [47]  [   0/3494]  eta: 2:13:22  lr: 0.0000001  loss: 0.3730 (0.3730)  bbox_regression: 0.0831 (0.0831)  classification: 0.2899 (0.2899)  time: 2.2905  data: 2.0576  max mem: 3278
Epoch: [47]  [ 100/3494]  eta: 0:21:34  lr: 0.0000001  loss: 0.5844 (0.5826)  bbox_regression: 0.0948 (0.1010)  classification: 0.4495 (0.4816)  time: 0.3611  data: 0.1318  max mem: 3278
Epoch: [47]  [ 200/3494]  eta: 0:20:26  lr: 0.0000001  loss: 0.5820 (0.5882)  bbox_regression: 0.0994 (0.1030)  classification: 0.4704 (0.4852)  time: 0.3582  data: 0.1279  max mem: 3278
Epoch: [47]  [ 300/3494]  eta: 0:19:29  lr: 0.0000001  loss: 0.6003 (0.5843)  bbox_regression: 0.0990 (0.1020)  classification: 0.4766 (0.4823)  time: 0.3602  data: 0.1278  max mem: 3278
Epoch: [47]  [ 400/3494]  eta: 0:18:48  lr: 0.0000001  loss: 0.5436 (0.5811)  bbox_regression: 0.0893 (0.1010)  classification: 0.4531 (0.4800)  time: 0.3719  data: 0.1353  max mem: 3278
Epoch: [47]  [ 500/3494]  eta: 0:18:04  lr: 0.0000001  loss: 0.5705 (0.5814)  bbox_regression: 0.0953 (0.1010)  classification: 0.4721 (0.4804)  time: 0.3610  data: 0.1268  max mem: 3278
Epoch: [47]  [ 600/3494]  eta: 0:17:27  lr: 0.0000001  loss: 0.5741 (0.5822)  bbox_regression: 0.0955 (0.1016)  classification: 0.4615 (0.4806)  time: 0.3664  data: 0.1296  max mem: 3278
Epoch: [47]  [ 700/3494]  eta: 0:16:53  lr: 0.0000001  loss: 0.5626 (0.5835)  bbox_regression: 0.0925 (0.1021)  classification: 0.4492 (0.4814)  time: 0.3654  data: 0.1304  max mem: 3278
Epoch: [47]  [ 800/3494]  eta: 0:16:15  lr: 0.0000001  loss: 0.5773 (0.5841)  bbox_regression: 0.1047 (0.1022)  classification: 0.4645 (0.4819)  time: 0.3607  data: 0.1268  max mem: 3278
Epoch: [47]  [ 900/3494]  eta: 0:15:39  lr: 0.0000001  loss: 0.5748 (0.5823)  bbox_regression: 0.1049 (0.1023)  classification: 0.4452 (0.4799)  time: 0.3574  data: 0.1263  max mem: 3278
Epoch: [47]  [1000/3494]  eta: 0:15:02  lr: 0.0000001  loss: 0.5466 (0.5808)  bbox_regression: 0.0827 (0.1018)  classification: 0.4597 (0.4791)  time: 0.3539  data: 0.1269  max mem: 3278
Epoch: [47]  [1100/3494]  eta: 0:14:26  lr: 0.0000001  loss: 0.5687 (0.5823)  bbox_regression: 0.1051 (0.1022)  classification: 0.4416 (0.4802)  time: 0.3634  data: 0.1309  max mem: 3278
Epoch: [47]  [1200/3494]  eta: 0:13:49  lr: 0.0000001  loss: 0.5874 (0.5827)  bbox_regression: 0.0961 (0.1020)  classification: 0.4883 (0.4807)  time: 0.3649  data: 0.1315  max mem: 3278
Epoch: [47]  [1300/3494]  eta: 0:13:12  lr: 0.0000001  loss: 0.5104 (0.5828)  bbox_regression: 0.0857 (0.1021)  classification: 0.4332 (0.4807)  time: 0.3418  data: 0.1219  max mem: 3278
Epoch: [47]  [1400/3494]  eta: 0:12:36  lr: 0.0000001  loss: 0.5470 (0.5832)  bbox_regression: 0.0946 (0.1022)  classification: 0.4694 (0.4811)  time: 0.3638  data: 0.1340  max mem: 3278
Epoch: [47]  [1500/3494]  eta: 0:12:00  lr: 0.0000001  loss: 0.5833 (0.5831)  bbox_regression: 0.0945 (0.1024)  classification: 0.4722 (0.4807)  time: 0.3499  data: 0.1243  max mem: 3278
Epoch: [47]  [1600/3494]  eta: 0:11:23  lr: 0.0000001  loss: 0.5671 (0.5838)  bbox_regression: 0.1037 (0.1025)  classification: 0.4667 (0.4813)  time: 0.3553  data: 0.1257  max mem: 3278
Epoch: [47]  [1700/3494]  eta: 0:10:47  lr: 0.0000001  loss: 0.5598 (0.5839)  bbox_regression: 0.0988 (0.1025)  classification: 0.4721 (0.4814)  time: 0.3628  data: 0.1305  max mem: 3278
Epoch: [47]  [1800/3494]  eta: 0:10:11  lr: 0.0000001  loss: 0.5733 (0.5844)  bbox_regression: 0.1042 (0.1027)  classification: 0.4566 (0.4817)  time: 0.3690  data: 0.1369  max mem: 3278
Epoch: [47]  [1900/3494]  eta: 0:09:35  lr: 0.0000001  loss: 0.5221 (0.5846)  bbox_regression: 0.0881 (0.1027)  classification: 0.4400 (0.4819)  time: 0.3657  data: 0.1297  max mem: 3278
Epoch: [47]  [2000/3494]  eta: 0:08:58  lr: 0.0000001  loss: 0.5747 (0.5843)  bbox_regression: 0.0961 (0.1028)  classification: 0.4895 (0.4815)  time: 0.3640  data: 0.1292  max mem: 3278
Epoch: [47]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.5670 (0.5843)  bbox_regression: 0.1037 (0.1028)  classification: 0.4627 (0.4815)  time: 0.3584  data: 0.1299  max mem: 3278
Epoch: [47]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.6099 (0.5854)  bbox_regression: 0.1119 (0.1030)  classification: 0.5059 (0.4824)  time: 0.3696  data: 0.1344  max mem: 3278
Epoch: [47]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5624 (0.5850)  bbox_regression: 0.1007 (0.1030)  classification: 0.4655 (0.4820)  time: 0.3643  data: 0.1339  max mem: 3278
Epoch: [47]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5831 (0.5848)  bbox_regression: 0.0969 (0.1031)  classification: 0.4838 (0.4817)  time: 0.3629  data: 0.1293  max mem: 3278
Epoch: [47]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5491 (0.5842)  bbox_regression: 0.0910 (0.1030)  classification: 0.4612 (0.4812)  time: 0.3498  data: 0.1243  max mem: 3278
Epoch: [47]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5444 (0.5843)  bbox_regression: 0.0901 (0.1030)  classification: 0.4544 (0.4813)  time: 0.3510  data: 0.1215  max mem: 3278
Epoch: [47]  [2700/3494]  eta: 0:04:45  lr: 0.0000001  loss: 0.5200 (0.5837)  bbox_regression: 0.0840 (0.1031)  classification: 0.4100 (0.4807)  time: 0.3625  data: 0.1348  max mem: 3278
Epoch: [47]  [2800/3494]  eta: 0:04:09  lr: 0.0000001  loss: 0.5605 (0.5830)  bbox_regression: 0.0961 (0.1029)  classification: 0.4419 (0.4801)  time: 0.3683  data: 0.1370  max mem: 3278
Epoch: [47]  [2900/3494]  eta: 0:03:33  lr: 0.0000001  loss: 0.5451 (0.5830)  bbox_regression: 0.1006 (0.1030)  classification: 0.4577 (0.4801)  time: 0.3649  data: 0.1263  max mem: 3278
Epoch: [47]  [3000/3494]  eta: 0:02:57  lr: 0.0000001  loss: 0.6010 (0.5833)  bbox_regression: 0.0915 (0.1030)  classification: 0.5088 (0.4803)  time: 0.3496  data: 0.1222  max mem: 3278
Epoch: [47]  [3100/3494]  eta: 0:02:21  lr: 0.0000001  loss: 0.5903 (0.5830)  bbox_regression: 0.0981 (0.1030)  classification: 0.4905 (0.4801)  time: 0.3675  data: 0.1353  max mem: 3278
Epoch: [47]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5854 (0.5834)  bbox_regression: 0.1065 (0.1031)  classification: 0.4952 (0.4803)  time: 0.3371  data: 0.1093  max mem: 3278
Epoch: [47]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5516 (0.5831)  bbox_regression: 0.1034 (0.1031)  classification: 0.4611 (0.4800)  time: 0.3616  data: 0.1311  max mem: 3278
Epoch: [47]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5150 (0.5830)  bbox_regression: 0.0907 (0.1031)  classification: 0.4346 (0.4799)  time: 0.3706  data: 0.1307  max mem: 3278
Epoch: [47]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5276 (0.5831)  bbox_regression: 0.0847 (0.1031)  classification: 0.4328 (0.4800)  time: 0.3480  data: 0.1242  max mem: 3278
Epoch: [47] Total time: 0:21:07 (0.3626 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:00  model_time: 0.1341 (0.1341)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.3362  data: 2.1652  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1169 (0.1216)  loss: 0.7711 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2609  data: 0.1230  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1233 (0.1212)  loss: 0.7657 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2727  data: 0.1307  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1173 (0.1211)  loss: 0.8971 (0.8652)  bbox_regression: 0.1451 (0.1499)  classification: 0.7643 (0.7153)  time: 0.2586  data: 0.1238  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1196 (0.1209)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2671  data: 0.1259  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1165 (0.1207)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2531  data: 0.1184  max mem: 3278
Validation: Total time: 0:01:56 (0.2673 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [48]  [   0/3494]  eta: 2:22:03  lr: 0.0000001  loss: 0.4656 (0.4656)  bbox_regression: 0.0701 (0.0701)  classification: 0.3954 (0.3954)  time: 2.4396  data: 2.1931  max mem: 3278
Epoch: [48]  [ 100/3494]  eta: 0:21:44  lr: 0.0000001  loss: 0.5677 (0.5770)  bbox_regression: 0.0995 (0.1028)  classification: 0.4665 (0.4743)  time: 0.3511  data: 0.1244  max mem: 3278
Epoch: [48]  [ 200/3494]  eta: 0:20:14  lr: 0.0000001  loss: 0.5559 (0.5825)  bbox_regression: 0.0855 (0.1015)  classification: 0.4571 (0.4810)  time: 0.3233  data: 0.1070  max mem: 3278
Epoch: [48]  [ 300/3494]  eta: 0:19:23  lr: 0.0000001  loss: 0.5928 (0.5832)  bbox_regression: 0.0990 (0.1019)  classification: 0.4779 (0.4813)  time: 0.3606  data: 0.1284  max mem: 3278
Epoch: [48]  [ 400/3494]  eta: 0:18:47  lr: 0.0000001  loss: 0.5543 (0.5862)  bbox_regression: 0.0961 (0.1025)  classification: 0.4477 (0.4837)  time: 0.3627  data: 0.1326  max mem: 3278
Epoch: [48]  [ 500/3494]  eta: 0:18:05  lr: 0.0000001  loss: 0.5981 (0.5848)  bbox_regression: 0.0976 (0.1023)  classification: 0.4766 (0.4825)  time: 0.3550  data: 0.1268  max mem: 3278
Epoch: [48]  [ 600/3494]  eta: 0:17:29  lr: 0.0000001  loss: 0.5898 (0.5871)  bbox_regression: 0.1004 (0.1029)  classification: 0.4931 (0.4842)  time: 0.3608  data: 0.1255  max mem: 3278
Epoch: [48]  [ 700/3494]  eta: 0:16:51  lr: 0.0000001  loss: 0.5345 (0.5853)  bbox_regression: 0.0984 (0.1028)  classification: 0.4281 (0.4825)  time: 0.3633  data: 0.1291  max mem: 3278
Epoch: [48]  [ 800/3494]  eta: 0:16:14  lr: 0.0000001  loss: 0.5408 (0.5868)  bbox_regression: 0.0954 (0.1033)  classification: 0.4456 (0.4835)  time: 0.3710  data: 0.1332  max mem: 3278
Epoch: [48]  [ 900/3494]  eta: 0:15:38  lr: 0.0000001  loss: 0.5468 (0.5854)  bbox_regression: 0.0886 (0.1026)  classification: 0.4687 (0.4828)  time: 0.3462  data: 0.1218  max mem: 3278
Epoch: [48]  [1000/3494]  eta: 0:14:59  lr: 0.0000001  loss: 0.5877 (0.5876)  bbox_regression: 0.0959 (0.1034)  classification: 0.4952 (0.4842)  time: 0.3553  data: 0.1239  max mem: 3278
Epoch: [48]  [1100/3494]  eta: 0:14:23  lr: 0.0000001  loss: 0.5607 (0.5873)  bbox_regression: 0.0892 (0.1036)  classification: 0.4633 (0.4837)  time: 0.3676  data: 0.1330  max mem: 3278
Epoch: [48]  [1200/3494]  eta: 0:13:47  lr: 0.0000001  loss: 0.5595 (0.5876)  bbox_regression: 0.0943 (0.1038)  classification: 0.4507 (0.4838)  time: 0.3612  data: 0.1270  max mem: 3278
Epoch: [48]  [1300/3494]  eta: 0:13:11  lr: 0.0000001  loss: 0.5488 (0.5861)  bbox_regression: 0.0911 (0.1034)  classification: 0.4526 (0.4827)  time: 0.3434  data: 0.1111  max mem: 3278
Epoch: [48]  [1400/3494]  eta: 0:12:35  lr: 0.0000001  loss: 0.5753 (0.5859)  bbox_regression: 0.1008 (0.1034)  classification: 0.4662 (0.4825)  time: 0.3650  data: 0.1301  max mem: 3278
Epoch: [48]  [1500/3494]  eta: 0:11:59  lr: 0.0000001  loss: 0.5572 (0.5855)  bbox_regression: 0.0931 (0.1034)  classification: 0.4834 (0.4821)  time: 0.3612  data: 0.1263  max mem: 3278
Epoch: [48]  [1600/3494]  eta: 0:11:23  lr: 0.0000001  loss: 0.5647 (0.5833)  bbox_regression: 0.0956 (0.1032)  classification: 0.4449 (0.4800)  time: 0.3566  data: 0.1272  max mem: 3278
Epoch: [48]  [1700/3494]  eta: 0:10:47  lr: 0.0000001  loss: 0.5553 (0.5826)  bbox_regression: 0.1046 (0.1030)  classification: 0.4545 (0.4796)  time: 0.3579  data: 0.1270  max mem: 3278
Epoch: [48]  [1800/3494]  eta: 0:10:10  lr: 0.0000001  loss: 0.5241 (0.5827)  bbox_regression: 0.0933 (0.1032)  classification: 0.4261 (0.4795)  time: 0.3613  data: 0.1295  max mem: 3278
Epoch: [48]  [1900/3494]  eta: 0:09:34  lr: 0.0000001  loss: 0.5568 (0.5825)  bbox_regression: 0.0946 (0.1032)  classification: 0.4612 (0.4793)  time: 0.3632  data: 0.1342  max mem: 3278
Epoch: [48]  [2000/3494]  eta: 0:08:58  lr: 0.0000001  loss: 0.5507 (0.5819)  bbox_regression: 0.0887 (0.1032)  classification: 0.4554 (0.4787)  time: 0.3697  data: 0.1380  max mem: 3278
Epoch: [48]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.5771 (0.5824)  bbox_regression: 0.0957 (0.1032)  classification: 0.4704 (0.4792)  time: 0.3571  data: 0.1268  max mem: 3278
Epoch: [48]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5809 (0.5823)  bbox_regression: 0.1004 (0.1031)  classification: 0.4791 (0.4792)  time: 0.3573  data: 0.1233  max mem: 3278
Epoch: [48]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5795 (0.5826)  bbox_regression: 0.0884 (0.1030)  classification: 0.4716 (0.4795)  time: 0.3550  data: 0.1244  max mem: 3278
Epoch: [48]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5816 (0.5836)  bbox_regression: 0.1077 (0.1033)  classification: 0.4837 (0.4802)  time: 0.3565  data: 0.1303  max mem: 3278
Epoch: [48]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5683 (0.5834)  bbox_regression: 0.1038 (0.1032)  classification: 0.4629 (0.4802)  time: 0.3664  data: 0.1360  max mem: 3278
Epoch: [48]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5479 (0.5836)  bbox_regression: 0.0927 (0.1032)  classification: 0.4532 (0.4805)  time: 0.3646  data: 0.1290  max mem: 3278
Epoch: [48]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5758 (0.5835)  bbox_regression: 0.0961 (0.1032)  classification: 0.4593 (0.4803)  time: 0.3563  data: 0.1257  max mem: 3278
Epoch: [48]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5687 (0.5837)  bbox_regression: 0.1051 (0.1032)  classification: 0.4597 (0.4805)  time: 0.3477  data: 0.1232  max mem: 3278
Epoch: [48]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5412 (0.5839)  bbox_regression: 0.0955 (0.1032)  classification: 0.4368 (0.4807)  time: 0.3628  data: 0.1293  max mem: 3278
Epoch: [48]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5603 (0.5841)  bbox_regression: 0.1025 (0.1032)  classification: 0.4786 (0.4809)  time: 0.3514  data: 0.1216  max mem: 3278
Epoch: [48]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5449 (0.5838)  bbox_regression: 0.0967 (0.1031)  classification: 0.4652 (0.4808)  time: 0.3575  data: 0.1268  max mem: 3278
Epoch: [48]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.6163 (0.5837)  bbox_regression: 0.1009 (0.1030)  classification: 0.5185 (0.4808)  time: 0.3545  data: 0.1245  max mem: 3278
Epoch: [48]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5784 (0.5833)  bbox_regression: 0.1073 (0.1029)  classification: 0.4748 (0.4805)  time: 0.3391  data: 0.1144  max mem: 3278
Epoch: [48]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5687 (0.5834)  bbox_regression: 0.1077 (0.1031)  classification: 0.4681 (0.4803)  time: 0.3630  data: 0.1261  max mem: 3278
Epoch: [48]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5759 (0.5835)  bbox_regression: 0.1053 (0.1032)  classification: 0.4620 (0.4803)  time: 0.3656  data: 0.1326  max mem: 3278
Epoch: [48] Total time: 0:21:11 (0.3639 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:18  model_time: 0.1501 (0.1501)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5129  data: 2.3189  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1174 (0.1218)  loss: 0.7711 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6139 (0.7383)  time: 0.2662  data: 0.1246  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1207 (0.1219)  loss: 0.7658 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6514 (0.7096)  time: 0.2633  data: 0.1241  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1198 (0.1232)  loss: 0.8971 (0.8652)  bbox_regression: 0.1451 (0.1499)  classification: 0.7643 (0.7153)  time: 0.2683  data: 0.1249  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1341 (0.1234)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2672  data: 0.1216  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1192 (0.1233)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2742  data: 0.1341  max mem: 3278
Validation: Total time: 0:01:58 (0.2708 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [49]  [   0/3494]  eta: 2:56:31  lr: 0.0000001  loss: 0.3729 (0.3729)  bbox_regression: 0.0592 (0.0592)  classification: 0.3137 (0.3137)  time: 3.0312  data: 2.7569  max mem: 3278
Epoch: [49]  [ 100/3494]  eta: 0:21:50  lr: 0.0000001  loss: 0.5717 (0.5830)  bbox_regression: 0.0937 (0.1011)  classification: 0.4620 (0.4820)  time: 0.3679  data: 0.1330  max mem: 3278
Epoch: [49]  [ 200/3494]  eta: 0:20:37  lr: 0.0000001  loss: 0.5483 (0.5841)  bbox_regression: 0.0909 (0.1029)  classification: 0.4474 (0.4812)  time: 0.3641  data: 0.1272  max mem: 3278
Epoch: [49]  [ 300/3494]  eta: 0:19:48  lr: 0.0000001  loss: 0.5762 (0.5887)  bbox_regression: 0.0966 (0.1036)  classification: 0.4677 (0.4850)  time: 0.3750  data: 0.1316  max mem: 3278
Epoch: [49]  [ 400/3494]  eta: 0:19:01  lr: 0.0000001  loss: 0.5323 (0.5815)  bbox_regression: 0.0892 (0.1025)  classification: 0.4395 (0.4790)  time: 0.3626  data: 0.1307  max mem: 3278
Epoch: [49]  [ 500/3494]  eta: 0:18:21  lr: 0.0000001  loss: 0.5392 (0.5788)  bbox_regression: 0.0859 (0.1011)  classification: 0.4546 (0.4777)  time: 0.3590  data: 0.1292  max mem: 3278
Epoch: [49]  [ 600/3494]  eta: 0:17:44  lr: 0.0000001  loss: 0.5685 (0.5761)  bbox_regression: 0.1059 (0.1013)  classification: 0.4619 (0.4748)  time: 0.3721  data: 0.1429  max mem: 3278
Epoch: [49]  [ 700/3494]  eta: 0:17:06  lr: 0.0000001  loss: 0.6126 (0.5798)  bbox_regression: 0.1076 (0.1021)  classification: 0.5035 (0.4777)  time: 0.3739  data: 0.1405  max mem: 3278
Epoch: [49]  [ 800/3494]  eta: 0:16:30  lr: 0.0000001  loss: 0.5482 (0.5792)  bbox_regression: 0.0912 (0.1017)  classification: 0.4615 (0.4776)  time: 0.3762  data: 0.1332  max mem: 3278
Epoch: [49]  [ 900/3494]  eta: 0:15:53  lr: 0.0000001  loss: 0.5348 (0.5802)  bbox_regression: 0.0934 (0.1018)  classification: 0.4370 (0.4784)  time: 0.3606  data: 0.1226  max mem: 3278
Epoch: [49]  [1000/3494]  eta: 0:15:13  lr: 0.0000001  loss: 0.6196 (0.5791)  bbox_regression: 0.0976 (0.1018)  classification: 0.4938 (0.4773)  time: 0.3567  data: 0.1265  max mem: 3278
Epoch: [49]  [1100/3494]  eta: 0:14:36  lr: 0.0000001  loss: 0.6116 (0.5804)  bbox_regression: 0.1043 (0.1025)  classification: 0.5099 (0.4779)  time: 0.3586  data: 0.1279  max mem: 3278
Epoch: [49]  [1200/3494]  eta: 0:13:58  lr: 0.0000001  loss: 0.5709 (0.5808)  bbox_regression: 0.0821 (0.1029)  classification: 0.4630 (0.4780)  time: 0.3622  data: 0.1288  max mem: 3278
Epoch: [49]  [1300/3494]  eta: 0:13:21  lr: 0.0000001  loss: 0.5737 (0.5799)  bbox_regression: 0.1034 (0.1028)  classification: 0.4643 (0.4771)  time: 0.3616  data: 0.1305  max mem: 3278
Epoch: [49]  [1400/3494]  eta: 0:12:44  lr: 0.0000001  loss: 0.5727 (0.5812)  bbox_regression: 0.0893 (0.1028)  classification: 0.4788 (0.4784)  time: 0.3666  data: 0.1258  max mem: 3278
Epoch: [49]  [1500/3494]  eta: 0:12:08  lr: 0.0000001  loss: 0.5792 (0.5813)  bbox_regression: 0.0875 (0.1029)  classification: 0.5045 (0.4784)  time: 0.3609  data: 0.1316  max mem: 3278
Epoch: [49]  [1600/3494]  eta: 0:11:31  lr: 0.0000001  loss: 0.5955 (0.5818)  bbox_regression: 0.1038 (0.1030)  classification: 0.5097 (0.4788)  time: 0.3675  data: 0.1290  max mem: 3278
Epoch: [49]  [1700/3494]  eta: 0:10:54  lr: 0.0000001  loss: 0.5096 (0.5810)  bbox_regression: 0.1016 (0.1029)  classification: 0.4074 (0.4781)  time: 0.3696  data: 0.1333  max mem: 3278
Epoch: [49]  [1800/3494]  eta: 0:10:18  lr: 0.0000001  loss: 0.5294 (0.5807)  bbox_regression: 0.0858 (0.1027)  classification: 0.4486 (0.4779)  time: 0.3609  data: 0.1249  max mem: 3278
Epoch: [49]  [1900/3494]  eta: 0:09:41  lr: 0.0000001  loss: 0.5482 (0.5802)  bbox_regression: 0.0894 (0.1028)  classification: 0.4424 (0.4775)  time: 0.3576  data: 0.1280  max mem: 3278
Epoch: [49]  [2000/3494]  eta: 0:09:04  lr: 0.0000001  loss: 0.5273 (0.5806)  bbox_regression: 0.0897 (0.1026)  classification: 0.4484 (0.4779)  time: 0.3630  data: 0.1287  max mem: 3278
Epoch: [49]  [2100/3494]  eta: 0:08:27  lr: 0.0000001  loss: 0.5475 (0.5810)  bbox_regression: 0.1006 (0.1029)  classification: 0.4373 (0.4780)  time: 0.3655  data: 0.1279  max mem: 3278
Epoch: [49]  [2200/3494]  eta: 0:07:50  lr: 0.0000001  loss: 0.5669 (0.5812)  bbox_regression: 0.1023 (0.1030)  classification: 0.4627 (0.4781)  time: 0.3709  data: 0.1411  max mem: 3278
Epoch: [49]  [2300/3494]  eta: 0:07:14  lr: 0.0000001  loss: 0.5763 (0.5819)  bbox_regression: 0.0927 (0.1033)  classification: 0.4687 (0.4786)  time: 0.3552  data: 0.1282  max mem: 3278
Epoch: [49]  [2400/3494]  eta: 0:06:37  lr: 0.0000001  loss: 0.6031 (0.5818)  bbox_regression: 0.1065 (0.1032)  classification: 0.5068 (0.4786)  time: 0.3450  data: 0.1244  max mem: 3278
Epoch: [49]  [2500/3494]  eta: 0:06:00  lr: 0.0000001  loss: 0.5678 (0.5819)  bbox_regression: 0.1005 (0.1033)  classification: 0.4805 (0.4786)  time: 0.3588  data: 0.1275  max mem: 3278
Epoch: [49]  [2600/3494]  eta: 0:05:24  lr: 0.0000001  loss: 0.5628 (0.5819)  bbox_regression: 0.0946 (0.1032)  classification: 0.4664 (0.4787)  time: 0.3596  data: 0.1269  max mem: 3278
Epoch: [49]  [2700/3494]  eta: 0:04:47  lr: 0.0000001  loss: 0.5609 (0.5825)  bbox_regression: 0.1066 (0.1033)  classification: 0.4635 (0.4792)  time: 0.3740  data: 0.1387  max mem: 3278
Epoch: [49]  [2800/3494]  eta: 0:04:11  lr: 0.0000001  loss: 0.5423 (0.5822)  bbox_regression: 0.0948 (0.1032)  classification: 0.4429 (0.4790)  time: 0.3443  data: 0.1218  max mem: 3278
Epoch: [49]  [2900/3494]  eta: 0:03:35  lr: 0.0000001  loss: 0.5379 (0.5828)  bbox_regression: 0.0977 (0.1033)  classification: 0.4321 (0.4795)  time: 0.3681  data: 0.1383  max mem: 3278
Epoch: [49]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5341 (0.5835)  bbox_regression: 0.0938 (0.1034)  classification: 0.4433 (0.4802)  time: 0.3567  data: 0.1273  max mem: 3278
Epoch: [49]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5738 (0.5839)  bbox_regression: 0.0927 (0.1034)  classification: 0.4791 (0.4805)  time: 0.3621  data: 0.1281  max mem: 3278
Epoch: [49]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5665 (0.5843)  bbox_regression: 0.0887 (0.1034)  classification: 0.4797 (0.4809)  time: 0.3612  data: 0.1256  max mem: 3278
Epoch: [49]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5488 (0.5841)  bbox_regression: 0.0991 (0.1034)  classification: 0.4432 (0.4807)  time: 0.3581  data: 0.1265  max mem: 3278
Epoch: [49]  [3400/3494]  eta: 0:00:34  lr: 0.0000001  loss: 0.5669 (0.5837)  bbox_regression: 0.0898 (0.1033)  classification: 0.4874 (0.4804)  time: 0.3615  data: 0.1324  max mem: 3278
Epoch: [49]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5734 (0.5838)  bbox_regression: 0.0989 (0.1033)  classification: 0.4605 (0.4805)  time: 0.3617  data: 0.1275  max mem: 3278
Epoch: [49] Total time: 0:21:15 (0.3650 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:25  model_time: 0.1527 (0.1527)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9206 (0.9206)  time: 2.1185  data: 1.9311  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1304 (0.1249)  loss: 0.7713 (0.9010)  bbox_regression: 0.1662 (0.1626)  classification: 0.6140 (0.7383)  time: 0.2968  data: 0.1381  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1142 (0.1230)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6513 (0.7096)  time: 0.2529  data: 0.1174  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1150 (0.1230)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2611  data: 0.1221  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1203 (0.1224)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6163 (0.7113)  time: 0.2667  data: 0.1256  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1171 (0.1220)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2446  data: 0.1144  max mem: 3278
Validation: Total time: 0:01:56 (0.2671 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [50]  [   0/3494]  eta: 2:28:34  lr: 0.0000001  loss: 0.5664 (0.5664)  bbox_regression: 0.0725 (0.0725)  classification: 0.4939 (0.4939)  time: 2.5513  data: 2.2868  max mem: 3278
Epoch: [50]  [ 100/3494]  eta: 0:21:53  lr: 0.0000001  loss: 0.6051 (0.6052)  bbox_regression: 0.1092 (0.1064)  classification: 0.4959 (0.4988)  time: 0.3574  data: 0.1259  max mem: 3278
Epoch: [50]  [ 200/3494]  eta: 0:20:40  lr: 0.0000001  loss: 0.5451 (0.5848)  bbox_regression: 0.1005 (0.1028)  classification: 0.4658 (0.4820)  time: 0.3657  data: 0.1303  max mem: 3278
Epoch: [50]  [ 300/3494]  eta: 0:19:42  lr: 0.0000001  loss: 0.5288 (0.5849)  bbox_regression: 0.0944 (0.1044)  classification: 0.4344 (0.4804)  time: 0.3371  data: 0.1157  max mem: 3278
Epoch: [50]  [ 400/3494]  eta: 0:19:05  lr: 0.0000001  loss: 0.5655 (0.5854)  bbox_regression: 0.1005 (0.1051)  classification: 0.4689 (0.4803)  time: 0.3760  data: 0.1373  max mem: 3278
Epoch: [50]  [ 500/3494]  eta: 0:18:23  lr: 0.0000001  loss: 0.5834 (0.5844)  bbox_regression: 0.0948 (0.1041)  classification: 0.4808 (0.4804)  time: 0.3518  data: 0.1269  max mem: 3278
Epoch: [50]  [ 600/3494]  eta: 0:17:42  lr: 0.0000001  loss: 0.5875 (0.5864)  bbox_regression: 0.0918 (0.1048)  classification: 0.4675 (0.4816)  time: 0.3675  data: 0.1300  max mem: 3278
Epoch: [50]  [ 700/3494]  eta: 0:17:04  lr: 0.0000001  loss: 0.5544 (0.5843)  bbox_regression: 0.0997 (0.1044)  classification: 0.4459 (0.4799)  time: 0.3490  data: 0.1268  max mem: 3278
Epoch: [50]  [ 800/3494]  eta: 0:16:24  lr: 0.0000001  loss: 0.5695 (0.5840)  bbox_regression: 0.0940 (0.1045)  classification: 0.4626 (0.4795)  time: 0.3563  data: 0.1291  max mem: 3278
Epoch: [50]  [ 900/3494]  eta: 0:15:46  lr: 0.0000001  loss: 0.5394 (0.5820)  bbox_regression: 0.0816 (0.1038)  classification: 0.4486 (0.4782)  time: 0.3656  data: 0.1293  max mem: 3278
Epoch: [50]  [1000/3494]  eta: 0:15:08  lr: 0.0000001  loss: 0.5724 (0.5808)  bbox_regression: 0.0953 (0.1033)  classification: 0.4716 (0.4776)  time: 0.3502  data: 0.1262  max mem: 3278
Epoch: [50]  [1100/3494]  eta: 0:14:31  lr: 0.0000001  loss: 0.5782 (0.5811)  bbox_regression: 0.0934 (0.1030)  classification: 0.4861 (0.4781)  time: 0.3629  data: 0.1292  max mem: 3278
Epoch: [50]  [1200/3494]  eta: 0:13:53  lr: 0.0000001  loss: 0.5843 (0.5810)  bbox_regression: 0.0959 (0.1030)  classification: 0.4733 (0.4780)  time: 0.3461  data: 0.1235  max mem: 3278
Epoch: [50]  [1300/3494]  eta: 0:13:16  lr: 0.0000001  loss: 0.6117 (0.5805)  bbox_regression: 0.0912 (0.1029)  classification: 0.5030 (0.4776)  time: 0.3516  data: 0.1235  max mem: 3278
Epoch: [50]  [1400/3494]  eta: 0:12:38  lr: 0.0000001  loss: 0.5906 (0.5807)  bbox_regression: 0.0849 (0.1028)  classification: 0.4775 (0.4779)  time: 0.3352  data: 0.1089  max mem: 3278
Epoch: [50]  [1500/3494]  eta: 0:12:02  lr: 0.0000001  loss: 0.5533 (0.5810)  bbox_regression: 0.0873 (0.1027)  classification: 0.4482 (0.4783)  time: 0.3697  data: 0.1350  max mem: 3278
Epoch: [50]  [1600/3494]  eta: 0:11:25  lr: 0.0000001  loss: 0.6399 (0.5816)  bbox_regression: 0.1114 (0.1027)  classification: 0.5275 (0.4789)  time: 0.3609  data: 0.1268  max mem: 3278
Epoch: [50]  [1700/3494]  eta: 0:10:49  lr: 0.0000001  loss: 0.5964 (0.5813)  bbox_regression: 0.1004 (0.1028)  classification: 0.4992 (0.4785)  time: 0.3750  data: 0.1352  max mem: 3278
Epoch: [50]  [1800/3494]  eta: 0:10:12  lr: 0.0000001  loss: 0.5400 (0.5811)  bbox_regression: 0.0855 (0.1026)  classification: 0.4585 (0.4784)  time: 0.3653  data: 0.1266  max mem: 3278
Epoch: [50]  [1900/3494]  eta: 0:09:36  lr: 0.0000001  loss: 0.5953 (0.5816)  bbox_regression: 0.0999 (0.1027)  classification: 0.4824 (0.4789)  time: 0.3578  data: 0.1269  max mem: 3278
Epoch: [50]  [2000/3494]  eta: 0:09:00  lr: 0.0000001  loss: 0.5485 (0.5816)  bbox_regression: 0.0989 (0.1027)  classification: 0.4582 (0.4789)  time: 0.3619  data: 0.1303  max mem: 3278
Epoch: [50]  [2100/3494]  eta: 0:08:24  lr: 0.0000001  loss: 0.5826 (0.5821)  bbox_regression: 0.0963 (0.1029)  classification: 0.4863 (0.4791)  time: 0.3540  data: 0.1224  max mem: 3278
Epoch: [50]  [2200/3494]  eta: 0:07:47  lr: 0.0000001  loss: 0.5477 (0.5823)  bbox_regression: 0.0921 (0.1031)  classification: 0.4565 (0.4792)  time: 0.3468  data: 0.1229  max mem: 3278
Epoch: [50]  [2300/3494]  eta: 0:07:11  lr: 0.0000001  loss: 0.6112 (0.5829)  bbox_regression: 0.1040 (0.1032)  classification: 0.5268 (0.4797)  time: 0.3552  data: 0.1266  max mem: 3278
Epoch: [50]  [2400/3494]  eta: 0:06:35  lr: 0.0000001  loss: 0.5361 (0.5825)  bbox_regression: 0.0885 (0.1031)  classification: 0.4301 (0.4793)  time: 0.3631  data: 0.1296  max mem: 3278
Epoch: [50]  [2500/3494]  eta: 0:05:59  lr: 0.0000001  loss: 0.5554 (0.5821)  bbox_regression: 0.0886 (0.1028)  classification: 0.4614 (0.4793)  time: 0.3605  data: 0.1292  max mem: 3278
Epoch: [50]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5865 (0.5827)  bbox_regression: 0.1081 (0.1028)  classification: 0.4964 (0.4799)  time: 0.3516  data: 0.1260  max mem: 3278
Epoch: [50]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5522 (0.5827)  bbox_regression: 0.1047 (0.1027)  classification: 0.4441 (0.4799)  time: 0.3606  data: 0.1231  max mem: 3278
Epoch: [50]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5495 (0.5827)  bbox_regression: 0.0907 (0.1027)  classification: 0.4355 (0.4800)  time: 0.3683  data: 0.1328  max mem: 3278
Epoch: [50]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5249 (0.5828)  bbox_regression: 0.0974 (0.1027)  classification: 0.4419 (0.4801)  time: 0.3684  data: 0.1392  max mem: 3278
Epoch: [50]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5488 (0.5826)  bbox_regression: 0.0958 (0.1028)  classification: 0.4555 (0.4798)  time: 0.3593  data: 0.1286  max mem: 3278
Epoch: [50]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5803 (0.5822)  bbox_regression: 0.1094 (0.1029)  classification: 0.4742 (0.4793)  time: 0.3557  data: 0.1282  max mem: 3278
Epoch: [50]  [3200/3494]  eta: 0:01:45  lr: 0.0000001  loss: 0.5868 (0.5820)  bbox_regression: 0.0887 (0.1027)  classification: 0.4901 (0.4792)  time: 0.3613  data: 0.1275  max mem: 3278
Epoch: [50]  [3300/3494]  eta: 0:01:09  lr: 0.0000001  loss: 0.5928 (0.5816)  bbox_regression: 0.1050 (0.1028)  classification: 0.4609 (0.4789)  time: 0.3586  data: 0.1271  max mem: 3278
Epoch: [50]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5797 (0.5822)  bbox_regression: 0.0907 (0.1029)  classification: 0.4862 (0.4793)  time: 0.3647  data: 0.1328  max mem: 3278
Epoch: [50]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5185 (0.5823)  bbox_regression: 0.0997 (0.1030)  classification: 0.4179 (0.4793)  time: 0.3773  data: 0.1326  max mem: 3278
Epoch: [50] Total time: 0:21:10 (0.3636 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:31  model_time: 0.1577 (0.1577)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9206 (0.9206)  time: 2.1309  data: 1.9434  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1207 (0.1236)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2668  data: 0.1240  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1168 (0.1230)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6513 (0.7096)  time: 0.2382  data: 0.1069  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1145 (0.1230)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2538  data: 0.1173  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1170 (0.1234)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6163 (0.7113)  time: 0.2621  data: 0.1240  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1346 (0.1236)  loss: 0.7318 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2721  data: 0.1229  max mem: 3278
Validation: Total time: 0:01:57 (0.2689 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [51]  [   0/3494]  eta: 3:13:20  lr: 0.0000001  loss: 0.7447 (0.7447)  bbox_regression: 0.2017 (0.2017)  classification: 0.5430 (0.5430)  time: 3.3202  data: 3.0382  max mem: 3278
Epoch: [51]  [ 100/3494]  eta: 0:22:42  lr: 0.0000001  loss: 0.6098 (0.5973)  bbox_regression: 0.1028 (0.1088)  classification: 0.4989 (0.4884)  time: 0.3585  data: 0.1288  max mem: 3278
Epoch: [51]  [ 200/3494]  eta: 0:19:52  lr: 0.0000001  loss: 0.5426 (0.5917)  bbox_regression: 0.0913 (0.1055)  classification: 0.4530 (0.4862)  time: 0.3658  data: 0.1309  max mem: 3278
Epoch: [51]  [ 300/3494]  eta: 0:19:20  lr: 0.0000001  loss: 0.5198 (0.5840)  bbox_regression: 0.0852 (0.1040)  classification: 0.4383 (0.4800)  time: 0.3697  data: 0.1273  max mem: 3278
Epoch: [51]  [ 400/3494]  eta: 0:18:47  lr: 0.0000001  loss: 0.5858 (0.5820)  bbox_regression: 0.0991 (0.1031)  classification: 0.4780 (0.4789)  time: 0.3559  data: 0.1257  max mem: 3278
Epoch: [51]  [ 500/3494]  eta: 0:18:08  lr: 0.0000001  loss: 0.5992 (0.5852)  bbox_regression: 0.0956 (0.1031)  classification: 0.4934 (0.4822)  time: 0.3628  data: 0.1321  max mem: 3278
Epoch: [51]  [ 600/3494]  eta: 0:17:34  lr: 0.0000001  loss: 0.5815 (0.5808)  bbox_regression: 0.1049 (0.1019)  classification: 0.4956 (0.4789)  time: 0.3760  data: 0.1344  max mem: 3278
Epoch: [51]  [ 700/3494]  eta: 0:17:00  lr: 0.0000001  loss: 0.5952 (0.5834)  bbox_regression: 0.0998 (0.1022)  classification: 0.4893 (0.4812)  time: 0.3630  data: 0.1304  max mem: 3278
Epoch: [51]  [ 800/3494]  eta: 0:16:25  lr: 0.0000001  loss: 0.5450 (0.5838)  bbox_regression: 0.0957 (0.1020)  classification: 0.4434 (0.4818)  time: 0.3561  data: 0.1196  max mem: 3278
Epoch: [51]  [ 900/3494]  eta: 0:15:49  lr: 0.0000001  loss: 0.5871 (0.5834)  bbox_regression: 0.0881 (0.1019)  classification: 0.4973 (0.4815)  time: 0.3560  data: 0.1249  max mem: 3278
Epoch: [51]  [1000/3494]  eta: 0:15:14  lr: 0.0000001  loss: 0.5535 (0.5828)  bbox_regression: 0.0929 (0.1019)  classification: 0.4254 (0.4809)  time: 0.3721  data: 0.1286  max mem: 3278
Epoch: [51]  [1100/3494]  eta: 0:14:38  lr: 0.0000001  loss: 0.5326 (0.5819)  bbox_regression: 0.0985 (0.1021)  classification: 0.4290 (0.4798)  time: 0.3602  data: 0.1270  max mem: 3278
Epoch: [51]  [1200/3494]  eta: 0:13:59  lr: 0.0000001  loss: 0.6348 (0.5827)  bbox_regression: 0.0965 (0.1023)  classification: 0.5095 (0.4803)  time: 0.3591  data: 0.1238  max mem: 3278
Epoch: [51]  [1300/3494]  eta: 0:13:24  lr: 0.0000001  loss: 0.5271 (0.5831)  bbox_regression: 0.0939 (0.1027)  classification: 0.4318 (0.4803)  time: 0.3813  data: 0.1405  max mem: 3278
Epoch: [51]  [1400/3494]  eta: 0:12:48  lr: 0.0000001  loss: 0.5844 (0.5841)  bbox_regression: 0.1039 (0.1033)  classification: 0.4839 (0.4808)  time: 0.3746  data: 0.1276  max mem: 3278
Epoch: [51]  [1500/3494]  eta: 0:12:11  lr: 0.0000001  loss: 0.5372 (0.5840)  bbox_regression: 0.0950 (0.1035)  classification: 0.4593 (0.4805)  time: 0.3598  data: 0.1293  max mem: 3278
Epoch: [51]  [1600/3494]  eta: 0:11:34  lr: 0.0000001  loss: 0.5524 (0.5842)  bbox_regression: 0.0957 (0.1036)  classification: 0.4692 (0.4806)  time: 0.3502  data: 0.1252  max mem: 3278
Epoch: [51]  [1700/3494]  eta: 0:10:57  lr: 0.0000001  loss: 0.5792 (0.5842)  bbox_regression: 0.0904 (0.1033)  classification: 0.4984 (0.4809)  time: 0.3633  data: 0.1273  max mem: 3278
Epoch: [51]  [1800/3494]  eta: 0:10:19  lr: 0.0000001  loss: 0.5356 (0.5829)  bbox_regression: 0.0982 (0.1032)  classification: 0.4320 (0.4797)  time: 0.3605  data: 0.1285  max mem: 3278
Epoch: [51]  [1900/3494]  eta: 0:09:42  lr: 0.0000001  loss: 0.5964 (0.5818)  bbox_regression: 0.1018 (0.1031)  classification: 0.4783 (0.4787)  time: 0.3569  data: 0.1304  max mem: 3278
Epoch: [51]  [2000/3494]  eta: 0:09:05  lr: 0.0000001  loss: 0.5922 (0.5814)  bbox_regression: 0.0966 (0.1030)  classification: 0.4703 (0.4784)  time: 0.3446  data: 0.1205  max mem: 3278
Epoch: [51]  [2100/3494]  eta: 0:08:28  lr: 0.0000001  loss: 0.5429 (0.5812)  bbox_regression: 0.0871 (0.1029)  classification: 0.4425 (0.4784)  time: 0.3638  data: 0.1332  max mem: 3278
Epoch: [51]  [2200/3494]  eta: 0:07:52  lr: 0.0000001  loss: 0.5406 (0.5809)  bbox_regression: 0.0901 (0.1026)  classification: 0.4710 (0.4782)  time: 0.3521  data: 0.1254  max mem: 3278
Epoch: [51]  [2300/3494]  eta: 0:07:14  lr: 0.0000001  loss: 0.5874 (0.5807)  bbox_regression: 0.1028 (0.1026)  classification: 0.4840 (0.4781)  time: 0.3514  data: 0.1241  max mem: 3278
Epoch: [51]  [2400/3494]  eta: 0:06:38  lr: 0.0000001  loss: 0.5715 (0.5810)  bbox_regression: 0.0831 (0.1025)  classification: 0.4696 (0.4785)  time: 0.3589  data: 0.1308  max mem: 3278
Epoch: [51]  [2500/3494]  eta: 0:06:02  lr: 0.0000001  loss: 0.5270 (0.5813)  bbox_regression: 0.1039 (0.1025)  classification: 0.4565 (0.4787)  time: 0.3737  data: 0.1291  max mem: 3278
Epoch: [51]  [2600/3494]  eta: 0:05:25  lr: 0.0000001  loss: 0.5679 (0.5817)  bbox_regression: 0.0985 (0.1027)  classification: 0.4525 (0.4790)  time: 0.3607  data: 0.1300  max mem: 3278
Epoch: [51]  [2700/3494]  eta: 0:04:49  lr: 0.0000001  loss: 0.5425 (0.5816)  bbox_regression: 0.0854 (0.1027)  classification: 0.4494 (0.4789)  time: 0.3790  data: 0.1368  max mem: 3278
Epoch: [51]  [2800/3494]  eta: 0:04:12  lr: 0.0000001  loss: 0.5740 (0.5818)  bbox_regression: 0.1040 (0.1027)  classification: 0.4798 (0.4792)  time: 0.3674  data: 0.1281  max mem: 3278
Epoch: [51]  [2900/3494]  eta: 0:03:36  lr: 0.0000001  loss: 0.6257 (0.5826)  bbox_regression: 0.1058 (0.1028)  classification: 0.5166 (0.4797)  time: 0.3649  data: 0.1285  max mem: 3278
Epoch: [51]  [3000/3494]  eta: 0:02:59  lr: 0.0000001  loss: 0.5357 (0.5833)  bbox_regression: 0.1021 (0.1029)  classification: 0.4452 (0.4804)  time: 0.3567  data: 0.1283  max mem: 3278
Epoch: [51]  [3100/3494]  eta: 0:02:23  lr: 0.0000001  loss: 0.5777 (0.5834)  bbox_regression: 0.1034 (0.1030)  classification: 0.4534 (0.4804)  time: 0.3601  data: 0.1295  max mem: 3278
Epoch: [51]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5663 (0.5835)  bbox_regression: 0.0938 (0.1030)  classification: 0.4691 (0.4805)  time: 0.3560  data: 0.1260  max mem: 3278
Epoch: [51]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5903 (0.5838)  bbox_regression: 0.1012 (0.1030)  classification: 0.4967 (0.4808)  time: 0.3693  data: 0.1317  max mem: 3278
Epoch: [51]  [3400/3494]  eta: 0:00:34  lr: 0.0000001  loss: 0.5254 (0.5840)  bbox_regression: 0.0850 (0.1031)  classification: 0.4361 (0.4809)  time: 0.3583  data: 0.1317  max mem: 3278
Epoch: [51]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5537 (0.5838)  bbox_regression: 0.0987 (0.1032)  classification: 0.4503 (0.4806)  time: 0.3448  data: 0.1218  max mem: 3278
Epoch: [51] Total time: 0:21:21 (0.3667 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:56  model_time: 0.1422 (0.1422)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0522  data: 1.8774  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1210 (0.1229)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2703  data: 0.1264  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1215 (0.1238)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6513 (0.7096)  time: 0.2645  data: 0.1244  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1152 (0.1233)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2229  data: 0.0937  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1143 (0.1225)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2569  data: 0.1224  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1204 (0.1227)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2710  data: 0.1276  max mem: 3278
Validation: Total time: 0:01:57 (0.2691 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [52]  [   0/3494]  eta: 2:22:36  lr: 0.0000001  loss: 0.8565 (0.8565)  bbox_regression: 0.1831 (0.1831)  classification: 0.6734 (0.6734)  time: 2.4489  data: 2.2109  max mem: 3278
Epoch: [52]  [ 100/3494]  eta: 0:21:59  lr: 0.0000001  loss: 0.5201 (0.5861)  bbox_regression: 0.1065 (0.1065)  classification: 0.4383 (0.4796)  time: 0.3688  data: 0.1292  max mem: 3278
Epoch: [52]  [ 200/3494]  eta: 0:20:31  lr: 0.0000001  loss: 0.5367 (0.5843)  bbox_regression: 0.0859 (0.1046)  classification: 0.4520 (0.4798)  time: 0.3572  data: 0.1293  max mem: 3278
Epoch: [52]  [ 300/3494]  eta: 0:19:38  lr: 0.0000001  loss: 0.5401 (0.5827)  bbox_regression: 0.0840 (0.1040)  classification: 0.4534 (0.4787)  time: 0.3658  data: 0.1331  max mem: 3278
Epoch: [52]  [ 400/3494]  eta: 0:18:52  lr: 0.0000001  loss: 0.5246 (0.5815)  bbox_regression: 0.0978 (0.1039)  classification: 0.4278 (0.4775)  time: 0.3586  data: 0.1250  max mem: 3278
Epoch: [52]  [ 500/3494]  eta: 0:18:09  lr: 0.0000001  loss: 0.5265 (0.5799)  bbox_regression: 0.0986 (0.1029)  classification: 0.4389 (0.4770)  time: 0.3606  data: 0.1259  max mem: 3278
Epoch: [52]  [ 600/3494]  eta: 0:17:32  lr: 0.0000001  loss: 0.5604 (0.5812)  bbox_regression: 0.1010 (0.1031)  classification: 0.4459 (0.4781)  time: 0.3558  data: 0.1234  max mem: 3278
Epoch: [52]  [ 700/3494]  eta: 0:16:57  lr: 0.0000001  loss: 0.6009 (0.5831)  bbox_regression: 0.1118 (0.1038)  classification: 0.4757 (0.4793)  time: 0.3618  data: 0.1276  max mem: 3278
Epoch: [52]  [ 800/3494]  eta: 0:16:17  lr: 0.0000001  loss: 0.5144 (0.5824)  bbox_regression: 0.1001 (0.1037)  classification: 0.4160 (0.4787)  time: 0.3648  data: 0.1308  max mem: 3278
Epoch: [52]  [ 900/3494]  eta: 0:15:40  lr: 0.0000001  loss: 0.5314 (0.5819)  bbox_regression: 0.0854 (0.1033)  classification: 0.4380 (0.4786)  time: 0.3597  data: 0.1252  max mem: 3278
Epoch: [52]  [1000/3494]  eta: 0:15:04  lr: 0.0000001  loss: 0.6022 (0.5826)  bbox_regression: 0.0973 (0.1036)  classification: 0.4843 (0.4790)  time: 0.3652  data: 0.1311  max mem: 3278
Epoch: [52]  [1100/3494]  eta: 0:14:26  lr: 0.0000001  loss: 0.5677 (0.5845)  bbox_regression: 0.1035 (0.1042)  classification: 0.4660 (0.4802)  time: 0.3586  data: 0.1283  max mem: 3278
Epoch: [52]  [1200/3494]  eta: 0:13:50  lr: 0.0000001  loss: 0.5728 (0.5855)  bbox_regression: 0.0890 (0.1040)  classification: 0.4803 (0.4816)  time: 0.3580  data: 0.1272  max mem: 3278
Epoch: [52]  [1300/3494]  eta: 0:13:14  lr: 0.0000001  loss: 0.5622 (0.5851)  bbox_regression: 0.1011 (0.1036)  classification: 0.4572 (0.4814)  time: 0.3657  data: 0.1334  max mem: 3278
Epoch: [52]  [1400/3494]  eta: 0:12:37  lr: 0.0000001  loss: 0.5858 (0.5851)  bbox_regression: 0.1009 (0.1038)  classification: 0.4715 (0.4813)  time: 0.3833  data: 0.1449  max mem: 3278
Epoch: [52]  [1500/3494]  eta: 0:12:01  lr: 0.0000001  loss: 0.5384 (0.5834)  bbox_regression: 0.0960 (0.1036)  classification: 0.4483 (0.4798)  time: 0.3641  data: 0.1283  max mem: 3278
Epoch: [52]  [1600/3494]  eta: 0:11:25  lr: 0.0000001  loss: 0.5829 (0.5830)  bbox_regression: 0.1103 (0.1034)  classification: 0.4861 (0.4796)  time: 0.3550  data: 0.1273  max mem: 3278
Epoch: [52]  [1700/3494]  eta: 0:10:49  lr: 0.0000001  loss: 0.5561 (0.5833)  bbox_regression: 0.0960 (0.1034)  classification: 0.4570 (0.4800)  time: 0.3671  data: 0.1213  max mem: 3278
Epoch: [52]  [1800/3494]  eta: 0:10:14  lr: 0.0000001  loss: 0.5457 (0.5832)  bbox_regression: 0.0951 (0.1033)  classification: 0.4453 (0.4800)  time: 0.3644  data: 0.1304  max mem: 3278
Epoch: [52]  [1900/3494]  eta: 0:09:39  lr: 0.0000001  loss: 0.5908 (0.5833)  bbox_regression: 0.1033 (0.1033)  classification: 0.4867 (0.4799)  time: 0.3623  data: 0.1269  max mem: 3278
Epoch: [52]  [2000/3494]  eta: 0:09:03  lr: 0.0000001  loss: 0.5932 (0.5837)  bbox_regression: 0.1006 (0.1034)  classification: 0.4873 (0.4803)  time: 0.3412  data: 0.1084  max mem: 3278
Epoch: [52]  [2100/3494]  eta: 0:08:26  lr: 0.0000001  loss: 0.5517 (0.5836)  bbox_regression: 0.0930 (0.1034)  classification: 0.4512 (0.4802)  time: 0.3487  data: 0.1215  max mem: 3278
Epoch: [52]  [2200/3494]  eta: 0:07:50  lr: 0.0000001  loss: 0.5387 (0.5837)  bbox_regression: 0.0945 (0.1033)  classification: 0.4380 (0.4805)  time: 0.3632  data: 0.1312  max mem: 3278
Epoch: [52]  [2300/3494]  eta: 0:07:13  lr: 0.0000001  loss: 0.5527 (0.5838)  bbox_regression: 0.1057 (0.1033)  classification: 0.4301 (0.4804)  time: 0.3654  data: 0.1289  max mem: 3278
Epoch: [52]  [2400/3494]  eta: 0:06:37  lr: 0.0000001  loss: 0.5841 (0.5832)  bbox_regression: 0.0881 (0.1031)  classification: 0.4802 (0.4801)  time: 0.3587  data: 0.1297  max mem: 3278
Epoch: [52]  [2500/3494]  eta: 0:06:00  lr: 0.0000001  loss: 0.5258 (0.5842)  bbox_regression: 0.1076 (0.1032)  classification: 0.4575 (0.4810)  time: 0.3586  data: 0.1263  max mem: 3278
Epoch: [52]  [2600/3494]  eta: 0:05:24  lr: 0.0000001  loss: 0.5662 (0.5845)  bbox_regression: 0.0931 (0.1032)  classification: 0.4743 (0.4814)  time: 0.3618  data: 0.1264  max mem: 3278
Epoch: [52]  [2700/3494]  eta: 0:04:47  lr: 0.0000001  loss: 0.5996 (0.5848)  bbox_regression: 0.0959 (0.1031)  classification: 0.5049 (0.4816)  time: 0.3659  data: 0.1310  max mem: 3278
Epoch: [52]  [2800/3494]  eta: 0:04:11  lr: 0.0000001  loss: 0.5656 (0.5845)  bbox_regression: 0.0915 (0.1031)  classification: 0.4614 (0.4814)  time: 0.3601  data: 0.1314  max mem: 3278
Epoch: [52]  [2900/3494]  eta: 0:03:35  lr: 0.0000001  loss: 0.5428 (0.5846)  bbox_regression: 0.0999 (0.1032)  classification: 0.4331 (0.4814)  time: 0.3755  data: 0.1426  max mem: 3278
Epoch: [52]  [3000/3494]  eta: 0:02:59  lr: 0.0000001  loss: 0.5990 (0.5846)  bbox_regression: 0.0881 (0.1032)  classification: 0.5090 (0.4814)  time: 0.3642  data: 0.1296  max mem: 3278
Epoch: [52]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5935 (0.5843)  bbox_regression: 0.1066 (0.1033)  classification: 0.4871 (0.4810)  time: 0.3588  data: 0.1273  max mem: 3278
Epoch: [52]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5466 (0.5841)  bbox_regression: 0.0860 (0.1033)  classification: 0.4385 (0.4808)  time: 0.3357  data: 0.1147  max mem: 3278
Epoch: [52]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5496 (0.5839)  bbox_regression: 0.1019 (0.1033)  classification: 0.4388 (0.4806)  time: 0.3683  data: 0.1325  max mem: 3278
Epoch: [52]  [3400/3494]  eta: 0:00:34  lr: 0.0000001  loss: 0.6006 (0.5837)  bbox_regression: 0.0948 (0.1033)  classification: 0.4988 (0.4804)  time: 0.3768  data: 0.1372  max mem: 3278
Epoch: [52]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.5922 (0.5834)  bbox_regression: 0.0966 (0.1031)  classification: 0.4956 (0.4803)  time: 0.3534  data: 0.1284  max mem: 3278
Epoch: [52] Total time: 0:21:16 (0.3654 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:30  model_time: 0.1403 (0.1403)  loss: 1.0474 (1.0474)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8541  data: 1.6872  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1203 (0.1228)  loss: 0.7715 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6142 (0.7383)  time: 0.2641  data: 0.1240  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1156 (0.1219)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6513 (0.7096)  time: 0.2618  data: 0.1214  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1166 (0.1216)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2623  data: 0.1287  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1209 (0.1217)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6162 (0.7113)  time: 0.2659  data: 0.1239  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1207 (0.1216)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6350 (0.7121)  time: 0.2604  data: 0.1210  max mem: 3278
Validation: Total time: 0:01:56 (0.2661 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [53]  [   0/3494]  eta: 1:53:18  lr: 0.0000001  loss: 0.6035 (0.6035)  bbox_regression: 0.1037 (0.1037)  classification: 0.4999 (0.4999)  time: 1.9458  data: 1.6967  max mem: 3278
Epoch: [53]  [ 100/3494]  eta: 0:21:39  lr: 0.0000001  loss: 0.5476 (0.5731)  bbox_regression: 0.0973 (0.0994)  classification: 0.4563 (0.4737)  time: 0.3717  data: 0.1414  max mem: 3278
Epoch: [53]  [ 200/3494]  eta: 0:20:21  lr: 0.0000001  loss: 0.6010 (0.5800)  bbox_regression: 0.1044 (0.1018)  classification: 0.4826 (0.4782)  time: 0.3402  data: 0.1169  max mem: 3278
Epoch: [53]  [ 300/3494]  eta: 0:19:30  lr: 0.0000001  loss: 0.5692 (0.5822)  bbox_regression: 0.0958 (0.1026)  classification: 0.4874 (0.4796)  time: 0.3594  data: 0.1288  max mem: 3278
Epoch: [53]  [ 400/3494]  eta: 0:18:47  lr: 0.0000001  loss: 0.5459 (0.5852)  bbox_regression: 0.0869 (0.1029)  classification: 0.4577 (0.4823)  time: 0.3514  data: 0.1248  max mem: 3278
Epoch: [53]  [ 500/3494]  eta: 0:18:05  lr: 0.0000001  loss: 0.5677 (0.5856)  bbox_regression: 0.1000 (0.1029)  classification: 0.4777 (0.4827)  time: 0.3628  data: 0.1286  max mem: 3278
Epoch: [53]  [ 600/3494]  eta: 0:17:27  lr: 0.0000001  loss: 0.5458 (0.5832)  bbox_regression: 0.0943 (0.1026)  classification: 0.4576 (0.4806)  time: 0.3523  data: 0.1264  max mem: 3278
Epoch: [53]  [ 700/3494]  eta: 0:16:51  lr: 0.0000001  loss: 0.5754 (0.5845)  bbox_regression: 0.1067 (0.1026)  classification: 0.4630 (0.4818)  time: 0.3647  data: 0.1294  max mem: 3278
Epoch: [53]  [ 800/3494]  eta: 0:16:14  lr: 0.0000001  loss: 0.5863 (0.5867)  bbox_regression: 0.1051 (0.1039)  classification: 0.4689 (0.4828)  time: 0.3597  data: 0.1252  max mem: 3278
Epoch: [53]  [ 900/3494]  eta: 0:15:35  lr: 0.0000001  loss: 0.6328 (0.5884)  bbox_regression: 0.1193 (0.1040)  classification: 0.4981 (0.4844)  time: 0.3503  data: 0.1237  max mem: 3278
Epoch: [53]  [1000/3494]  eta: 0:14:58  lr: 0.0000001  loss: 0.5802 (0.5887)  bbox_regression: 0.0963 (0.1038)  classification: 0.4780 (0.4848)  time: 0.3575  data: 0.1298  max mem: 3278
Epoch: [53]  [1100/3494]  eta: 0:14:21  lr: 0.0000001  loss: 0.5656 (0.5856)  bbox_regression: 0.0990 (0.1034)  classification: 0.4656 (0.4822)  time: 0.3640  data: 0.1328  max mem: 3278
Epoch: [53]  [1200/3494]  eta: 0:13:45  lr: 0.0000001  loss: 0.5791 (0.5854)  bbox_regression: 0.0963 (0.1035)  classification: 0.4634 (0.4819)  time: 0.3661  data: 0.1276  max mem: 3278
Epoch: [53]  [1300/3494]  eta: 0:13:08  lr: 0.0000001  loss: 0.5442 (0.5861)  bbox_regression: 0.1021 (0.1035)  classification: 0.4730 (0.4826)  time: 0.3343  data: 0.1095  max mem: 3278
Epoch: [53]  [1400/3494]  eta: 0:12:33  lr: 0.0000001  loss: 0.6160 (0.5860)  bbox_regression: 0.0969 (0.1038)  classification: 0.5009 (0.4822)  time: 0.3745  data: 0.1381  max mem: 3278
Epoch: [53]  [1500/3494]  eta: 0:11:58  lr: 0.0000001  loss: 0.5426 (0.5860)  bbox_regression: 0.0934 (0.1037)  classification: 0.4493 (0.4823)  time: 0.3765  data: 0.1328  max mem: 3278
Epoch: [53]  [1600/3494]  eta: 0:11:22  lr: 0.0000001  loss: 0.5894 (0.5863)  bbox_regression: 0.1022 (0.1038)  classification: 0.4767 (0.4826)  time: 0.3672  data: 0.1355  max mem: 3278
Epoch: [53]  [1700/3494]  eta: 0:10:45  lr: 0.0000001  loss: 0.5570 (0.5869)  bbox_regression: 0.0969 (0.1038)  classification: 0.4739 (0.4830)  time: 0.3594  data: 0.1265  max mem: 3278
Epoch: [53]  [1800/3494]  eta: 0:10:09  lr: 0.0000001  loss: 0.5831 (0.5867)  bbox_regression: 0.0934 (0.1039)  classification: 0.4786 (0.4828)  time: 0.3624  data: 0.1265  max mem: 3278
Epoch: [53]  [1900/3494]  eta: 0:09:33  lr: 0.0000001  loss: 0.5783 (0.5870)  bbox_regression: 0.1013 (0.1039)  classification: 0.4774 (0.4831)  time: 0.3672  data: 0.1330  max mem: 3278
Epoch: [53]  [2000/3494]  eta: 0:08:57  lr: 0.0000001  loss: 0.5434 (0.5871)  bbox_regression: 0.0973 (0.1038)  classification: 0.4507 (0.4833)  time: 0.3671  data: 0.1306  max mem: 3278
Epoch: [53]  [2100/3494]  eta: 0:08:22  lr: 0.0000001  loss: 0.5501 (0.5863)  bbox_regression: 0.0811 (0.1036)  classification: 0.4495 (0.4828)  time: 0.3562  data: 0.1254  max mem: 3278
Epoch: [53]  [2200/3494]  eta: 0:07:46  lr: 0.0000001  loss: 0.5861 (0.5863)  bbox_regression: 0.1107 (0.1036)  classification: 0.4552 (0.4828)  time: 0.3613  data: 0.1268  max mem: 3278
Epoch: [53]  [2300/3494]  eta: 0:07:10  lr: 0.0000001  loss: 0.5558 (0.5863)  bbox_regression: 0.0953 (0.1035)  classification: 0.4607 (0.4827)  time: 0.3646  data: 0.1281  max mem: 3278
Epoch: [53]  [2400/3494]  eta: 0:06:34  lr: 0.0000001  loss: 0.5230 (0.5863)  bbox_regression: 0.0988 (0.1038)  classification: 0.4179 (0.4825)  time: 0.3598  data: 0.1272  max mem: 3278
Epoch: [53]  [2500/3494]  eta: 0:05:58  lr: 0.0000001  loss: 0.5268 (0.5855)  bbox_regression: 0.0933 (0.1037)  classification: 0.4380 (0.4818)  time: 0.3715  data: 0.1363  max mem: 3278
Epoch: [53]  [2600/3494]  eta: 0:05:22  lr: 0.0000001  loss: 0.5897 (0.5854)  bbox_regression: 0.0930 (0.1037)  classification: 0.4861 (0.4817)  time: 0.3504  data: 0.1226  max mem: 3278
Epoch: [53]  [2700/3494]  eta: 0:04:46  lr: 0.0000001  loss: 0.5462 (0.5848)  bbox_regression: 0.0866 (0.1036)  classification: 0.4273 (0.4811)  time: 0.3539  data: 0.1280  max mem: 3278
Epoch: [53]  [2800/3494]  eta: 0:04:10  lr: 0.0000001  loss: 0.5697 (0.5844)  bbox_regression: 0.0873 (0.1035)  classification: 0.4873 (0.4810)  time: 0.3696  data: 0.1403  max mem: 3278
Epoch: [53]  [2900/3494]  eta: 0:03:34  lr: 0.0000001  loss: 0.5729 (0.5846)  bbox_regression: 0.0980 (0.1036)  classification: 0.4780 (0.4810)  time: 0.3561  data: 0.1277  max mem: 3278
Epoch: [53]  [3000/3494]  eta: 0:02:58  lr: 0.0000001  loss: 0.5263 (0.5845)  bbox_regression: 0.0973 (0.1036)  classification: 0.4439 (0.4808)  time: 0.3696  data: 0.1368  max mem: 3278
Epoch: [53]  [3100/3494]  eta: 0:02:22  lr: 0.0000001  loss: 0.5633 (0.5844)  bbox_regression: 0.0870 (0.1035)  classification: 0.4552 (0.4808)  time: 0.3623  data: 0.1286  max mem: 3278
Epoch: [53]  [3200/3494]  eta: 0:01:46  lr: 0.0000001  loss: 0.5381 (0.5838)  bbox_regression: 0.0912 (0.1034)  classification: 0.4646 (0.4804)  time: 0.3524  data: 0.1231  max mem: 3278
Epoch: [53]  [3300/3494]  eta: 0:01:10  lr: 0.0000001  loss: 0.5669 (0.5837)  bbox_regression: 0.0984 (0.1034)  classification: 0.4692 (0.4804)  time: 0.3631  data: 0.1299  max mem: 3278
Epoch: [53]  [3400/3494]  eta: 0:00:33  lr: 0.0000001  loss: 0.5529 (0.5834)  bbox_regression: 0.0982 (0.1033)  classification: 0.4606 (0.4801)  time: 0.3682  data: 0.1320  max mem: 3278
Epoch: [53]  [3493/3494]  eta: 0:00:00  lr: 0.0000001  loss: 0.6096 (0.5834)  bbox_regression: 0.0976 (0.1033)  classification: 0.4730 (0.4801)  time: 0.3611  data: 0.1342  max mem: 3278
Epoch: [53] Total time: 0:21:12 (0.3642 s / it)
Epoch 00054: reducing learning rate of group 0 to 1.0000e-08.
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:17  model_time: 0.1342 (0.1342)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8245  data: 1.6373  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1236 (0.1243)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2555  data: 0.1148  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1162 (0.1244)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2842  data: 0.1444  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1155 (0.1235)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2551  data: 0.1201  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1219 (0.1234)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2724  data: 0.1279  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1200 (0.1235)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2679  data: 0.1243  max mem: 3278
Validation: Total time: 0:01:58 (0.2720 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [54]  [   0/3494]  eta: 1:49:09  lr: 0.0000000  loss: 0.4683 (0.4683)  bbox_regression: 0.0899 (0.0899)  classification: 0.3784 (0.3784)  time: 1.8746  data: 1.6392  max mem: 3278
Epoch: [54]  [ 100/3494]  eta: 0:21:38  lr: 0.0000000  loss: 0.5204 (0.5799)  bbox_regression: 0.0987 (0.1033)  classification: 0.4321 (0.4766)  time: 0.3543  data: 0.1164  max mem: 3278
Epoch: [54]  [ 200/3494]  eta: 0:20:31  lr: 0.0000000  loss: 0.5376 (0.5852)  bbox_regression: 0.0865 (0.1048)  classification: 0.4358 (0.4804)  time: 0.3639  data: 0.1303  max mem: 3278
Epoch: [54]  [ 300/3494]  eta: 0:19:55  lr: 0.0000000  loss: 0.5848 (0.5870)  bbox_regression: 0.1066 (0.1041)  classification: 0.4688 (0.4829)  time: 0.3740  data: 0.1376  max mem: 3278
Epoch: [54]  [ 400/3494]  eta: 0:19:14  lr: 0.0000000  loss: 0.5314 (0.5831)  bbox_regression: 0.0870 (0.1027)  classification: 0.4414 (0.4804)  time: 0.3569  data: 0.1162  max mem: 3278
Epoch: [54]  [ 500/3494]  eta: 0:18:35  lr: 0.0000000  loss: 0.6061 (0.5816)  bbox_regression: 0.1026 (0.1022)  classification: 0.5018 (0.4795)  time: 0.3638  data: 0.1311  max mem: 3278
Epoch: [54]  [ 600/3494]  eta: 0:17:52  lr: 0.0000000  loss: 0.5526 (0.5810)  bbox_regression: 0.0997 (0.1023)  classification: 0.4651 (0.4787)  time: 0.3542  data: 0.1242  max mem: 3278
Epoch: [54]  [ 700/3494]  eta: 0:17:11  lr: 0.0000000  loss: 0.5644 (0.5809)  bbox_regression: 0.1055 (0.1025)  classification: 0.4483 (0.4784)  time: 0.3731  data: 0.1346  max mem: 3278
Epoch: [54]  [ 800/3494]  eta: 0:16:33  lr: 0.0000000  loss: 0.5495 (0.5830)  bbox_regression: 0.1034 (0.1031)  classification: 0.4364 (0.4799)  time: 0.3659  data: 0.1328  max mem: 3278
Epoch: [54]  [ 900/3494]  eta: 0:15:58  lr: 0.0000000  loss: 0.5473 (0.5826)  bbox_regression: 0.0909 (0.1028)  classification: 0.4500 (0.4799)  time: 0.3662  data: 0.1273  max mem: 3278
Epoch: [54]  [1000/3494]  eta: 0:15:20  lr: 0.0000000  loss: 0.5607 (0.5835)  bbox_regression: 0.1034 (0.1029)  classification: 0.4524 (0.4806)  time: 0.3542  data: 0.1255  max mem: 3278
Epoch: [54]  [1100/3494]  eta: 0:14:41  lr: 0.0000000  loss: 0.5331 (0.5834)  bbox_regression: 0.0895 (0.1027)  classification: 0.4353 (0.4807)  time: 0.3517  data: 0.1270  max mem: 3278
Epoch: [54]  [1200/3494]  eta: 0:14:03  lr: 0.0000000  loss: 0.5916 (0.5835)  bbox_regression: 0.1042 (0.1029)  classification: 0.4389 (0.4805)  time: 0.3746  data: 0.1409  max mem: 3278
Epoch: [54]  [1300/3494]  eta: 0:13:25  lr: 0.0000000  loss: 0.5265 (0.5820)  bbox_regression: 0.0912 (0.1026)  classification: 0.4350 (0.4794)  time: 0.3664  data: 0.1256  max mem: 3278
Epoch: [54]  [1400/3494]  eta: 0:12:48  lr: 0.0000000  loss: 0.5787 (0.5818)  bbox_regression: 0.1022 (0.1026)  classification: 0.4616 (0.4792)  time: 0.3662  data: 0.1294  max mem: 3278
Epoch: [54]  [1500/3494]  eta: 0:12:11  lr: 0.0000000  loss: 0.5373 (0.5812)  bbox_regression: 0.0895 (0.1028)  classification: 0.4400 (0.4784)  time: 0.3613  data: 0.1282  max mem: 3278
Epoch: [54]  [1600/3494]  eta: 0:11:34  lr: 0.0000000  loss: 0.5334 (0.5811)  bbox_regression: 0.0909 (0.1029)  classification: 0.4223 (0.4782)  time: 0.3637  data: 0.1283  max mem: 3278
Epoch: [54]  [1700/3494]  eta: 0:10:57  lr: 0.0000000  loss: 0.5507 (0.5814)  bbox_regression: 0.0927 (0.1029)  classification: 0.4556 (0.4785)  time: 0.3585  data: 0.1244  max mem: 3278
Epoch: [54]  [1800/3494]  eta: 0:10:20  lr: 0.0000000  loss: 0.5607 (0.5816)  bbox_regression: 0.0893 (0.1030)  classification: 0.4570 (0.4786)  time: 0.3586  data: 0.1280  max mem: 3278
Epoch: [54]  [1900/3494]  eta: 0:09:43  lr: 0.0000000  loss: 0.5528 (0.5816)  bbox_regression: 0.0929 (0.1030)  classification: 0.4548 (0.4786)  time: 0.3714  data: 0.1332  max mem: 3278
Epoch: [54]  [2000/3494]  eta: 0:09:07  lr: 0.0000000  loss: 0.5795 (0.5818)  bbox_regression: 0.1004 (0.1030)  classification: 0.4829 (0.4788)  time: 0.3643  data: 0.1298  max mem: 3278
Epoch: [54]  [2100/3494]  eta: 0:08:30  lr: 0.0000000  loss: 0.5651 (0.5820)  bbox_regression: 0.0970 (0.1031)  classification: 0.4666 (0.4789)  time: 0.3764  data: 0.1319  max mem: 3278
Epoch: [54]  [2200/3494]  eta: 0:07:53  lr: 0.0000000  loss: 0.5772 (0.5814)  bbox_regression: 0.0997 (0.1030)  classification: 0.4688 (0.4784)  time: 0.3635  data: 0.1298  max mem: 3278
Epoch: [54]  [2300/3494]  eta: 0:07:16  lr: 0.0000000  loss: 0.5964 (0.5829)  bbox_regression: 0.1167 (0.1032)  classification: 0.4873 (0.4797)  time: 0.3666  data: 0.1296  max mem: 3278
Epoch: [54]  [2400/3494]  eta: 0:06:40  lr: 0.0000000  loss: 0.5591 (0.5821)  bbox_regression: 0.0953 (0.1029)  classification: 0.4504 (0.4791)  time: 0.3469  data: 0.1170  max mem: 3278
Epoch: [54]  [2500/3494]  eta: 0:06:03  lr: 0.0000000  loss: 0.5448 (0.5826)  bbox_regression: 0.0853 (0.1029)  classification: 0.4741 (0.4798)  time: 0.3558  data: 0.1228  max mem: 3278
Epoch: [54]  [2600/3494]  eta: 0:05:26  lr: 0.0000000  loss: 0.5244 (0.5826)  bbox_regression: 0.0973 (0.1028)  classification: 0.4153 (0.4798)  time: 0.3614  data: 0.1291  max mem: 3278
Epoch: [54]  [2700/3494]  eta: 0:04:50  lr: 0.0000000  loss: 0.5895 (0.5832)  bbox_regression: 0.0932 (0.1029)  classification: 0.4910 (0.4803)  time: 0.3588  data: 0.1277  max mem: 3278
Epoch: [54]  [2800/3494]  eta: 0:04:13  lr: 0.0000000  loss: 0.5815 (0.5829)  bbox_regression: 0.1052 (0.1028)  classification: 0.4826 (0.4800)  time: 0.3650  data: 0.1276  max mem: 3278
Epoch: [54]  [2900/3494]  eta: 0:03:37  lr: 0.0000000  loss: 0.5226 (0.5828)  bbox_regression: 0.0974 (0.1028)  classification: 0.4204 (0.4800)  time: 0.3702  data: 0.1313  max mem: 3278
Epoch: [54]  [3000/3494]  eta: 0:03:00  lr: 0.0000000  loss: 0.5363 (0.5827)  bbox_regression: 0.0929 (0.1028)  classification: 0.4312 (0.4798)  time: 0.3568  data: 0.1282  max mem: 3278
Epoch: [54]  [3100/3494]  eta: 0:02:23  lr: 0.0000000  loss: 0.5536 (0.5824)  bbox_regression: 0.0942 (0.1029)  classification: 0.4504 (0.4795)  time: 0.3466  data: 0.1151  max mem: 3278
Epoch: [54]  [3200/3494]  eta: 0:01:47  lr: 0.0000000  loss: 0.5476 (0.5818)  bbox_regression: 0.0997 (0.1028)  classification: 0.4636 (0.4791)  time: 0.3763  data: 0.1376  max mem: 3278
Epoch: [54]  [3300/3494]  eta: 0:01:10  lr: 0.0000000  loss: 0.5258 (0.5814)  bbox_regression: 0.0879 (0.1027)  classification: 0.4318 (0.4787)  time: 0.3705  data: 0.1359  max mem: 3278
Epoch: [54]  [3400/3494]  eta: 0:00:34  lr: 0.0000000  loss: 0.5655 (0.5821)  bbox_regression: 0.0936 (0.1028)  classification: 0.4817 (0.4793)  time: 0.3697  data: 0.1323  max mem: 3278
Epoch: [54]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5484 (0.5820)  bbox_regression: 0.0889 (0.1028)  classification: 0.4519 (0.4792)  time: 0.3620  data: 0.1342  max mem: 3278
Epoch: [54] Total time: 0:21:27 (0.3685 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:34  model_time: 0.1458 (0.1458)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0020  data: 1.8285  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1292 (0.1274)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2900  data: 0.1429  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1167 (0.1269)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2707  data: 0.1310  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1244 (0.1273)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2687  data: 0.1242  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1193 (0.1270)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2679  data: 0.1282  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1184 (0.1268)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2582  data: 0.1203  max mem: 3278
Validation: Total time: 0:02:01 (0.2771 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [55]  [   0/3494]  eta: 2:45:56  lr: 0.0000000  loss: 0.4582 (0.4582)  bbox_regression: 0.0996 (0.0996)  classification: 0.3586 (0.3586)  time: 2.8497  data: 2.6065  max mem: 3278
Epoch: [55]  [ 100/3494]  eta: 0:22:23  lr: 0.0000000  loss: 0.5638 (0.5769)  bbox_regression: 0.0952 (0.1042)  classification: 0.4571 (0.4727)  time: 0.3811  data: 0.1361  max mem: 3278
Epoch: [55]  [ 200/3494]  eta: 0:21:01  lr: 0.0000000  loss: 0.5907 (0.5896)  bbox_regression: 0.1083 (0.1059)  classification: 0.4656 (0.4837)  time: 0.3776  data: 0.1396  max mem: 3278
Epoch: [55]  [ 300/3494]  eta: 0:20:18  lr: 0.0000000  loss: 0.5637 (0.5824)  bbox_regression: 0.0951 (0.1040)  classification: 0.4716 (0.4784)  time: 0.3978  data: 0.1395  max mem: 3278
Epoch: [55]  [ 400/3494]  eta: 0:19:27  lr: 0.0000000  loss: 0.5827 (0.5830)  bbox_regression: 0.0978 (0.1043)  classification: 0.4590 (0.4787)  time: 0.3680  data: 0.1353  max mem: 3278
Epoch: [55]  [ 500/3494]  eta: 0:18:49  lr: 0.0000000  loss: 0.5863 (0.5838)  bbox_regression: 0.0949 (0.1041)  classification: 0.4921 (0.4797)  time: 0.3755  data: 0.1339  max mem: 3278
Epoch: [55]  [ 600/3494]  eta: 0:18:08  lr: 0.0000000  loss: 0.5343 (0.5826)  bbox_regression: 0.0986 (0.1039)  classification: 0.4402 (0.4787)  time: 0.3571  data: 0.1260  max mem: 3278
Epoch: [55]  [ 700/3494]  eta: 0:17:29  lr: 0.0000000  loss: 0.5499 (0.5843)  bbox_regression: 0.0846 (0.1038)  classification: 0.4541 (0.4805)  time: 0.3770  data: 0.1369  max mem: 3278
Epoch: [55]  [ 800/3494]  eta: 0:16:48  lr: 0.0000000  loss: 0.5763 (0.5843)  bbox_regression: 0.0991 (0.1037)  classification: 0.4862 (0.4807)  time: 0.3675  data: 0.1278  max mem: 3278
Epoch: [55]  [ 900/3494]  eta: 0:16:10  lr: 0.0000000  loss: 0.5796 (0.5865)  bbox_regression: 0.1045 (0.1041)  classification: 0.4629 (0.4824)  time: 0.3688  data: 0.1364  max mem: 3278
Epoch: [55]  [1000/3494]  eta: 0:15:30  lr: 0.0000000  loss: 0.5622 (0.5853)  bbox_regression: 0.0916 (0.1035)  classification: 0.4679 (0.4818)  time: 0.3614  data: 0.1282  max mem: 3278
Epoch: [55]  [1100/3494]  eta: 0:14:53  lr: 0.0000000  loss: 0.4930 (0.5842)  bbox_regression: 0.0848 (0.1033)  classification: 0.4253 (0.4809)  time: 0.3589  data: 0.1287  max mem: 3278
Epoch: [55]  [1200/3494]  eta: 0:14:14  lr: 0.0000000  loss: 0.5819 (0.5843)  bbox_regression: 0.1105 (0.1032)  classification: 0.4745 (0.4810)  time: 0.3559  data: 0.1278  max mem: 3278
Epoch: [55]  [1300/3494]  eta: 0:13:37  lr: 0.0000000  loss: 0.5483 (0.5857)  bbox_regression: 0.0868 (0.1032)  classification: 0.4656 (0.4825)  time: 0.3798  data: 0.1376  max mem: 3278
Epoch: [55]  [1400/3494]  eta: 0:13:00  lr: 0.0000000  loss: 0.5223 (0.5846)  bbox_regression: 0.1027 (0.1031)  classification: 0.4243 (0.4814)  time: 0.3799  data: 0.1343  max mem: 3278
Epoch: [55]  [1500/3494]  eta: 0:12:23  lr: 0.0000000  loss: 0.5152 (0.5846)  bbox_regression: 0.0880 (0.1029)  classification: 0.4239 (0.4817)  time: 0.3632  data: 0.1303  max mem: 3278
Epoch: [55]  [1600/3494]  eta: 0:11:46  lr: 0.0000000  loss: 0.5609 (0.5839)  bbox_regression: 0.0921 (0.1027)  classification: 0.4472 (0.4812)  time: 0.3887  data: 0.1489  max mem: 3278
Epoch: [55]  [1700/3494]  eta: 0:11:09  lr: 0.0000000  loss: 0.5411 (0.5836)  bbox_regression: 0.1028 (0.1028)  classification: 0.4507 (0.4809)  time: 0.3703  data: 0.1339  max mem: 3278
Epoch: [55]  [1800/3494]  eta: 0:10:31  lr: 0.0000000  loss: 0.4959 (0.5827)  bbox_regression: 0.0898 (0.1026)  classification: 0.4174 (0.4802)  time: 0.3799  data: 0.1353  max mem: 3278
Epoch: [55]  [1900/3494]  eta: 0:09:54  lr: 0.0000000  loss: 0.5130 (0.5828)  bbox_regression: 0.0911 (0.1025)  classification: 0.4246 (0.4802)  time: 0.3598  data: 0.1253  max mem: 3278
Epoch: [55]  [2000/3494]  eta: 0:09:16  lr: 0.0000000  loss: 0.6078 (0.5828)  bbox_regression: 0.1014 (0.1025)  classification: 0.5039 (0.4802)  time: 0.3651  data: 0.1297  max mem: 3278
Epoch: [55]  [2100/3494]  eta: 0:08:39  lr: 0.0000000  loss: 0.5894 (0.5833)  bbox_regression: 0.1062 (0.1027)  classification: 0.4586 (0.4807)  time: 0.3611  data: 0.1284  max mem: 3278
Epoch: [55]  [2200/3494]  eta: 0:08:02  lr: 0.0000000  loss: 0.5532 (0.5834)  bbox_regression: 0.0960 (0.1029)  classification: 0.4530 (0.4805)  time: 0.3675  data: 0.1278  max mem: 3278
Epoch: [55]  [2300/3494]  eta: 0:07:24  lr: 0.0000000  loss: 0.5165 (0.5829)  bbox_regression: 0.0875 (0.1029)  classification: 0.4277 (0.4801)  time: 0.3550  data: 0.1167  max mem: 3278
Epoch: [55]  [2400/3494]  eta: 0:06:47  lr: 0.0000000  loss: 0.5224 (0.5821)  bbox_regression: 0.0955 (0.1028)  classification: 0.4207 (0.4793)  time: 0.3615  data: 0.1295  max mem: 3278
Epoch: [55]  [2500/3494]  eta: 0:06:09  lr: 0.0000000  loss: 0.5731 (0.5828)  bbox_regression: 0.1026 (0.1029)  classification: 0.4698 (0.4799)  time: 0.3597  data: 0.1277  max mem: 3278
Epoch: [55]  [2600/3494]  eta: 0:05:32  lr: 0.0000000  loss: 0.6002 (0.5834)  bbox_regression: 0.1052 (0.1031)  classification: 0.4898 (0.4803)  time: 0.3728  data: 0.1371  max mem: 3278
Epoch: [55]  [2700/3494]  eta: 0:04:55  lr: 0.0000000  loss: 0.5680 (0.5831)  bbox_regression: 0.1008 (0.1030)  classification: 0.4534 (0.4801)  time: 0.3702  data: 0.1307  max mem: 3278
Epoch: [55]  [2800/3494]  eta: 0:04:17  lr: 0.0000000  loss: 0.6179 (0.5828)  bbox_regression: 0.1170 (0.1030)  classification: 0.4900 (0.4798)  time: 0.3659  data: 0.1313  max mem: 3278
Epoch: [55]  [2900/3494]  eta: 0:03:40  lr: 0.0000000  loss: 0.5627 (0.5825)  bbox_regression: 0.1008 (0.1030)  classification: 0.4726 (0.4795)  time: 0.3611  data: 0.1267  max mem: 3278
Epoch: [55]  [3000/3494]  eta: 0:03:03  lr: 0.0000000  loss: 0.6034 (0.5826)  bbox_regression: 0.0950 (0.1029)  classification: 0.5071 (0.4797)  time: 0.3734  data: 0.1301  max mem: 3278
Epoch: [55]  [3100/3494]  eta: 0:02:26  lr: 0.0000000  loss: 0.5238 (0.5820)  bbox_regression: 0.0928 (0.1029)  classification: 0.4283 (0.4792)  time: 0.3718  data: 0.1406  max mem: 3278
Epoch: [55]  [3200/3494]  eta: 0:01:48  lr: 0.0000000  loss: 0.5116 (0.5821)  bbox_regression: 0.0928 (0.1029)  classification: 0.4256 (0.4792)  time: 0.3749  data: 0.1355  max mem: 3278
Epoch: [55]  [3300/3494]  eta: 0:01:11  lr: 0.0000000  loss: 0.5947 (0.5828)  bbox_regression: 0.1006 (0.1031)  classification: 0.4958 (0.4797)  time: 0.3824  data: 0.1351  max mem: 3278
Epoch: [55]  [3400/3494]  eta: 0:00:34  lr: 0.0000000  loss: 0.5894 (0.5830)  bbox_regression: 0.1136 (0.1032)  classification: 0.4951 (0.4799)  time: 0.3682  data: 0.1286  max mem: 3278
Epoch: [55]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.6262 (0.5835)  bbox_regression: 0.0975 (0.1032)  classification: 0.5038 (0.4803)  time: 0.4051  data: 0.1536  max mem: 3278
Epoch: [55] Total time: 0:21:46 (0.3739 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:30:37  model_time: 0.1335 (0.1335)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 4.2053  data: 4.0373  max mem: 3278
Validation:  [100/437]  eta: 0:01:43  model_time: 0.1244 (0.1257)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2580  data: 0.1131  max mem: 3278
Validation:  [200/437]  eta: 0:01:09  model_time: 0.1252 (0.1274)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2758  data: 0.1282  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1249 (0.1281)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2790  data: 0.1311  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1291 (0.1279)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2777  data: 0.1275  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1249 (0.1276)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2631  data: 0.1229  max mem: 3278
Validation: Total time: 0:02:03 (0.2836 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [56]  [   0/3494]  eta: 2:04:19  lr: 0.0000000  loss: 0.8378 (0.8378)  bbox_regression: 0.1698 (0.1698)  classification: 0.6680 (0.6680)  time: 2.1351  data: 1.8801  max mem: 3278
Epoch: [56]  [ 100/3494]  eta: 0:22:20  lr: 0.0000000  loss: 0.5404 (0.5807)  bbox_regression: 0.0867 (0.1019)  classification: 0.4481 (0.4788)  time: 0.3681  data: 0.1331  max mem: 3278
Epoch: [56]  [ 200/3494]  eta: 0:20:34  lr: 0.0000000  loss: 0.5904 (0.5803)  bbox_regression: 0.1036 (0.1016)  classification: 0.4596 (0.4788)  time: 0.3696  data: 0.1307  max mem: 3278
Epoch: [56]  [ 300/3494]  eta: 0:19:55  lr: 0.0000000  loss: 0.5738 (0.5811)  bbox_regression: 0.0990 (0.1030)  classification: 0.4795 (0.4781)  time: 0.3642  data: 0.1291  max mem: 3278
Epoch: [56]  [ 400/3494]  eta: 0:19:16  lr: 0.0000000  loss: 0.5525 (0.5781)  bbox_regression: 0.0897 (0.1020)  classification: 0.4567 (0.4760)  time: 0.3585  data: 0.1284  max mem: 3278
Epoch: [56]  [ 500/3494]  eta: 0:18:37  lr: 0.0000000  loss: 0.5373 (0.5785)  bbox_regression: 0.0962 (0.1021)  classification: 0.4545 (0.4763)  time: 0.3786  data: 0.1357  max mem: 3278
Epoch: [56]  [ 600/3494]  eta: 0:17:57  lr: 0.0000000  loss: 0.5398 (0.5811)  bbox_regression: 0.0947 (0.1028)  classification: 0.4403 (0.4783)  time: 0.3671  data: 0.1287  max mem: 3278
Epoch: [56]  [ 700/3494]  eta: 0:17:19  lr: 0.0000000  loss: 0.5061 (0.5809)  bbox_regression: 0.0959 (0.1025)  classification: 0.4380 (0.4784)  time: 0.3713  data: 0.1265  max mem: 3278
Epoch: [56]  [ 800/3494]  eta: 0:16:42  lr: 0.0000000  loss: 0.5290 (0.5819)  bbox_regression: 0.0949 (0.1027)  classification: 0.4455 (0.4791)  time: 0.3535  data: 0.1228  max mem: 3278
Epoch: [56]  [ 900/3494]  eta: 0:16:02  lr: 0.0000000  loss: 0.6335 (0.5862)  bbox_regression: 0.1068 (0.1033)  classification: 0.5192 (0.4829)  time: 0.3624  data: 0.1236  max mem: 3278
Epoch: [56]  [1000/3494]  eta: 0:15:13  lr: 0.0000000  loss: 0.5799 (0.5846)  bbox_regression: 0.0961 (0.1030)  classification: 0.4843 (0.4815)  time: 0.3715  data: 0.1312  max mem: 3278
Epoch: [56]  [1100/3494]  eta: 0:14:38  lr: 0.0000000  loss: 0.5670 (0.5833)  bbox_regression: 0.1028 (0.1033)  classification: 0.4576 (0.4800)  time: 0.3759  data: 0.1312  max mem: 3278
Epoch: [56]  [1200/3494]  eta: 0:14:02  lr: 0.0000000  loss: 0.6181 (0.5825)  bbox_regression: 0.1162 (0.1032)  classification: 0.4931 (0.4793)  time: 0.3918  data: 0.1484  max mem: 3278
Epoch: [56]  [1300/3494]  eta: 0:13:25  lr: 0.0000000  loss: 0.5874 (0.5824)  bbox_regression: 0.1006 (0.1031)  classification: 0.4823 (0.4794)  time: 0.3716  data: 0.1374  max mem: 3278
Epoch: [56]  [1400/3494]  eta: 0:12:49  lr: 0.0000000  loss: 0.5792 (0.5828)  bbox_regression: 0.0981 (0.1033)  classification: 0.4574 (0.4795)  time: 0.3726  data: 0.1343  max mem: 3278
Epoch: [56]  [1500/3494]  eta: 0:12:13  lr: 0.0000000  loss: 0.5153 (0.5831)  bbox_regression: 0.0987 (0.1036)  classification: 0.4072 (0.4795)  time: 0.3761  data: 0.1307  max mem: 3278
Epoch: [56]  [1600/3494]  eta: 0:11:38  lr: 0.0000000  loss: 0.5720 (0.5833)  bbox_regression: 0.0904 (0.1032)  classification: 0.4799 (0.4801)  time: 0.3799  data: 0.1393  max mem: 3278
Epoch: [56]  [1700/3494]  eta: 0:11:01  lr: 0.0000000  loss: 0.6224 (0.5834)  bbox_regression: 0.1072 (0.1034)  classification: 0.5162 (0.4800)  time: 0.3702  data: 0.1335  max mem: 3278
Epoch: [56]  [1800/3494]  eta: 0:10:24  lr: 0.0000000  loss: 0.5360 (0.5825)  bbox_regression: 0.0922 (0.1032)  classification: 0.4325 (0.4793)  time: 0.3562  data: 0.1299  max mem: 3278
Epoch: [56]  [1900/3494]  eta: 0:09:47  lr: 0.0000000  loss: 0.5997 (0.5832)  bbox_regression: 0.1002 (0.1033)  classification: 0.4838 (0.4799)  time: 0.3692  data: 0.1250  max mem: 3278
Epoch: [56]  [2000/3494]  eta: 0:09:11  lr: 0.0000000  loss: 0.5856 (0.5834)  bbox_regression: 0.1031 (0.1035)  classification: 0.4825 (0.4799)  time: 0.3855  data: 0.1308  max mem: 3278
Epoch: [56]  [2100/3494]  eta: 0:08:36  lr: 0.0000000  loss: 0.5351 (0.5821)  bbox_regression: 0.0929 (0.1031)  classification: 0.4519 (0.4790)  time: 0.3732  data: 0.1349  max mem: 3278
Epoch: [56]  [2200/3494]  eta: 0:07:59  lr: 0.0000000  loss: 0.5394 (0.5827)  bbox_regression: 0.0968 (0.1033)  classification: 0.4466 (0.4793)  time: 0.3829  data: 0.1327  max mem: 3278
Epoch: [56]  [2300/3494]  eta: 0:07:23  lr: 0.0000000  loss: 0.5440 (0.5822)  bbox_regression: 0.0946 (0.1033)  classification: 0.4466 (0.4788)  time: 0.3894  data: 0.1307  max mem: 3278
Epoch: [56]  [2400/3494]  eta: 0:06:46  lr: 0.0000000  loss: 0.5493 (0.5823)  bbox_regression: 0.0867 (0.1034)  classification: 0.4523 (0.4789)  time: 0.4001  data: 0.1415  max mem: 3278
Epoch: [56]  [2500/3494]  eta: 0:06:10  lr: 0.0000000  loss: 0.5497 (0.5825)  bbox_regression: 0.0911 (0.1035)  classification: 0.4649 (0.4790)  time: 0.3789  data: 0.1386  max mem: 3278
Epoch: [56]  [2600/3494]  eta: 0:05:32  lr: 0.0000000  loss: 0.5364 (0.5829)  bbox_regression: 0.0925 (0.1036)  classification: 0.4451 (0.4793)  time: 0.3282  data: 0.0985  max mem: 3278
Epoch: [56]  [2700/3494]  eta: 0:04:55  lr: 0.0000000  loss: 0.5835 (0.5828)  bbox_regression: 0.0900 (0.1035)  classification: 0.4897 (0.4793)  time: 0.3782  data: 0.1310  max mem: 3278
Epoch: [56]  [2800/3494]  eta: 0:04:18  lr: 0.0000000  loss: 0.5628 (0.5828)  bbox_regression: 0.0943 (0.1034)  classification: 0.4649 (0.4794)  time: 0.3874  data: 0.1349  max mem: 3278
Epoch: [56]  [2900/3494]  eta: 0:03:41  lr: 0.0000000  loss: 0.5680 (0.5833)  bbox_regression: 0.0987 (0.1034)  classification: 0.4578 (0.4799)  time: 0.3724  data: 0.1318  max mem: 3278
Epoch: [56]  [3000/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5197 (0.5836)  bbox_regression: 0.0926 (0.1034)  classification: 0.4244 (0.4801)  time: 0.3711  data: 0.1314  max mem: 3278
Epoch: [56]  [3100/3494]  eta: 0:02:26  lr: 0.0000000  loss: 0.5298 (0.5831)  bbox_regression: 0.0927 (0.1034)  classification: 0.4354 (0.4798)  time: 0.3537  data: 0.1234  max mem: 3278
Epoch: [56]  [3200/3494]  eta: 0:01:49  lr: 0.0000000  loss: 0.5633 (0.5831)  bbox_regression: 0.0938 (0.1034)  classification: 0.4673 (0.4797)  time: 0.3738  data: 0.1332  max mem: 3278
Epoch: [56]  [3300/3494]  eta: 0:01:12  lr: 0.0000000  loss: 0.5560 (0.5826)  bbox_regression: 0.0938 (0.1033)  classification: 0.4560 (0.4794)  time: 0.3516  data: 0.1156  max mem: 3278
Epoch: [56]  [3400/3494]  eta: 0:00:34  lr: 0.0000000  loss: 0.5311 (0.5833)  bbox_regression: 0.0869 (0.1033)  classification: 0.4468 (0.4799)  time: 0.3690  data: 0.1257  max mem: 3278
Epoch: [56]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5167 (0.5827)  bbox_regression: 0.0861 (0.1032)  classification: 0.4413 (0.4795)  time: 0.4119  data: 0.1594  max mem: 3278
Epoch: [56] Total time: 0:21:53 (0.3759 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:39:19  model_time: 0.1843 (0.1843)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 5.4001  data: 5.1285  max mem: 3278
Validation:  [100/437]  eta: 0:01:49  model_time: 0.1383 (0.1353)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2856  data: 0.1260  max mem: 3278
Validation:  [200/437]  eta: 0:01:11  model_time: 0.1285 (0.1334)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2781  data: 0.1248  max mem: 3278
Validation:  [300/437]  eta: 0:00:40  model_time: 0.1529 (0.1349)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3095  data: 0.1270  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1355 (0.1356)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2800  data: 0.1258  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1333 (0.1354)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2645  data: 0.1164  max mem: 3278
Validation: Total time: 0:02:07 (0.2927 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [57]  [   0/3494]  eta: 2:25:30  lr: 0.0000000  loss: 0.5966 (0.5966)  bbox_regression: 0.1008 (0.1008)  classification: 0.4959 (0.4959)  time: 2.4987  data: 2.1098  max mem: 3278
Epoch: [57]  [ 100/3494]  eta: 0:23:01  lr: 0.0000000  loss: 0.5806 (0.5803)  bbox_regression: 0.0957 (0.1031)  classification: 0.4606 (0.4772)  time: 0.3905  data: 0.1288  max mem: 3278
Epoch: [57]  [ 200/3494]  eta: 0:21:46  lr: 0.0000000  loss: 0.5547 (0.5789)  bbox_regression: 0.0958 (0.1038)  classification: 0.4647 (0.4751)  time: 0.4208  data: 0.1229  max mem: 3278
Epoch: [57]  [ 300/3494]  eta: 0:20:40  lr: 0.0000000  loss: 0.5768 (0.5874)  bbox_regression: 0.0936 (0.1056)  classification: 0.4793 (0.4818)  time: 0.3754  data: 0.1330  max mem: 3278
Epoch: [57]  [ 400/3494]  eta: 0:19:44  lr: 0.0000000  loss: 0.4931 (0.5843)  bbox_regression: 0.0863 (0.1042)  classification: 0.4097 (0.4800)  time: 0.3572  data: 0.1260  max mem: 3278
Epoch: [57]  [ 500/3494]  eta: 0:19:07  lr: 0.0000000  loss: 0.5713 (0.5840)  bbox_regression: 0.0861 (0.1034)  classification: 0.4744 (0.4807)  time: 0.3974  data: 0.1422  max mem: 3278
Epoch: [57]  [ 600/3494]  eta: 0:18:27  lr: 0.0000000  loss: 0.5798 (0.5825)  bbox_regression: 0.1005 (0.1030)  classification: 0.4762 (0.4796)  time: 0.3929  data: 0.1406  max mem: 3278
Epoch: [57]  [ 700/3494]  eta: 0:17:45  lr: 0.0000000  loss: 0.5448 (0.5825)  bbox_regression: 0.0931 (0.1028)  classification: 0.4550 (0.4797)  time: 0.3591  data: 0.1234  max mem: 3278
Epoch: [57]  [ 800/3494]  eta: 0:17:11  lr: 0.0000000  loss: 0.5585 (0.5814)  bbox_regression: 0.0932 (0.1028)  classification: 0.4722 (0.4786)  time: 0.3924  data: 0.1419  max mem: 3278
Epoch: [57]  [ 900/3494]  eta: 0:16:35  lr: 0.0000000  loss: 0.5565 (0.5824)  bbox_regression: 0.1029 (0.1034)  classification: 0.4390 (0.4790)  time: 0.4071  data: 0.1330  max mem: 3278
Epoch: [57]  [1000/3494]  eta: 0:15:59  lr: 0.0000000  loss: 0.5430 (0.5817)  bbox_regression: 0.0917 (0.1031)  classification: 0.4476 (0.4786)  time: 0.4511  data: 0.1475  max mem: 3278
Epoch: [57]  [1100/3494]  eta: 0:15:17  lr: 0.0000000  loss: 0.5679 (0.5822)  bbox_regression: 0.0994 (0.1028)  classification: 0.4443 (0.4794)  time: 0.3537  data: 0.1185  max mem: 3278
Epoch: [57]  [1200/3494]  eta: 0:14:35  lr: 0.0000000  loss: 0.5366 (0.5828)  bbox_regression: 0.0957 (0.1027)  classification: 0.4484 (0.4801)  time: 0.3722  data: 0.1321  max mem: 3278
Epoch: [57]  [1300/3494]  eta: 0:13:56  lr: 0.0000000  loss: 0.5578 (0.5822)  bbox_regression: 0.1002 (0.1027)  classification: 0.4465 (0.4795)  time: 0.3795  data: 0.1344  max mem: 3278
Epoch: [57]  [1400/3494]  eta: 0:13:18  lr: 0.0000000  loss: 0.5672 (0.5834)  bbox_regression: 0.0923 (0.1027)  classification: 0.4736 (0.4807)  time: 0.4084  data: 0.1535  max mem: 3278
Epoch: [57]  [1500/3494]  eta: 0:12:40  lr: 0.0000000  loss: 0.5644 (0.5831)  bbox_regression: 0.0964 (0.1027)  classification: 0.4510 (0.4805)  time: 0.3872  data: 0.1288  max mem: 3278
Epoch: [57]  [1600/3494]  eta: 0:12:03  lr: 0.0000000  loss: 0.5351 (0.5829)  bbox_regression: 0.0993 (0.1028)  classification: 0.4358 (0.4802)  time: 0.4050  data: 0.1286  max mem: 3278
Epoch: [57]  [1700/3494]  eta: 0:11:26  lr: 0.0000000  loss: 0.5659 (0.5825)  bbox_regression: 0.0971 (0.1027)  classification: 0.4506 (0.4798)  time: 0.3951  data: 0.1373  max mem: 3278
Epoch: [57]  [1800/3494]  eta: 0:10:48  lr: 0.0000000  loss: 0.5578 (0.5835)  bbox_regression: 0.0961 (0.1030)  classification: 0.4597 (0.4805)  time: 0.4237  data: 0.1235  max mem: 3278
Epoch: [57]  [1900/3494]  eta: 0:10:10  lr: 0.0000000  loss: 0.5756 (0.5831)  bbox_regression: 0.1001 (0.1029)  classification: 0.4808 (0.4803)  time: 0.3573  data: 0.1216  max mem: 3278
Epoch: [57]  [2000/3494]  eta: 0:09:30  lr: 0.0000000  loss: 0.5545 (0.5829)  bbox_regression: 0.0960 (0.1028)  classification: 0.4618 (0.4802)  time: 0.3631  data: 0.1202  max mem: 3278
Epoch: [57]  [2100/3494]  eta: 0:08:52  lr: 0.0000000  loss: 0.5711 (0.5828)  bbox_regression: 0.0955 (0.1028)  classification: 0.4570 (0.4800)  time: 0.3908  data: 0.1346  max mem: 3278
Epoch: [57]  [2200/3494]  eta: 0:08:14  lr: 0.0000000  loss: 0.5738 (0.5834)  bbox_regression: 0.1041 (0.1028)  classification: 0.4905 (0.4805)  time: 0.3827  data: 0.1350  max mem: 3278
Epoch: [57]  [2300/3494]  eta: 0:07:36  lr: 0.0000000  loss: 0.6285 (0.5832)  bbox_regression: 0.1087 (0.1029)  classification: 0.5014 (0.4803)  time: 0.3935  data: 0.1398  max mem: 3278
Epoch: [57]  [2400/3494]  eta: 0:06:58  lr: 0.0000000  loss: 0.5414 (0.5831)  bbox_regression: 0.0960 (0.1030)  classification: 0.4559 (0.4801)  time: 0.3869  data: 0.1353  max mem: 3278
Epoch: [57]  [2500/3494]  eta: 0:06:20  lr: 0.0000000  loss: 0.5679 (0.5832)  bbox_regression: 0.0887 (0.1029)  classification: 0.4622 (0.4803)  time: 0.3823  data: 0.1362  max mem: 3278
Epoch: [57]  [2600/3494]  eta: 0:05:42  lr: 0.0000000  loss: 0.5310 (0.5826)  bbox_regression: 0.0938 (0.1028)  classification: 0.4527 (0.4798)  time: 0.4295  data: 0.1331  max mem: 3278
Epoch: [57]  [2700/3494]  eta: 0:05:04  lr: 0.0000000  loss: 0.5503 (0.5827)  bbox_regression: 0.0984 (0.1029)  classification: 0.4484 (0.4798)  time: 0.3821  data: 0.1367  max mem: 3278
Epoch: [57]  [2800/3494]  eta: 0:04:25  lr: 0.0000000  loss: 0.5380 (0.5822)  bbox_regression: 0.0907 (0.1028)  classification: 0.4453 (0.4794)  time: 0.3905  data: 0.1357  max mem: 3278
Epoch: [57]  [2900/3494]  eta: 0:03:47  lr: 0.0000000  loss: 0.5278 (0.5819)  bbox_regression: 0.0940 (0.1028)  classification: 0.4364 (0.4791)  time: 0.3908  data: 0.1348  max mem: 3278
Epoch: [57]  [3000/3494]  eta: 0:03:09  lr: 0.0000000  loss: 0.5538 (0.5814)  bbox_regression: 0.0915 (0.1028)  classification: 0.4564 (0.4786)  time: 0.3801  data: 0.1334  max mem: 3278
Epoch: [57]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5617 (0.5816)  bbox_regression: 0.0941 (0.1028)  classification: 0.4615 (0.4789)  time: 0.3705  data: 0.1265  max mem: 3278
Epoch: [57]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5924 (0.5814)  bbox_regression: 0.1077 (0.1028)  classification: 0.4823 (0.4786)  time: 0.3852  data: 0.1428  max mem: 3278
Epoch: [57]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5597 (0.5817)  bbox_regression: 0.0877 (0.1029)  classification: 0.4696 (0.4788)  time: 0.3865  data: 0.1540  max mem: 3278
Epoch: [57]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5181 (0.5817)  bbox_regression: 0.0932 (0.1030)  classification: 0.4377 (0.4788)  time: 0.3671  data: 0.1294  max mem: 3278
Epoch: [57]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5221 (0.5820)  bbox_regression: 0.0992 (0.1030)  classification: 0.4255 (0.4789)  time: 0.3534  data: 0.1279  max mem: 3278
Epoch: [57] Total time: 0:22:26 (0.3854 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:05  model_time: 0.1151 (0.1151)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9353  data: 1.7769  max mem: 3278
Validation:  [100/437]  eta: 0:01:38  model_time: 0.1301 (0.1290)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2687  data: 0.1226  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1389 (0.1309)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2939  data: 0.1433  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1334 (0.1312)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2759  data: 0.1238  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1379 (0.1338)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2833  data: 0.1252  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1267 (0.1340)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2596  data: 0.1199  max mem: 3278
Validation: Total time: 0:02:04 (0.2851 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [58]  [   0/3494]  eta: 2:42:57  lr: 0.0000000  loss: 0.8128 (0.8128)  bbox_regression: 0.1865 (0.1865)  classification: 0.6263 (0.6263)  time: 2.7984  data: 2.5394  max mem: 3278
Epoch: [58]  [ 100/3494]  eta: 0:22:21  lr: 0.0000000  loss: 0.5305 (0.5877)  bbox_regression: 0.0972 (0.1032)  classification: 0.4227 (0.4845)  time: 0.3701  data: 0.1259  max mem: 3278
Epoch: [58]  [ 200/3494]  eta: 0:21:32  lr: 0.0000000  loss: 0.5413 (0.5860)  bbox_regression: 0.1031 (0.1039)  classification: 0.4329 (0.4820)  time: 0.4004  data: 0.1306  max mem: 3278
Epoch: [58]  [ 300/3494]  eta: 0:20:55  lr: 0.0000000  loss: 0.5746 (0.5858)  bbox_regression: 0.0932 (0.1036)  classification: 0.4825 (0.4822)  time: 0.4116  data: 0.1325  max mem: 3278
Epoch: [58]  [ 400/3494]  eta: 0:20:02  lr: 0.0000000  loss: 0.5546 (0.5808)  bbox_regression: 0.0944 (0.1031)  classification: 0.4419 (0.4777)  time: 0.3735  data: 0.1286  max mem: 3278
Epoch: [58]  [ 500/3494]  eta: 0:19:18  lr: 0.0000000  loss: 0.5795 (0.5815)  bbox_regression: 0.0925 (0.1028)  classification: 0.4785 (0.4787)  time: 0.4068  data: 0.1480  max mem: 3278
Epoch: [58]  [ 600/3494]  eta: 0:18:32  lr: 0.0000000  loss: 0.5930 (0.5823)  bbox_regression: 0.1008 (0.1026)  classification: 0.4946 (0.4797)  time: 0.3798  data: 0.1336  max mem: 3278
Epoch: [58]  [ 700/3494]  eta: 0:17:51  lr: 0.0000000  loss: 0.5875 (0.5849)  bbox_regression: 0.1054 (0.1027)  classification: 0.5008 (0.4823)  time: 0.3746  data: 0.1268  max mem: 3278
Epoch: [58]  [ 800/3494]  eta: 0:17:14  lr: 0.0000000  loss: 0.5481 (0.5855)  bbox_regression: 0.0952 (0.1028)  classification: 0.4720 (0.4828)  time: 0.3958  data: 0.1354  max mem: 3278
Epoch: [58]  [ 900/3494]  eta: 0:16:34  lr: 0.0000000  loss: 0.6111 (0.5844)  bbox_regression: 0.1131 (0.1029)  classification: 0.5098 (0.4815)  time: 0.3650  data: 0.1244  max mem: 3278
Epoch: [58]  [1000/3494]  eta: 0:15:56  lr: 0.0000000  loss: 0.5344 (0.5840)  bbox_regression: 0.0865 (0.1029)  classification: 0.4428 (0.4811)  time: 0.3706  data: 0.1291  max mem: 3278
Epoch: [58]  [1100/3494]  eta: 0:15:17  lr: 0.0000000  loss: 0.5914 (0.5867)  bbox_regression: 0.1159 (0.1034)  classification: 0.4695 (0.4833)  time: 0.3644  data: 0.1252  max mem: 3278
Epoch: [58]  [1200/3494]  eta: 0:14:36  lr: 0.0000000  loss: 0.5415 (0.5861)  bbox_regression: 0.1040 (0.1033)  classification: 0.4416 (0.4827)  time: 0.3748  data: 0.1318  max mem: 3278
Epoch: [58]  [1300/3494]  eta: 0:13:56  lr: 0.0000000  loss: 0.5388 (0.5869)  bbox_regression: 0.0945 (0.1034)  classification: 0.4510 (0.4835)  time: 0.3626  data: 0.1288  max mem: 3278
Epoch: [58]  [1400/3494]  eta: 0:13:17  lr: 0.0000000  loss: 0.5484 (0.5875)  bbox_regression: 0.1075 (0.1034)  classification: 0.4657 (0.4840)  time: 0.3865  data: 0.1338  max mem: 3278
Epoch: [58]  [1500/3494]  eta: 0:12:40  lr: 0.0000000  loss: 0.5187 (0.5864)  bbox_regression: 0.0856 (0.1033)  classification: 0.4315 (0.4831)  time: 0.3749  data: 0.1337  max mem: 3278
Epoch: [58]  [1600/3494]  eta: 0:12:03  lr: 0.0000000  loss: 0.5757 (0.5860)  bbox_regression: 0.0983 (0.1031)  classification: 0.4907 (0.4829)  time: 0.3883  data: 0.1377  max mem: 3278
Epoch: [58]  [1700/3494]  eta: 0:11:25  lr: 0.0000000  loss: 0.5437 (0.5863)  bbox_regression: 0.0919 (0.1032)  classification: 0.4245 (0.4831)  time: 0.3721  data: 0.1276  max mem: 3278
Epoch: [58]  [1800/3494]  eta: 0:10:47  lr: 0.0000000  loss: 0.5694 (0.5857)  bbox_regression: 0.0877 (0.1031)  classification: 0.4873 (0.4826)  time: 0.3662  data: 0.1218  max mem: 3278
Epoch: [58]  [1900/3494]  eta: 0:10:09  lr: 0.0000000  loss: 0.5175 (0.5852)  bbox_regression: 0.0888 (0.1030)  classification: 0.4314 (0.4822)  time: 0.3664  data: 0.1316  max mem: 3278
Epoch: [58]  [2000/3494]  eta: 0:09:29  lr: 0.0000000  loss: 0.5954 (0.5850)  bbox_regression: 0.1086 (0.1032)  classification: 0.4512 (0.4818)  time: 0.3760  data: 0.1288  max mem: 3278
Epoch: [58]  [2100/3494]  eta: 0:08:51  lr: 0.0000000  loss: 0.5679 (0.5858)  bbox_regression: 0.1075 (0.1033)  classification: 0.4790 (0.4825)  time: 0.3713  data: 0.1276  max mem: 3278
Epoch: [58]  [2200/3494]  eta: 0:08:12  lr: 0.0000000  loss: 0.5825 (0.5852)  bbox_regression: 0.0929 (0.1033)  classification: 0.4847 (0.4818)  time: 0.3810  data: 0.1341  max mem: 3278
Epoch: [58]  [2300/3494]  eta: 0:07:34  lr: 0.0000000  loss: 0.5708 (0.5859)  bbox_regression: 0.1089 (0.1036)  classification: 0.4501 (0.4823)  time: 0.4300  data: 0.1374  max mem: 3278
Epoch: [58]  [2400/3494]  eta: 0:06:56  lr: 0.0000000  loss: 0.5833 (0.5860)  bbox_regression: 0.0949 (0.1036)  classification: 0.4953 (0.4824)  time: 0.3735  data: 0.1259  max mem: 3278
Epoch: [58]  [2500/3494]  eta: 0:06:18  lr: 0.0000000  loss: 0.5362 (0.5861)  bbox_regression: 0.0853 (0.1036)  classification: 0.4522 (0.4824)  time: 0.3928  data: 0.1307  max mem: 3278
Epoch: [58]  [2600/3494]  eta: 0:05:41  lr: 0.0000000  loss: 0.5826 (0.5862)  bbox_regression: 0.0975 (0.1037)  classification: 0.4816 (0.4825)  time: 0.3817  data: 0.1341  max mem: 3278
Epoch: [58]  [2700/3494]  eta: 0:05:02  lr: 0.0000000  loss: 0.5254 (0.5852)  bbox_regression: 0.0976 (0.1034)  classification: 0.4498 (0.4818)  time: 0.3690  data: 0.1305  max mem: 3278
Epoch: [58]  [2800/3494]  eta: 0:04:24  lr: 0.0000000  loss: 0.5670 (0.5849)  bbox_regression: 0.1019 (0.1035)  classification: 0.4671 (0.4813)  time: 0.3982  data: 0.1414  max mem: 3278
Epoch: [58]  [2900/3494]  eta: 0:03:46  lr: 0.0000000  loss: 0.5533 (0.5852)  bbox_regression: 0.0868 (0.1037)  classification: 0.4757 (0.4815)  time: 0.3984  data: 0.1435  max mem: 3278
Epoch: [58]  [3000/3494]  eta: 0:03:08  lr: 0.0000000  loss: 0.5126 (0.5846)  bbox_regression: 0.0882 (0.1036)  classification: 0.4138 (0.4810)  time: 0.4133  data: 0.1559  max mem: 3278
Epoch: [58]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5206 (0.5841)  bbox_regression: 0.0811 (0.1034)  classification: 0.4320 (0.4808)  time: 0.3685  data: 0.1249  max mem: 3278
Epoch: [58]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.6081 (0.5842)  bbox_regression: 0.1040 (0.1034)  classification: 0.5033 (0.4808)  time: 0.3747  data: 0.1313  max mem: 3278
Epoch: [58]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5936 (0.5841)  bbox_regression: 0.0944 (0.1033)  classification: 0.4928 (0.4808)  time: 0.3999  data: 0.1325  max mem: 3278
Epoch: [58]  [3400/3494]  eta: 0:00:36  lr: 0.0000000  loss: 0.6057 (0.5843)  bbox_regression: 0.1024 (0.1033)  classification: 0.4980 (0.4810)  time: 0.3761  data: 0.1358  max mem: 3278
Epoch: [58]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5811 (0.5842)  bbox_regression: 0.1037 (0.1033)  classification: 0.4957 (0.4809)  time: 0.3810  data: 0.1330  max mem: 3278
Epoch: [58] Total time: 0:22:27 (0.3857 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:20  model_time: 0.1459 (0.1459)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9697  data: 1.7677  max mem: 3278
Validation:  [100/437]  eta: 0:01:38  model_time: 0.1273 (0.1274)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2670  data: 0.1227  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1356 (0.1286)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2866  data: 0.1288  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1334 (0.1308)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2829  data: 0.1322  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1336 (0.1308)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2716  data: 0.1220  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1324 (0.1311)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2867  data: 0.1237  max mem: 3278
Validation: Total time: 0:02:03 (0.2827 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [59]  [   0/3494]  eta: 2:42:09  lr: 0.0000000  loss: 0.6034 (0.6034)  bbox_regression: 0.1350 (0.1350)  classification: 0.4684 (0.4684)  time: 2.7846  data: 2.4436  max mem: 3278
Epoch: [59]  [ 100/3494]  eta: 0:22:50  lr: 0.0000000  loss: 0.5839 (0.5992)  bbox_regression: 0.0959 (0.1084)  classification: 0.4651 (0.4909)  time: 0.3754  data: 0.1345  max mem: 3278
Epoch: [59]  [ 200/3494]  eta: 0:21:35  lr: 0.0000000  loss: 0.5698 (0.5835)  bbox_regression: 0.1048 (0.1045)  classification: 0.4570 (0.4790)  time: 0.3773  data: 0.1319  max mem: 3278
Epoch: [59]  [ 300/3494]  eta: 0:20:42  lr: 0.0000000  loss: 0.5642 (0.5872)  bbox_regression: 0.0902 (0.1047)  classification: 0.4550 (0.4825)  time: 0.3765  data: 0.1313  max mem: 3278
Epoch: [59]  [ 400/3494]  eta: 0:19:45  lr: 0.0000000  loss: 0.5985 (0.5847)  bbox_regression: 0.0934 (0.1038)  classification: 0.5143 (0.4809)  time: 0.3638  data: 0.1282  max mem: 3278
Epoch: [59]  [ 500/3494]  eta: 0:19:03  lr: 0.0000000  loss: 0.5735 (0.5846)  bbox_regression: 0.0923 (0.1035)  classification: 0.4657 (0.4812)  time: 0.3691  data: 0.1286  max mem: 3278
Epoch: [59]  [ 600/3494]  eta: 0:18:28  lr: 0.0000000  loss: 0.5204 (0.5854)  bbox_regression: 0.0907 (0.1031)  classification: 0.4297 (0.4823)  time: 0.3930  data: 0.1387  max mem: 3278
Epoch: [59]  [ 700/3494]  eta: 0:17:50  lr: 0.0000000  loss: 0.5233 (0.5827)  bbox_regression: 0.0865 (0.1026)  classification: 0.4299 (0.4801)  time: 0.3866  data: 0.1369  max mem: 3278
Epoch: [59]  [ 800/3494]  eta: 0:17:16  lr: 0.0000000  loss: 0.5659 (0.5815)  bbox_regression: 0.0983 (0.1022)  classification: 0.4713 (0.4793)  time: 0.3675  data: 0.1239  max mem: 3278
Epoch: [59]  [ 900/3494]  eta: 0:16:38  lr: 0.0000000  loss: 0.5606 (0.5806)  bbox_regression: 0.0995 (0.1023)  classification: 0.4646 (0.4783)  time: 0.3951  data: 0.1427  max mem: 3278
Epoch: [59]  [1000/3494]  eta: 0:16:02  lr: 0.0000000  loss: 0.5995 (0.5821)  bbox_regression: 0.1066 (0.1025)  classification: 0.4826 (0.4796)  time: 0.3748  data: 0.1338  max mem: 3278
Epoch: [59]  [1100/3494]  eta: 0:15:23  lr: 0.0000000  loss: 0.5844 (0.5823)  bbox_regression: 0.0912 (0.1023)  classification: 0.4903 (0.4800)  time: 0.3777  data: 0.1330  max mem: 3278
Epoch: [59]  [1200/3494]  eta: 0:14:43  lr: 0.0000000  loss: 0.5763 (0.5834)  bbox_regression: 0.0947 (0.1025)  classification: 0.4646 (0.4808)  time: 0.3939  data: 0.1435  max mem: 3278
Epoch: [59]  [1300/3494]  eta: 0:14:02  lr: 0.0000000  loss: 0.5573 (0.5830)  bbox_regression: 0.0934 (0.1027)  classification: 0.4642 (0.4803)  time: 0.3767  data: 0.1318  max mem: 3278
Epoch: [59]  [1400/3494]  eta: 0:13:24  lr: 0.0000000  loss: 0.5254 (0.5818)  bbox_regression: 0.0950 (0.1025)  classification: 0.4208 (0.4793)  time: 0.3797  data: 0.1322  max mem: 3278
Epoch: [59]  [1500/3494]  eta: 0:12:46  lr: 0.0000000  loss: 0.5650 (0.5820)  bbox_regression: 0.0970 (0.1029)  classification: 0.4503 (0.4791)  time: 0.4006  data: 0.1376  max mem: 3278
Epoch: [59]  [1600/3494]  eta: 0:12:07  lr: 0.0000000  loss: 0.5664 (0.5818)  bbox_regression: 0.1097 (0.1031)  classification: 0.4414 (0.4787)  time: 0.3727  data: 0.1314  max mem: 3278
Epoch: [59]  [1700/3494]  eta: 0:11:29  lr: 0.0000000  loss: 0.5361 (0.5817)  bbox_regression: 0.0858 (0.1031)  classification: 0.4605 (0.4786)  time: 0.4275  data: 0.1396  max mem: 3278
Epoch: [59]  [1800/3494]  eta: 0:10:50  lr: 0.0000000  loss: 0.5681 (0.5823)  bbox_regression: 0.0853 (0.1031)  classification: 0.4687 (0.4793)  time: 0.3699  data: 0.1333  max mem: 3278
Epoch: [59]  [1900/3494]  eta: 0:10:11  lr: 0.0000000  loss: 0.5671 (0.5825)  bbox_regression: 0.0877 (0.1029)  classification: 0.4786 (0.4796)  time: 0.3644  data: 0.1295  max mem: 3278
Epoch: [59]  [2000/3494]  eta: 0:09:32  lr: 0.0000000  loss: 0.5427 (0.5836)  bbox_regression: 0.0986 (0.1029)  classification: 0.4535 (0.4807)  time: 0.3811  data: 0.1470  max mem: 3278
Epoch: [59]  [2100/3494]  eta: 0:08:54  lr: 0.0000000  loss: 0.6066 (0.5842)  bbox_regression: 0.1062 (0.1030)  classification: 0.4929 (0.4812)  time: 0.3786  data: 0.1273  max mem: 3278
Epoch: [59]  [2200/3494]  eta: 0:08:16  lr: 0.0000000  loss: 0.5681 (0.5838)  bbox_regression: 0.0899 (0.1030)  classification: 0.4531 (0.4808)  time: 0.3771  data: 0.1292  max mem: 3278
Epoch: [59]  [2300/3494]  eta: 0:07:38  lr: 0.0000000  loss: 0.5686 (0.5839)  bbox_regression: 0.0970 (0.1031)  classification: 0.4817 (0.4808)  time: 0.3884  data: 0.1391  max mem: 3278
Epoch: [59]  [2400/3494]  eta: 0:06:59  lr: 0.0000000  loss: 0.6479 (0.5843)  bbox_regression: 0.0959 (0.1033)  classification: 0.5356 (0.4811)  time: 0.3651  data: 0.1240  max mem: 3278
Epoch: [59]  [2500/3494]  eta: 0:06:21  lr: 0.0000000  loss: 0.5703 (0.5837)  bbox_regression: 0.1111 (0.1032)  classification: 0.4617 (0.4806)  time: 0.3700  data: 0.1259  max mem: 3278
Epoch: [59]  [2600/3494]  eta: 0:05:42  lr: 0.0000000  loss: 0.6194 (0.5836)  bbox_regression: 0.1010 (0.1031)  classification: 0.4952 (0.4805)  time: 0.3716  data: 0.1258  max mem: 3278
Epoch: [59]  [2700/3494]  eta: 0:05:04  lr: 0.0000000  loss: 0.5907 (0.5837)  bbox_regression: 0.1121 (0.1031)  classification: 0.4740 (0.4806)  time: 0.3720  data: 0.1333  max mem: 3278
Epoch: [59]  [2800/3494]  eta: 0:04:25  lr: 0.0000000  loss: 0.5758 (0.5836)  bbox_regression: 0.1062 (0.1031)  classification: 0.4561 (0.4805)  time: 0.3877  data: 0.1356  max mem: 3278
Epoch: [59]  [2900/3494]  eta: 0:03:47  lr: 0.0000000  loss: 0.5238 (0.5837)  bbox_regression: 0.0830 (0.1030)  classification: 0.4478 (0.4807)  time: 0.3737  data: 0.1308  max mem: 3278
Epoch: [59]  [3000/3494]  eta: 0:03:09  lr: 0.0000000  loss: 0.5306 (0.5835)  bbox_regression: 0.0890 (0.1030)  classification: 0.4181 (0.4805)  time: 0.3926  data: 0.1356  max mem: 3278
Epoch: [59]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5981 (0.5834)  bbox_regression: 0.0868 (0.1030)  classification: 0.4818 (0.4804)  time: 0.3811  data: 0.1389  max mem: 3278
Epoch: [59]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5232 (0.5837)  bbox_regression: 0.0950 (0.1031)  classification: 0.4391 (0.4806)  time: 0.3762  data: 0.1278  max mem: 3278
Epoch: [59]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5600 (0.5833)  bbox_regression: 0.0924 (0.1030)  classification: 0.4775 (0.4803)  time: 0.4063  data: 0.1272  max mem: 3278
Epoch: [59]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5877 (0.5830)  bbox_regression: 0.1051 (0.1030)  classification: 0.4759 (0.4800)  time: 0.3606  data: 0.1294  max mem: 3278
Epoch: [59]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5752 (0.5826)  bbox_regression: 0.0980 (0.1030)  classification: 0.4499 (0.4796)  time: 0.3582  data: 0.1288  max mem: 3278
Epoch: [59] Total time: 0:22:25 (0.3852 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:58  model_time: 0.2054 (0.2054)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9183  data: 1.6663  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1190 (0.1317)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2646  data: 0.1252  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1223 (0.1311)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2624  data: 0.1202  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1314 (0.1325)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2735  data: 0.1237  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1347 (0.1321)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2865  data: 0.1332  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1346 (0.1320)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2666  data: 0.1169  max mem: 3278
Validation: Total time: 0:02:03 (0.2817 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [60]  [   0/3494]  eta: 2:43:17  lr: 0.0000000  loss: 0.4517 (0.4517)  bbox_regression: 0.0711 (0.0711)  classification: 0.3806 (0.3806)  time: 2.8041  data: 2.4790  max mem: 3278
Epoch: [60]  [ 100/3494]  eta: 0:23:46  lr: 0.0000000  loss: 0.5465 (0.5653)  bbox_regression: 0.0987 (0.0979)  classification: 0.4364 (0.4674)  time: 0.4093  data: 0.1509  max mem: 3278
Epoch: [60]  [ 200/3494]  eta: 0:22:19  lr: 0.0000000  loss: 0.5607 (0.5668)  bbox_regression: 0.0939 (0.0975)  classification: 0.4748 (0.4693)  time: 0.3728  data: 0.1301  max mem: 3278
Epoch: [60]  [ 300/3494]  eta: 0:21:30  lr: 0.0000000  loss: 0.5838 (0.5685)  bbox_regression: 0.0903 (0.0971)  classification: 0.4825 (0.4714)  time: 0.4215  data: 0.1328  max mem: 3278
Epoch: [60]  [ 400/3494]  eta: 0:20:25  lr: 0.0000000  loss: 0.5484 (0.5701)  bbox_regression: 0.0975 (0.0978)  classification: 0.4449 (0.4723)  time: 0.3782  data: 0.1386  max mem: 3278
Epoch: [60]  [ 500/3494]  eta: 0:19:36  lr: 0.0000000  loss: 0.5168 (0.5711)  bbox_regression: 0.0857 (0.0985)  classification: 0.4380 (0.4727)  time: 0.3844  data: 0.1302  max mem: 3278
Epoch: [60]  [ 600/3494]  eta: 0:18:46  lr: 0.0000000  loss: 0.5709 (0.5725)  bbox_regression: 0.0977 (0.0991)  classification: 0.4662 (0.4734)  time: 0.3735  data: 0.1364  max mem: 3278
Epoch: [60]  [ 700/3494]  eta: 0:18:06  lr: 0.0000000  loss: 0.5805 (0.5747)  bbox_regression: 0.0992 (0.0997)  classification: 0.4899 (0.4750)  time: 0.3874  data: 0.1364  max mem: 3278
Epoch: [60]  [ 800/3494]  eta: 0:17:25  lr: 0.0000000  loss: 0.5335 (0.5769)  bbox_regression: 0.0990 (0.1006)  classification: 0.4554 (0.4764)  time: 0.3912  data: 0.1443  max mem: 3278
Epoch: [60]  [ 900/3494]  eta: 0:16:45  lr: 0.0000000  loss: 0.5142 (0.5758)  bbox_regression: 0.0803 (0.1005)  classification: 0.4237 (0.4753)  time: 0.3887  data: 0.1429  max mem: 3278
Epoch: [60]  [1000/3494]  eta: 0:16:04  lr: 0.0000000  loss: 0.5899 (0.5798)  bbox_regression: 0.0961 (0.1015)  classification: 0.4597 (0.4782)  time: 0.3779  data: 0.1325  max mem: 3278
Epoch: [60]  [1100/3494]  eta: 0:15:27  lr: 0.0000000  loss: 0.4930 (0.5785)  bbox_regression: 0.0869 (0.1013)  classification: 0.4017 (0.4773)  time: 0.3746  data: 0.1356  max mem: 3278
Epoch: [60]  [1200/3494]  eta: 0:14:45  lr: 0.0000000  loss: 0.5932 (0.5768)  bbox_regression: 0.0927 (0.1008)  classification: 0.4846 (0.4759)  time: 0.3710  data: 0.1292  max mem: 3278
Epoch: [60]  [1300/3494]  eta: 0:14:04  lr: 0.0000000  loss: 0.5737 (0.5767)  bbox_regression: 0.0989 (0.1007)  classification: 0.4978 (0.4760)  time: 0.3807  data: 0.1298  max mem: 3278
Epoch: [60]  [1400/3494]  eta: 0:13:25  lr: 0.0000000  loss: 0.5568 (0.5772)  bbox_regression: 0.0945 (0.1008)  classification: 0.4545 (0.4763)  time: 0.3811  data: 0.1337  max mem: 3278
Epoch: [60]  [1500/3494]  eta: 0:12:46  lr: 0.0000000  loss: 0.5802 (0.5778)  bbox_regression: 0.0941 (0.1010)  classification: 0.4767 (0.4768)  time: 0.3796  data: 0.1302  max mem: 3278
Epoch: [60]  [1600/3494]  eta: 0:12:08  lr: 0.0000000  loss: 0.5863 (0.5785)  bbox_regression: 0.1031 (0.1013)  classification: 0.4741 (0.4772)  time: 0.3740  data: 0.1338  max mem: 3278
Epoch: [60]  [1700/3494]  eta: 0:11:28  lr: 0.0000000  loss: 0.5584 (0.5792)  bbox_regression: 0.0960 (0.1016)  classification: 0.4471 (0.4776)  time: 0.3711  data: 0.1276  max mem: 3278
Epoch: [60]  [1800/3494]  eta: 0:10:51  lr: 0.0000000  loss: 0.5849 (0.5798)  bbox_regression: 0.1045 (0.1015)  classification: 0.4982 (0.4782)  time: 0.4362  data: 0.1413  max mem: 3278
Epoch: [60]  [1900/3494]  eta: 0:10:13  lr: 0.0000000  loss: 0.5772 (0.5797)  bbox_regression: 0.0969 (0.1016)  classification: 0.4720 (0.4781)  time: 0.3701  data: 0.1257  max mem: 3278
Epoch: [60]  [2000/3494]  eta: 0:09:34  lr: 0.0000000  loss: 0.5656 (0.5800)  bbox_regression: 0.0939 (0.1017)  classification: 0.4742 (0.4783)  time: 0.3652  data: 0.1308  max mem: 3278
Epoch: [60]  [2100/3494]  eta: 0:08:54  lr: 0.0000000  loss: 0.5688 (0.5801)  bbox_regression: 0.1004 (0.1016)  classification: 0.4840 (0.4785)  time: 0.3826  data: 0.1301  max mem: 3278
Epoch: [60]  [2200/3494]  eta: 0:08:16  lr: 0.0000000  loss: 0.5185 (0.5800)  bbox_regression: 0.0897 (0.1017)  classification: 0.4257 (0.4783)  time: 0.3852  data: 0.1304  max mem: 3278
Epoch: [60]  [2300/3494]  eta: 0:07:38  lr: 0.0000000  loss: 0.5503 (0.5796)  bbox_regression: 0.0904 (0.1018)  classification: 0.4368 (0.4778)  time: 0.3879  data: 0.1368  max mem: 3278
Epoch: [60]  [2400/3494]  eta: 0:06:59  lr: 0.0000000  loss: 0.5396 (0.5804)  bbox_regression: 0.0973 (0.1021)  classification: 0.4645 (0.4783)  time: 0.3684  data: 0.1280  max mem: 3278
Epoch: [60]  [2500/3494]  eta: 0:06:21  lr: 0.0000000  loss: 0.5579 (0.5807)  bbox_regression: 0.0917 (0.1021)  classification: 0.4715 (0.4786)  time: 0.3830  data: 0.1318  max mem: 3278
Epoch: [60]  [2600/3494]  eta: 0:05:43  lr: 0.0000000  loss: 0.6145 (0.5814)  bbox_regression: 0.1029 (0.1023)  classification: 0.4980 (0.4792)  time: 0.4086  data: 0.1355  max mem: 3278
Epoch: [60]  [2700/3494]  eta: 0:05:04  lr: 0.0000000  loss: 0.5440 (0.5805)  bbox_regression: 0.0955 (0.1022)  classification: 0.4553 (0.4784)  time: 0.3434  data: 0.1166  max mem: 3278
Epoch: [60]  [2800/3494]  eta: 0:04:25  lr: 0.0000000  loss: 0.5516 (0.5801)  bbox_regression: 0.0949 (0.1022)  classification: 0.4320 (0.4779)  time: 0.3809  data: 0.1329  max mem: 3278
Epoch: [60]  [2900/3494]  eta: 0:03:47  lr: 0.0000000  loss: 0.5357 (0.5804)  bbox_regression: 0.0841 (0.1022)  classification: 0.4584 (0.4782)  time: 0.3840  data: 0.1343  max mem: 3278
Epoch: [60]  [3000/3494]  eta: 0:03:09  lr: 0.0000000  loss: 0.5616 (0.5809)  bbox_regression: 0.0976 (0.1024)  classification: 0.4655 (0.4785)  time: 0.3623  data: 0.1221  max mem: 3278
Epoch: [60]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5763 (0.5810)  bbox_regression: 0.1058 (0.1025)  classification: 0.4338 (0.4785)  time: 0.4258  data: 0.1346  max mem: 3278
Epoch: [60]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5392 (0.5817)  bbox_regression: 0.0906 (0.1026)  classification: 0.4510 (0.4791)  time: 0.3701  data: 0.1284  max mem: 3278
Epoch: [60]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5896 (0.5821)  bbox_regression: 0.1090 (0.1027)  classification: 0.4847 (0.4794)  time: 0.4144  data: 0.1309  max mem: 3278
Epoch: [60]  [3400/3494]  eta: 0:00:36  lr: 0.0000000  loss: 0.5554 (0.5822)  bbox_regression: 0.0910 (0.1028)  classification: 0.4515 (0.4794)  time: 0.3801  data: 0.1325  max mem: 3278
Epoch: [60]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5832 (0.5826)  bbox_regression: 0.1030 (0.1029)  classification: 0.4549 (0.4797)  time: 0.3692  data: 0.1400  max mem: 3278
Epoch: [60] Total time: 0:22:27 (0.3857 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:11  model_time: 0.1273 (0.1273)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.4975  data: 2.2990  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1338 (0.1269)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2696  data: 0.1197  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1350 (0.1298)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2767  data: 0.1270  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1288 (0.1306)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2750  data: 0.1259  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1268 (0.1317)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2775  data: 0.1312  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1349 (0.1322)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2838  data: 0.1190  max mem: 3278
Validation: Total time: 0:02:02 (0.2808 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [61]  [   0/3494]  eta: 1:56:38  lr: 0.0000000  loss: 0.4327 (0.4327)  bbox_regression: 0.0889 (0.0889)  classification: 0.3438 (0.3438)  time: 2.0031  data: 1.7263  max mem: 3278
Epoch: [61]  [ 100/3494]  eta: 0:23:15  lr: 0.0000000  loss: 0.5687 (0.5733)  bbox_regression: 0.0862 (0.0990)  classification: 0.4648 (0.4743)  time: 0.3983  data: 0.1529  max mem: 3278
Epoch: [61]  [ 200/3494]  eta: 0:21:39  lr: 0.0000000  loss: 0.5118 (0.5712)  bbox_regression: 0.0880 (0.0987)  classification: 0.4467 (0.4725)  time: 0.3707  data: 0.1277  max mem: 3278
Epoch: [61]  [ 300/3494]  eta: 0:20:53  lr: 0.0000000  loss: 0.5460 (0.5674)  bbox_regression: 0.0835 (0.0986)  classification: 0.4509 (0.4688)  time: 0.3879  data: 0.1426  max mem: 3278
Epoch: [61]  [ 400/3494]  eta: 0:20:01  lr: 0.0000000  loss: 0.5478 (0.5663)  bbox_regression: 0.0964 (0.0979)  classification: 0.4670 (0.4684)  time: 0.3821  data: 0.1356  max mem: 3278
Epoch: [61]  [ 500/3494]  eta: 0:19:15  lr: 0.0000000  loss: 0.5400 (0.5677)  bbox_regression: 0.0928 (0.0985)  classification: 0.4549 (0.4692)  time: 0.3766  data: 0.1323  max mem: 3278
Epoch: [61]  [ 600/3494]  eta: 0:18:35  lr: 0.0000000  loss: 0.5966 (0.5701)  bbox_regression: 0.0985 (0.0991)  classification: 0.5105 (0.4711)  time: 0.3975  data: 0.1430  max mem: 3278
Epoch: [61]  [ 700/3494]  eta: 0:17:57  lr: 0.0000000  loss: 0.5519 (0.5727)  bbox_regression: 0.0960 (0.0996)  classification: 0.4658 (0.4731)  time: 0.3970  data: 0.1263  max mem: 3278
Epoch: [61]  [ 800/3494]  eta: 0:17:20  lr: 0.0000000  loss: 0.5937 (0.5759)  bbox_regression: 0.1006 (0.1004)  classification: 0.4839 (0.4755)  time: 0.3798  data: 0.1342  max mem: 3278
Epoch: [61]  [ 900/3494]  eta: 0:16:43  lr: 0.0000000  loss: 0.5489 (0.5788)  bbox_regression: 0.1049 (0.1013)  classification: 0.4614 (0.4774)  time: 0.4058  data: 0.1495  max mem: 3278
Epoch: [61]  [1000/3494]  eta: 0:16:07  lr: 0.0000000  loss: 0.5666 (0.5805)  bbox_regression: 0.0912 (0.1019)  classification: 0.4709 (0.4786)  time: 0.3770  data: 0.1296  max mem: 3278
Epoch: [61]  [1100/3494]  eta: 0:15:29  lr: 0.0000000  loss: 0.5721 (0.5817)  bbox_regression: 0.1063 (0.1022)  classification: 0.4639 (0.4795)  time: 0.3727  data: 0.1302  max mem: 3278
Epoch: [61]  [1200/3494]  eta: 0:14:49  lr: 0.0000000  loss: 0.5952 (0.5823)  bbox_regression: 0.1114 (0.1025)  classification: 0.4898 (0.4798)  time: 0.3765  data: 0.1340  max mem: 3278
Epoch: [61]  [1300/3494]  eta: 0:14:11  lr: 0.0000000  loss: 0.5604 (0.5824)  bbox_regression: 0.0892 (0.1028)  classification: 0.4570 (0.4796)  time: 0.3707  data: 0.1271  max mem: 3278
Epoch: [61]  [1400/3494]  eta: 0:13:29  lr: 0.0000000  loss: 0.6103 (0.5822)  bbox_regression: 0.0990 (0.1029)  classification: 0.5008 (0.4793)  time: 0.3544  data: 0.1207  max mem: 3278
Epoch: [61]  [1500/3494]  eta: 0:12:50  lr: 0.0000000  loss: 0.5321 (0.5824)  bbox_regression: 0.0954 (0.1029)  classification: 0.4540 (0.4795)  time: 0.3920  data: 0.1354  max mem: 3278
Epoch: [61]  [1600/3494]  eta: 0:12:11  lr: 0.0000000  loss: 0.6165 (0.5833)  bbox_regression: 0.0974 (0.1032)  classification: 0.4910 (0.4801)  time: 0.3901  data: 0.1310  max mem: 3278
Epoch: [61]  [1700/3494]  eta: 0:11:31  lr: 0.0000000  loss: 0.6086 (0.5844)  bbox_regression: 0.1140 (0.1034)  classification: 0.4863 (0.4810)  time: 0.3675  data: 0.1285  max mem: 3278
Epoch: [61]  [1800/3494]  eta: 0:10:54  lr: 0.0000000  loss: 0.5197 (0.5836)  bbox_regression: 0.0729 (0.1034)  classification: 0.4438 (0.4802)  time: 0.4312  data: 0.1310  max mem: 3278
Epoch: [61]  [1900/3494]  eta: 0:10:14  lr: 0.0000000  loss: 0.5311 (0.5841)  bbox_regression: 0.0753 (0.1034)  classification: 0.4531 (0.4807)  time: 0.3621  data: 0.1284  max mem: 3278
Epoch: [61]  [2000/3494]  eta: 0:09:35  lr: 0.0000000  loss: 0.5283 (0.5841)  bbox_regression: 0.0941 (0.1033)  classification: 0.4304 (0.4809)  time: 0.3830  data: 0.1339  max mem: 3278
Epoch: [61]  [2100/3494]  eta: 0:08:56  lr: 0.0000000  loss: 0.5290 (0.5839)  bbox_regression: 0.0954 (0.1032)  classification: 0.4226 (0.4806)  time: 0.3830  data: 0.1367  max mem: 3278
Epoch: [61]  [2200/3494]  eta: 0:08:17  lr: 0.0000000  loss: 0.5614 (0.5835)  bbox_regression: 0.0916 (0.1032)  classification: 0.4743 (0.4803)  time: 0.3743  data: 0.1317  max mem: 3278
Epoch: [61]  [2300/3494]  eta: 0:07:39  lr: 0.0000000  loss: 0.6065 (0.5835)  bbox_regression: 0.1034 (0.1032)  classification: 0.5027 (0.4804)  time: 0.3646  data: 0.1253  max mem: 3278
Epoch: [61]  [2400/3494]  eta: 0:07:00  lr: 0.0000000  loss: 0.5289 (0.5830)  bbox_regression: 0.0860 (0.1031)  classification: 0.4335 (0.4800)  time: 0.3924  data: 0.1310  max mem: 3278
Epoch: [61]  [2500/3494]  eta: 0:06:23  lr: 0.0000000  loss: 0.5678 (0.5824)  bbox_regression: 0.0991 (0.1031)  classification: 0.4892 (0.4793)  time: 0.4342  data: 0.1384  max mem: 3278
Epoch: [61]  [2600/3494]  eta: 0:05:44  lr: 0.0000000  loss: 0.5771 (0.5829)  bbox_regression: 0.0978 (0.1031)  classification: 0.4756 (0.4798)  time: 0.3723  data: 0.1274  max mem: 3278
Epoch: [61]  [2700/3494]  eta: 0:05:05  lr: 0.0000000  loss: 0.5982 (0.5827)  bbox_regression: 0.1029 (0.1030)  classification: 0.4788 (0.4796)  time: 0.3604  data: 0.1266  max mem: 3278
Epoch: [61]  [2800/3494]  eta: 0:04:26  lr: 0.0000000  loss: 0.5883 (0.5829)  bbox_regression: 0.1042 (0.1031)  classification: 0.4680 (0.4798)  time: 0.3868  data: 0.1432  max mem: 3278
Epoch: [61]  [2900/3494]  eta: 0:03:48  lr: 0.0000000  loss: 0.5467 (0.5830)  bbox_regression: 0.0997 (0.1032)  classification: 0.4557 (0.4799)  time: 0.3857  data: 0.1348  max mem: 3278
Epoch: [61]  [3000/3494]  eta: 0:03:09  lr: 0.0000000  loss: 0.5641 (0.5837)  bbox_regression: 0.0930 (0.1032)  classification: 0.4664 (0.4806)  time: 0.4217  data: 0.1399  max mem: 3278
Epoch: [61]  [3100/3494]  eta: 0:02:31  lr: 0.0000000  loss: 0.5222 (0.5830)  bbox_regression: 0.0955 (0.1031)  classification: 0.4230 (0.4799)  time: 0.3603  data: 0.1240  max mem: 3278
Epoch: [61]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5440 (0.5829)  bbox_regression: 0.0939 (0.1030)  classification: 0.4415 (0.4799)  time: 0.3863  data: 0.1289  max mem: 3278
Epoch: [61]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5304 (0.5834)  bbox_regression: 0.0895 (0.1030)  classification: 0.4467 (0.4804)  time: 0.4089  data: 0.1196  max mem: 3278
Epoch: [61]  [3400/3494]  eta: 0:00:36  lr: 0.0000000  loss: 0.5244 (0.5835)  bbox_regression: 0.0819 (0.1031)  classification: 0.4443 (0.4804)  time: 0.3617  data: 0.1271  max mem: 3278
Epoch: [61]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5720 (0.5831)  bbox_regression: 0.0846 (0.1031)  classification: 0.4781 (0.4800)  time: 0.3676  data: 0.1314  max mem: 3278
Epoch: [61] Total time: 0:22:30 (0.3866 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:46  model_time: 0.1493 (0.1493)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.1663  data: 1.8890  max mem: 3278
Validation:  [100/437]  eta: 0:01:41  model_time: 0.1369 (0.1339)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2814  data: 0.1254  max mem: 3278
Validation:  [200/437]  eta: 0:01:08  model_time: 0.1327 (0.1336)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2749  data: 0.1256  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1225 (0.1315)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2722  data: 0.1280  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1243 (0.1316)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2605  data: 0.1198  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1408 (0.1325)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2923  data: 0.1220  max mem: 3278
Validation: Total time: 0:02:04 (0.2844 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [62]  [   0/3494]  eta: 2:18:13  lr: 0.0000000  loss: 0.4938 (0.4938)  bbox_regression: 0.1069 (0.1069)  classification: 0.3869 (0.3869)  time: 2.3735  data: 2.0989  max mem: 3278
Epoch: [62]  [ 100/3494]  eta: 0:22:15  lr: 0.0000000  loss: 0.6318 (0.5930)  bbox_regression: 0.0963 (0.1048)  classification: 0.4941 (0.4882)  time: 0.3703  data: 0.1272  max mem: 3278
Epoch: [62]  [ 200/3494]  eta: 0:21:39  lr: 0.0000000  loss: 0.5333 (0.5873)  bbox_regression: 0.0974 (0.1030)  classification: 0.4440 (0.4843)  time: 0.3834  data: 0.1321  max mem: 3278
Epoch: [62]  [ 300/3494]  eta: 0:20:48  lr: 0.0000000  loss: 0.5352 (0.5839)  bbox_regression: 0.0905 (0.1031)  classification: 0.4328 (0.4807)  time: 0.3723  data: 0.1333  max mem: 3278
Epoch: [62]  [ 400/3494]  eta: 0:19:55  lr: 0.0000000  loss: 0.5409 (0.5836)  bbox_regression: 0.0948 (0.1032)  classification: 0.4376 (0.4805)  time: 0.3709  data: 0.1340  max mem: 3278
Epoch: [62]  [ 500/3494]  eta: 0:19:08  lr: 0.0000000  loss: 0.5586 (0.5820)  bbox_regression: 0.0946 (0.1036)  classification: 0.4484 (0.4784)  time: 0.3726  data: 0.1313  max mem: 3278
Epoch: [62]  [ 600/3494]  eta: 0:18:24  lr: 0.0000000  loss: 0.5634 (0.5818)  bbox_regression: 0.0958 (0.1032)  classification: 0.4676 (0.4786)  time: 0.3761  data: 0.1293  max mem: 3278
Epoch: [62]  [ 700/3494]  eta: 0:17:48  lr: 0.0000000  loss: 0.5331 (0.5819)  bbox_regression: 0.0924 (0.1032)  classification: 0.4437 (0.4786)  time: 0.3924  data: 0.1368  max mem: 3278
Epoch: [62]  [ 800/3494]  eta: 0:17:11  lr: 0.0000000  loss: 0.5611 (0.5819)  bbox_regression: 0.0871 (0.1031)  classification: 0.4742 (0.4789)  time: 0.3867  data: 0.1375  max mem: 3278
Epoch: [62]  [ 900/3494]  eta: 0:16:32  lr: 0.0000000  loss: 0.5143 (0.5812)  bbox_regression: 0.0936 (0.1030)  classification: 0.4158 (0.4783)  time: 0.3809  data: 0.1334  max mem: 3278
Epoch: [62]  [1000/3494]  eta: 0:15:56  lr: 0.0000000  loss: 0.6130 (0.5822)  bbox_regression: 0.1141 (0.1037)  classification: 0.4902 (0.4786)  time: 0.3974  data: 0.1294  max mem: 3278
Epoch: [62]  [1100/3494]  eta: 0:15:18  lr: 0.0000000  loss: 0.5911 (0.5836)  bbox_regression: 0.0971 (0.1040)  classification: 0.4820 (0.4796)  time: 0.3659  data: 0.1290  max mem: 3278
Epoch: [62]  [1200/3494]  eta: 0:14:39  lr: 0.0000000  loss: 0.5867 (0.5844)  bbox_regression: 0.0934 (0.1035)  classification: 0.4932 (0.4809)  time: 0.3823  data: 0.1379  max mem: 3278
Epoch: [62]  [1300/3494]  eta: 0:14:00  lr: 0.0000000  loss: 0.4911 (0.5841)  bbox_regression: 0.0881 (0.1034)  classification: 0.4065 (0.4807)  time: 0.3760  data: 0.1266  max mem: 3278
Epoch: [62]  [1400/3494]  eta: 0:13:22  lr: 0.0000000  loss: 0.5446 (0.5837)  bbox_regression: 0.0853 (0.1033)  classification: 0.4595 (0.4805)  time: 0.3850  data: 0.1310  max mem: 3278
Epoch: [62]  [1500/3494]  eta: 0:12:44  lr: 0.0000000  loss: 0.5578 (0.5837)  bbox_regression: 0.1084 (0.1033)  classification: 0.4626 (0.4803)  time: 0.4025  data: 0.1462  max mem: 3278
Epoch: [62]  [1600/3494]  eta: 0:12:06  lr: 0.0000000  loss: 0.5454 (0.5833)  bbox_regression: 0.0978 (0.1034)  classification: 0.4407 (0.4799)  time: 0.3711  data: 0.1284  max mem: 3278
Epoch: [62]  [1700/3494]  eta: 0:11:27  lr: 0.0000000  loss: 0.5674 (0.5834)  bbox_regression: 0.0977 (0.1033)  classification: 0.4676 (0.4801)  time: 0.3803  data: 0.1381  max mem: 3278
Epoch: [62]  [1800/3494]  eta: 0:10:48  lr: 0.0000000  loss: 0.5988 (0.5824)  bbox_regression: 0.0930 (0.1030)  classification: 0.4949 (0.4794)  time: 0.3847  data: 0.1280  max mem: 3278
Epoch: [62]  [1900/3494]  eta: 0:10:10  lr: 0.0000000  loss: 0.5667 (0.5821)  bbox_regression: 0.0822 (0.1031)  classification: 0.4553 (0.4790)  time: 0.3834  data: 0.1377  max mem: 3278
Epoch: [62]  [2000/3494]  eta: 0:09:30  lr: 0.0000000  loss: 0.5556 (0.5817)  bbox_regression: 0.0945 (0.1030)  classification: 0.4508 (0.4788)  time: 0.3574  data: 0.1248  max mem: 3278
Epoch: [62]  [2100/3494]  eta: 0:08:52  lr: 0.0000000  loss: 0.5565 (0.5827)  bbox_regression: 0.1187 (0.1032)  classification: 0.4461 (0.4795)  time: 0.3708  data: 0.1309  max mem: 3278
Epoch: [62]  [2200/3494]  eta: 0:08:14  lr: 0.0000000  loss: 0.5135 (0.5827)  bbox_regression: 0.0922 (0.1032)  classification: 0.4238 (0.4795)  time: 0.3671  data: 0.1262  max mem: 3278
Epoch: [62]  [2300/3494]  eta: 0:07:35  lr: 0.0000000  loss: 0.5405 (0.5825)  bbox_regression: 0.0958 (0.1032)  classification: 0.4423 (0.4793)  time: 0.3651  data: 0.1237  max mem: 3278
Epoch: [62]  [2400/3494]  eta: 0:06:57  lr: 0.0000000  loss: 0.5663 (0.5831)  bbox_regression: 0.0965 (0.1032)  classification: 0.4889 (0.4799)  time: 0.3976  data: 0.1446  max mem: 3278
Epoch: [62]  [2500/3494]  eta: 0:06:19  lr: 0.0000000  loss: 0.5705 (0.5830)  bbox_regression: 0.0890 (0.1033)  classification: 0.4403 (0.4798)  time: 0.3821  data: 0.1361  max mem: 3278
Epoch: [62]  [2600/3494]  eta: 0:05:41  lr: 0.0000000  loss: 0.5447 (0.5832)  bbox_regression: 0.0800 (0.1032)  classification: 0.4529 (0.4800)  time: 0.3544  data: 0.1227  max mem: 3278
Epoch: [62]  [2700/3494]  eta: 0:05:02  lr: 0.0000000  loss: 0.6030 (0.5835)  bbox_regression: 0.0980 (0.1033)  classification: 0.4841 (0.4801)  time: 0.3689  data: 0.1349  max mem: 3278
Epoch: [62]  [2800/3494]  eta: 0:04:24  lr: 0.0000000  loss: 0.5263 (0.5830)  bbox_regression: 0.0929 (0.1032)  classification: 0.4271 (0.4798)  time: 0.3952  data: 0.1412  max mem: 3278
Epoch: [62]  [2900/3494]  eta: 0:03:46  lr: 0.0000000  loss: 0.5722 (0.5832)  bbox_regression: 0.0853 (0.1032)  classification: 0.4678 (0.4799)  time: 0.3686  data: 0.1209  max mem: 3278
Epoch: [62]  [3000/3494]  eta: 0:03:08  lr: 0.0000000  loss: 0.5759 (0.5835)  bbox_regression: 0.0968 (0.1032)  classification: 0.4879 (0.4803)  time: 0.3627  data: 0.1267  max mem: 3278
Epoch: [62]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5695 (0.5834)  bbox_regression: 0.1021 (0.1032)  classification: 0.4932 (0.4802)  time: 0.3784  data: 0.1335  max mem: 3278
Epoch: [62]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5358 (0.5835)  bbox_regression: 0.0911 (0.1032)  classification: 0.4443 (0.4803)  time: 0.3949  data: 0.1409  max mem: 3278
Epoch: [62]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.6278 (0.5833)  bbox_regression: 0.1133 (0.1031)  classification: 0.5287 (0.4801)  time: 0.3992  data: 0.1347  max mem: 3278
Epoch: [62]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5261 (0.5836)  bbox_regression: 0.0916 (0.1031)  classification: 0.4419 (0.4804)  time: 0.3560  data: 0.1256  max mem: 3278
Epoch: [62]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5646 (0.5839)  bbox_regression: 0.0960 (0.1032)  classification: 0.4709 (0.4806)  time: 0.3501  data: 0.1202  max mem: 3278
Epoch: [62] Total time: 0:22:18 (0.3832 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:16  model_time: 0.1885 (0.1885)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0975  data: 1.8876  max mem: 3278
Validation:  [100/437]  eta: 0:01:38  model_time: 0.1230 (0.1302)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2616  data: 0.1220  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1333 (0.1286)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2729  data: 0.1239  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1319 (0.1287)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2881  data: 0.1372  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1348 (0.1298)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2829  data: 0.1210  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1332 (0.1300)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2642  data: 0.1178  max mem: 3278
Validation: Total time: 0:02:01 (0.2788 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [63]  [   0/3494]  eta: 2:43:58  lr: 0.0000000  loss: 0.5921 (0.5921)  bbox_regression: 0.1123 (0.1123)  classification: 0.4799 (0.4799)  time: 2.8157  data: 2.5663  max mem: 3278
Epoch: [63]  [ 100/3494]  eta: 0:23:34  lr: 0.0000000  loss: 0.5136 (0.6021)  bbox_regression: 0.0888 (0.1080)  classification: 0.4420 (0.4941)  time: 0.3747  data: 0.1280  max mem: 3278
Epoch: [63]  [ 200/3494]  eta: 0:21:59  lr: 0.0000000  loss: 0.5720 (0.5940)  bbox_regression: 0.0912 (0.1065)  classification: 0.4640 (0.4875)  time: 0.3770  data: 0.1441  max mem: 3278
Epoch: [63]  [ 300/3494]  eta: 0:21:06  lr: 0.0000000  loss: 0.5594 (0.5946)  bbox_regression: 0.0966 (0.1059)  classification: 0.4581 (0.4886)  time: 0.3652  data: 0.1292  max mem: 3278
Epoch: [63]  [ 400/3494]  eta: 0:20:09  lr: 0.0000000  loss: 0.5591 (0.5936)  bbox_regression: 0.0952 (0.1061)  classification: 0.4657 (0.4875)  time: 0.3732  data: 0.1332  max mem: 3278
Epoch: [63]  [ 500/3494]  eta: 0:19:19  lr: 0.0000000  loss: 0.5602 (0.5892)  bbox_regression: 0.0930 (0.1055)  classification: 0.4424 (0.4836)  time: 0.3870  data: 0.1337  max mem: 3278
Epoch: [63]  [ 600/3494]  eta: 0:18:36  lr: 0.0000000  loss: 0.5121 (0.5866)  bbox_regression: 0.0899 (0.1047)  classification: 0.4302 (0.4820)  time: 0.3852  data: 0.1294  max mem: 3278
Epoch: [63]  [ 700/3494]  eta: 0:18:00  lr: 0.0000000  loss: 0.5972 (0.5843)  bbox_regression: 0.0878 (0.1039)  classification: 0.5006 (0.4804)  time: 0.4009  data: 0.1346  max mem: 3278
Epoch: [63]  [ 800/3494]  eta: 0:17:24  lr: 0.0000000  loss: 0.5831 (0.5822)  bbox_regression: 0.0966 (0.1034)  classification: 0.4726 (0.4787)  time: 0.3883  data: 0.1387  max mem: 3278
Epoch: [63]  [ 900/3494]  eta: 0:16:44  lr: 0.0000000  loss: 0.5814 (0.5828)  bbox_regression: 0.1021 (0.1035)  classification: 0.4940 (0.4793)  time: 0.3846  data: 0.1294  max mem: 3278
Epoch: [63]  [1000/3494]  eta: 0:16:04  lr: 0.0000000  loss: 0.5379 (0.5830)  bbox_regression: 0.0855 (0.1034)  classification: 0.4553 (0.4797)  time: 0.3715  data: 0.1254  max mem: 3278
Epoch: [63]  [1100/3494]  eta: 0:15:22  lr: 0.0000000  loss: 0.5551 (0.5827)  bbox_regression: 0.0862 (0.1032)  classification: 0.4754 (0.4795)  time: 0.3676  data: 0.1324  max mem: 3278
Epoch: [63]  [1200/3494]  eta: 0:14:42  lr: 0.0000000  loss: 0.5930 (0.5839)  bbox_regression: 0.1002 (0.1035)  classification: 0.4718 (0.4804)  time: 0.3822  data: 0.1334  max mem: 3278
Epoch: [63]  [1300/3494]  eta: 0:14:03  lr: 0.0000000  loss: 0.5321 (0.5845)  bbox_regression: 0.0974 (0.1037)  classification: 0.4458 (0.4808)  time: 0.3666  data: 0.1240  max mem: 3278
Epoch: [63]  [1400/3494]  eta: 0:13:23  lr: 0.0000000  loss: 0.5687 (0.5836)  bbox_regression: 0.1012 (0.1035)  classification: 0.4803 (0.4800)  time: 0.3807  data: 0.1266  max mem: 3278
Epoch: [63]  [1500/3494]  eta: 0:12:45  lr: 0.0000000  loss: 0.5643 (0.5839)  bbox_regression: 0.0867 (0.1032)  classification: 0.4669 (0.4806)  time: 0.3899  data: 0.1438  max mem: 3278
Epoch: [63]  [1600/3494]  eta: 0:12:08  lr: 0.0000000  loss: 0.5260 (0.5834)  bbox_regression: 0.0974 (0.1032)  classification: 0.4285 (0.4802)  time: 0.3955  data: 0.1448  max mem: 3278
Epoch: [63]  [1700/3494]  eta: 0:11:30  lr: 0.0000000  loss: 0.5530 (0.5832)  bbox_regression: 0.0941 (0.1032)  classification: 0.4589 (0.4799)  time: 0.3659  data: 0.1326  max mem: 3278
Epoch: [63]  [1800/3494]  eta: 0:10:50  lr: 0.0000000  loss: 0.5801 (0.5831)  bbox_regression: 0.1010 (0.1033)  classification: 0.4799 (0.4797)  time: 0.3468  data: 0.1226  max mem: 3278
Epoch: [63]  [1900/3494]  eta: 0:10:10  lr: 0.0000000  loss: 0.6640 (0.5832)  bbox_regression: 0.1052 (0.1033)  classification: 0.5323 (0.4799)  time: 0.3722  data: 0.1324  max mem: 3278
Epoch: [63]  [2000/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5254 (0.5832)  bbox_regression: 0.0877 (0.1034)  classification: 0.4284 (0.4798)  time: 0.3633  data: 0.1272  max mem: 3278
Epoch: [63]  [2100/3494]  eta: 0:08:52  lr: 0.0000000  loss: 0.6303 (0.5828)  bbox_regression: 0.0886 (0.1034)  classification: 0.4982 (0.4795)  time: 0.3663  data: 0.1254  max mem: 3278
Epoch: [63]  [2200/3494]  eta: 0:08:14  lr: 0.0000000  loss: 0.5245 (0.5827)  bbox_regression: 0.0945 (0.1033)  classification: 0.4335 (0.4793)  time: 0.3910  data: 0.1404  max mem: 3278
Epoch: [63]  [2300/3494]  eta: 0:07:36  lr: 0.0000000  loss: 0.5151 (0.5821)  bbox_regression: 0.0826 (0.1033)  classification: 0.4137 (0.4788)  time: 0.3779  data: 0.1338  max mem: 3278
Epoch: [63]  [2400/3494]  eta: 0:06:58  lr: 0.0000000  loss: 0.5658 (0.5826)  bbox_regression: 0.1016 (0.1033)  classification: 0.4642 (0.4792)  time: 0.3907  data: 0.1363  max mem: 3278
Epoch: [63]  [2500/3494]  eta: 0:06:20  lr: 0.0000000  loss: 0.6098 (0.5831)  bbox_regression: 0.1017 (0.1034)  classification: 0.5074 (0.4796)  time: 0.3752  data: 0.1276  max mem: 3278
Epoch: [63]  [2600/3494]  eta: 0:05:41  lr: 0.0000000  loss: 0.5770 (0.5825)  bbox_regression: 0.0912 (0.1033)  classification: 0.4762 (0.4792)  time: 0.3531  data: 0.1237  max mem: 3278
Epoch: [63]  [2700/3494]  eta: 0:05:02  lr: 0.0000000  loss: 0.5409 (0.5829)  bbox_regression: 0.0872 (0.1033)  classification: 0.4531 (0.4796)  time: 0.3646  data: 0.1218  max mem: 3278
Epoch: [63]  [2800/3494]  eta: 0:04:24  lr: 0.0000000  loss: 0.5651 (0.5826)  bbox_regression: 0.1006 (0.1032)  classification: 0.4711 (0.4794)  time: 0.3925  data: 0.1407  max mem: 3278
Epoch: [63]  [2900/3494]  eta: 0:03:46  lr: 0.0000000  loss: 0.5727 (0.5829)  bbox_regression: 0.0853 (0.1032)  classification: 0.4661 (0.4796)  time: 0.3699  data: 0.1224  max mem: 3278
Epoch: [63]  [3000/3494]  eta: 0:03:08  lr: 0.0000000  loss: 0.5701 (0.5829)  bbox_regression: 0.1053 (0.1032)  classification: 0.4595 (0.4797)  time: 0.3934  data: 0.1328  max mem: 3278
Epoch: [63]  [3100/3494]  eta: 0:02:30  lr: 0.0000000  loss: 0.5849 (0.5833)  bbox_regression: 0.1098 (0.1033)  classification: 0.4533 (0.4800)  time: 0.3716  data: 0.1298  max mem: 3278
Epoch: [63]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5626 (0.5833)  bbox_regression: 0.0951 (0.1032)  classification: 0.4788 (0.4801)  time: 0.3703  data: 0.1353  max mem: 3278
Epoch: [63]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.6367 (0.5831)  bbox_regression: 0.1030 (0.1030)  classification: 0.5366 (0.4801)  time: 0.3724  data: 0.1286  max mem: 3278
Epoch: [63]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5275 (0.5828)  bbox_regression: 0.1048 (0.1030)  classification: 0.4172 (0.4798)  time: 0.3672  data: 0.1269  max mem: 3278
Epoch: [63]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5791 (0.5826)  bbox_regression: 0.0919 (0.1030)  classification: 0.4788 (0.4796)  time: 0.3634  data: 0.1303  max mem: 3278
Epoch: [63] Total time: 0:22:22 (0.3841 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:35  model_time: 0.1553 (0.1553)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5525  data: 2.3765  max mem: 3278
Validation:  [100/437]  eta: 0:01:42  model_time: 0.1321 (0.1391)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2750  data: 0.1243  max mem: 3278
Validation:  [200/437]  eta: 0:01:09  model_time: 0.1325 (0.1364)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2991  data: 0.1443  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1340 (0.1357)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2872  data: 0.1305  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1407 (0.1370)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2970  data: 0.1298  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1342 (0.1369)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2697  data: 0.1193  max mem: 3278
Validation: Total time: 0:02:06 (0.2902 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [64]  [   0/3494]  eta: 2:40:12  lr: 0.0000000  loss: 0.5880 (0.5880)  bbox_regression: 0.1331 (0.1331)  classification: 0.4548 (0.4548)  time: 2.7510  data: 2.4683  max mem: 3278
Epoch: [64]  [ 100/3494]  eta: 0:22:46  lr: 0.0000000  loss: 0.5906 (0.5691)  bbox_regression: 0.1045 (0.0999)  classification: 0.4599 (0.4692)  time: 0.3771  data: 0.1397  max mem: 3278
Epoch: [64]  [ 200/3494]  eta: 0:21:37  lr: 0.0000000  loss: 0.5590 (0.5848)  bbox_regression: 0.1046 (0.1043)  classification: 0.4567 (0.4805)  time: 0.4198  data: 0.1319  max mem: 3278
Epoch: [64]  [ 300/3494]  eta: 0:20:36  lr: 0.0000000  loss: 0.5605 (0.5834)  bbox_regression: 0.0964 (0.1032)  classification: 0.4482 (0.4802)  time: 0.3726  data: 0.1352  max mem: 3278
Epoch: [64]  [ 400/3494]  eta: 0:19:45  lr: 0.0000000  loss: 0.5558 (0.5820)  bbox_regression: 0.1016 (0.1034)  classification: 0.4727 (0.4787)  time: 0.3629  data: 0.1236  max mem: 3278
Epoch: [64]  [ 500/3494]  eta: 0:19:04  lr: 0.0000000  loss: 0.5842 (0.5798)  bbox_regression: 0.0930 (0.1024)  classification: 0.4849 (0.4774)  time: 0.3866  data: 0.1370  max mem: 3278
Epoch: [64]  [ 600/3494]  eta: 0:18:21  lr: 0.0000000  loss: 0.5876 (0.5796)  bbox_regression: 0.0922 (0.1023)  classification: 0.4722 (0.4773)  time: 0.3758  data: 0.1321  max mem: 3278
Epoch: [64]  [ 700/3494]  eta: 0:17:51  lr: 0.0000000  loss: 0.5289 (0.5823)  bbox_regression: 0.0924 (0.1029)  classification: 0.4488 (0.4793)  time: 0.4156  data: 0.1549  max mem: 3278
Epoch: [64]  [ 800/3494]  eta: 0:17:12  lr: 0.0000000  loss: 0.5654 (0.5825)  bbox_regression: 0.0873 (0.1030)  classification: 0.4453 (0.4795)  time: 0.3744  data: 0.1290  max mem: 3278
Epoch: [64]  [ 900/3494]  eta: 0:16:34  lr: 0.0000000  loss: 0.5985 (0.5830)  bbox_regression: 0.1015 (0.1026)  classification: 0.5049 (0.4804)  time: 0.3735  data: 0.1339  max mem: 3278
Epoch: [64]  [1000/3494]  eta: 0:15:55  lr: 0.0000000  loss: 0.5511 (0.5830)  bbox_regression: 0.1059 (0.1028)  classification: 0.4269 (0.4802)  time: 0.3527  data: 0.1254  max mem: 3278
Epoch: [64]  [1100/3494]  eta: 0:15:14  lr: 0.0000000  loss: 0.5137 (0.5817)  bbox_regression: 0.0970 (0.1027)  classification: 0.4258 (0.4790)  time: 0.3748  data: 0.1312  max mem: 3278
Epoch: [64]  [1200/3494]  eta: 0:14:32  lr: 0.0000000  loss: 0.5878 (0.5826)  bbox_regression: 0.1090 (0.1031)  classification: 0.4811 (0.4795)  time: 0.3756  data: 0.1251  max mem: 3278
Epoch: [64]  [1300/3494]  eta: 0:13:55  lr: 0.0000000  loss: 0.5685 (0.5826)  bbox_regression: 0.1012 (0.1034)  classification: 0.4722 (0.4792)  time: 0.3755  data: 0.1255  max mem: 3278
Epoch: [64]  [1400/3494]  eta: 0:13:18  lr: 0.0000000  loss: 0.5281 (0.5833)  bbox_regression: 0.1022 (0.1034)  classification: 0.4456 (0.4799)  time: 0.3804  data: 0.1284  max mem: 3278
Epoch: [64]  [1500/3494]  eta: 0:12:42  lr: 0.0000000  loss: 0.5401 (0.5841)  bbox_regression: 0.0983 (0.1034)  classification: 0.4660 (0.4807)  time: 0.3874  data: 0.1389  max mem: 3278
Epoch: [64]  [1600/3494]  eta: 0:12:05  lr: 0.0000000  loss: 0.5809 (0.5842)  bbox_regression: 0.0885 (0.1035)  classification: 0.4536 (0.4807)  time: 0.3681  data: 0.1316  max mem: 3278
Epoch: [64]  [1700/3494]  eta: 0:11:27  lr: 0.0000000  loss: 0.5726 (0.5849)  bbox_regression: 0.0900 (0.1035)  classification: 0.4908 (0.4814)  time: 0.3599  data: 0.1251  max mem: 3278
Epoch: [64]  [1800/3494]  eta: 0:10:48  lr: 0.0000000  loss: 0.5498 (0.5836)  bbox_regression: 0.0980 (0.1033)  classification: 0.4552 (0.4803)  time: 0.3692  data: 0.1294  max mem: 3278
Epoch: [64]  [1900/3494]  eta: 0:10:09  lr: 0.0000000  loss: 0.5691 (0.5845)  bbox_regression: 0.0914 (0.1033)  classification: 0.4779 (0.4811)  time: 0.3727  data: 0.1223  max mem: 3278
Epoch: [64]  [2000/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5847 (0.5847)  bbox_regression: 0.0986 (0.1032)  classification: 0.4836 (0.4814)  time: 0.3777  data: 0.1326  max mem: 3278
Epoch: [64]  [2100/3494]  eta: 0:08:52  lr: 0.0000000  loss: 0.5811 (0.5850)  bbox_regression: 0.0922 (0.1033)  classification: 0.4880 (0.4817)  time: 0.3878  data: 0.1395  max mem: 3278
Epoch: [64]  [2200/3494]  eta: 0:08:15  lr: 0.0000000  loss: 0.6149 (0.5845)  bbox_regression: 0.1184 (0.1031)  classification: 0.4992 (0.4814)  time: 0.3868  data: 0.1390  max mem: 3278
Epoch: [64]  [2300/3494]  eta: 0:07:37  lr: 0.0000000  loss: 0.5700 (0.5842)  bbox_regression: 0.0933 (0.1031)  classification: 0.4767 (0.4811)  time: 0.3990  data: 0.1526  max mem: 3278
Epoch: [64]  [2400/3494]  eta: 0:06:59  lr: 0.0000000  loss: 0.5651 (0.5846)  bbox_regression: 0.0912 (0.1032)  classification: 0.4721 (0.4814)  time: 0.4168  data: 0.1372  max mem: 3278
Epoch: [64]  [2500/3494]  eta: 0:06:20  lr: 0.0000000  loss: 0.5407 (0.5841)  bbox_regression: 0.0958 (0.1032)  classification: 0.4388 (0.4809)  time: 0.3721  data: 0.1318  max mem: 3278
Epoch: [64]  [2600/3494]  eta: 0:05:42  lr: 0.0000000  loss: 0.5333 (0.5840)  bbox_regression: 0.0953 (0.1030)  classification: 0.4227 (0.4810)  time: 0.3997  data: 0.1493  max mem: 3278
Epoch: [64]  [2700/3494]  eta: 0:05:04  lr: 0.0000000  loss: 0.5447 (0.5839)  bbox_regression: 0.0967 (0.1031)  classification: 0.4598 (0.4808)  time: 0.3933  data: 0.1402  max mem: 3278
Epoch: [64]  [2800/3494]  eta: 0:04:25  lr: 0.0000000  loss: 0.5825 (0.5837)  bbox_regression: 0.0983 (0.1031)  classification: 0.4763 (0.4806)  time: 0.3963  data: 0.1399  max mem: 3278
Epoch: [64]  [2900/3494]  eta: 0:03:47  lr: 0.0000000  loss: 0.5732 (0.5836)  bbox_regression: 0.0961 (0.1030)  classification: 0.4612 (0.4806)  time: 0.3674  data: 0.1244  max mem: 3278
Epoch: [64]  [3000/3494]  eta: 0:03:09  lr: 0.0000000  loss: 0.5563 (0.5840)  bbox_regression: 0.1015 (0.1032)  classification: 0.4514 (0.4808)  time: 0.3792  data: 0.1330  max mem: 3278
Epoch: [64]  [3100/3494]  eta: 0:02:31  lr: 0.0000000  loss: 0.5442 (0.5833)  bbox_regression: 0.0926 (0.1030)  classification: 0.4380 (0.4803)  time: 0.4164  data: 0.1330  max mem: 3278
Epoch: [64]  [3200/3494]  eta: 0:01:52  lr: 0.0000000  loss: 0.5740 (0.5833)  bbox_regression: 0.1008 (0.1030)  classification: 0.4730 (0.4803)  time: 0.3674  data: 0.1272  max mem: 3278
Epoch: [64]  [3300/3494]  eta: 0:01:14  lr: 0.0000000  loss: 0.5599 (0.5834)  bbox_regression: 0.1117 (0.1030)  classification: 0.4549 (0.4804)  time: 0.3710  data: 0.1291  max mem: 3278
Epoch: [64]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5590 (0.5832)  bbox_regression: 0.0953 (0.1030)  classification: 0.4670 (0.4802)  time: 0.3890  data: 0.1371  max mem: 3278
Epoch: [64]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5308 (0.5826)  bbox_regression: 0.0849 (0.1030)  classification: 0.4487 (0.4796)  time: 0.3741  data: 0.1371  max mem: 3278
Epoch: [64] Total time: 0:22:25 (0.3852 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:33  model_time: 0.1153 (0.1153)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.4110  data: 2.2584  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1402 (0.1344)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2835  data: 0.1269  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1301 (0.1315)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2677  data: 0.1208  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1322 (0.1340)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2674  data: 0.1204  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1282 (0.1336)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2732  data: 0.1246  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1383 (0.1337)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2730  data: 0.1232  max mem: 3278
Validation: Total time: 0:02:03 (0.2818 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [65]  [   0/3494]  eta: 2:29:32  lr: 0.0000000  loss: 0.5601 (0.5601)  bbox_regression: 0.0938 (0.0938)  classification: 0.4663 (0.4663)  time: 2.5679  data: 2.2854  max mem: 3278
Epoch: [65]  [ 100/3494]  eta: 0:22:58  lr: 0.0000000  loss: 0.5858 (0.5819)  bbox_regression: 0.0944 (0.0990)  classification: 0.4670 (0.4830)  time: 0.3554  data: 0.1277  max mem: 3278
Epoch: [65]  [ 200/3494]  eta: 0:21:24  lr: 0.0000000  loss: 0.5695 (0.5900)  bbox_regression: 0.1120 (0.1028)  classification: 0.4574 (0.4872)  time: 0.3679  data: 0.1312  max mem: 3278
Epoch: [65]  [ 300/3494]  eta: 0:20:27  lr: 0.0000000  loss: 0.5854 (0.5907)  bbox_regression: 0.0945 (0.1033)  classification: 0.4677 (0.4875)  time: 0.3889  data: 0.1402  max mem: 3278
Epoch: [65]  [ 400/3494]  eta: 0:19:42  lr: 0.0000000  loss: 0.5519 (0.5901)  bbox_regression: 0.1011 (0.1029)  classification: 0.4510 (0.4872)  time: 0.3763  data: 0.1328  max mem: 3278
Epoch: [65]  [ 500/3494]  eta: 0:18:59  lr: 0.0000000  loss: 0.5356 (0.5905)  bbox_regression: 0.0958 (0.1028)  classification: 0.4582 (0.4876)  time: 0.3790  data: 0.1279  max mem: 3278
Epoch: [65]  [ 600/3494]  eta: 0:18:28  lr: 0.0000000  loss: 0.5918 (0.5898)  bbox_regression: 0.1006 (0.1037)  classification: 0.4657 (0.4861)  time: 0.3842  data: 0.1387  max mem: 3278
Epoch: [65]  [ 700/3494]  eta: 0:17:47  lr: 0.0000000  loss: 0.5697 (0.5892)  bbox_regression: 0.0905 (0.1036)  classification: 0.4708 (0.4856)  time: 0.3740  data: 0.1285  max mem: 3278
Epoch: [65]  [ 800/3494]  eta: 0:17:11  lr: 0.0000000  loss: 0.5284 (0.5867)  bbox_regression: 0.0972 (0.1033)  classification: 0.4312 (0.4834)  time: 0.3738  data: 0.1311  max mem: 3278
Epoch: [65]  [ 900/3494]  eta: 0:16:27  lr: 0.0000000  loss: 0.5888 (0.5864)  bbox_regression: 0.1037 (0.1036)  classification: 0.4901 (0.4828)  time: 0.3623  data: 0.1261  max mem: 3278
Epoch: [65]  [1000/3494]  eta: 0:15:48  lr: 0.0000000  loss: 0.5459 (0.5847)  bbox_regression: 0.0967 (0.1037)  classification: 0.4518 (0.4810)  time: 0.3818  data: 0.1403  max mem: 3278
Epoch: [65]  [1100/3494]  eta: 0:15:08  lr: 0.0000000  loss: 0.5595 (0.5846)  bbox_regression: 0.0890 (0.1042)  classification: 0.4504 (0.4804)  time: 0.3828  data: 0.1388  max mem: 3278
Epoch: [65]  [1200/3494]  eta: 0:14:29  lr: 0.0000000  loss: 0.5992 (0.5841)  bbox_regression: 0.0875 (0.1039)  classification: 0.5018 (0.4803)  time: 0.3780  data: 0.1354  max mem: 3278
Epoch: [65]  [1300/3494]  eta: 0:13:52  lr: 0.0000000  loss: 0.5990 (0.5844)  bbox_regression: 0.0984 (0.1034)  classification: 0.5126 (0.4810)  time: 0.3868  data: 0.1417  max mem: 3278
Epoch: [65]  [1400/3494]  eta: 0:13:14  lr: 0.0000000  loss: 0.5988 (0.5840)  bbox_regression: 0.0941 (0.1032)  classification: 0.4998 (0.4808)  time: 0.3765  data: 0.1306  max mem: 3278
Epoch: [65]  [1500/3494]  eta: 0:12:37  lr: 0.0000000  loss: 0.5913 (0.5851)  bbox_regression: 0.0966 (0.1034)  classification: 0.4913 (0.4818)  time: 0.3786  data: 0.1425  max mem: 3278
Epoch: [65]  [1600/3494]  eta: 0:11:57  lr: 0.0000000  loss: 0.5326 (0.5847)  bbox_regression: 0.0877 (0.1032)  classification: 0.4411 (0.4815)  time: 0.3623  data: 0.1300  max mem: 3278
Epoch: [65]  [1700/3494]  eta: 0:11:18  lr: 0.0000000  loss: 0.4994 (0.5840)  bbox_regression: 0.0806 (0.1031)  classification: 0.4153 (0.4809)  time: 0.3567  data: 0.1239  max mem: 3278
Epoch: [65]  [1800/3494]  eta: 0:10:40  lr: 0.0000000  loss: 0.5839 (0.5846)  bbox_regression: 0.1016 (0.1032)  classification: 0.4640 (0.4814)  time: 0.3870  data: 0.1442  max mem: 3278
Epoch: [65]  [1900/3494]  eta: 0:10:02  lr: 0.0000000  loss: 0.5858 (0.5844)  bbox_regression: 0.0954 (0.1031)  classification: 0.4790 (0.4814)  time: 0.3820  data: 0.1372  max mem: 3278
Epoch: [65]  [2000/3494]  eta: 0:09:25  lr: 0.0000000  loss: 0.5546 (0.5835)  bbox_regression: 0.0957 (0.1029)  classification: 0.4548 (0.4806)  time: 0.4008  data: 0.1355  max mem: 3278
Epoch: [65]  [2100/3494]  eta: 0:08:47  lr: 0.0000000  loss: 0.5282 (0.5828)  bbox_regression: 0.1009 (0.1029)  classification: 0.4285 (0.4798)  time: 0.3788  data: 0.1319  max mem: 3278
Epoch: [65]  [2200/3494]  eta: 0:08:10  lr: 0.0000000  loss: 0.5109 (0.5816)  bbox_regression: 0.0860 (0.1026)  classification: 0.4240 (0.4791)  time: 0.4188  data: 0.1265  max mem: 3278
Epoch: [65]  [2300/3494]  eta: 0:07:32  lr: 0.0000000  loss: 0.5297 (0.5823)  bbox_regression: 0.0938 (0.1027)  classification: 0.4434 (0.4796)  time: 0.3732  data: 0.1257  max mem: 3278
Epoch: [65]  [2400/3494]  eta: 0:06:53  lr: 0.0000000  loss: 0.5532 (0.5823)  bbox_regression: 0.1080 (0.1028)  classification: 0.4451 (0.4796)  time: 0.3614  data: 0.1273  max mem: 3278
Epoch: [65]  [2500/3494]  eta: 0:06:15  lr: 0.0000000  loss: 0.5248 (0.5820)  bbox_regression: 0.0901 (0.1027)  classification: 0.4430 (0.4793)  time: 0.3832  data: 0.1342  max mem: 3278
Epoch: [65]  [2600/3494]  eta: 0:05:37  lr: 0.0000000  loss: 0.5738 (0.5821)  bbox_regression: 0.0927 (0.1028)  classification: 0.4741 (0.4793)  time: 0.3756  data: 0.1254  max mem: 3278
Epoch: [65]  [2700/3494]  eta: 0:05:00  lr: 0.0000000  loss: 0.5305 (0.5813)  bbox_regression: 0.0899 (0.1026)  classification: 0.4514 (0.4787)  time: 0.4068  data: 0.1281  max mem: 3278
Epoch: [65]  [2800/3494]  eta: 0:04:22  lr: 0.0000000  loss: 0.5413 (0.5811)  bbox_regression: 0.0933 (0.1026)  classification: 0.4435 (0.4786)  time: 0.3576  data: 0.1254  max mem: 3278
Epoch: [65]  [2900/3494]  eta: 0:03:44  lr: 0.0000000  loss: 0.5505 (0.5812)  bbox_regression: 0.0979 (0.1026)  classification: 0.4435 (0.4786)  time: 0.3676  data: 0.1252  max mem: 3278
Epoch: [65]  [3000/3494]  eta: 0:03:06  lr: 0.0000000  loss: 0.5741 (0.5817)  bbox_regression: 0.1064 (0.1028)  classification: 0.4821 (0.4789)  time: 0.3920  data: 0.1467  max mem: 3278
Epoch: [65]  [3100/3494]  eta: 0:02:28  lr: 0.0000000  loss: 0.6367 (0.5817)  bbox_regression: 0.1109 (0.1029)  classification: 0.4809 (0.4788)  time: 0.3601  data: 0.1298  max mem: 3278
Epoch: [65]  [3200/3494]  eta: 0:01:50  lr: 0.0000000  loss: 0.6383 (0.5822)  bbox_regression: 0.1009 (0.1029)  classification: 0.5437 (0.4793)  time: 0.3809  data: 0.1335  max mem: 3278
Epoch: [65]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.4887 (0.5820)  bbox_regression: 0.0852 (0.1029)  classification: 0.4020 (0.4791)  time: 0.3685  data: 0.1247  max mem: 3278
Epoch: [65]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5526 (0.5823)  bbox_regression: 0.0986 (0.1030)  classification: 0.4565 (0.4793)  time: 0.3894  data: 0.1272  max mem: 3278
Epoch: [65]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5499 (0.5826)  bbox_regression: 0.0888 (0.1029)  classification: 0.4562 (0.4796)  time: 0.3610  data: 0.1225  max mem: 3278
Epoch: [65] Total time: 0:22:06 (0.3798 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:31  model_time: 0.1449 (0.1449)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5444  data: 2.3736  max mem: 3278
Validation:  [100/437]  eta: 0:01:40  model_time: 0.1253 (0.1322)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2641  data: 0.1225  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1277 (0.1301)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2840  data: 0.1260  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1244 (0.1334)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3097  data: 0.1217  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1163 (0.1316)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2634  data: 0.1249  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1187 (0.1307)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2533  data: 0.1173  max mem: 3278
Validation: Total time: 0:02:01 (0.2785 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [66]  [   0/3494]  eta: 2:03:32  lr: 0.0000000  loss: 0.6581 (0.6581)  bbox_regression: 0.1669 (0.1669)  classification: 0.4912 (0.4912)  time: 2.1216  data: 1.8703  max mem: 3278
Epoch: [66]  [ 100/3494]  eta: 0:21:36  lr: 0.0000000  loss: 0.4988 (0.5729)  bbox_regression: 0.0837 (0.0987)  classification: 0.4253 (0.4742)  time: 0.3833  data: 0.1413  max mem: 3278
Epoch: [66]  [ 200/3494]  eta: 0:20:53  lr: 0.0000000  loss: 0.5449 (0.5705)  bbox_regression: 0.0988 (0.0993)  classification: 0.4663 (0.4711)  time: 0.3664  data: 0.1259  max mem: 3278
Epoch: [66]  [ 300/3494]  eta: 0:20:21  lr: 0.0000000  loss: 0.5724 (0.5726)  bbox_regression: 0.0964 (0.1019)  classification: 0.4929 (0.4707)  time: 0.4305  data: 0.1455  max mem: 3278
Epoch: [66]  [ 400/3494]  eta: 0:19:40  lr: 0.0000000  loss: 0.5912 (0.5727)  bbox_regression: 0.1040 (0.1023)  classification: 0.4916 (0.4703)  time: 0.3661  data: 0.1274  max mem: 3278
Epoch: [66]  [ 500/3494]  eta: 0:19:01  lr: 0.0000000  loss: 0.5559 (0.5751)  bbox_regression: 0.0933 (0.1023)  classification: 0.4515 (0.4728)  time: 0.3762  data: 0.1326  max mem: 3278
Epoch: [66]  [ 600/3494]  eta: 0:18:22  lr: 0.0000000  loss: 0.6372 (0.5802)  bbox_regression: 0.1020 (0.1030)  classification: 0.5311 (0.4773)  time: 0.3951  data: 0.1254  max mem: 3278
Epoch: [66]  [ 700/3494]  eta: 0:17:41  lr: 0.0000000  loss: 0.5333 (0.5811)  bbox_regression: 0.1031 (0.1036)  classification: 0.4482 (0.4775)  time: 0.3594  data: 0.1284  max mem: 3278
Epoch: [66]  [ 800/3494]  eta: 0:17:00  lr: 0.0000000  loss: 0.5378 (0.5770)  bbox_regression: 0.1047 (0.1034)  classification: 0.4367 (0.4736)  time: 0.3814  data: 0.1312  max mem: 3278
Epoch: [66]  [ 900/3494]  eta: 0:16:20  lr: 0.0000000  loss: 0.6101 (0.5771)  bbox_regression: 0.1031 (0.1031)  classification: 0.4975 (0.4741)  time: 0.3697  data: 0.1281  max mem: 3278
Epoch: [66]  [1000/3494]  eta: 0:15:43  lr: 0.0000000  loss: 0.5487 (0.5772)  bbox_regression: 0.1015 (0.1029)  classification: 0.4394 (0.4743)  time: 0.3841  data: 0.1325  max mem: 3278
Epoch: [66]  [1100/3494]  eta: 0:15:08  lr: 0.0000000  loss: 0.5140 (0.5764)  bbox_regression: 0.0866 (0.1027)  classification: 0.4242 (0.4738)  time: 0.3881  data: 0.1436  max mem: 3278
Epoch: [66]  [1200/3494]  eta: 0:14:30  lr: 0.0000000  loss: 0.5273 (0.5765)  bbox_regression: 0.0878 (0.1027)  classification: 0.4421 (0.4738)  time: 0.3782  data: 0.1395  max mem: 3278
Epoch: [66]  [1300/3494]  eta: 0:13:52  lr: 0.0000000  loss: 0.5702 (0.5779)  bbox_regression: 0.0930 (0.1028)  classification: 0.4744 (0.4752)  time: 0.3770  data: 0.1298  max mem: 3278
Epoch: [66]  [1400/3494]  eta: 0:13:15  lr: 0.0000000  loss: 0.5764 (0.5787)  bbox_regression: 0.0880 (0.1029)  classification: 0.5006 (0.4758)  time: 0.3725  data: 0.1351  max mem: 3278
Epoch: [66]  [1500/3494]  eta: 0:12:35  lr: 0.0000000  loss: 0.5106 (0.5786)  bbox_regression: 0.0818 (0.1028)  classification: 0.4246 (0.4757)  time: 0.3787  data: 0.1354  max mem: 3278
Epoch: [66]  [1600/3494]  eta: 0:11:56  lr: 0.0000000  loss: 0.6070 (0.5783)  bbox_regression: 0.1045 (0.1026)  classification: 0.4853 (0.4757)  time: 0.3680  data: 0.1306  max mem: 3278
Epoch: [66]  [1700/3494]  eta: 0:11:18  lr: 0.0000000  loss: 0.6079 (0.5793)  bbox_regression: 0.1016 (0.1026)  classification: 0.4741 (0.4767)  time: 0.3747  data: 0.1301  max mem: 3278
Epoch: [66]  [1800/3494]  eta: 0:10:40  lr: 0.0000000  loss: 0.5423 (0.5795)  bbox_regression: 0.0927 (0.1027)  classification: 0.4657 (0.4768)  time: 0.3961  data: 0.1370  max mem: 3278
Epoch: [66]  [1900/3494]  eta: 0:10:02  lr: 0.0000000  loss: 0.6363 (0.5809)  bbox_regression: 0.1197 (0.1032)  classification: 0.5026 (0.4776)  time: 0.3658  data: 0.1239  max mem: 3278
Epoch: [66]  [2000/3494]  eta: 0:09:24  lr: 0.0000000  loss: 0.6235 (0.5812)  bbox_regression: 0.1038 (0.1031)  classification: 0.5198 (0.4780)  time: 0.3598  data: 0.1285  max mem: 3278
Epoch: [66]  [2100/3494]  eta: 0:08:47  lr: 0.0000000  loss: 0.5229 (0.5817)  bbox_regression: 0.0922 (0.1031)  classification: 0.4387 (0.4786)  time: 0.3601  data: 0.1336  max mem: 3278
Epoch: [66]  [2200/3494]  eta: 0:08:08  lr: 0.0000000  loss: 0.5910 (0.5816)  bbox_regression: 0.0996 (0.1030)  classification: 0.4876 (0.4786)  time: 0.4082  data: 0.1463  max mem: 3278
Epoch: [66]  [2300/3494]  eta: 0:07:32  lr: 0.0000000  loss: 0.5375 (0.5815)  bbox_regression: 0.0870 (0.1030)  classification: 0.4421 (0.4785)  time: 0.3689  data: 0.1224  max mem: 3278
Epoch: [66]  [2400/3494]  eta: 0:06:54  lr: 0.0000000  loss: 0.5735 (0.5821)  bbox_regression: 0.0864 (0.1031)  classification: 0.4747 (0.4791)  time: 0.3871  data: 0.1324  max mem: 3278
Epoch: [66]  [2500/3494]  eta: 0:06:17  lr: 0.0000000  loss: 0.5641 (0.5818)  bbox_regression: 0.0850 (0.1030)  classification: 0.4661 (0.4788)  time: 0.3832  data: 0.1264  max mem: 3278
Epoch: [66]  [2600/3494]  eta: 0:05:38  lr: 0.0000000  loss: 0.5327 (0.5816)  bbox_regression: 0.0901 (0.1028)  classification: 0.4195 (0.4788)  time: 0.3638  data: 0.1225  max mem: 3278
Epoch: [66]  [2700/3494]  eta: 0:05:01  lr: 0.0000000  loss: 0.6034 (0.5823)  bbox_regression: 0.1029 (0.1030)  classification: 0.4878 (0.4793)  time: 0.3847  data: 0.1340  max mem: 3278
Epoch: [66]  [2800/3494]  eta: 0:04:23  lr: 0.0000000  loss: 0.5368 (0.5821)  bbox_regression: 0.0938 (0.1029)  classification: 0.4650 (0.4792)  time: 0.3576  data: 0.1277  max mem: 3278
Epoch: [66]  [2900/3494]  eta: 0:03:45  lr: 0.0000000  loss: 0.6117 (0.5822)  bbox_regression: 0.1038 (0.1030)  classification: 0.4863 (0.4793)  time: 0.3741  data: 0.1339  max mem: 3278
Epoch: [66]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.5666 (0.5826)  bbox_regression: 0.1027 (0.1030)  classification: 0.4730 (0.4796)  time: 0.3718  data: 0.1330  max mem: 3278
Epoch: [66]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5381 (0.5828)  bbox_regression: 0.0935 (0.1031)  classification: 0.4532 (0.4797)  time: 0.3913  data: 0.1351  max mem: 3278
Epoch: [66]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5707 (0.5829)  bbox_regression: 0.0920 (0.1030)  classification: 0.4711 (0.4799)  time: 0.3839  data: 0.1276  max mem: 3278
Epoch: [66]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5040 (0.5827)  bbox_regression: 0.0794 (0.1030)  classification: 0.4155 (0.4798)  time: 0.3775  data: 0.1368  max mem: 3278
Epoch: [66]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5030 (0.5825)  bbox_regression: 0.0967 (0.1029)  classification: 0.4371 (0.4796)  time: 0.3843  data: 0.1294  max mem: 3278
Epoch: [66]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.6843 (0.5827)  bbox_regression: 0.1041 (0.1029)  classification: 0.5661 (0.4798)  time: 0.3483  data: 0.1231  max mem: 3278
Epoch: [66] Total time: 0:22:13 (0.3817 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:53  model_time: 0.2847 (0.2847)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.7700  data: 1.4450  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1184 (0.1283)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2614  data: 0.1232  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1185 (0.1253)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2705  data: 0.1312  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1325 (0.1264)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2666  data: 0.1191  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1243 (0.1262)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2640  data: 0.1223  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1333 (0.1266)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2656  data: 0.1173  max mem: 3278
Validation: Total time: 0:01:58 (0.2712 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [67]  [   0/3494]  eta: 2:36:14  lr: 0.0000000  loss: 0.4424 (0.4424)  bbox_regression: 0.0927 (0.0927)  classification: 0.3497 (0.3497)  time: 2.6832  data: 2.4262  max mem: 3278
Epoch: [67]  [ 100/3494]  eta: 0:23:49  lr: 0.0000000  loss: 0.5772 (0.5909)  bbox_regression: 0.0996 (0.1046)  classification: 0.4680 (0.4863)  time: 0.4046  data: 0.1432  max mem: 3278
Epoch: [67]  [ 200/3494]  eta: 0:22:05  lr: 0.0000000  loss: 0.5482 (0.5816)  bbox_regression: 0.0971 (0.1025)  classification: 0.4604 (0.4791)  time: 0.3497  data: 0.1200  max mem: 3278
Epoch: [67]  [ 300/3494]  eta: 0:21:03  lr: 0.0000000  loss: 0.5943 (0.5831)  bbox_regression: 0.0945 (0.1021)  classification: 0.4873 (0.4810)  time: 0.3889  data: 0.1320  max mem: 3278
Epoch: [67]  [ 400/3494]  eta: 0:20:16  lr: 0.0000000  loss: 0.6093 (0.5834)  bbox_regression: 0.1035 (0.1024)  classification: 0.4980 (0.4810)  time: 0.3649  data: 0.1314  max mem: 3278
Epoch: [67]  [ 500/3494]  eta: 0:19:21  lr: 0.0000000  loss: 0.5962 (0.5808)  bbox_regression: 0.1090 (0.1030)  classification: 0.4978 (0.4779)  time: 0.3550  data: 0.1232  max mem: 3278
Epoch: [67]  [ 600/3494]  eta: 0:18:35  lr: 0.0000000  loss: 0.5692 (0.5808)  bbox_regression: 0.0869 (0.1031)  classification: 0.4768 (0.4778)  time: 0.3749  data: 0.1258  max mem: 3278
Epoch: [67]  [ 700/3494]  eta: 0:17:55  lr: 0.0000000  loss: 0.5676 (0.5834)  bbox_regression: 0.0975 (0.1031)  classification: 0.4752 (0.4803)  time: 0.3644  data: 0.1321  max mem: 3278
Epoch: [67]  [ 800/3494]  eta: 0:17:12  lr: 0.0000000  loss: 0.5278 (0.5809)  bbox_regression: 0.0838 (0.1025)  classification: 0.4429 (0.4784)  time: 0.3616  data: 0.1239  max mem: 3278
Epoch: [67]  [ 900/3494]  eta: 0:16:34  lr: 0.0000000  loss: 0.5789 (0.5800)  bbox_regression: 0.1073 (0.1026)  classification: 0.4691 (0.4774)  time: 0.4205  data: 0.1389  max mem: 3278
Epoch: [67]  [1000/3494]  eta: 0:15:54  lr: 0.0000000  loss: 0.5696 (0.5803)  bbox_regression: 0.0997 (0.1029)  classification: 0.4487 (0.4774)  time: 0.3748  data: 0.1335  max mem: 3278
Epoch: [67]  [1100/3494]  eta: 0:15:16  lr: 0.0000000  loss: 0.5939 (0.5806)  bbox_regression: 0.1042 (0.1031)  classification: 0.4823 (0.4776)  time: 0.3697  data: 0.1352  max mem: 3278
Epoch: [67]  [1200/3494]  eta: 0:14:38  lr: 0.0000000  loss: 0.5954 (0.5804)  bbox_regression: 0.0897 (0.1028)  classification: 0.5038 (0.4777)  time: 0.3831  data: 0.1393  max mem: 3278
Epoch: [67]  [1300/3494]  eta: 0:13:58  lr: 0.0000000  loss: 0.6040 (0.5810)  bbox_regression: 0.1109 (0.1030)  classification: 0.4995 (0.4780)  time: 0.3973  data: 0.1401  max mem: 3278
Epoch: [67]  [1400/3494]  eta: 0:13:19  lr: 0.0000000  loss: 0.5357 (0.5813)  bbox_regression: 0.0933 (0.1031)  classification: 0.4446 (0.4782)  time: 0.3856  data: 0.1390  max mem: 3278
Epoch: [67]  [1500/3494]  eta: 0:12:40  lr: 0.0000000  loss: 0.5437 (0.5819)  bbox_regression: 0.0911 (0.1031)  classification: 0.4491 (0.4787)  time: 0.3733  data: 0.1254  max mem: 3278
Epoch: [67]  [1600/3494]  eta: 0:12:03  lr: 0.0000000  loss: 0.5799 (0.5816)  bbox_regression: 0.1039 (0.1032)  classification: 0.4722 (0.4784)  time: 0.4185  data: 0.1357  max mem: 3278
Epoch: [67]  [1700/3494]  eta: 0:11:24  lr: 0.0000000  loss: 0.5464 (0.5814)  bbox_regression: 0.0973 (0.1032)  classification: 0.4426 (0.4782)  time: 0.3751  data: 0.1324  max mem: 3278
Epoch: [67]  [1800/3494]  eta: 0:10:47  lr: 0.0000000  loss: 0.5435 (0.5813)  bbox_regression: 0.0922 (0.1029)  classification: 0.4547 (0.4784)  time: 0.4084  data: 0.1310  max mem: 3278
Epoch: [67]  [1900/3494]  eta: 0:10:08  lr: 0.0000000  loss: 0.5736 (0.5816)  bbox_regression: 0.0954 (0.1029)  classification: 0.4882 (0.4787)  time: 0.3684  data: 0.1339  max mem: 3278
Epoch: [67]  [2000/3494]  eta: 0:09:29  lr: 0.0000000  loss: 0.5880 (0.5822)  bbox_regression: 0.1080 (0.1030)  classification: 0.4931 (0.4792)  time: 0.3720  data: 0.1314  max mem: 3278
Epoch: [67]  [2100/3494]  eta: 0:08:50  lr: 0.0000000  loss: 0.5572 (0.5821)  bbox_regression: 0.1011 (0.1031)  classification: 0.4585 (0.4790)  time: 0.3910  data: 0.1460  max mem: 3278
Epoch: [67]  [2200/3494]  eta: 0:08:12  lr: 0.0000000  loss: 0.6015 (0.5828)  bbox_regression: 0.1057 (0.1035)  classification: 0.4867 (0.4793)  time: 0.3758  data: 0.1259  max mem: 3278
Epoch: [67]  [2300/3494]  eta: 0:07:34  lr: 0.0000000  loss: 0.5627 (0.5838)  bbox_regression: 0.0879 (0.1035)  classification: 0.4398 (0.4802)  time: 0.3871  data: 0.1391  max mem: 3278
Epoch: [67]  [2400/3494]  eta: 0:06:56  lr: 0.0000000  loss: 0.5692 (0.5837)  bbox_regression: 0.1009 (0.1036)  classification: 0.4741 (0.4801)  time: 0.3721  data: 0.1223  max mem: 3278
Epoch: [67]  [2500/3494]  eta: 0:06:18  lr: 0.0000000  loss: 0.6112 (0.5836)  bbox_regression: 0.1052 (0.1036)  classification: 0.4866 (0.4800)  time: 0.3562  data: 0.1293  max mem: 3278
Epoch: [67]  [2600/3494]  eta: 0:05:40  lr: 0.0000000  loss: 0.5760 (0.5835)  bbox_regression: 0.0997 (0.1033)  classification: 0.4837 (0.4802)  time: 0.3666  data: 0.1343  max mem: 3278
Epoch: [67]  [2700/3494]  eta: 0:05:01  lr: 0.0000000  loss: 0.5404 (0.5836)  bbox_regression: 0.0880 (0.1033)  classification: 0.4507 (0.4803)  time: 0.3814  data: 0.1401  max mem: 3278
Epoch: [67]  [2800/3494]  eta: 0:04:23  lr: 0.0000000  loss: 0.5725 (0.5831)  bbox_regression: 0.0951 (0.1032)  classification: 0.4605 (0.4799)  time: 0.3737  data: 0.1352  max mem: 3278
Epoch: [67]  [2900/3494]  eta: 0:03:45  lr: 0.0000000  loss: 0.5495 (0.5828)  bbox_regression: 0.0929 (0.1032)  classification: 0.4689 (0.4796)  time: 0.3717  data: 0.1269  max mem: 3278
Epoch: [67]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.5609 (0.5830)  bbox_regression: 0.0948 (0.1033)  classification: 0.4533 (0.4797)  time: 0.3759  data: 0.1236  max mem: 3278
Epoch: [67]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5665 (0.5829)  bbox_regression: 0.0896 (0.1031)  classification: 0.4769 (0.4798)  time: 0.3790  data: 0.1321  max mem: 3278
Epoch: [67]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5648 (0.5829)  bbox_regression: 0.0898 (0.1030)  classification: 0.4645 (0.4799)  time: 0.3691  data: 0.1319  max mem: 3278
Epoch: [67]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5943 (0.5836)  bbox_regression: 0.0964 (0.1033)  classification: 0.4856 (0.4804)  time: 0.3692  data: 0.1391  max mem: 3278
Epoch: [67]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5292 (0.5829)  bbox_regression: 0.0936 (0.1031)  classification: 0.4383 (0.4797)  time: 0.3622  data: 0.1258  max mem: 3278
Epoch: [67]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5602 (0.5826)  bbox_regression: 0.0928 (0.1030)  classification: 0.4624 (0.4796)  time: 0.3621  data: 0.1261  max mem: 3278
Epoch: [67] Total time: 0:22:15 (0.3822 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:08  model_time: 0.1376 (0.1376)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.2157  data: 2.0550  max mem: 3278
Validation:  [100/437]  eta: 0:01:40  model_time: 0.1305 (0.1310)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2788  data: 0.1308  max mem: 3278
Validation:  [200/437]  eta: 0:01:08  model_time: 0.1387 (0.1321)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2862  data: 0.1242  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1507 (0.1317)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3035  data: 0.1291  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1300 (0.1325)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2635  data: 0.1200  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1351 (0.1327)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2884  data: 0.1322  max mem: 3278
Validation: Total time: 0:02:04 (0.2844 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [68]  [   0/3494]  eta: 2:18:20  lr: 0.0000000  loss: 0.5948 (0.5948)  bbox_regression: 0.1017 (0.1017)  classification: 0.4932 (0.4932)  time: 2.3755  data: 2.1046  max mem: 3278
Epoch: [68]  [ 100/3494]  eta: 0:22:38  lr: 0.0000000  loss: 0.5546 (0.5825)  bbox_regression: 0.0892 (0.1005)  classification: 0.4392 (0.4820)  time: 0.3609  data: 0.1286  max mem: 3278
Epoch: [68]  [ 200/3494]  eta: 0:21:12  lr: 0.0000000  loss: 0.5734 (0.5844)  bbox_regression: 0.1059 (0.1031)  classification: 0.4532 (0.4813)  time: 0.3642  data: 0.1260  max mem: 3278
Epoch: [68]  [ 300/3494]  eta: 0:20:00  lr: 0.0000000  loss: 0.6160 (0.5888)  bbox_regression: 0.1087 (0.1044)  classification: 0.4990 (0.4844)  time: 0.3574  data: 0.1194  max mem: 3278
Epoch: [68]  [ 400/3494]  eta: 0:19:26  lr: 0.0000000  loss: 0.5786 (0.5896)  bbox_regression: 0.0906 (0.1044)  classification: 0.4952 (0.4852)  time: 0.3651  data: 0.1279  max mem: 3278
Epoch: [68]  [ 500/3494]  eta: 0:18:51  lr: 0.0000000  loss: 0.5726 (0.5877)  bbox_regression: 0.0901 (0.1044)  classification: 0.4534 (0.4833)  time: 0.4015  data: 0.1450  max mem: 3278
Epoch: [68]  [ 600/3494]  eta: 0:18:13  lr: 0.0000000  loss: 0.5741 (0.5859)  bbox_regression: 0.0940 (0.1034)  classification: 0.4686 (0.4825)  time: 0.3962  data: 0.1246  max mem: 3278
Epoch: [68]  [ 700/3494]  eta: 0:17:39  lr: 0.0000000  loss: 0.5441 (0.5827)  bbox_regression: 0.0896 (0.1031)  classification: 0.4601 (0.4797)  time: 0.4135  data: 0.1512  max mem: 3278
Epoch: [68]  [ 800/3494]  eta: 0:17:01  lr: 0.0000000  loss: 0.5219 (0.5823)  bbox_regression: 0.0885 (0.1027)  classification: 0.4331 (0.4796)  time: 0.3674  data: 0.1326  max mem: 3278
Epoch: [68]  [ 900/3494]  eta: 0:16:25  lr: 0.0000000  loss: 0.5089 (0.5809)  bbox_regression: 0.0914 (0.1023)  classification: 0.4170 (0.4786)  time: 0.3738  data: 0.1326  max mem: 3278
Epoch: [68]  [1000/3494]  eta: 0:15:40  lr: 0.0000000  loss: 0.5639 (0.5800)  bbox_regression: 0.0964 (0.1026)  classification: 0.4829 (0.4775)  time: 0.3511  data: 0.1211  max mem: 3278
Epoch: [68]  [1100/3494]  eta: 0:15:04  lr: 0.0000000  loss: 0.5434 (0.5810)  bbox_regression: 0.1032 (0.1028)  classification: 0.4334 (0.4781)  time: 0.3976  data: 0.1501  max mem: 3278
Epoch: [68]  [1200/3494]  eta: 0:14:25  lr: 0.0000000  loss: 0.5498 (0.5809)  bbox_regression: 0.0891 (0.1027)  classification: 0.4893 (0.4782)  time: 0.3687  data: 0.1260  max mem: 3278
Epoch: [68]  [1300/3494]  eta: 0:13:47  lr: 0.0000000  loss: 0.5570 (0.5812)  bbox_regression: 0.0902 (0.1027)  classification: 0.4724 (0.4785)  time: 0.3802  data: 0.1332  max mem: 3278
Epoch: [68]  [1400/3494]  eta: 0:13:09  lr: 0.0000000  loss: 0.5423 (0.5816)  bbox_regression: 0.0945 (0.1030)  classification: 0.4522 (0.4786)  time: 0.3922  data: 0.1445  max mem: 3278
Epoch: [68]  [1500/3494]  eta: 0:12:38  lr: 0.0000000  loss: 0.5852 (0.5823)  bbox_regression: 0.1025 (0.1031)  classification: 0.4865 (0.4792)  time: 0.5677  data: 0.1798  max mem: 3278
Epoch: [68]  [1600/3494]  eta: 0:12:07  lr: 0.0000000  loss: 0.5322 (0.5818)  bbox_regression: 0.1023 (0.1030)  classification: 0.4389 (0.4787)  time: 0.4278  data: 0.1553  max mem: 3278
Epoch: [68]  [1700/3494]  eta: 0:11:34  lr: 0.0000000  loss: 0.5326 (0.5819)  bbox_regression: 0.1002 (0.1030)  classification: 0.4399 (0.4789)  time: 0.4897  data: 0.1686  max mem: 3278
Epoch: [68]  [1800/3494]  eta: 0:11:05  lr: 0.0000000  loss: 0.6243 (0.5831)  bbox_regression: 0.0980 (0.1031)  classification: 0.5097 (0.4800)  time: 0.5153  data: 0.1747  max mem: 3278
Epoch: [68]  [1900/3494]  eta: 0:10:37  lr: 0.0000000  loss: 0.5482 (0.5832)  bbox_regression: 0.1009 (0.1031)  classification: 0.4439 (0.4802)  time: 0.5204  data: 0.1678  max mem: 3278
Epoch: [68]  [2000/3494]  eta: 0:10:03  lr: 0.0000000  loss: 0.5598 (0.5836)  bbox_regression: 0.1018 (0.1032)  classification: 0.4783 (0.4803)  time: 0.4987  data: 0.1769  max mem: 3278
Epoch: [68]  [2100/3494]  eta: 0:09:28  lr: 0.0000000  loss: 0.5611 (0.5838)  bbox_regression: 0.1094 (0.1034)  classification: 0.4706 (0.4804)  time: 0.4247  data: 0.1501  max mem: 3278
Epoch: [68]  [2200/3494]  eta: 0:08:48  lr: 0.0000000  loss: 0.5366 (0.5837)  bbox_regression: 0.0924 (0.1034)  classification: 0.4275 (0.4803)  time: 0.3884  data: 0.1359  max mem: 3278
Epoch: [68]  [2300/3494]  eta: 0:08:08  lr: 0.0000000  loss: 0.5449 (0.5836)  bbox_regression: 0.0916 (0.1035)  classification: 0.4546 (0.4801)  time: 0.4321  data: 0.1599  max mem: 3278
Epoch: [68]  [2400/3494]  eta: 0:07:29  lr: 0.0000000  loss: 0.6024 (0.5833)  bbox_regression: 0.1046 (0.1034)  classification: 0.4947 (0.4799)  time: 0.4725  data: 0.1563  max mem: 3278
Epoch: [68]  [2500/3494]  eta: 0:06:51  lr: 0.0000000  loss: 0.5642 (0.5825)  bbox_regression: 0.1001 (0.1033)  classification: 0.4551 (0.4792)  time: 0.5145  data: 0.1742  max mem: 3278
Epoch: [68]  [2600/3494]  eta: 0:06:12  lr: 0.0000000  loss: 0.5681 (0.5827)  bbox_regression: 0.1040 (0.1033)  classification: 0.4580 (0.4794)  time: 0.4504  data: 0.1602  max mem: 3278
Epoch: [68]  [2700/3494]  eta: 0:05:34  lr: 0.0000000  loss: 0.6188 (0.5837)  bbox_regression: 0.0980 (0.1036)  classification: 0.5211 (0.4801)  time: 0.5375  data: 0.1754  max mem: 3278
Epoch: [68]  [2800/3494]  eta: 0:04:52  lr: 0.0000000  loss: 0.5697 (0.5837)  bbox_regression: 0.0997 (0.1035)  classification: 0.4746 (0.4801)  time: 0.4564  data: 0.1479  max mem: 3278
Epoch: [68]  [2900/3494]  eta: 0:04:10  lr: 0.0000000  loss: 0.5921 (0.5835)  bbox_regression: 0.0969 (0.1034)  classification: 0.4850 (0.4801)  time: 0.4401  data: 0.1558  max mem: 3278
Epoch: [68]  [3000/3494]  eta: 0:03:28  lr: 0.0000000  loss: 0.5827 (0.5832)  bbox_regression: 0.0991 (0.1034)  classification: 0.4743 (0.4798)  time: 0.5121  data: 0.1649  max mem: 3278
Epoch: [68]  [3100/3494]  eta: 0:02:47  lr: 0.0000000  loss: 0.6266 (0.5830)  bbox_regression: 0.0948 (0.1034)  classification: 0.5052 (0.4796)  time: 0.5059  data: 0.1745  max mem: 3278
Epoch: [68]  [3200/3494]  eta: 0:02:05  lr: 0.0000000  loss: 0.5142 (0.5824)  bbox_regression: 0.0882 (0.1032)  classification: 0.4367 (0.4792)  time: 0.4752  data: 0.1742  max mem: 3278
Epoch: [68]  [3300/3494]  eta: 0:01:23  lr: 0.0000000  loss: 0.5744 (0.5822)  bbox_regression: 0.0944 (0.1030)  classification: 0.4473 (0.4792)  time: 0.5156  data: 0.1786  max mem: 3278
Epoch: [68]  [3400/3494]  eta: 0:00:40  lr: 0.0000000  loss: 0.6150 (0.5824)  bbox_regression: 0.1066 (0.1030)  classification: 0.4977 (0.4794)  time: 0.4127  data: 0.1422  max mem: 3278
Epoch: [68]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5735 (0.5822)  bbox_regression: 0.0956 (0.1029)  classification: 0.4757 (0.4793)  time: 0.3866  data: 0.1390  max mem: 3278
Epoch: [68] Total time: 0:25:17 (0.4343 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:55  model_time: 0.1906 (0.1906)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.4602  data: 2.2264  max mem: 3278
Validation:  [100/437]  eta: 0:01:54  model_time: 0.1409 (0.1501)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3006  data: 0.1403  max mem: 3278
Validation:  [200/437]  eta: 0:01:25  model_time: 0.2332 (0.1700)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.4781  data: 0.2015  max mem: 3278
Validation:  [300/437]  eta: 0:00:50  model_time: 0.1975 (0.1744)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.4011  data: 0.1766  max mem: 3278
Validation:  [400/437]  eta: 0:00:13  model_time: 0.1831 (0.1797)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3997  data: 0.1705  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1698 (0.1797)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3623  data: 0.1695  max mem: 3278
Validation: Total time: 0:02:42 (0.3725 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [69]  [   0/3494]  eta: 2:23:42  lr: 0.0000000  loss: 0.6671 (0.6671)  bbox_regression: 0.1020 (0.1020)  classification: 0.5650 (0.5650)  time: 2.4679  data: 2.0919  max mem: 3278
Epoch: [69]  [ 100/3494]  eta: 0:31:02  lr: 0.0000000  loss: 0.5843 (0.5729)  bbox_regression: 0.0886 (0.1035)  classification: 0.4891 (0.4694)  time: 0.5220  data: 0.1695  max mem: 3278
Epoch: [69]  [ 200/3494]  eta: 0:28:26  lr: 0.0000000  loss: 0.5697 (0.5745)  bbox_regression: 0.0941 (0.1035)  classification: 0.4569 (0.4710)  time: 0.4477  data: 0.1482  max mem: 3278
Epoch: [69]  [ 300/3494]  eta: 0:25:55  lr: 0.0000000  loss: 0.5554 (0.5738)  bbox_regression: 0.0947 (0.1030)  classification: 0.4545 (0.4708)  time: 0.4354  data: 0.1508  max mem: 3278
Epoch: [69]  [ 400/3494]  eta: 0:24:14  lr: 0.0000000  loss: 0.5621 (0.5747)  bbox_regression: 0.0964 (0.1021)  classification: 0.4656 (0.4725)  time: 0.4364  data: 0.1473  max mem: 3278
Epoch: [69]  [ 500/3494]  eta: 0:24:08  lr: 0.0000000  loss: 0.6452 (0.5764)  bbox_regression: 0.1072 (0.1025)  classification: 0.5230 (0.4739)  time: 0.5528  data: 0.1917  max mem: 3278
Epoch: [69]  [ 600/3494]  eta: 0:23:14  lr: 0.0000000  loss: 0.5395 (0.5787)  bbox_regression: 0.0884 (0.1033)  classification: 0.4271 (0.4754)  time: 0.4398  data: 0.1496  max mem: 3278
Epoch: [69]  [ 700/3494]  eta: 0:22:48  lr: 0.0000000  loss: 0.5647 (0.5805)  bbox_regression: 0.0936 (0.1034)  classification: 0.4757 (0.4771)  time: 0.4932  data: 0.1752  max mem: 3278
Epoch: [69]  [ 800/3494]  eta: 0:22:09  lr: 0.0000000  loss: 0.5453 (0.5808)  bbox_regression: 0.0978 (0.1033)  classification: 0.4442 (0.4775)  time: 0.4788  data: 0.1785  max mem: 3278
Epoch: [69]  [ 900/3494]  eta: 0:20:59  lr: 0.0000000  loss: 0.5321 (0.5809)  bbox_regression: 0.0954 (0.1033)  classification: 0.4514 (0.4776)  time: 0.3913  data: 0.1395  max mem: 3278
Epoch: [69]  [1000/3494]  eta: 0:19:58  lr: 0.0000000  loss: 0.5375 (0.5788)  bbox_regression: 0.0871 (0.1027)  classification: 0.4441 (0.4762)  time: 0.4349  data: 0.1425  max mem: 3278
Epoch: [69]  [1100/3494]  eta: 0:19:13  lr: 0.0000000  loss: 0.5346 (0.5792)  bbox_regression: 0.0870 (0.1027)  classification: 0.4490 (0.4765)  time: 0.5282  data: 0.1703  max mem: 3278
Epoch: [69]  [1200/3494]  eta: 0:18:29  lr: 0.0000000  loss: 0.5647 (0.5791)  bbox_regression: 0.0946 (0.1027)  classification: 0.4729 (0.4764)  time: 0.4945  data: 0.1576  max mem: 3278
Epoch: [69]  [1300/3494]  eta: 0:17:43  lr: 0.0000000  loss: 0.5277 (0.5791)  bbox_regression: 0.0918 (0.1026)  classification: 0.4463 (0.4765)  time: 0.4789  data: 0.1670  max mem: 3278
Epoch: [69]  [1400/3494]  eta: 0:16:52  lr: 0.0000000  loss: 0.5641 (0.5805)  bbox_regression: 0.0938 (0.1028)  classification: 0.4721 (0.4777)  time: 0.4228  data: 0.1503  max mem: 3278
Epoch: [69]  [1500/3494]  eta: 0:15:57  lr: 0.0000000  loss: 0.5579 (0.5812)  bbox_regression: 0.0850 (0.1029)  classification: 0.4791 (0.4782)  time: 0.4129  data: 0.1429  max mem: 3278
Epoch: [69]  [1600/3494]  eta: 0:15:02  lr: 0.0000000  loss: 0.5296 (0.5816)  bbox_regression: 0.0918 (0.1030)  classification: 0.4485 (0.4786)  time: 0.4859  data: 0.1688  max mem: 3278
Epoch: [69]  [1700/3494]  eta: 0:14:15  lr: 0.0000000  loss: 0.5617 (0.5812)  bbox_regression: 0.0966 (0.1027)  classification: 0.4557 (0.4785)  time: 0.4907  data: 0.1661  max mem: 3278
Epoch: [69]  [1800/3494]  eta: 0:13:28  lr: 0.0000000  loss: 0.5590 (0.5825)  bbox_regression: 0.0994 (0.1029)  classification: 0.4649 (0.4796)  time: 0.4932  data: 0.1649  max mem: 3278
Epoch: [69]  [1900/3494]  eta: 0:12:43  lr: 0.0000000  loss: 0.5853 (0.5826)  bbox_regression: 0.0845 (0.1028)  classification: 0.5023 (0.4798)  time: 0.4962  data: 0.1664  max mem: 3278
Epoch: [69]  [2000/3494]  eta: 0:11:56  lr: 0.0000000  loss: 0.5514 (0.5827)  bbox_regression: 0.0925 (0.1029)  classification: 0.4793 (0.4798)  time: 0.4523  data: 0.1644  max mem: 3278
Epoch: [69]  [2100/3494]  eta: 0:11:05  lr: 0.0000000  loss: 0.6017 (0.5828)  bbox_regression: 0.0945 (0.1029)  classification: 0.4835 (0.4800)  time: 0.4303  data: 0.1518  max mem: 3278
Epoch: [69]  [2200/3494]  eta: 0:10:13  lr: 0.0000000  loss: 0.5592 (0.5840)  bbox_regression: 0.1126 (0.1032)  classification: 0.4721 (0.4808)  time: 0.4403  data: 0.1470  max mem: 3278
Epoch: [69]  [2300/3494]  eta: 0:09:27  lr: 0.0000000  loss: 0.5456 (0.5840)  bbox_regression: 0.0871 (0.1031)  classification: 0.4515 (0.4809)  time: 0.4943  data: 0.1571  max mem: 3278
Epoch: [69]  [2400/3494]  eta: 0:08:40  lr: 0.0000000  loss: 0.5665 (0.5844)  bbox_regression: 0.1004 (0.1032)  classification: 0.4859 (0.4812)  time: 0.4869  data: 0.1609  max mem: 3278
Epoch: [69]  [2500/3494]  eta: 0:07:52  lr: 0.0000000  loss: 0.5653 (0.5846)  bbox_regression: 0.0999 (0.1033)  classification: 0.4654 (0.4813)  time: 0.4955  data: 0.1689  max mem: 3278
Epoch: [69]  [2600/3494]  eta: 0:07:05  lr: 0.0000000  loss: 0.5692 (0.5847)  bbox_regression: 0.0890 (0.1033)  classification: 0.4609 (0.4814)  time: 0.4841  data: 0.1767  max mem: 3278
Epoch: [69]  [2700/3494]  eta: 0:06:17  lr: 0.0000000  loss: 0.6051 (0.5843)  bbox_regression: 0.1004 (0.1032)  classification: 0.5034 (0.4811)  time: 0.4028  data: 0.1396  max mem: 3278
Epoch: [69]  [2800/3494]  eta: 0:05:28  lr: 0.0000000  loss: 0.5806 (0.5842)  bbox_regression: 0.1107 (0.1033)  classification: 0.4780 (0.4809)  time: 0.4019  data: 0.1402  max mem: 3278
Epoch: [69]  [2900/3494]  eta: 0:04:41  lr: 0.0000000  loss: 0.6022 (0.5836)  bbox_regression: 0.0923 (0.1031)  classification: 0.4813 (0.4804)  time: 0.4464  data: 0.1535  max mem: 3278
Epoch: [69]  [3000/3494]  eta: 0:03:53  lr: 0.0000000  loss: 0.5466 (0.5831)  bbox_regression: 0.0930 (0.1031)  classification: 0.4599 (0.4801)  time: 0.4401  data: 0.1543  max mem: 3278
Epoch: [69]  [3100/3494]  eta: 0:03:06  lr: 0.0000000  loss: 0.5992 (0.5829)  bbox_regression: 0.0988 (0.1030)  classification: 0.4607 (0.4799)  time: 0.5026  data: 0.1714  max mem: 3278
Epoch: [69]  [3200/3494]  eta: 0:02:19  lr: 0.0000000  loss: 0.5808 (0.5828)  bbox_regression: 0.1014 (0.1030)  classification: 0.4618 (0.4798)  time: 0.4882  data: 0.1517  max mem: 3278
Epoch: [69]  [3300/3494]  eta: 0:01:31  lr: 0.0000000  loss: 0.5301 (0.5830)  bbox_regression: 0.0875 (0.1029)  classification: 0.4441 (0.4801)  time: 0.3961  data: 0.1433  max mem: 3278
Epoch: [69]  [3400/3494]  eta: 0:00:44  lr: 0.0000000  loss: 0.5469 (0.5834)  bbox_regression: 0.1009 (0.1031)  classification: 0.4475 (0.4803)  time: 0.4001  data: 0.1299  max mem: 3278
Epoch: [69]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5375 (0.5833)  bbox_regression: 0.0873 (0.1032)  classification: 0.4534 (0.4802)  time: 0.4548  data: 0.1530  max mem: 3278
Epoch: [69] Total time: 0:27:36 (0.4741 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:21:33  model_time: 0.2564 (0.2564)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.9604  data: 2.6749  max mem: 3278
Validation:  [100/437]  eta: 0:02:21  model_time: 0.2000 (0.2050)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3972  data: 0.1710  max mem: 3278
Validation:  [200/437]  eta: 0:01:36  model_time: 0.1980 (0.2038)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.4166  data: 0.1893  max mem: 3278
Validation:  [300/437]  eta: 0:00:54  model_time: 0.1595 (0.1977)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3789  data: 0.1720  max mem: 3278
Validation:  [400/437]  eta: 0:00:14  model_time: 0.1985 (0.1989)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3786  data: 0.1576  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1372 (0.1963)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3235  data: 0.1547  max mem: 3278
Validation: Total time: 0:02:52 (0.3957 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [70]  [   0/3494]  eta: 3:10:57  lr: 0.0000000  loss: 0.5693 (0.5693)  bbox_regression: 0.0879 (0.0879)  classification: 0.4815 (0.4815)  time: 3.2792  data: 2.9389  max mem: 3278
Epoch: [70]  [ 100/3494]  eta: 0:25:16  lr: 0.0000000  loss: 0.5747 (0.5819)  bbox_regression: 0.0919 (0.1018)  classification: 0.4780 (0.4801)  time: 0.4161  data: 0.1461  max mem: 3278
Epoch: [70]  [ 200/3494]  eta: 0:24:34  lr: 0.0000000  loss: 0.5642 (0.5741)  bbox_regression: 0.0811 (0.1008)  classification: 0.4787 (0.4733)  time: 0.5094  data: 0.1873  max mem: 3278
Epoch: [70]  [ 300/3494]  eta: 0:24:36  lr: 0.0000000  loss: 0.5446 (0.5831)  bbox_regression: 0.0991 (0.1031)  classification: 0.4458 (0.4800)  time: 0.4814  data: 0.1635  max mem: 3278
Epoch: [70]  [ 400/3494]  eta: 0:24:16  lr: 0.0000000  loss: 0.5833 (0.5838)  bbox_regression: 0.0983 (0.1022)  classification: 0.4923 (0.4816)  time: 0.4941  data: 0.1662  max mem: 3278
Epoch: [70]  [ 500/3494]  eta: 0:23:34  lr: 0.0000000  loss: 0.5831 (0.5868)  bbox_regression: 0.0987 (0.1031)  classification: 0.4750 (0.4837)  time: 0.4900  data: 0.1622  max mem: 3278
Epoch: [70]  [ 600/3494]  eta: 0:22:55  lr: 0.0000000  loss: 0.5815 (0.5865)  bbox_regression: 0.1055 (0.1030)  classification: 0.4798 (0.4834)  time: 0.4448  data: 0.1637  max mem: 3278
Epoch: [70]  [ 700/3494]  eta: 0:21:48  lr: 0.0000000  loss: 0.5746 (0.5863)  bbox_regression: 0.0950 (0.1026)  classification: 0.4845 (0.4837)  time: 0.4274  data: 0.1491  max mem: 3278
Epoch: [70]  [ 800/3494]  eta: 0:20:44  lr: 0.0000000  loss: 0.5830 (0.5845)  bbox_regression: 0.1000 (0.1023)  classification: 0.4616 (0.4821)  time: 0.3502  data: 0.1236  max mem: 3278
Epoch: [70]  [ 900/3494]  eta: 0:19:31  lr: 0.0000000  loss: 0.5729 (0.5850)  bbox_regression: 0.0988 (0.1029)  classification: 0.4614 (0.4822)  time: 0.3710  data: 0.1352  max mem: 3278
Epoch: [70]  [1000/3494]  eta: 0:18:26  lr: 0.0000000  loss: 0.5575 (0.5851)  bbox_regression: 0.0892 (0.1030)  classification: 0.4573 (0.4821)  time: 0.3842  data: 0.1356  max mem: 3278
Epoch: [70]  [1100/3494]  eta: 0:17:30  lr: 0.0000000  loss: 0.5916 (0.5837)  bbox_regression: 0.0989 (0.1029)  classification: 0.4768 (0.4808)  time: 0.4042  data: 0.1254  max mem: 3278
Epoch: [70]  [1200/3494]  eta: 0:16:37  lr: 0.0000000  loss: 0.5972 (0.5837)  bbox_regression: 0.1025 (0.1028)  classification: 0.4669 (0.4808)  time: 0.3694  data: 0.1326  max mem: 3278
Epoch: [70]  [1300/3494]  eta: 0:15:45  lr: 0.0000000  loss: 0.5504 (0.5851)  bbox_regression: 0.0887 (0.1032)  classification: 0.4502 (0.4819)  time: 0.3743  data: 0.1284  max mem: 3278
Epoch: [70]  [1400/3494]  eta: 0:14:55  lr: 0.0000000  loss: 0.5663 (0.5838)  bbox_regression: 0.0967 (0.1029)  classification: 0.4645 (0.4809)  time: 0.3524  data: 0.1221  max mem: 3278
Epoch: [70]  [1500/3494]  eta: 0:14:03  lr: 0.0000000  loss: 0.6106 (0.5836)  bbox_regression: 0.0960 (0.1028)  classification: 0.5173 (0.4808)  time: 0.3666  data: 0.1395  max mem: 3278
Epoch: [70]  [1600/3494]  eta: 0:13:14  lr: 0.0000000  loss: 0.5672 (0.5833)  bbox_regression: 0.1031 (0.1030)  classification: 0.4616 (0.4803)  time: 0.3603  data: 0.1273  max mem: 3278
Epoch: [70]  [1700/3494]  eta: 0:12:27  lr: 0.0000000  loss: 0.6243 (0.5833)  bbox_regression: 0.1037 (0.1031)  classification: 0.5028 (0.4802)  time: 0.3886  data: 0.1319  max mem: 3278
Epoch: [70]  [1800/3494]  eta: 0:11:42  lr: 0.0000000  loss: 0.5550 (0.5818)  bbox_regression: 0.0955 (0.1027)  classification: 0.4691 (0.4791)  time: 0.3905  data: 0.1280  max mem: 3278
Epoch: [70]  [1900/3494]  eta: 0:10:58  lr: 0.0000000  loss: 0.5438 (0.5822)  bbox_regression: 0.0986 (0.1027)  classification: 0.4676 (0.4795)  time: 0.3490  data: 0.1257  max mem: 3278
Epoch: [70]  [2000/3494]  eta: 0:10:14  lr: 0.0000000  loss: 0.5870 (0.5823)  bbox_regression: 0.0991 (0.1028)  classification: 0.4736 (0.4794)  time: 0.3928  data: 0.1521  max mem: 3278
Epoch: [70]  [2100/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5772 (0.5832)  bbox_regression: 0.0963 (0.1029)  classification: 0.4717 (0.4803)  time: 0.3665  data: 0.1336  max mem: 3278
Epoch: [70]  [2200/3494]  eta: 0:08:47  lr: 0.0000000  loss: 0.6075 (0.5846)  bbox_regression: 0.0979 (0.1032)  classification: 0.4820 (0.4815)  time: 0.3620  data: 0.1269  max mem: 3278
Epoch: [70]  [2300/3494]  eta: 0:08:04  lr: 0.0000000  loss: 0.5432 (0.5843)  bbox_regression: 0.0902 (0.1031)  classification: 0.4598 (0.4812)  time: 0.3830  data: 0.1385  max mem: 3278
Epoch: [70]  [2400/3494]  eta: 0:07:22  lr: 0.0000000  loss: 0.5729 (0.5842)  bbox_regression: 0.0909 (0.1030)  classification: 0.4782 (0.4812)  time: 0.3701  data: 0.1291  max mem: 3278
Epoch: [70]  [2500/3494]  eta: 0:06:42  lr: 0.0000000  loss: 0.5293 (0.5837)  bbox_regression: 0.0909 (0.1029)  classification: 0.4315 (0.4807)  time: 0.4182  data: 0.1320  max mem: 3278
Epoch: [70]  [2600/3494]  eta: 0:06:00  lr: 0.0000000  loss: 0.5250 (0.5840)  bbox_regression: 0.0914 (0.1029)  classification: 0.4350 (0.4811)  time: 0.3975  data: 0.1483  max mem: 3278
Epoch: [70]  [2700/3494]  eta: 0:05:19  lr: 0.0000000  loss: 0.5856 (0.5843)  bbox_regression: 0.1014 (0.1031)  classification: 0.4704 (0.4813)  time: 0.3704  data: 0.1349  max mem: 3278
Epoch: [70]  [2800/3494]  eta: 0:04:39  lr: 0.0000000  loss: 0.5676 (0.5842)  bbox_regression: 0.1021 (0.1031)  classification: 0.4687 (0.4811)  time: 0.3661  data: 0.1320  max mem: 3278
Epoch: [70]  [2900/3494]  eta: 0:03:58  lr: 0.0000000  loss: 0.5892 (0.5848)  bbox_regression: 0.0996 (0.1032)  classification: 0.4837 (0.4816)  time: 0.3784  data: 0.1362  max mem: 3278
Epoch: [70]  [3000/3494]  eta: 0:03:17  lr: 0.0000000  loss: 0.5782 (0.5842)  bbox_regression: 0.0976 (0.1032)  classification: 0.4753 (0.4810)  time: 0.3646  data: 0.1256  max mem: 3278
Epoch: [70]  [3100/3494]  eta: 0:02:37  lr: 0.0000000  loss: 0.5646 (0.5837)  bbox_regression: 0.0877 (0.1032)  classification: 0.4778 (0.4805)  time: 0.3905  data: 0.1474  max mem: 3278
Epoch: [70]  [3200/3494]  eta: 0:01:57  lr: 0.0000000  loss: 0.5505 (0.5833)  bbox_regression: 0.0902 (0.1032)  classification: 0.4490 (0.4802)  time: 0.3798  data: 0.1319  max mem: 3278
Epoch: [70]  [3300/3494]  eta: 0:01:17  lr: 0.0000000  loss: 0.5341 (0.5830)  bbox_regression: 0.0967 (0.1031)  classification: 0.4391 (0.4799)  time: 0.4373  data: 0.1435  max mem: 3278
Epoch: [70]  [3400/3494]  eta: 0:00:37  lr: 0.0000000  loss: 0.5570 (0.5832)  bbox_regression: 0.0990 (0.1032)  classification: 0.4677 (0.4801)  time: 0.3760  data: 0.1335  max mem: 3278
Epoch: [70]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5715 (0.5835)  bbox_regression: 0.0925 (0.1032)  classification: 0.4816 (0.4803)  time: 0.3774  data: 0.1309  max mem: 3278
Epoch: [70] Total time: 0:23:18 (0.4003 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:17:48  model_time: 0.1361 (0.1361)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.4442  data: 2.2591  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1125 (0.1276)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2550  data: 0.1224  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1144 (0.1236)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2625  data: 0.1236  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1211 (0.1240)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2843  data: 0.1395  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1376 (0.1269)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2780  data: 0.1229  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1176 (0.1268)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2599  data: 0.1207  max mem: 3278
Validation: Total time: 0:01:59 (0.2729 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [71]  [   0/3494]  eta: 2:21:57  lr: 0.0000000  loss: 0.5192 (0.5192)  bbox_regression: 0.0827 (0.0827)  classification: 0.4365 (0.4365)  time: 2.4377  data: 2.1912  max mem: 3278
Epoch: [71]  [ 100/3494]  eta: 0:22:48  lr: 0.0000000  loss: 0.5810 (0.6023)  bbox_regression: 0.1004 (0.1037)  classification: 0.4784 (0.4987)  time: 0.3729  data: 0.1331  max mem: 3278
Epoch: [71]  [ 200/3494]  eta: 0:21:22  lr: 0.0000000  loss: 0.5217 (0.5962)  bbox_regression: 0.0990 (0.1049)  classification: 0.4294 (0.4913)  time: 0.3669  data: 0.1262  max mem: 3278
Epoch: [71]  [ 300/3494]  eta: 0:20:49  lr: 0.0000000  loss: 0.5393 (0.5888)  bbox_regression: 0.0929 (0.1034)  classification: 0.4381 (0.4854)  time: 0.3927  data: 0.1371  max mem: 3278
Epoch: [71]  [ 400/3494]  eta: 0:20:09  lr: 0.0000000  loss: 0.5369 (0.5824)  bbox_regression: 0.0981 (0.1022)  classification: 0.4381 (0.4801)  time: 0.3625  data: 0.1290  max mem: 3278
Epoch: [71]  [ 500/3494]  eta: 0:19:22  lr: 0.0000000  loss: 0.5820 (0.5880)  bbox_regression: 0.0966 (0.1041)  classification: 0.4613 (0.4839)  time: 0.3750  data: 0.1317  max mem: 3278
Epoch: [71]  [ 600/3494]  eta: 0:18:32  lr: 0.0000000  loss: 0.5731 (0.5869)  bbox_regression: 0.1017 (0.1040)  classification: 0.4628 (0.4829)  time: 0.3725  data: 0.1342  max mem: 3278
Epoch: [71]  [ 700/3494]  eta: 0:17:51  lr: 0.0000000  loss: 0.5596 (0.5839)  bbox_regression: 0.0947 (0.1035)  classification: 0.4524 (0.4803)  time: 0.3602  data: 0.1246  max mem: 3278
Epoch: [71]  [ 800/3494]  eta: 0:17:10  lr: 0.0000000  loss: 0.5552 (0.5849)  bbox_regression: 0.1075 (0.1037)  classification: 0.4731 (0.4811)  time: 0.3688  data: 0.1420  max mem: 3278
Epoch: [71]  [ 900/3494]  eta: 0:16:31  lr: 0.0000000  loss: 0.5265 (0.5850)  bbox_regression: 0.0987 (0.1040)  classification: 0.4348 (0.4810)  time: 0.3910  data: 0.1343  max mem: 3278
Epoch: [71]  [1000/3494]  eta: 0:15:55  lr: 0.0000000  loss: 0.5979 (0.5855)  bbox_regression: 0.1073 (0.1041)  classification: 0.4569 (0.4814)  time: 0.3908  data: 0.1457  max mem: 3278
Epoch: [71]  [1100/3494]  eta: 0:15:17  lr: 0.0000000  loss: 0.5155 (0.5858)  bbox_regression: 0.0969 (0.1044)  classification: 0.4263 (0.4814)  time: 0.3576  data: 0.1277  max mem: 3278
Epoch: [71]  [1200/3494]  eta: 0:14:38  lr: 0.0000000  loss: 0.5250 (0.5849)  bbox_regression: 0.0893 (0.1038)  classification: 0.4475 (0.4811)  time: 0.3545  data: 0.1271  max mem: 3278
Epoch: [71]  [1300/3494]  eta: 0:13:55  lr: 0.0000000  loss: 0.5652 (0.5852)  bbox_regression: 0.0905 (0.1038)  classification: 0.4640 (0.4814)  time: 0.3405  data: 0.1201  max mem: 3278
Epoch: [71]  [1400/3494]  eta: 0:13:16  lr: 0.0000000  loss: 0.5369 (0.5839)  bbox_regression: 0.0930 (0.1037)  classification: 0.4391 (0.4802)  time: 0.3875  data: 0.1364  max mem: 3278
Epoch: [71]  [1500/3494]  eta: 0:12:37  lr: 0.0000000  loss: 0.5349 (0.5837)  bbox_regression: 0.1001 (0.1037)  classification: 0.4388 (0.4800)  time: 0.3742  data: 0.1281  max mem: 3278
Epoch: [71]  [1600/3494]  eta: 0:11:59  lr: 0.0000000  loss: 0.5342 (0.5829)  bbox_regression: 0.0891 (0.1034)  classification: 0.4356 (0.4795)  time: 0.3864  data: 0.1451  max mem: 3278
Epoch: [71]  [1700/3494]  eta: 0:11:22  lr: 0.0000000  loss: 0.5263 (0.5836)  bbox_regression: 0.1023 (0.1035)  classification: 0.4442 (0.4801)  time: 0.3693  data: 0.1356  max mem: 3278
Epoch: [71]  [1800/3494]  eta: 0:10:45  lr: 0.0000000  loss: 0.5038 (0.5825)  bbox_regression: 0.0860 (0.1031)  classification: 0.4219 (0.4794)  time: 0.4368  data: 0.1469  max mem: 3278
Epoch: [71]  [1900/3494]  eta: 0:10:07  lr: 0.0000000  loss: 0.5649 (0.5839)  bbox_regression: 0.1017 (0.1036)  classification: 0.4551 (0.4803)  time: 0.3588  data: 0.1261  max mem: 3278
Epoch: [71]  [2000/3494]  eta: 0:09:27  lr: 0.0000000  loss: 0.5486 (0.5839)  bbox_regression: 0.0934 (0.1036)  classification: 0.4719 (0.4803)  time: 0.3699  data: 0.1355  max mem: 3278
Epoch: [71]  [2100/3494]  eta: 0:08:49  lr: 0.0000000  loss: 0.5277 (0.5839)  bbox_regression: 0.0987 (0.1036)  classification: 0.4430 (0.4803)  time: 0.3797  data: 0.1370  max mem: 3278
Epoch: [71]  [2200/3494]  eta: 0:08:10  lr: 0.0000000  loss: 0.5918 (0.5857)  bbox_regression: 0.1080 (0.1039)  classification: 0.5147 (0.4818)  time: 0.3663  data: 0.1273  max mem: 3278
Epoch: [71]  [2300/3494]  eta: 0:07:33  lr: 0.0000000  loss: 0.5848 (0.5862)  bbox_regression: 0.1022 (0.1039)  classification: 0.4860 (0.4823)  time: 0.4018  data: 0.1238  max mem: 3278
Epoch: [71]  [2400/3494]  eta: 0:06:55  lr: 0.0000000  loss: 0.5855 (0.5858)  bbox_regression: 0.0937 (0.1039)  classification: 0.4703 (0.4819)  time: 0.3729  data: 0.1305  max mem: 3278
Epoch: [71]  [2500/3494]  eta: 0:06:17  lr: 0.0000000  loss: 0.5889 (0.5856)  bbox_regression: 0.0876 (0.1038)  classification: 0.4664 (0.4819)  time: 0.3850  data: 0.1374  max mem: 3278
Epoch: [71]  [2600/3494]  eta: 0:05:39  lr: 0.0000000  loss: 0.5361 (0.5848)  bbox_regression: 0.0952 (0.1036)  classification: 0.4275 (0.4811)  time: 0.4207  data: 0.1401  max mem: 3278
Epoch: [71]  [2700/3494]  eta: 0:05:00  lr: 0.0000000  loss: 0.5389 (0.5848)  bbox_regression: 0.0786 (0.1036)  classification: 0.4656 (0.4811)  time: 0.3630  data: 0.1295  max mem: 3278
Epoch: [71]  [2800/3494]  eta: 0:04:22  lr: 0.0000000  loss: 0.5296 (0.5839)  bbox_regression: 0.0988 (0.1035)  classification: 0.4305 (0.4804)  time: 0.3752  data: 0.1300  max mem: 3278
Epoch: [71]  [2900/3494]  eta: 0:03:44  lr: 0.0000000  loss: 0.5958 (0.5837)  bbox_regression: 0.0937 (0.1035)  classification: 0.4796 (0.4802)  time: 0.3747  data: 0.1303  max mem: 3278
Epoch: [71]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.4911 (0.5830)  bbox_regression: 0.0861 (0.1033)  classification: 0.4160 (0.4797)  time: 0.3827  data: 0.1354  max mem: 3278
Epoch: [71]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5460 (0.5824)  bbox_regression: 0.0928 (0.1032)  classification: 0.4423 (0.4792)  time: 0.3958  data: 0.1367  max mem: 3278
Epoch: [71]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5779 (0.5830)  bbox_regression: 0.0938 (0.1033)  classification: 0.4811 (0.4797)  time: 0.3698  data: 0.1285  max mem: 3278
Epoch: [71]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5553 (0.5834)  bbox_regression: 0.0993 (0.1034)  classification: 0.4679 (0.4800)  time: 0.4016  data: 0.1267  max mem: 3278
Epoch: [71]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5797 (0.5834)  bbox_regression: 0.0968 (0.1034)  classification: 0.4537 (0.4800)  time: 0.3619  data: 0.1291  max mem: 3278
Epoch: [71]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5667 (0.5830)  bbox_regression: 0.0931 (0.1032)  classification: 0.4519 (0.4798)  time: 0.3857  data: 0.1465  max mem: 3278
Epoch: [71] Total time: 0:22:13 (0.3816 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:50  model_time: 0.1780 (0.1780)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0374  data: 1.8179  max mem: 3278
Validation:  [100/437]  eta: 0:01:41  model_time: 0.1345 (0.1296)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2725  data: 0.1257  max mem: 3278
Validation:  [200/437]  eta: 0:01:08  model_time: 0.1236 (0.1300)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2675  data: 0.1255  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1327 (0.1317)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2840  data: 0.1292  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1412 (0.1340)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2854  data: 0.1267  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1388 (0.1341)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2756  data: 0.1256  max mem: 3278
Validation: Total time: 0:02:04 (0.2858 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [72]  [   0/3494]  eta: 2:04:04  lr: 0.0000000  loss: 0.4843 (0.4843)  bbox_regression: 0.0790 (0.0790)  classification: 0.4053 (0.4053)  time: 2.1306  data: 1.8222  max mem: 3278
Epoch: [72]  [ 100/3494]  eta: 0:23:23  lr: 0.0000000  loss: 0.6168 (0.5914)  bbox_regression: 0.0997 (0.1047)  classification: 0.4961 (0.4866)  time: 0.3723  data: 0.1396  max mem: 3278
Epoch: [72]  [ 200/3494]  eta: 0:21:30  lr: 0.0000000  loss: 0.5472 (0.5932)  bbox_regression: 0.0995 (0.1035)  classification: 0.4549 (0.4897)  time: 0.3702  data: 0.1270  max mem: 3278
Epoch: [72]  [ 300/3494]  eta: 0:20:30  lr: 0.0000000  loss: 0.5925 (0.5884)  bbox_regression: 0.0888 (0.1028)  classification: 0.5003 (0.4857)  time: 0.3738  data: 0.1363  max mem: 3278
Epoch: [72]  [ 400/3494]  eta: 0:19:38  lr: 0.0000000  loss: 0.5370 (0.5830)  bbox_regression: 0.0899 (0.1018)  classification: 0.4446 (0.4812)  time: 0.3671  data: 0.1327  max mem: 3278
Epoch: [72]  [ 500/3494]  eta: 0:19:01  lr: 0.0000000  loss: 0.5178 (0.5792)  bbox_regression: 0.0951 (0.1009)  classification: 0.4204 (0.4782)  time: 0.3933  data: 0.1419  max mem: 3278
Epoch: [72]  [ 600/3494]  eta: 0:18:22  lr: 0.0000000  loss: 0.6169 (0.5820)  bbox_regression: 0.0996 (0.1022)  classification: 0.5034 (0.4797)  time: 0.3702  data: 0.1303  max mem: 3278
Epoch: [72]  [ 700/3494]  eta: 0:17:47  lr: 0.0000000  loss: 0.5165 (0.5783)  bbox_regression: 0.0921 (0.1018)  classification: 0.4289 (0.4765)  time: 0.3646  data: 0.1259  max mem: 3278
Epoch: [72]  [ 800/3494]  eta: 0:17:10  lr: 0.0000000  loss: 0.5491 (0.5777)  bbox_regression: 0.0933 (0.1013)  classification: 0.4629 (0.4764)  time: 0.4034  data: 0.1352  max mem: 3278
Epoch: [72]  [ 900/3494]  eta: 0:16:32  lr: 0.0000000  loss: 0.5881 (0.5785)  bbox_regression: 0.1024 (0.1017)  classification: 0.4749 (0.4768)  time: 0.3780  data: 0.1249  max mem: 3278
Epoch: [72]  [1000/3494]  eta: 0:15:48  lr: 0.0000000  loss: 0.5564 (0.5783)  bbox_regression: 0.0968 (0.1020)  classification: 0.4397 (0.4763)  time: 0.3622  data: 0.1305  max mem: 3278
Epoch: [72]  [1100/3494]  eta: 0:15:10  lr: 0.0000000  loss: 0.5490 (0.5772)  bbox_regression: 0.0939 (0.1017)  classification: 0.4453 (0.4754)  time: 0.3804  data: 0.1289  max mem: 3278
Epoch: [72]  [1200/3494]  eta: 0:14:33  lr: 0.0000000  loss: 0.5654 (0.5773)  bbox_regression: 0.0908 (0.1019)  classification: 0.4758 (0.4753)  time: 0.4019  data: 0.1439  max mem: 3278
Epoch: [72]  [1300/3494]  eta: 0:13:54  lr: 0.0000000  loss: 0.5322 (0.5783)  bbox_regression: 0.0938 (0.1022)  classification: 0.4443 (0.4761)  time: 0.3699  data: 0.1260  max mem: 3278
Epoch: [72]  [1400/3494]  eta: 0:13:17  lr: 0.0000000  loss: 0.5762 (0.5790)  bbox_regression: 0.0957 (0.1024)  classification: 0.4640 (0.4766)  time: 0.3891  data: 0.1333  max mem: 3278
Epoch: [72]  [1500/3494]  eta: 0:12:38  lr: 0.0000000  loss: 0.5375 (0.5788)  bbox_regression: 0.0936 (0.1024)  classification: 0.4537 (0.4764)  time: 0.3801  data: 0.1358  max mem: 3278
Epoch: [72]  [1600/3494]  eta: 0:12:00  lr: 0.0000000  loss: 0.5612 (0.5802)  bbox_regression: 0.0976 (0.1026)  classification: 0.4678 (0.4776)  time: 0.3851  data: 0.1315  max mem: 3278
Epoch: [72]  [1700/3494]  eta: 0:11:21  lr: 0.0000000  loss: 0.5067 (0.5798)  bbox_regression: 0.0795 (0.1024)  classification: 0.4272 (0.4774)  time: 0.3676  data: 0.1376  max mem: 3278
Epoch: [72]  [1800/3494]  eta: 0:10:42  lr: 0.0000000  loss: 0.5503 (0.5792)  bbox_regression: 0.0894 (0.1022)  classification: 0.4610 (0.4770)  time: 0.3854  data: 0.1358  max mem: 3278
Epoch: [72]  [1900/3494]  eta: 0:10:04  lr: 0.0000000  loss: 0.6180 (0.5795)  bbox_regression: 0.0932 (0.1024)  classification: 0.4936 (0.4771)  time: 0.3872  data: 0.1377  max mem: 3278
Epoch: [72]  [2000/3494]  eta: 0:09:26  lr: 0.0000000  loss: 0.5473 (0.5806)  bbox_regression: 0.1026 (0.1027)  classification: 0.4641 (0.4779)  time: 0.3575  data: 0.1203  max mem: 3278
Epoch: [72]  [2100/3494]  eta: 0:08:48  lr: 0.0000000  loss: 0.5800 (0.5810)  bbox_regression: 0.0989 (0.1030)  classification: 0.4645 (0.4781)  time: 0.3770  data: 0.1361  max mem: 3278
Epoch: [72]  [2200/3494]  eta: 0:08:10  lr: 0.0000000  loss: 0.5607 (0.5805)  bbox_regression: 0.0925 (0.1028)  classification: 0.4756 (0.4776)  time: 0.3945  data: 0.1277  max mem: 3278
Epoch: [72]  [2300/3494]  eta: 0:07:32  lr: 0.0000000  loss: 0.5447 (0.5806)  bbox_regression: 0.0945 (0.1028)  classification: 0.4562 (0.4778)  time: 0.3644  data: 0.1307  max mem: 3278
Epoch: [72]  [2400/3494]  eta: 0:06:54  lr: 0.0000000  loss: 0.6077 (0.5808)  bbox_regression: 0.0905 (0.1028)  classification: 0.4938 (0.4780)  time: 0.3795  data: 0.1368  max mem: 3278
Epoch: [72]  [2500/3494]  eta: 0:06:16  lr: 0.0000000  loss: 0.5740 (0.5807)  bbox_regression: 0.0965 (0.1029)  classification: 0.4776 (0.4778)  time: 0.4019  data: 0.1487  max mem: 3278
Epoch: [72]  [2600/3494]  eta: 0:05:38  lr: 0.0000000  loss: 0.5823 (0.5807)  bbox_regression: 0.0978 (0.1029)  classification: 0.4667 (0.4778)  time: 0.3912  data: 0.1371  max mem: 3278
Epoch: [72]  [2700/3494]  eta: 0:05:00  lr: 0.0000000  loss: 0.5574 (0.5811)  bbox_regression: 0.0839 (0.1030)  classification: 0.4527 (0.4781)  time: 0.4023  data: 0.1430  max mem: 3278
Epoch: [72]  [2800/3494]  eta: 0:04:23  lr: 0.0000000  loss: 0.5552 (0.5813)  bbox_regression: 0.0974 (0.1030)  classification: 0.4621 (0.4782)  time: 0.3973  data: 0.1304  max mem: 3278
Epoch: [72]  [2900/3494]  eta: 0:03:45  lr: 0.0000000  loss: 0.5395 (0.5816)  bbox_regression: 0.0860 (0.1030)  classification: 0.4452 (0.4786)  time: 0.3749  data: 0.1385  max mem: 3278
Epoch: [72]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.5269 (0.5815)  bbox_regression: 0.0907 (0.1029)  classification: 0.4268 (0.4786)  time: 0.3666  data: 0.1281  max mem: 3278
Epoch: [72]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5613 (0.5819)  bbox_regression: 0.1031 (0.1030)  classification: 0.4746 (0.4788)  time: 0.3620  data: 0.1272  max mem: 3278
Epoch: [72]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5703 (0.5826)  bbox_regression: 0.0937 (0.1031)  classification: 0.4673 (0.4794)  time: 0.3890  data: 0.1381  max mem: 3278
Epoch: [72]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5182 (0.5825)  bbox_regression: 0.0949 (0.1031)  classification: 0.4143 (0.4794)  time: 0.3605  data: 0.1230  max mem: 3278
Epoch: [72]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5520 (0.5826)  bbox_regression: 0.0983 (0.1031)  classification: 0.4465 (0.4795)  time: 0.3884  data: 0.1386  max mem: 3278
Epoch: [72]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5449 (0.5825)  bbox_regression: 0.0917 (0.1031)  classification: 0.4485 (0.4794)  time: 0.3622  data: 0.1261  max mem: 3278
Epoch: [72] Total time: 0:22:12 (0.3814 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:35  model_time: 0.1485 (0.1485)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8660  data: 1.6940  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1331 (0.1312)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2650  data: 0.1199  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1321 (0.1294)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2853  data: 0.1368  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1240 (0.1310)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2687  data: 0.1190  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1340 (0.1319)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2770  data: 0.1305  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1122 (0.1309)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2452  data: 0.1146  max mem: 3278
Validation: Total time: 0:02:02 (0.2797 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [73]  [   0/3494]  eta: 2:32:26  lr: 0.0000000  loss: 0.7276 (0.7276)  bbox_regression: 0.1399 (0.1399)  classification: 0.5877 (0.5877)  time: 2.6178  data: 2.3533  max mem: 3278
Epoch: [73]  [ 100/3494]  eta: 0:22:09  lr: 0.0000000  loss: 0.5593 (0.5838)  bbox_regression: 0.1022 (0.1063)  classification: 0.4514 (0.4774)  time: 0.3803  data: 0.1360  max mem: 3278
Epoch: [73]  [ 200/3494]  eta: 0:21:18  lr: 0.0000000  loss: 0.5882 (0.5862)  bbox_regression: 0.1138 (0.1071)  classification: 0.4707 (0.4792)  time: 0.3766  data: 0.1310  max mem: 3278
Epoch: [73]  [ 300/3494]  eta: 0:20:32  lr: 0.0000000  loss: 0.5425 (0.5869)  bbox_regression: 0.0892 (0.1052)  classification: 0.4496 (0.4818)  time: 0.3855  data: 0.1341  max mem: 3278
Epoch: [73]  [ 400/3494]  eta: 0:20:03  lr: 0.0000000  loss: 0.5919 (0.5842)  bbox_regression: 0.0966 (0.1038)  classification: 0.4658 (0.4804)  time: 0.3797  data: 0.1303  max mem: 3278
Epoch: [73]  [ 500/3494]  eta: 0:19:24  lr: 0.0000000  loss: 0.5587 (0.5811)  bbox_regression: 0.0892 (0.1028)  classification: 0.4623 (0.4783)  time: 0.4281  data: 0.1387  max mem: 3278
Epoch: [73]  [ 600/3494]  eta: 0:18:36  lr: 0.0000000  loss: 0.6043 (0.5848)  bbox_regression: 0.1045 (0.1037)  classification: 0.4789 (0.4811)  time: 0.3707  data: 0.1330  max mem: 3278
Epoch: [73]  [ 700/3494]  eta: 0:17:57  lr: 0.0000000  loss: 0.5905 (0.5854)  bbox_regression: 0.0946 (0.1038)  classification: 0.4856 (0.4816)  time: 0.3729  data: 0.1312  max mem: 3278
Epoch: [73]  [ 800/3494]  eta: 0:17:07  lr: 0.0000000  loss: 0.5690 (0.5841)  bbox_regression: 0.0930 (0.1035)  classification: 0.4618 (0.4807)  time: 0.3641  data: 0.1290  max mem: 3278
Epoch: [73]  [ 900/3494]  eta: 0:16:27  lr: 0.0000000  loss: 0.5736 (0.5831)  bbox_regression: 0.1009 (0.1031)  classification: 0.4657 (0.4800)  time: 0.4023  data: 0.1553  max mem: 3278
Epoch: [73]  [1000/3494]  eta: 0:15:49  lr: 0.0000000  loss: 0.5200 (0.5836)  bbox_regression: 0.0869 (0.1030)  classification: 0.4449 (0.4806)  time: 0.3823  data: 0.1396  max mem: 3278
Epoch: [73]  [1100/3494]  eta: 0:15:10  lr: 0.0000000  loss: 0.5949 (0.5839)  bbox_regression: 0.1057 (0.1033)  classification: 0.4875 (0.4806)  time: 0.3879  data: 0.1373  max mem: 3278
Epoch: [73]  [1200/3494]  eta: 0:14:32  lr: 0.0000000  loss: 0.5680 (0.5831)  bbox_regression: 0.0860 (0.1028)  classification: 0.4684 (0.4802)  time: 0.3690  data: 0.1276  max mem: 3278
Epoch: [73]  [1300/3494]  eta: 0:13:55  lr: 0.0000000  loss: 0.5785 (0.5837)  bbox_regression: 0.1011 (0.1033)  classification: 0.4588 (0.4805)  time: 0.3880  data: 0.1376  max mem: 3278
Epoch: [73]  [1400/3494]  eta: 0:13:16  lr: 0.0000000  loss: 0.4841 (0.5825)  bbox_regression: 0.0952 (0.1035)  classification: 0.3851 (0.4790)  time: 0.3514  data: 0.1270  max mem: 3278
Epoch: [73]  [1500/3494]  eta: 0:12:36  lr: 0.0000000  loss: 0.5988 (0.5843)  bbox_regression: 0.0980 (0.1040)  classification: 0.5073 (0.4803)  time: 0.3590  data: 0.1254  max mem: 3278
Epoch: [73]  [1600/3494]  eta: 0:11:57  lr: 0.0000000  loss: 0.5079 (0.5839)  bbox_regression: 0.0859 (0.1039)  classification: 0.4175 (0.4800)  time: 0.3768  data: 0.1305  max mem: 3278
Epoch: [73]  [1700/3494]  eta: 0:11:20  lr: 0.0000000  loss: 0.5174 (0.5841)  bbox_regression: 0.0848 (0.1037)  classification: 0.4326 (0.4804)  time: 0.3870  data: 0.1433  max mem: 3278
Epoch: [73]  [1800/3494]  eta: 0:10:43  lr: 0.0000000  loss: 0.5614 (0.5845)  bbox_regression: 0.0934 (0.1037)  classification: 0.4809 (0.4808)  time: 0.3964  data: 0.1441  max mem: 3278
Epoch: [73]  [1900/3494]  eta: 0:10:06  lr: 0.0000000  loss: 0.5358 (0.5835)  bbox_regression: 0.1053 (0.1034)  classification: 0.4367 (0.4801)  time: 0.3966  data: 0.1412  max mem: 3278
Epoch: [73]  [2000/3494]  eta: 0:09:28  lr: 0.0000000  loss: 0.5743 (0.5828)  bbox_regression: 0.0943 (0.1032)  classification: 0.4668 (0.4796)  time: 0.3895  data: 0.1344  max mem: 3278
Epoch: [73]  [2100/3494]  eta: 0:08:50  lr: 0.0000000  loss: 0.5552 (0.5823)  bbox_regression: 0.0906 (0.1033)  classification: 0.4646 (0.4790)  time: 0.3660  data: 0.1317  max mem: 3278
Epoch: [73]  [2200/3494]  eta: 0:08:11  lr: 0.0000000  loss: 0.5359 (0.5819)  bbox_regression: 0.0923 (0.1030)  classification: 0.4711 (0.4789)  time: 0.3631  data: 0.1328  max mem: 3278
Epoch: [73]  [2300/3494]  eta: 0:07:33  lr: 0.0000000  loss: 0.5233 (0.5813)  bbox_regression: 0.0852 (0.1030)  classification: 0.4389 (0.4783)  time: 0.3669  data: 0.1344  max mem: 3278
Epoch: [73]  [2400/3494]  eta: 0:06:55  lr: 0.0000000  loss: 0.5801 (0.5818)  bbox_regression: 0.0903 (0.1030)  classification: 0.4638 (0.4787)  time: 0.3941  data: 0.1404  max mem: 3278
Epoch: [73]  [2500/3494]  eta: 0:06:17  lr: 0.0000000  loss: 0.5881 (0.5817)  bbox_regression: 0.0974 (0.1030)  classification: 0.4906 (0.4787)  time: 0.3875  data: 0.1387  max mem: 3278
Epoch: [73]  [2600/3494]  eta: 0:05:39  lr: 0.0000000  loss: 0.6109 (0.5822)  bbox_regression: 0.1038 (0.1029)  classification: 0.4990 (0.4793)  time: 0.3802  data: 0.1283  max mem: 3278
Epoch: [73]  [2700/3494]  eta: 0:05:01  lr: 0.0000000  loss: 0.5595 (0.5827)  bbox_regression: 0.0926 (0.1029)  classification: 0.4645 (0.4798)  time: 0.3759  data: 0.1238  max mem: 3278
Epoch: [73]  [2800/3494]  eta: 0:04:23  lr: 0.0000000  loss: 0.6270 (0.5828)  bbox_regression: 0.1035 (0.1029)  classification: 0.5017 (0.4798)  time: 0.3832  data: 0.1298  max mem: 3278
Epoch: [73]  [2900/3494]  eta: 0:03:45  lr: 0.0000000  loss: 0.5393 (0.5827)  bbox_regression: 0.0972 (0.1029)  classification: 0.4599 (0.4798)  time: 0.3639  data: 0.1292  max mem: 3278
Epoch: [73]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.5858 (0.5829)  bbox_regression: 0.1012 (0.1031)  classification: 0.4951 (0.4799)  time: 0.3725  data: 0.1275  max mem: 3278
Epoch: [73]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5459 (0.5828)  bbox_regression: 0.1019 (0.1030)  classification: 0.4439 (0.4797)  time: 0.3795  data: 0.1289  max mem: 3278
Epoch: [73]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5915 (0.5833)  bbox_regression: 0.1014 (0.1032)  classification: 0.4820 (0.4801)  time: 0.3674  data: 0.1292  max mem: 3278
Epoch: [73]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5154 (0.5831)  bbox_regression: 0.0808 (0.1032)  classification: 0.4357 (0.4799)  time: 0.3679  data: 0.1304  max mem: 3278
Epoch: [73]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.4973 (0.5826)  bbox_regression: 0.0861 (0.1030)  classification: 0.4201 (0.4796)  time: 0.3561  data: 0.1268  max mem: 3278
Epoch: [73]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5714 (0.5827)  bbox_regression: 0.1021 (0.1030)  classification: 0.4771 (0.4797)  time: 0.4147  data: 0.1321  max mem: 3278
Epoch: [73] Total time: 0:22:13 (0.3818 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:37  model_time: 0.1485 (0.1485)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0070  data: 1.8223  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1266 (0.1235)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2766  data: 0.1267  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1189 (0.1232)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2660  data: 0.1243  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1174 (0.1267)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2603  data: 0.1209  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1276 (0.1276)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2797  data: 0.1330  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1365 (0.1280)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2682  data: 0.1210  max mem: 3278
Validation: Total time: 0:02:00 (0.2759 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [74]  [   0/3494]  eta: 2:36:10  lr: 0.0000000  loss: 0.7229 (0.7229)  bbox_regression: 0.1681 (0.1681)  classification: 0.5548 (0.5548)  time: 2.6818  data: 2.4206  max mem: 3278
Epoch: [74]  [ 100/3494]  eta: 0:22:56  lr: 0.0000000  loss: 0.5523 (0.5806)  bbox_regression: 0.0939 (0.1027)  classification: 0.4484 (0.4779)  time: 0.3785  data: 0.1392  max mem: 3278
Epoch: [74]  [ 200/3494]  eta: 0:21:37  lr: 0.0000000  loss: 0.5546 (0.5825)  bbox_regression: 0.1026 (0.1028)  classification: 0.4614 (0.4797)  time: 0.3764  data: 0.1283  max mem: 3278
Epoch: [74]  [ 300/3494]  eta: 0:20:41  lr: 0.0000000  loss: 0.5620 (0.5787)  bbox_regression: 0.0884 (0.1018)  classification: 0.4583 (0.4769)  time: 0.4088  data: 0.1247  max mem: 3278
Epoch: [74]  [ 400/3494]  eta: 0:19:52  lr: 0.0000000  loss: 0.5529 (0.5781)  bbox_regression: 0.0888 (0.1012)  classification: 0.4558 (0.4769)  time: 0.3941  data: 0.1331  max mem: 3278
Epoch: [74]  [ 500/3494]  eta: 0:19:08  lr: 0.0000000  loss: 0.5626 (0.5816)  bbox_regression: 0.0904 (0.1020)  classification: 0.4760 (0.4796)  time: 0.3662  data: 0.1342  max mem: 3278
Epoch: [74]  [ 600/3494]  eta: 0:18:19  lr: 0.0000000  loss: 0.5573 (0.5840)  bbox_regression: 0.0876 (0.1024)  classification: 0.4733 (0.4815)  time: 0.3801  data: 0.1309  max mem: 3278
Epoch: [74]  [ 700/3494]  eta: 0:17:41  lr: 0.0000000  loss: 0.5101 (0.5812)  bbox_regression: 0.0876 (0.1020)  classification: 0.4235 (0.4792)  time: 0.3978  data: 0.1557  max mem: 3278
Epoch: [74]  [ 800/3494]  eta: 0:17:08  lr: 0.0000000  loss: 0.5314 (0.5806)  bbox_regression: 0.0913 (0.1021)  classification: 0.4410 (0.4784)  time: 0.4252  data: 0.1482  max mem: 3278
Epoch: [74]  [ 900/3494]  eta: 0:16:31  lr: 0.0000000  loss: 0.5920 (0.5811)  bbox_regression: 0.1050 (0.1021)  classification: 0.5013 (0.4790)  time: 0.3833  data: 0.1357  max mem: 3278
Epoch: [74]  [1000/3494]  eta: 0:15:53  lr: 0.0000000  loss: 0.5824 (0.5846)  bbox_regression: 0.0978 (0.1027)  classification: 0.4747 (0.4819)  time: 0.3715  data: 0.1280  max mem: 3278
Epoch: [74]  [1100/3494]  eta: 0:15:17  lr: 0.0000000  loss: 0.5389 (0.5831)  bbox_regression: 0.0905 (0.1022)  classification: 0.4379 (0.4809)  time: 0.4051  data: 0.1367  max mem: 3278
Epoch: [74]  [1200/3494]  eta: 0:14:36  lr: 0.0000000  loss: 0.5521 (0.5833)  bbox_regression: 0.0974 (0.1024)  classification: 0.4561 (0.4810)  time: 0.3792  data: 0.1425  max mem: 3278
Epoch: [74]  [1300/3494]  eta: 0:13:55  lr: 0.0000000  loss: 0.5135 (0.5836)  bbox_regression: 0.0894 (0.1025)  classification: 0.4123 (0.4811)  time: 0.3810  data: 0.1314  max mem: 3278
Epoch: [74]  [1400/3494]  eta: 0:13:17  lr: 0.0000000  loss: 0.5975 (0.5848)  bbox_regression: 0.0879 (0.1027)  classification: 0.4855 (0.4822)  time: 0.3807  data: 0.1338  max mem: 3278
Epoch: [74]  [1500/3494]  eta: 0:12:39  lr: 0.0000000  loss: 0.6209 (0.5844)  bbox_regression: 0.0921 (0.1026)  classification: 0.5199 (0.4819)  time: 0.3583  data: 0.1255  max mem: 3278
Epoch: [74]  [1600/3494]  eta: 0:12:01  lr: 0.0000000  loss: 0.5729 (0.5849)  bbox_regression: 0.0958 (0.1027)  classification: 0.4759 (0.4822)  time: 0.3681  data: 0.1342  max mem: 3278
Epoch: [74]  [1700/3494]  eta: 0:11:23  lr: 0.0000000  loss: 0.5404 (0.5825)  bbox_regression: 0.0940 (0.1023)  classification: 0.4340 (0.4803)  time: 0.3674  data: 0.1325  max mem: 3278
Epoch: [74]  [1800/3494]  eta: 0:10:45  lr: 0.0000000  loss: 0.6148 (0.5819)  bbox_regression: 0.1050 (0.1020)  classification: 0.5234 (0.4799)  time: 0.4343  data: 0.1276  max mem: 3278
Epoch: [74]  [1900/3494]  eta: 0:10:05  lr: 0.0000000  loss: 0.5598 (0.5819)  bbox_regression: 0.0955 (0.1023)  classification: 0.4643 (0.4796)  time: 0.3638  data: 0.1399  max mem: 3278
Epoch: [74]  [2000/3494]  eta: 0:09:25  lr: 0.0000000  loss: 0.5335 (0.5826)  bbox_regression: 0.0957 (0.1024)  classification: 0.4398 (0.4802)  time: 0.3582  data: 0.1284  max mem: 3278
Epoch: [74]  [2100/3494]  eta: 0:08:48  lr: 0.0000000  loss: 0.5314 (0.5822)  bbox_regression: 0.0880 (0.1025)  classification: 0.4451 (0.4797)  time: 0.3788  data: 0.1281  max mem: 3278
Epoch: [74]  [2200/3494]  eta: 0:08:09  lr: 0.0000000  loss: 0.5759 (0.5829)  bbox_regression: 0.0961 (0.1027)  classification: 0.4837 (0.4801)  time: 0.3666  data: 0.1284  max mem: 3278
Epoch: [74]  [2300/3494]  eta: 0:07:31  lr: 0.0000000  loss: 0.5968 (0.5830)  bbox_regression: 0.1011 (0.1028)  classification: 0.4673 (0.4802)  time: 0.3919  data: 0.1416  max mem: 3278
Epoch: [74]  [2400/3494]  eta: 0:06:54  lr: 0.0000000  loss: 0.6152 (0.5826)  bbox_regression: 0.1064 (0.1029)  classification: 0.4876 (0.4797)  time: 0.3571  data: 0.1279  max mem: 3278
Epoch: [74]  [2500/3494]  eta: 0:06:16  lr: 0.0000000  loss: 0.5623 (0.5831)  bbox_regression: 0.0914 (0.1029)  classification: 0.4631 (0.4801)  time: 0.3839  data: 0.1357  max mem: 3278
Epoch: [74]  [2600/3494]  eta: 0:05:38  lr: 0.0000000  loss: 0.5616 (0.5825)  bbox_regression: 0.0944 (0.1030)  classification: 0.4619 (0.4796)  time: 0.3716  data: 0.1361  max mem: 3278
Epoch: [74]  [2700/3494]  eta: 0:05:00  lr: 0.0000000  loss: 0.5718 (0.5822)  bbox_regression: 0.0991 (0.1030)  classification: 0.4658 (0.4792)  time: 0.3688  data: 0.1370  max mem: 3278
Epoch: [74]  [2800/3494]  eta: 0:04:22  lr: 0.0000000  loss: 0.5416 (0.5823)  bbox_regression: 0.0960 (0.1029)  classification: 0.4424 (0.4794)  time: 0.3544  data: 0.1263  max mem: 3278
Epoch: [74]  [2900/3494]  eta: 0:03:44  lr: 0.0000000  loss: 0.5496 (0.5824)  bbox_regression: 0.0897 (0.1029)  classification: 0.4536 (0.4794)  time: 0.3730  data: 0.1316  max mem: 3278
Epoch: [74]  [3000/3494]  eta: 0:03:06  lr: 0.0000000  loss: 0.5405 (0.5825)  bbox_regression: 0.0960 (0.1031)  classification: 0.4406 (0.4794)  time: 0.3854  data: 0.1406  max mem: 3278
Epoch: [74]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5719 (0.5818)  bbox_regression: 0.0873 (0.1029)  classification: 0.4668 (0.4789)  time: 0.3889  data: 0.1355  max mem: 3278
Epoch: [74]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5750 (0.5821)  bbox_regression: 0.0952 (0.1029)  classification: 0.4793 (0.4793)  time: 0.4054  data: 0.1289  max mem: 3278
Epoch: [74]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5908 (0.5826)  bbox_regression: 0.1102 (0.1032)  classification: 0.4740 (0.4795)  time: 0.3543  data: 0.1267  max mem: 3278
Epoch: [74]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5506 (0.5826)  bbox_regression: 0.1014 (0.1032)  classification: 0.4649 (0.4794)  time: 0.3552  data: 0.1277  max mem: 3278
Epoch: [74]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5638 (0.5827)  bbox_regression: 0.0938 (0.1031)  classification: 0.4564 (0.4796)  time: 0.3571  data: 0.1253  max mem: 3278
Epoch: [74] Total time: 0:22:09 (0.3805 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:40  model_time: 0.1574 (0.1574)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.2900  data: 2.0917  max mem: 3278
Validation:  [100/437]  eta: 0:01:40  model_time: 0.1277 (0.1341)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2919  data: 0.1392  max mem: 3278
Validation:  [200/437]  eta: 0:01:09  model_time: 0.1391 (0.1373)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2926  data: 0.1211  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1379 (0.1378)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2877  data: 0.1282  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1350 (0.1368)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2767  data: 0.1230  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1212 (0.1362)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2639  data: 0.1228  max mem: 3278
Validation: Total time: 0:02:05 (0.2868 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [75]  [   0/3494]  eta: 2:43:15  lr: 0.0000000  loss: 0.6546 (0.6546)  bbox_regression: 0.1427 (0.1427)  classification: 0.5119 (0.5119)  time: 2.8037  data: 2.5680  max mem: 3278
Epoch: [75]  [ 100/3494]  eta: 0:22:48  lr: 0.0000000  loss: 0.5356 (0.6126)  bbox_regression: 0.0977 (0.1097)  classification: 0.4637 (0.5029)  time: 0.3521  data: 0.1251  max mem: 3278
Epoch: [75]  [ 200/3494]  eta: 0:21:21  lr: 0.0000000  loss: 0.5398 (0.5901)  bbox_regression: 0.0878 (0.1042)  classification: 0.4568 (0.4858)  time: 0.3454  data: 0.1156  max mem: 3278
Epoch: [75]  [ 300/3494]  eta: 0:20:12  lr: 0.0000000  loss: 0.5939 (0.5952)  bbox_regression: 0.0980 (0.1059)  classification: 0.4788 (0.4893)  time: 0.3532  data: 0.1234  max mem: 3278
Epoch: [75]  [ 400/3494]  eta: 0:19:30  lr: 0.0000000  loss: 0.5637 (0.5890)  bbox_regression: 0.0916 (0.1048)  classification: 0.4476 (0.4842)  time: 0.3795  data: 0.1343  max mem: 3278
Epoch: [75]  [ 500/3494]  eta: 0:18:49  lr: 0.0000000  loss: 0.5454 (0.5882)  bbox_regression: 0.0928 (0.1039)  classification: 0.4528 (0.4843)  time: 0.3705  data: 0.1269  max mem: 3278
Epoch: [75]  [ 600/3494]  eta: 0:18:10  lr: 0.0000000  loss: 0.5624 (0.5887)  bbox_regression: 0.1105 (0.1041)  classification: 0.4584 (0.4846)  time: 0.3693  data: 0.1329  max mem: 3278
Epoch: [75]  [ 700/3494]  eta: 0:17:35  lr: 0.0000000  loss: 0.5290 (0.5869)  bbox_regression: 0.0778 (0.1032)  classification: 0.4506 (0.4837)  time: 0.4221  data: 0.1359  max mem: 3278
Epoch: [75]  [ 800/3494]  eta: 0:16:55  lr: 0.0000000  loss: 0.5680 (0.5883)  bbox_regression: 0.0927 (0.1039)  classification: 0.4702 (0.4845)  time: 0.3661  data: 0.1261  max mem: 3278
Epoch: [75]  [ 900/3494]  eta: 0:16:21  lr: 0.0000000  loss: 0.5433 (0.5864)  bbox_regression: 0.0909 (0.1037)  classification: 0.4524 (0.4827)  time: 0.3820  data: 0.1472  max mem: 3278
Epoch: [75]  [1000/3494]  eta: 0:15:42  lr: 0.0000000  loss: 0.5875 (0.5865)  bbox_regression: 0.0925 (0.1036)  classification: 0.4801 (0.4829)  time: 0.3559  data: 0.1250  max mem: 3278
Epoch: [75]  [1100/3494]  eta: 0:15:01  lr: 0.0000000  loss: 0.5571 (0.5861)  bbox_regression: 0.0971 (0.1035)  classification: 0.4687 (0.4826)  time: 0.3663  data: 0.1329  max mem: 3278
Epoch: [75]  [1200/3494]  eta: 0:14:22  lr: 0.0000000  loss: 0.5543 (0.5863)  bbox_regression: 0.1029 (0.1036)  classification: 0.4479 (0.4827)  time: 0.3806  data: 0.1285  max mem: 3278
Epoch: [75]  [1300/3494]  eta: 0:13:44  lr: 0.0000000  loss: 0.5618 (0.5853)  bbox_regression: 0.0892 (0.1034)  classification: 0.4504 (0.4819)  time: 0.3648  data: 0.1265  max mem: 3278
Epoch: [75]  [1400/3494]  eta: 0:13:08  lr: 0.0000000  loss: 0.6135 (0.5862)  bbox_regression: 0.1002 (0.1036)  classification: 0.5239 (0.4826)  time: 0.3805  data: 0.1325  max mem: 3278
Epoch: [75]  [1500/3494]  eta: 0:12:32  lr: 0.0000000  loss: 0.4894 (0.5858)  bbox_regression: 0.0922 (0.1035)  classification: 0.4154 (0.4823)  time: 0.3783  data: 0.1288  max mem: 3278
Epoch: [75]  [1600/3494]  eta: 0:11:55  lr: 0.0000000  loss: 0.5400 (0.5844)  bbox_regression: 0.0908 (0.1035)  classification: 0.4454 (0.4809)  time: 0.3793  data: 0.1305  max mem: 3278
Epoch: [75]  [1700/3494]  eta: 0:11:18  lr: 0.0000000  loss: 0.5822 (0.5849)  bbox_regression: 0.0888 (0.1035)  classification: 0.5033 (0.4814)  time: 0.3995  data: 0.1300  max mem: 3278
Epoch: [75]  [1800/3494]  eta: 0:10:39  lr: 0.0000000  loss: 0.5480 (0.5850)  bbox_regression: 0.0985 (0.1035)  classification: 0.4633 (0.4815)  time: 0.3585  data: 0.1234  max mem: 3278
Epoch: [75]  [1900/3494]  eta: 0:10:01  lr: 0.0000000  loss: 0.5549 (0.5846)  bbox_regression: 0.1019 (0.1035)  classification: 0.4568 (0.4811)  time: 0.3771  data: 0.1318  max mem: 3278
Epoch: [75]  [2000/3494]  eta: 0:09:23  lr: 0.0000000  loss: 0.5274 (0.5840)  bbox_regression: 0.0911 (0.1035)  classification: 0.4232 (0.4805)  time: 0.3828  data: 0.1389  max mem: 3278
Epoch: [75]  [2100/3494]  eta: 0:08:46  lr: 0.0000000  loss: 0.5781 (0.5841)  bbox_regression: 0.0977 (0.1034)  classification: 0.4781 (0.4808)  time: 0.3821  data: 0.1314  max mem: 3278
Epoch: [75]  [2200/3494]  eta: 0:08:09  lr: 0.0000000  loss: 0.5714 (0.5832)  bbox_regression: 0.0973 (0.1032)  classification: 0.4740 (0.4800)  time: 0.3881  data: 0.1329  max mem: 3278
Epoch: [75]  [2300/3494]  eta: 0:07:31  lr: 0.0000000  loss: 0.5777 (0.5831)  bbox_regression: 0.0982 (0.1032)  classification: 0.4667 (0.4798)  time: 0.3789  data: 0.1349  max mem: 3278
Epoch: [75]  [2400/3494]  eta: 0:06:54  lr: 0.0000000  loss: 0.6122 (0.5835)  bbox_regression: 0.0992 (0.1034)  classification: 0.5010 (0.4801)  time: 0.3706  data: 0.1283  max mem: 3278
Epoch: [75]  [2500/3494]  eta: 0:06:16  lr: 0.0000000  loss: 0.5749 (0.5838)  bbox_regression: 0.0983 (0.1036)  classification: 0.4750 (0.4802)  time: 0.3787  data: 0.1404  max mem: 3278
Epoch: [75]  [2600/3494]  eta: 0:05:38  lr: 0.0000000  loss: 0.5781 (0.5836)  bbox_regression: 0.0866 (0.1035)  classification: 0.4848 (0.4801)  time: 0.3736  data: 0.1304  max mem: 3278
Epoch: [75]  [2700/3494]  eta: 0:05:00  lr: 0.0000000  loss: 0.5793 (0.5834)  bbox_regression: 0.1005 (0.1035)  classification: 0.4747 (0.4800)  time: 0.3794  data: 0.1389  max mem: 3278
Epoch: [75]  [2800/3494]  eta: 0:04:22  lr: 0.0000000  loss: 0.5850 (0.5837)  bbox_regression: 0.0888 (0.1033)  classification: 0.4730 (0.4804)  time: 0.3742  data: 0.1317  max mem: 3278
Epoch: [75]  [2900/3494]  eta: 0:03:45  lr: 0.0000000  loss: 0.5486 (0.5830)  bbox_regression: 0.0956 (0.1032)  classification: 0.4568 (0.4798)  time: 0.3761  data: 0.1320  max mem: 3278
Epoch: [75]  [3000/3494]  eta: 0:03:07  lr: 0.0000000  loss: 0.5215 (0.5833)  bbox_regression: 0.0855 (0.1032)  classification: 0.4314 (0.4801)  time: 0.3606  data: 0.1265  max mem: 3278
Epoch: [75]  [3100/3494]  eta: 0:02:29  lr: 0.0000000  loss: 0.5645 (0.5836)  bbox_regression: 0.0996 (0.1034)  classification: 0.4627 (0.4802)  time: 0.3688  data: 0.1296  max mem: 3278
Epoch: [75]  [3200/3494]  eta: 0:01:51  lr: 0.0000000  loss: 0.5538 (0.5837)  bbox_regression: 0.0927 (0.1034)  classification: 0.4544 (0.4803)  time: 0.3716  data: 0.1319  max mem: 3278
Epoch: [75]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5250 (0.5841)  bbox_regression: 0.0956 (0.1035)  classification: 0.4240 (0.4806)  time: 0.3829  data: 0.1349  max mem: 3278
Epoch: [75]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5413 (0.5840)  bbox_regression: 0.0977 (0.1035)  classification: 0.4292 (0.4804)  time: 0.3852  data: 0.1361  max mem: 3278
Epoch: [75]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5456 (0.5836)  bbox_regression: 0.0880 (0.1034)  classification: 0.4485 (0.4802)  time: 0.3594  data: 0.1223  max mem: 3278
Epoch: [75] Total time: 0:22:11 (0.3812 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:34  model_time: 0.1375 (0.1375)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8636  data: 1.6874  max mem: 3278
Validation:  [100/437]  eta: 0:01:43  model_time: 0.1419 (0.1404)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2933  data: 0.1232  max mem: 3278
Validation:  [200/437]  eta: 0:01:10  model_time: 0.1401 (0.1399)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2842  data: 0.1298  max mem: 3278
Validation:  [300/437]  eta: 0:00:39  model_time: 0.1307 (0.1367)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2750  data: 0.1295  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1227 (0.1355)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2791  data: 0.1355  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1166 (0.1342)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2567  data: 0.1189  max mem: 3278
Validation: Total time: 0:02:04 (0.2842 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [76]  [   0/3494]  eta: 1:55:04  lr: 0.0000000  loss: 0.6418 (0.6418)  bbox_regression: 0.1153 (0.1153)  classification: 0.5265 (0.5265)  time: 1.9762  data: 1.7398  max mem: 3278
Epoch: [76]  [ 100/3494]  eta: 0:22:22  lr: 0.0000000  loss: 0.5256 (0.5823)  bbox_regression: 0.0933 (0.1052)  classification: 0.4473 (0.4770)  time: 0.3501  data: 0.1234  max mem: 3278
Epoch: [76]  [ 200/3494]  eta: 0:20:47  lr: 0.0000000  loss: 0.5662 (0.5914)  bbox_regression: 0.0961 (0.1043)  classification: 0.4696 (0.4871)  time: 0.3660  data: 0.1300  max mem: 3278
Epoch: [76]  [ 300/3494]  eta: 0:20:02  lr: 0.0000000  loss: 0.6219 (0.5880)  bbox_regression: 0.1068 (0.1044)  classification: 0.5197 (0.4835)  time: 0.3655  data: 0.1259  max mem: 3278
Epoch: [76]  [ 400/3494]  eta: 0:19:32  lr: 0.0000000  loss: 0.5594 (0.5913)  bbox_regression: 0.0985 (0.1058)  classification: 0.4391 (0.4855)  time: 0.3987  data: 0.1379  max mem: 3278
Epoch: [76]  [ 500/3494]  eta: 0:19:01  lr: 0.0000000  loss: 0.5713 (0.5903)  bbox_regression: 0.0884 (0.1061)  classification: 0.4711 (0.4842)  time: 0.3715  data: 0.1361  max mem: 3278
Epoch: [76]  [ 600/3494]  eta: 0:18:25  lr: 0.0000000  loss: 0.5396 (0.5874)  bbox_regression: 0.0844 (0.1058)  classification: 0.4632 (0.4816)  time: 0.3939  data: 0.1314  max mem: 3278
Epoch: [76]  [ 700/3494]  eta: 0:17:45  lr: 0.0000000  loss: 0.5720 (0.5887)  bbox_regression: 0.1069 (0.1057)  classification: 0.4674 (0.4830)  time: 0.3894  data: 0.1265  max mem: 3278
Epoch: [76]  [ 800/3494]  eta: 0:17:04  lr: 0.0000000  loss: 0.6092 (0.5893)  bbox_regression: 0.0944 (0.1053)  classification: 0.4970 (0.4840)  time: 0.3603  data: 0.1277  max mem: 3278
Epoch: [76]  [ 900/3494]  eta: 0:16:20  lr: 0.0000000  loss: 0.5475 (0.5879)  bbox_regression: 0.1095 (0.1050)  classification: 0.4430 (0.4830)  time: 0.3629  data: 0.1330  max mem: 3278
Epoch: [76]  [1000/3494]  eta: 0:15:41  lr: 0.0000000  loss: 0.6312 (0.5868)  bbox_regression: 0.1000 (0.1046)  classification: 0.5041 (0.4822)  time: 0.3764  data: 0.1277  max mem: 3278
Epoch: [76]  [1100/3494]  eta: 0:15:05  lr: 0.0000000  loss: 0.5945 (0.5871)  bbox_regression: 0.1009 (0.1046)  classification: 0.4850 (0.4826)  time: 0.3762  data: 0.1311  max mem: 3278
Epoch: [76]  [1200/3494]  eta: 0:14:28  lr: 0.0000000  loss: 0.6108 (0.5862)  bbox_regression: 0.0962 (0.1043)  classification: 0.4780 (0.4819)  time: 0.3635  data: 0.1245  max mem: 3278
Epoch: [76]  [1300/3494]  eta: 0:13:50  lr: 0.0000000  loss: 0.6087 (0.5859)  bbox_regression: 0.1062 (0.1042)  classification: 0.5091 (0.4817)  time: 0.3835  data: 0.1369  max mem: 3278
Epoch: [76]  [1400/3494]  eta: 0:13:14  lr: 0.0000000  loss: 0.5555 (0.5851)  bbox_regression: 0.0867 (0.1039)  classification: 0.4725 (0.4811)  time: 0.3875  data: 0.1341  max mem: 3278
Epoch: [76]  [1500/3494]  eta: 0:12:35  lr: 0.0000000  loss: 0.5539 (0.5855)  bbox_regression: 0.0919 (0.1040)  classification: 0.4683 (0.4815)  time: 0.3605  data: 0.1288  max mem: 3278
Epoch: [76]  [1600/3494]  eta: 0:11:56  lr: 0.0000000  loss: 0.5764 (0.5860)  bbox_regression: 0.0995 (0.1042)  classification: 0.4789 (0.4818)  time: 0.3829  data: 0.1433  max mem: 3278
Epoch: [76]  [1700/3494]  eta: 0:11:17  lr: 0.0000000  loss: 0.5154 (0.5854)  bbox_regression: 0.0921 (0.1041)  classification: 0.4271 (0.4814)  time: 0.3645  data: 0.1319  max mem: 3278
Epoch: [76]  [1800/3494]  eta: 0:10:37  lr: 0.0000000  loss: 0.5459 (0.5855)  bbox_regression: 0.0887 (0.1041)  classification: 0.4574 (0.4814)  time: 0.3467  data: 0.1224  max mem: 3278
Epoch: [76]  [1900/3494]  eta: 0:09:57  lr: 0.0000000  loss: 0.6007 (0.5855)  bbox_regression: 0.1007 (0.1040)  classification: 0.5104 (0.4814)  time: 0.3475  data: 0.1252  max mem: 3278
Epoch: [76]  [2000/3494]  eta: 0:09:20  lr: 0.0000000  loss: 0.5886 (0.5855)  bbox_regression: 0.1036 (0.1039)  classification: 0.4935 (0.4816)  time: 0.3596  data: 0.1258  max mem: 3278
Epoch: [76]  [2100/3494]  eta: 0:08:43  lr: 0.0000000  loss: 0.5286 (0.5844)  bbox_regression: 0.0899 (0.1036)  classification: 0.4450 (0.4808)  time: 0.3836  data: 0.1330  max mem: 3278
Epoch: [76]  [2200/3494]  eta: 0:08:06  lr: 0.0000000  loss: 0.5373 (0.5839)  bbox_regression: 0.0882 (0.1037)  classification: 0.4384 (0.4802)  time: 0.3608  data: 0.1252  max mem: 3278
Epoch: [76]  [2300/3494]  eta: 0:07:28  lr: 0.0000000  loss: 0.5427 (0.5842)  bbox_regression: 0.0974 (0.1037)  classification: 0.4477 (0.4806)  time: 0.3526  data: 0.1237  max mem: 3278
Epoch: [76]  [2400/3494]  eta: 0:06:51  lr: 0.0000000  loss: 0.4961 (0.5843)  bbox_regression: 0.0845 (0.1037)  classification: 0.4188 (0.4806)  time: 0.3845  data: 0.1341  max mem: 3278
Epoch: [76]  [2500/3494]  eta: 0:06:13  lr: 0.0000000  loss: 0.5988 (0.5838)  bbox_regression: 0.0895 (0.1035)  classification: 0.4918 (0.4803)  time: 0.3731  data: 0.1447  max mem: 3278
Epoch: [76]  [2600/3494]  eta: 0:05:36  lr: 0.0000000  loss: 0.5379 (0.5849)  bbox_regression: 0.1053 (0.1038)  classification: 0.4398 (0.4811)  time: 0.3676  data: 0.1375  max mem: 3278
Epoch: [76]  [2700/3494]  eta: 0:04:58  lr: 0.0000000  loss: 0.5547 (0.5845)  bbox_regression: 0.1004 (0.1038)  classification: 0.4691 (0.4807)  time: 0.3845  data: 0.1460  max mem: 3278
Epoch: [76]  [2800/3494]  eta: 0:04:20  lr: 0.0000000  loss: 0.5321 (0.5846)  bbox_regression: 0.0864 (0.1037)  classification: 0.4537 (0.4809)  time: 0.3703  data: 0.1337  max mem: 3278
Epoch: [76]  [2900/3494]  eta: 0:03:43  lr: 0.0000000  loss: 0.5395 (0.5846)  bbox_regression: 0.0932 (0.1037)  classification: 0.4361 (0.4809)  time: 0.3795  data: 0.1325  max mem: 3278
Epoch: [76]  [3000/3494]  eta: 0:03:05  lr: 0.0000000  loss: 0.5562 (0.5841)  bbox_regression: 0.0905 (0.1036)  classification: 0.4539 (0.4805)  time: 0.3934  data: 0.1402  max mem: 3278
Epoch: [76]  [3100/3494]  eta: 0:02:28  lr: 0.0000000  loss: 0.5557 (0.5834)  bbox_regression: 0.0890 (0.1035)  classification: 0.4500 (0.4799)  time: 0.3898  data: 0.1450  max mem: 3278
Epoch: [76]  [3200/3494]  eta: 0:01:50  lr: 0.0000000  loss: 0.4975 (0.5830)  bbox_regression: 0.0902 (0.1034)  classification: 0.4133 (0.4796)  time: 0.4213  data: 0.1547  max mem: 3278
Epoch: [76]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5336 (0.5826)  bbox_regression: 0.0865 (0.1033)  classification: 0.4532 (0.4793)  time: 0.4069  data: 0.1351  max mem: 3278
Epoch: [76]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5836 (0.5827)  bbox_regression: 0.0967 (0.1032)  classification: 0.4732 (0.4795)  time: 0.3669  data: 0.1312  max mem: 3278
Epoch: [76]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5967 (0.5829)  bbox_regression: 0.0955 (0.1032)  classification: 0.5033 (0.4797)  time: 0.3545  data: 0.1277  max mem: 3278
Epoch: [76] Total time: 0:22:03 (0.3788 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:21:02  model_time: 0.1255 (0.1255)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.8880  data: 2.7359  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1324 (0.1265)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2631  data: 0.1194  max mem: 3278
Validation:  [200/437]  eta: 0:01:07  model_time: 0.1305 (0.1282)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2721  data: 0.1228  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1326 (0.1292)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2747  data: 0.1265  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1374 (0.1312)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2795  data: 0.1223  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1376 (0.1316)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2822  data: 0.1287  max mem: 3278
Validation: Total time: 0:02:02 (0.2807 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [77]  [   0/3494]  eta: 2:28:56  lr: 0.0000000  loss: 0.6167 (0.6167)  bbox_regression: 0.0869 (0.0869)  classification: 0.5298 (0.5298)  time: 2.5578  data: 2.3213  max mem: 3278
Epoch: [77]  [ 100/3494]  eta: 0:22:24  lr: 0.0000000  loss: 0.5790 (0.5672)  bbox_regression: 0.1064 (0.0971)  classification: 0.4719 (0.4701)  time: 0.3698  data: 0.1325  max mem: 3278
Epoch: [77]  [ 200/3494]  eta: 0:21:14  lr: 0.0000000  loss: 0.5958 (0.5694)  bbox_regression: 0.1045 (0.0999)  classification: 0.4773 (0.4695)  time: 0.3673  data: 0.1274  max mem: 3278
Epoch: [77]  [ 300/3494]  eta: 0:20:24  lr: 0.0000000  loss: 0.5800 (0.5829)  bbox_regression: 0.0995 (0.1028)  classification: 0.4772 (0.4801)  time: 0.3837  data: 0.1470  max mem: 3278
Epoch: [77]  [ 400/3494]  eta: 0:19:22  lr: 0.0000000  loss: 0.5630 (0.5859)  bbox_regression: 0.0911 (0.1037)  classification: 0.4470 (0.4822)  time: 0.3458  data: 0.1197  max mem: 3278
Epoch: [77]  [ 500/3494]  eta: 0:18:42  lr: 0.0000000  loss: 0.6012 (0.5840)  bbox_regression: 0.0962 (0.1033)  classification: 0.5046 (0.4807)  time: 0.3736  data: 0.1300  max mem: 3278
Epoch: [77]  [ 600/3494]  eta: 0:18:02  lr: 0.0000000  loss: 0.5178 (0.5814)  bbox_regression: 0.0815 (0.1025)  classification: 0.4263 (0.4788)  time: 0.3749  data: 0.1330  max mem: 3278
Epoch: [77]  [ 700/3494]  eta: 0:17:27  lr: 0.0000000  loss: 0.5479 (0.5803)  bbox_regression: 0.0934 (0.1021)  classification: 0.4384 (0.4783)  time: 0.3775  data: 0.1346  max mem: 3278
Epoch: [77]  [ 800/3494]  eta: 0:16:50  lr: 0.0000000  loss: 0.5414 (0.5802)  bbox_regression: 0.0919 (0.1019)  classification: 0.4561 (0.4783)  time: 0.3751  data: 0.1317  max mem: 3278
Epoch: [77]  [ 900/3494]  eta: 0:16:12  lr: 0.0000000  loss: 0.5665 (0.5820)  bbox_regression: 0.0946 (0.1024)  classification: 0.4669 (0.4797)  time: 0.3528  data: 0.1226  max mem: 3278
Epoch: [77]  [1000/3494]  eta: 0:15:35  lr: 0.0000000  loss: 0.5166 (0.5820)  bbox_regression: 0.0889 (0.1023)  classification: 0.4351 (0.4797)  time: 0.3830  data: 0.1399  max mem: 3278
Epoch: [77]  [1100/3494]  eta: 0:14:54  lr: 0.0000000  loss: 0.5505 (0.5830)  bbox_regression: 0.0974 (0.1026)  classification: 0.4426 (0.4804)  time: 0.3506  data: 0.1245  max mem: 3278
Epoch: [77]  [1200/3494]  eta: 0:14:14  lr: 0.0000000  loss: 0.5872 (0.5825)  bbox_regression: 0.1046 (0.1028)  classification: 0.4552 (0.4797)  time: 0.3746  data: 0.1295  max mem: 3278
Epoch: [77]  [1300/3494]  eta: 0:13:38  lr: 0.0000000  loss: 0.6164 (0.5840)  bbox_regression: 0.0951 (0.1031)  classification: 0.5084 (0.4809)  time: 0.3759  data: 0.1359  max mem: 3278
Epoch: [77]  [1400/3494]  eta: 0:13:02  lr: 0.0000000  loss: 0.5731 (0.5847)  bbox_regression: 0.0948 (0.1030)  classification: 0.4701 (0.4817)  time: 0.3845  data: 0.1460  max mem: 3278
Epoch: [77]  [1500/3494]  eta: 0:12:27  lr: 0.0000000  loss: 0.5895 (0.5840)  bbox_regression: 0.0960 (0.1027)  classification: 0.5059 (0.4813)  time: 0.4026  data: 0.1406  max mem: 3278
Epoch: [77]  [1600/3494]  eta: 0:11:50  lr: 0.0000000  loss: 0.5659 (0.5840)  bbox_regression: 0.1094 (0.1028)  classification: 0.4594 (0.4812)  time: 0.3771  data: 0.1318  max mem: 3278
Epoch: [77]  [1700/3494]  eta: 0:11:14  lr: 0.0000000  loss: 0.5709 (0.5844)  bbox_regression: 0.0918 (0.1028)  classification: 0.4702 (0.4815)  time: 0.3813  data: 0.1406  max mem: 3278
Epoch: [77]  [1800/3494]  eta: 0:10:36  lr: 0.0000000  loss: 0.5593 (0.5840)  bbox_regression: 0.0916 (0.1029)  classification: 0.4773 (0.4812)  time: 0.3748  data: 0.1413  max mem: 3278
Epoch: [77]  [1900/3494]  eta: 0:09:58  lr: 0.0000000  loss: 0.6024 (0.5845)  bbox_regression: 0.1142 (0.1031)  classification: 0.4882 (0.4814)  time: 0.3969  data: 0.1440  max mem: 3278
Epoch: [77]  [2000/3494]  eta: 0:09:20  lr: 0.0000000  loss: 0.5281 (0.5841)  bbox_regression: 0.0902 (0.1031)  classification: 0.4388 (0.4811)  time: 0.3718  data: 0.1350  max mem: 3278
Epoch: [77]  [2100/3494]  eta: 0:08:44  lr: 0.0000000  loss: 0.5250 (0.5837)  bbox_regression: 0.0910 (0.1032)  classification: 0.3998 (0.4805)  time: 0.3852  data: 0.1386  max mem: 3278
Epoch: [77]  [2200/3494]  eta: 0:08:06  lr: 0.0000000  loss: 0.5680 (0.5832)  bbox_regression: 0.0925 (0.1030)  classification: 0.4567 (0.4802)  time: 0.3675  data: 0.1252  max mem: 3278
Epoch: [77]  [2300/3494]  eta: 0:07:29  lr: 0.0000000  loss: 0.5552 (0.5828)  bbox_regression: 0.0934 (0.1029)  classification: 0.4575 (0.4799)  time: 0.3697  data: 0.1344  max mem: 3278
Epoch: [77]  [2400/3494]  eta: 0:06:52  lr: 0.0000000  loss: 0.5669 (0.5821)  bbox_regression: 0.0928 (0.1028)  classification: 0.4740 (0.4792)  time: 0.3715  data: 0.1309  max mem: 3278
Epoch: [77]  [2500/3494]  eta: 0:06:14  lr: 0.0000000  loss: 0.5897 (0.5823)  bbox_regression: 0.0912 (0.1029)  classification: 0.4913 (0.4795)  time: 0.3597  data: 0.1305  max mem: 3278
Epoch: [77]  [2600/3494]  eta: 0:05:36  lr: 0.0000000  loss: 0.5828 (0.5823)  bbox_regression: 0.0987 (0.1030)  classification: 0.4909 (0.4793)  time: 0.3631  data: 0.1292  max mem: 3278
Epoch: [77]  [2700/3494]  eta: 0:04:58  lr: 0.0000000  loss: 0.5593 (0.5821)  bbox_regression: 0.0966 (0.1030)  classification: 0.4768 (0.4791)  time: 0.3901  data: 0.1379  max mem: 3278
Epoch: [77]  [2800/3494]  eta: 0:04:21  lr: 0.0000000  loss: 0.5525 (0.5818)  bbox_regression: 0.0898 (0.1030)  classification: 0.4608 (0.4788)  time: 0.3837  data: 0.1413  max mem: 3278
Epoch: [77]  [2900/3494]  eta: 0:03:43  lr: 0.0000000  loss: 0.5594 (0.5816)  bbox_regression: 0.1005 (0.1030)  classification: 0.4553 (0.4786)  time: 0.3823  data: 0.1370  max mem: 3278
Epoch: [77]  [3000/3494]  eta: 0:03:06  lr: 0.0000000  loss: 0.5327 (0.5817)  bbox_regression: 0.0860 (0.1030)  classification: 0.4558 (0.4787)  time: 0.3603  data: 0.1244  max mem: 3278
Epoch: [77]  [3100/3494]  eta: 0:02:28  lr: 0.0000000  loss: 0.5764 (0.5821)  bbox_regression: 0.0924 (0.1030)  classification: 0.4720 (0.4790)  time: 0.3608  data: 0.1283  max mem: 3278
Epoch: [77]  [3200/3494]  eta: 0:01:50  lr: 0.0000000  loss: 0.5910 (0.5826)  bbox_regression: 0.1075 (0.1031)  classification: 0.4890 (0.4795)  time: 0.3709  data: 0.1296  max mem: 3278
Epoch: [77]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5912 (0.5830)  bbox_regression: 0.0940 (0.1032)  classification: 0.4903 (0.4798)  time: 0.3700  data: 0.1334  max mem: 3278
Epoch: [77]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.6081 (0.5829)  bbox_regression: 0.0954 (0.1031)  classification: 0.4863 (0.4798)  time: 0.3742  data: 0.1379  max mem: 3278
Epoch: [77]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5210 (0.5827)  bbox_regression: 0.0921 (0.1031)  classification: 0.4365 (0.4796)  time: 0.3808  data: 0.1332  max mem: 3278
Epoch: [77] Total time: 0:22:06 (0.3795 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:50  model_time: 0.1897 (0.1897)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9007  data: 1.6699  max mem: 3278
Validation:  [100/437]  eta: 0:01:39  model_time: 0.1280 (0.1315)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2819  data: 0.1360  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1289 (0.1292)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2798  data: 0.1330  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1298 (0.1329)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2831  data: 0.1293  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1339 (0.1325)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2691  data: 0.1196  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1178 (0.1316)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2604  data: 0.1221  max mem: 3278
Validation: Total time: 0:02:03 (0.2817 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [78]  [   0/3494]  eta: 1:58:21  lr: 0.0000000  loss: 0.5263 (0.5263)  bbox_regression: 0.0792 (0.0792)  classification: 0.4471 (0.4471)  time: 2.0324  data: 1.7556  max mem: 3278
Epoch: [78]  [ 100/3494]  eta: 0:22:47  lr: 0.0000000  loss: 0.5542 (0.5892)  bbox_regression: 0.0968 (0.1048)  classification: 0.4810 (0.4844)  time: 0.3560  data: 0.1215  max mem: 3278
Epoch: [78]  [ 200/3494]  eta: 0:21:05  lr: 0.0000000  loss: 0.5910 (0.5828)  bbox_regression: 0.0957 (0.1023)  classification: 0.4595 (0.4804)  time: 0.3594  data: 0.1302  max mem: 3278
Epoch: [78]  [ 300/3494]  eta: 0:20:19  lr: 0.0000000  loss: 0.5726 (0.5787)  bbox_regression: 0.0987 (0.1015)  classification: 0.4437 (0.4771)  time: 0.3736  data: 0.1376  max mem: 3278
Epoch: [78]  [ 400/3494]  eta: 0:19:45  lr: 0.0000000  loss: 0.5999 (0.5869)  bbox_regression: 0.1051 (0.1037)  classification: 0.4844 (0.4832)  time: 0.4005  data: 0.1599  max mem: 3278
Epoch: [78]  [ 500/3494]  eta: 0:19:00  lr: 0.0000000  loss: 0.6223 (0.5870)  bbox_regression: 0.0946 (0.1037)  classification: 0.5077 (0.4833)  time: 0.3844  data: 0.1253  max mem: 3278
Epoch: [78]  [ 600/3494]  eta: 0:18:21  lr: 0.0000000  loss: 0.5549 (0.5873)  bbox_regression: 0.0953 (0.1041)  classification: 0.4437 (0.4832)  time: 0.3620  data: 0.1221  max mem: 3278
Epoch: [78]  [ 700/3494]  eta: 0:17:43  lr: 0.0000000  loss: 0.5399 (0.5865)  bbox_regression: 0.0958 (0.1041)  classification: 0.4511 (0.4824)  time: 0.3888  data: 0.1355  max mem: 3278
Epoch: [78]  [ 800/3494]  eta: 0:17:02  lr: 0.0000000  loss: 0.6086 (0.5884)  bbox_regression: 0.0957 (0.1045)  classification: 0.5021 (0.4839)  time: 0.3749  data: 0.1343  max mem: 3278
Epoch: [78]  [ 900/3494]  eta: 0:16:20  lr: 0.0000000  loss: 0.5629 (0.5878)  bbox_regression: 0.0915 (0.1042)  classification: 0.4752 (0.4836)  time: 0.3616  data: 0.1289  max mem: 3278
Epoch: [78]  [1000/3494]  eta: 0:15:41  lr: 0.0000000  loss: 0.5739 (0.5860)  bbox_regression: 0.1074 (0.1040)  classification: 0.4687 (0.4820)  time: 0.3696  data: 0.1299  max mem: 3278
Epoch: [78]  [1100/3494]  eta: 0:15:04  lr: 0.0000000  loss: 0.5930 (0.5867)  bbox_regression: 0.0964 (0.1041)  classification: 0.4776 (0.4827)  time: 0.3761  data: 0.1349  max mem: 3278
Epoch: [78]  [1200/3494]  eta: 0:14:25  lr: 0.0000000  loss: 0.6008 (0.5851)  bbox_regression: 0.0982 (0.1038)  classification: 0.5040 (0.4813)  time: 0.3774  data: 0.1414  max mem: 3278
Epoch: [78]  [1300/3494]  eta: 0:13:49  lr: 0.0000000  loss: 0.6096 (0.5856)  bbox_regression: 0.1133 (0.1042)  classification: 0.4869 (0.4814)  time: 0.3747  data: 0.1302  max mem: 3278
Epoch: [78]  [1400/3494]  eta: 0:13:11  lr: 0.0000000  loss: 0.6039 (0.5862)  bbox_regression: 0.0986 (0.1038)  classification: 0.4938 (0.4824)  time: 0.4031  data: 0.1423  max mem: 3278
Epoch: [78]  [1500/3494]  eta: 0:12:33  lr: 0.0000000  loss: 0.5725 (0.5852)  bbox_regression: 0.1008 (0.1036)  classification: 0.4567 (0.4815)  time: 0.4256  data: 0.1331  max mem: 3278
Epoch: [78]  [1600/3494]  eta: 0:11:55  lr: 0.0000000  loss: 0.5247 (0.5844)  bbox_regression: 0.0836 (0.1034)  classification: 0.4479 (0.4810)  time: 0.3566  data: 0.1285  max mem: 3278
Epoch: [78]  [1700/3494]  eta: 0:11:15  lr: 0.0000000  loss: 0.5746 (0.5843)  bbox_regression: 0.1107 (0.1035)  classification: 0.4768 (0.4808)  time: 0.3697  data: 0.1286  max mem: 3278
Epoch: [78]  [1800/3494]  eta: 0:10:36  lr: 0.0000000  loss: 0.5470 (0.5848)  bbox_regression: 0.0964 (0.1036)  classification: 0.4467 (0.4811)  time: 0.3640  data: 0.1285  max mem: 3278
Epoch: [78]  [1900/3494]  eta: 0:09:59  lr: 0.0000000  loss: 0.5437 (0.5844)  bbox_regression: 0.0960 (0.1034)  classification: 0.4488 (0.4810)  time: 0.3724  data: 0.1301  max mem: 3278
Epoch: [78]  [2000/3494]  eta: 0:09:22  lr: 0.0000000  loss: 0.5972 (0.5851)  bbox_regression: 0.1149 (0.1036)  classification: 0.4957 (0.4815)  time: 0.3957  data: 0.1335  max mem: 3278
Epoch: [78]  [2100/3494]  eta: 0:08:44  lr: 0.0000000  loss: 0.5596 (0.5851)  bbox_regression: 0.0977 (0.1035)  classification: 0.4527 (0.4816)  time: 0.3656  data: 0.1246  max mem: 3278
Epoch: [78]  [2200/3494]  eta: 0:08:07  lr: 0.0000000  loss: 0.5463 (0.5848)  bbox_regression: 0.1000 (0.1036)  classification: 0.4543 (0.4811)  time: 0.3752  data: 0.1316  max mem: 3278
Epoch: [78]  [2300/3494]  eta: 0:07:29  lr: 0.0000000  loss: 0.5768 (0.5849)  bbox_regression: 0.0857 (0.1038)  classification: 0.4767 (0.4812)  time: 0.3620  data: 0.1223  max mem: 3278
Epoch: [78]  [2400/3494]  eta: 0:06:51  lr: 0.0000000  loss: 0.5296 (0.5845)  bbox_regression: 0.0942 (0.1037)  classification: 0.4410 (0.4808)  time: 0.3536  data: 0.1247  max mem: 3278
Epoch: [78]  [2500/3494]  eta: 0:06:13  lr: 0.0000000  loss: 0.5798 (0.5840)  bbox_regression: 0.0995 (0.1035)  classification: 0.4894 (0.4804)  time: 0.3903  data: 0.1484  max mem: 3278
Epoch: [78]  [2600/3494]  eta: 0:05:35  lr: 0.0000000  loss: 0.5850 (0.5844)  bbox_regression: 0.0936 (0.1036)  classification: 0.4691 (0.4808)  time: 0.3751  data: 0.1372  max mem: 3278
Epoch: [78]  [2700/3494]  eta: 0:04:58  lr: 0.0000000  loss: 0.5056 (0.5842)  bbox_regression: 0.0968 (0.1036)  classification: 0.4200 (0.4806)  time: 0.3800  data: 0.1370  max mem: 3278
Epoch: [78]  [2800/3494]  eta: 0:04:21  lr: 0.0000000  loss: 0.5441 (0.5844)  bbox_regression: 0.0899 (0.1036)  classification: 0.4471 (0.4808)  time: 0.3910  data: 0.1456  max mem: 3278
Epoch: [78]  [2900/3494]  eta: 0:03:43  lr: 0.0000000  loss: 0.5374 (0.5840)  bbox_regression: 0.1001 (0.1035)  classification: 0.4399 (0.4805)  time: 0.3779  data: 0.1379  max mem: 3278
Epoch: [78]  [3000/3494]  eta: 0:03:05  lr: 0.0000000  loss: 0.5316 (0.5839)  bbox_regression: 0.0877 (0.1035)  classification: 0.4549 (0.4804)  time: 0.4172  data: 0.1268  max mem: 3278
Epoch: [78]  [3100/3494]  eta: 0:02:28  lr: 0.0000000  loss: 0.6267 (0.5842)  bbox_regression: 0.1076 (0.1035)  classification: 0.5375 (0.4807)  time: 0.3703  data: 0.1317  max mem: 3278
Epoch: [78]  [3200/3494]  eta: 0:01:50  lr: 0.0000000  loss: 0.5728 (0.5845)  bbox_regression: 0.1036 (0.1035)  classification: 0.4702 (0.4810)  time: 0.4090  data: 0.1481  max mem: 3278
Epoch: [78]  [3300/3494]  eta: 0:01:13  lr: 0.0000000  loss: 0.5553 (0.5840)  bbox_regression: 0.0899 (0.1034)  classification: 0.4309 (0.4806)  time: 0.3803  data: 0.1335  max mem: 3278
Epoch: [78]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5911 (0.5842)  bbox_regression: 0.1088 (0.1034)  classification: 0.4767 (0.4808)  time: 0.3852  data: 0.1384  max mem: 3278
Epoch: [78]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5337 (0.5839)  bbox_regression: 0.0892 (0.1034)  classification: 0.4354 (0.4805)  time: 0.3916  data: 0.1328  max mem: 3278
Epoch: [78] Total time: 0:22:08 (0.3802 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:21  model_time: 0.1539 (0.1539)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.1095  data: 1.9141  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1335 (0.1255)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2687  data: 0.1187  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1446 (0.1299)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.3108  data: 0.1336  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1202 (0.1291)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2716  data: 0.1303  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1139 (0.1284)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2664  data: 0.1288  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1180 (0.1277)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2617  data: 0.1266  max mem: 3278
Validation: Total time: 0:01:59 (0.2738 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [79]  [   0/3494]  eta: 2:07:17  lr: 0.0000000  loss: 0.4551 (0.4551)  bbox_regression: 0.1036 (0.1036)  classification: 0.3515 (0.3515)  time: 2.1860  data: 1.9267  max mem: 3278
Epoch: [79]  [ 100/3494]  eta: 0:21:19  lr: 0.0000000  loss: 0.5527 (0.5927)  bbox_regression: 0.0932 (0.1047)  classification: 0.4673 (0.4880)  time: 0.3647  data: 0.1268  max mem: 3278
Epoch: [79]  [ 200/3494]  eta: 0:20:46  lr: 0.0000000  loss: 0.5777 (0.5914)  bbox_regression: 0.1125 (0.1050)  classification: 0.4627 (0.4863)  time: 0.3756  data: 0.1300  max mem: 3278
Epoch: [79]  [ 300/3494]  eta: 0:20:14  lr: 0.0000000  loss: 0.5758 (0.5914)  bbox_regression: 0.0978 (0.1046)  classification: 0.4825 (0.4868)  time: 0.3723  data: 0.1274  max mem: 3278
Epoch: [79]  [ 400/3494]  eta: 0:19:47  lr: 0.0000000  loss: 0.5740 (0.5884)  bbox_regression: 0.0967 (0.1040)  classification: 0.4847 (0.4844)  time: 0.4183  data: 0.1366  max mem: 3278
Epoch: [79]  [ 500/3494]  eta: 0:19:10  lr: 0.0000000  loss: 0.5881 (0.5893)  bbox_regression: 0.0988 (0.1045)  classification: 0.5038 (0.4848)  time: 0.4115  data: 0.1386  max mem: 3278
Epoch: [79]  [ 600/3494]  eta: 0:19:21  lr: 0.0000000  loss: 0.5283 (0.5889)  bbox_regression: 0.1135 (0.1047)  classification: 0.4198 (0.4842)  time: 0.4560  data: 0.1654  max mem: 3278
Epoch: [79]  [ 700/3494]  eta: 0:18:54  lr: 0.0000000  loss: 0.5301 (0.5868)  bbox_regression: 0.0869 (0.1045)  classification: 0.4370 (0.4823)  time: 0.4516  data: 0.1540  max mem: 3278
Epoch: [79]  [ 800/3494]  eta: 0:18:33  lr: 0.0000000  loss: 0.5610 (0.5899)  bbox_regression: 0.0950 (0.1050)  classification: 0.4690 (0.4849)  time: 0.4829  data: 0.1889  max mem: 3278
Epoch: [79]  [ 900/3494]  eta: 0:18:15  lr: 0.0000000  loss: 0.6074 (0.5907)  bbox_regression: 0.1143 (0.1057)  classification: 0.5122 (0.4850)  time: 0.5081  data: 0.1576  max mem: 3278
Epoch: [79]  [1000/3494]  eta: 0:18:00  lr: 0.0000000  loss: 0.5681 (0.5891)  bbox_regression: 0.0909 (0.1051)  classification: 0.4592 (0.4841)  time: 0.5266  data: 0.1631  max mem: 3278
Epoch: [79]  [1100/3494]  eta: 0:17:31  lr: 0.0000000  loss: 0.5915 (0.5866)  bbox_regression: 0.0903 (0.1044)  classification: 0.4841 (0.4822)  time: 0.4969  data: 0.1717  max mem: 3278
Epoch: [79]  [1200/3494]  eta: 0:16:57  lr: 0.0000000  loss: 0.5415 (0.5866)  bbox_regression: 0.0947 (0.1045)  classification: 0.4467 (0.4822)  time: 0.5003  data: 0.1518  max mem: 3278
Epoch: [79]  [1300/3494]  eta: 0:16:12  lr: 0.0000000  loss: 0.5346 (0.5855)  bbox_regression: 0.0977 (0.1045)  classification: 0.4338 (0.4811)  time: 0.4376  data: 0.1340  max mem: 3278
Epoch: [79]  [1400/3494]  eta: 0:15:23  lr: 0.0000000  loss: 0.5778 (0.5862)  bbox_regression: 0.1020 (0.1045)  classification: 0.4758 (0.4818)  time: 0.4039  data: 0.1463  max mem: 3278
Epoch: [79]  [1500/3494]  eta: 0:14:45  lr: 0.0000000  loss: 0.5620 (0.5867)  bbox_regression: 0.1114 (0.1044)  classification: 0.4572 (0.4823)  time: 0.4950  data: 0.1548  max mem: 3278
Epoch: [79]  [1600/3494]  eta: 0:14:09  lr: 0.0000000  loss: 0.5257 (0.5860)  bbox_regression: 0.0971 (0.1044)  classification: 0.4314 (0.4816)  time: 0.5313  data: 0.1748  max mem: 3278
Epoch: [79]  [1700/3494]  eta: 0:13:29  lr: 0.0000000  loss: 0.4918 (0.5835)  bbox_regression: 0.0856 (0.1039)  classification: 0.3999 (0.4796)  time: 0.4923  data: 0.1635  max mem: 3278
Epoch: [79]  [1800/3494]  eta: 0:12:46  lr: 0.0000000  loss: 0.5819 (0.5845)  bbox_regression: 0.0955 (0.1042)  classification: 0.4652 (0.4803)  time: 0.5041  data: 0.1742  max mem: 3278
Epoch: [79]  [1900/3494]  eta: 0:12:03  lr: 0.0000000  loss: 0.5267 (0.5842)  bbox_regression: 0.0849 (0.1040)  classification: 0.4556 (0.4802)  time: 0.4656  data: 0.1580  max mem: 3278
Epoch: [79]  [2000/3494]  eta: 0:11:12  lr: 0.0000000  loss: 0.6115 (0.5851)  bbox_regression: 0.0937 (0.1041)  classification: 0.4776 (0.4809)  time: 0.3645  data: 0.1250  max mem: 3278
Epoch: [79]  [2100/3494]  eta: 0:10:29  lr: 0.0000000  loss: 0.5558 (0.5853)  bbox_regression: 0.1009 (0.1042)  classification: 0.4631 (0.4811)  time: 0.4710  data: 0.1508  max mem: 3278
Epoch: [79]  [2200/3494]  eta: 0:09:45  lr: 0.0000000  loss: 0.5756 (0.5848)  bbox_regression: 0.0912 (0.1040)  classification: 0.4552 (0.4807)  time: 0.4569  data: 0.1661  max mem: 3278
Epoch: [79]  [2300/3494]  eta: 0:09:01  lr: 0.0000000  loss: 0.5779 (0.5845)  bbox_regression: 0.0997 (0.1038)  classification: 0.4814 (0.4807)  time: 0.4949  data: 0.1689  max mem: 3278
Epoch: [79]  [2400/3494]  eta: 0:08:17  lr: 0.0000000  loss: 0.5642 (0.5847)  bbox_regression: 0.0990 (0.1037)  classification: 0.4692 (0.4810)  time: 0.4841  data: 0.1541  max mem: 3278
Epoch: [79]  [2500/3494]  eta: 0:07:32  lr: 0.0000000  loss: 0.5405 (0.5851)  bbox_regression: 0.0925 (0.1038)  classification: 0.4544 (0.4814)  time: 0.4256  data: 0.1543  max mem: 3278
Epoch: [79]  [2600/3494]  eta: 0:06:44  lr: 0.0000000  loss: 0.5392 (0.5856)  bbox_regression: 0.0926 (0.1037)  classification: 0.4479 (0.4819)  time: 0.4131  data: 0.1474  max mem: 3278
Epoch: [79]  [2700/3494]  eta: 0:06:01  lr: 0.0000000  loss: 0.5467 (0.5854)  bbox_regression: 0.0880 (0.1037)  classification: 0.4605 (0.4817)  time: 0.4953  data: 0.1709  max mem: 3278
Epoch: [79]  [2800/3494]  eta: 0:05:16  lr: 0.0000000  loss: 0.5631 (0.5856)  bbox_regression: 0.0864 (0.1037)  classification: 0.4773 (0.4820)  time: 0.4541  data: 0.1487  max mem: 3278
Epoch: [79]  [2900/3494]  eta: 0:04:31  lr: 0.0000000  loss: 0.5863 (0.5857)  bbox_regression: 0.0999 (0.1037)  classification: 0.4768 (0.4820)  time: 0.5334  data: 0.1821  max mem: 3278
Epoch: [79]  [3000/3494]  eta: 0:03:46  lr: 0.0000000  loss: 0.5186 (0.5852)  bbox_regression: 0.0780 (0.1035)  classification: 0.4348 (0.4817)  time: 0.5422  data: 0.1806  max mem: 3278
Epoch: [79]  [3100/3494]  eta: 0:03:00  lr: 0.0000000  loss: 0.5141 (0.5840)  bbox_regression: 0.0817 (0.1032)  classification: 0.4239 (0.4809)  time: 0.3757  data: 0.1300  max mem: 3278
Epoch: [79]  [3200/3494]  eta: 0:02:14  lr: 0.0000000  loss: 0.5569 (0.5838)  bbox_regression: 0.0955 (0.1030)  classification: 0.4620 (0.4808)  time: 0.4195  data: 0.1500  max mem: 3278
Epoch: [79]  [3300/3494]  eta: 0:01:28  lr: 0.0000000  loss: 0.5268 (0.5834)  bbox_regression: 0.0962 (0.1031)  classification: 0.4140 (0.4803)  time: 0.4677  data: 0.1562  max mem: 3278
Epoch: [79]  [3400/3494]  eta: 0:00:42  lr: 0.0000000  loss: 0.5961 (0.5836)  bbox_regression: 0.1135 (0.1030)  classification: 0.4766 (0.4806)  time: 0.4830  data: 0.1605  max mem: 3278
Epoch: [79]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5464 (0.5837)  bbox_regression: 0.0986 (0.1032)  classification: 0.4557 (0.4805)  time: 0.5003  data: 0.1682  max mem: 3278
Epoch: [79] Total time: 0:26:50 (0.4610 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:20:11  model_time: 0.2391 (0.2391)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.7723  data: 2.4716  max mem: 3278
Validation:  [100/437]  eta: 0:02:23  model_time: 0.1995 (0.2024)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3944  data: 0.1662  max mem: 3278
Validation:  [200/437]  eta: 0:01:32  model_time: 0.1429 (0.1888)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.3177  data: 0.1482  max mem: 3278
Validation:  [300/437]  eta: 0:00:50  model_time: 0.1404 (0.1793)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3062  data: 0.1406  max mem: 3278
Validation:  [400/437]  eta: 0:00:13  model_time: 0.1435 (0.1723)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3269  data: 0.1523  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1494 (0.1707)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3162  data: 0.1389  max mem: 3278
Validation: Total time: 0:02:35 (0.3569 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [80]  [   0/3494]  eta: 3:03:11  lr: 0.0000000  loss: 0.5180 (0.5180)  bbox_regression: 0.0824 (0.0824)  classification: 0.4357 (0.4357)  time: 3.1457  data: 2.7261  max mem: 3278
Epoch: [80]  [ 100/3494]  eta: 0:30:09  lr: 0.0000000  loss: 0.5499 (0.5750)  bbox_regression: 0.1043 (0.1057)  classification: 0.4497 (0.4693)  time: 0.4999  data: 0.1662  max mem: 3278
Epoch: [80]  [ 200/3494]  eta: 0:27:59  lr: 0.0000000  loss: 0.5517 (0.5781)  bbox_regression: 0.0915 (0.1022)  classification: 0.4715 (0.4759)  time: 0.5040  data: 0.1655  max mem: 3278
Epoch: [80]  [ 300/3494]  eta: 0:26:33  lr: 0.0000000  loss: 0.6299 (0.5884)  bbox_regression: 0.0945 (0.1037)  classification: 0.5142 (0.4847)  time: 0.4490  data: 0.1496  max mem: 3278
Epoch: [80]  [ 400/3494]  eta: 0:25:39  lr: 0.0000000  loss: 0.5412 (0.5894)  bbox_regression: 0.0948 (0.1036)  classification: 0.4470 (0.4858)  time: 0.4565  data: 0.1456  max mem: 3278
Epoch: [80]  [ 500/3494]  eta: 0:24:22  lr: 0.0000000  loss: 0.5042 (0.5891)  bbox_regression: 0.0872 (0.1029)  classification: 0.4189 (0.4862)  time: 0.4349  data: 0.1444  max mem: 3278
Epoch: [80]  [ 600/3494]  eta: 0:22:52  lr: 0.0000000  loss: 0.5589 (0.5911)  bbox_regression: 0.0913 (0.1038)  classification: 0.4733 (0.4873)  time: 0.3801  data: 0.1285  max mem: 3278
Epoch: [80]  [ 700/3494]  eta: 0:21:54  lr: 0.0000000  loss: 0.5551 (0.5868)  bbox_regression: 0.1051 (0.1033)  classification: 0.4500 (0.4835)  time: 0.4433  data: 0.1448  max mem: 3278
Epoch: [80]  [ 800/3494]  eta: 0:21:03  lr: 0.0000000  loss: 0.5797 (0.5868)  bbox_regression: 0.0906 (0.1029)  classification: 0.4784 (0.4839)  time: 0.4318  data: 0.1510  max mem: 3278
Epoch: [80]  [ 900/3494]  eta: 0:20:18  lr: 0.0000000  loss: 0.5888 (0.5859)  bbox_regression: 0.0944 (0.1028)  classification: 0.4925 (0.4830)  time: 0.4380  data: 0.1444  max mem: 3278
Epoch: [80]  [1000/3494]  eta: 0:19:34  lr: 0.0000000  loss: 0.5005 (0.5850)  bbox_regression: 0.0771 (0.1029)  classification: 0.4266 (0.4821)  time: 0.4718  data: 0.1696  max mem: 3278
Epoch: [80]  [1100/3494]  eta: 0:18:46  lr: 0.0000000  loss: 0.5524 (0.5839)  bbox_regression: 0.0932 (0.1028)  classification: 0.4496 (0.4811)  time: 0.4067  data: 0.1447  max mem: 3278
Epoch: [80]  [1200/3494]  eta: 0:17:51  lr: 0.0000000  loss: 0.5327 (0.5829)  bbox_regression: 0.1000 (0.1029)  classification: 0.4332 (0.4801)  time: 0.4198  data: 0.1478  max mem: 3278
Epoch: [80]  [1300/3494]  eta: 0:17:01  lr: 0.0000000  loss: 0.5739 (0.5828)  bbox_regression: 0.0944 (0.1026)  classification: 0.4756 (0.4802)  time: 0.5219  data: 0.1841  max mem: 3278
Epoch: [80]  [1400/3494]  eta: 0:16:18  lr: 0.0000000  loss: 0.5582 (0.5832)  bbox_regression: 0.0989 (0.1028)  classification: 0.4665 (0.4804)  time: 0.5175  data: 0.1740  max mem: 3278
Epoch: [80]  [1500/3494]  eta: 0:15:35  lr: 0.0000000  loss: 0.5369 (0.5827)  bbox_regression: 0.0926 (0.1027)  classification: 0.4452 (0.4800)  time: 0.4964  data: 0.1601  max mem: 3278
Epoch: [80]  [1600/3494]  eta: 0:14:52  lr: 0.0000000  loss: 0.5712 (0.5828)  bbox_regression: 0.1062 (0.1029)  classification: 0.4824 (0.4799)  time: 0.5022  data: 0.1729  max mem: 3278
Epoch: [80]  [1700/3494]  eta: 0:14:05  lr: 0.0000000  loss: 0.5912 (0.5831)  bbox_regression: 0.1045 (0.1030)  classification: 0.4921 (0.4801)  time: 0.4396  data: 0.1514  max mem: 3278
Epoch: [80]  [1800/3494]  eta: 0:13:15  lr: 0.0000000  loss: 0.5533 (0.5831)  bbox_regression: 0.0863 (0.1031)  classification: 0.4726 (0.4799)  time: 0.4494  data: 0.1554  max mem: 3278
Epoch: [80]  [1900/3494]  eta: 0:12:23  lr: 0.0000000  loss: 0.5698 (0.5832)  bbox_regression: 0.1013 (0.1033)  classification: 0.4611 (0.4799)  time: 0.4280  data: 0.1502  max mem: 3278
Epoch: [80]  [2000/3494]  eta: 0:11:38  lr: 0.0000000  loss: 0.5364 (0.5820)  bbox_regression: 0.0870 (0.1030)  classification: 0.4383 (0.4790)  time: 0.4662  data: 0.1542  max mem: 3278
Epoch: [80]  [2100/3494]  eta: 0:10:52  lr: 0.0000000  loss: 0.5231 (0.5818)  bbox_regression: 0.0953 (0.1031)  classification: 0.4236 (0.4786)  time: 0.5237  data: 0.1623  max mem: 3278
Epoch: [80]  [2200/3494]  eta: 0:10:05  lr: 0.0000000  loss: 0.5821 (0.5822)  bbox_regression: 0.0979 (0.1031)  classification: 0.4894 (0.4790)  time: 0.4727  data: 0.1599  max mem: 3278
Epoch: [80]  [2300/3494]  eta: 0:09:19  lr: 0.0000000  loss: 0.5987 (0.5826)  bbox_regression: 0.1037 (0.1031)  classification: 0.4409 (0.4796)  time: 0.5082  data: 0.1660  max mem: 3278
Epoch: [80]  [2400/3494]  eta: 0:08:31  lr: 0.0000000  loss: 0.5001 (0.5819)  bbox_regression: 0.1009 (0.1029)  classification: 0.4141 (0.4790)  time: 0.4668  data: 0.1632  max mem: 3278
Epoch: [80]  [2500/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.5578 (0.5819)  bbox_regression: 0.0899 (0.1028)  classification: 0.4682 (0.4791)  time: 0.4117  data: 0.1447  max mem: 3278
Epoch: [80]  [2600/3494]  eta: 0:06:57  lr: 0.0000000  loss: 0.5146 (0.5821)  bbox_regression: 0.1011 (0.1029)  classification: 0.4141 (0.4792)  time: 0.4923  data: 0.1621  max mem: 3278
Epoch: [80]  [2700/3494]  eta: 0:06:11  lr: 0.0000000  loss: 0.6557 (0.5821)  bbox_regression: 0.1208 (0.1029)  classification: 0.5334 (0.4791)  time: 0.5077  data: 0.1630  max mem: 3278
Epoch: [80]  [2800/3494]  eta: 0:05:25  lr: 0.0000000  loss: 0.5399 (0.5818)  bbox_regression: 0.0856 (0.1029)  classification: 0.4479 (0.4789)  time: 0.4792  data: 0.1551  max mem: 3278
Epoch: [80]  [2900/3494]  eta: 0:04:39  lr: 0.0000000  loss: 0.5526 (0.5820)  bbox_regression: 0.1054 (0.1029)  classification: 0.4511 (0.4790)  time: 0.4618  data: 0.1532  max mem: 3278
Epoch: [80]  [3000/3494]  eta: 0:03:51  lr: 0.0000000  loss: 0.5973 (0.5825)  bbox_regression: 0.0905 (0.1029)  classification: 0.5032 (0.4795)  time: 0.4261  data: 0.1464  max mem: 3278
Epoch: [80]  [3100/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5509 (0.5822)  bbox_regression: 0.0974 (0.1031)  classification: 0.4619 (0.4791)  time: 0.4127  data: 0.1503  max mem: 3278
Epoch: [80]  [3200/3494]  eta: 0:02:17  lr: 0.0000000  loss: 0.5885 (0.5823)  bbox_regression: 0.0984 (0.1029)  classification: 0.4700 (0.4794)  time: 0.4225  data: 0.1500  max mem: 3278
Epoch: [80]  [3300/3494]  eta: 0:01:30  lr: 0.0000000  loss: 0.5529 (0.5819)  bbox_regression: 0.0976 (0.1030)  classification: 0.4659 (0.4789)  time: 0.4968  data: 0.1650  max mem: 3278
Epoch: [80]  [3400/3494]  eta: 0:00:44  lr: 0.0000000  loss: 0.5637 (0.5818)  bbox_regression: 0.0971 (0.1031)  classification: 0.4704 (0.4788)  time: 0.5092  data: 0.1513  max mem: 3278
Epoch: [80]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.6150 (0.5822)  bbox_regression: 0.0878 (0.1030)  classification: 0.5237 (0.4792)  time: 0.4390  data: 0.1513  max mem: 3278
Epoch: [80] Total time: 0:27:29 (0.4721 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:41  model_time: 0.3589 (0.3589)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5667  data: 2.1519  max mem: 3278
Validation:  [100/437]  eta: 0:02:08  model_time: 0.1487 (0.1731)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3338  data: 0.1550  max mem: 3278
Validation:  [200/437]  eta: 0:01:25  model_time: 0.1591 (0.1679)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.3466  data: 0.1573  max mem: 3278
Validation:  [300/437]  eta: 0:00:48  model_time: 0.1526 (0.1644)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3408  data: 0.1609  max mem: 3278
Validation:  [400/437]  eta: 0:00:13  model_time: 0.1831 (0.1690)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3714  data: 0.1583  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1683 (0.1700)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3358  data: 0.1487  max mem: 3278
Validation: Total time: 0:02:36 (0.3592 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [81]  [   0/3494]  eta: 2:36:07  lr: 0.0000000  loss: 0.5015 (0.5015)  bbox_regression: 0.0752 (0.0752)  classification: 0.4264 (0.4264)  time: 2.6809  data: 2.4252  max mem: 3278
Epoch: [81]  [ 100/3494]  eta: 0:28:36  lr: 0.0000000  loss: 0.5651 (0.5998)  bbox_regression: 0.1006 (0.1061)  classification: 0.4550 (0.4936)  time: 0.4337  data: 0.1426  max mem: 3278
Epoch: [81]  [ 200/3494]  eta: 0:27:30  lr: 0.0000000  loss: 0.5420 (0.6056)  bbox_regression: 0.0972 (0.1103)  classification: 0.4579 (0.4953)  time: 0.5370  data: 0.1842  max mem: 3278
Epoch: [81]  [ 300/3494]  eta: 0:26:36  lr: 0.0000000  loss: 0.5605 (0.5996)  bbox_regression: 0.0917 (0.1078)  classification: 0.4630 (0.4917)  time: 0.5117  data: 0.1630  max mem: 3278
Epoch: [81]  [ 400/3494]  eta: 0:25:11  lr: 0.0000000  loss: 0.5798 (0.5998)  bbox_regression: 0.0967 (0.1078)  classification: 0.4992 (0.4920)  time: 0.4221  data: 0.1431  max mem: 3278
Epoch: [81]  [ 500/3494]  eta: 0:23:41  lr: 0.0000000  loss: 0.5674 (0.5965)  bbox_regression: 0.0917 (0.1064)  classification: 0.4754 (0.4901)  time: 0.4468  data: 0.1520  max mem: 3278
Epoch: [81]  [ 600/3494]  eta: 0:23:07  lr: 0.0000000  loss: 0.5691 (0.5935)  bbox_regression: 0.1026 (0.1058)  classification: 0.4887 (0.4877)  time: 0.5298  data: 0.1736  max mem: 3278
Epoch: [81]  [ 700/3494]  eta: 0:22:27  lr: 0.0000000  loss: 0.5456 (0.5932)  bbox_regression: 0.0917 (0.1057)  classification: 0.4593 (0.4876)  time: 0.5161  data: 0.1727  max mem: 3278
Epoch: [81]  [ 800/3494]  eta: 0:21:38  lr: 0.0000000  loss: 0.5430 (0.5901)  bbox_regression: 0.0930 (0.1045)  classification: 0.4491 (0.4857)  time: 0.4744  data: 0.1518  max mem: 3278
Epoch: [81]  [ 900/3494]  eta: 0:20:59  lr: 0.0000000  loss: 0.5862 (0.5886)  bbox_regression: 0.1021 (0.1043)  classification: 0.4788 (0.4843)  time: 0.5534  data: 0.2105  max mem: 3278
Epoch: [81]  [1000/3494]  eta: 0:19:58  lr: 0.0000000  loss: 0.5387 (0.5869)  bbox_regression: 0.0849 (0.1039)  classification: 0.4448 (0.4830)  time: 0.4411  data: 0.1575  max mem: 3278
Epoch: [81]  [1100/3494]  eta: 0:18:53  lr: 0.0000000  loss: 0.5215 (0.5857)  bbox_regression: 0.0944 (0.1037)  classification: 0.4004 (0.4820)  time: 0.3860  data: 0.1421  max mem: 3278
Epoch: [81]  [1200/3494]  eta: 0:18:07  lr: 0.0000000  loss: 0.5879 (0.5871)  bbox_regression: 0.1128 (0.1043)  classification: 0.4703 (0.4829)  time: 0.4989  data: 0.1719  max mem: 3278
Epoch: [81]  [1300/3494]  eta: 0:17:22  lr: 0.0000000  loss: 0.5420 (0.5858)  bbox_regression: 0.0901 (0.1039)  classification: 0.4569 (0.4819)  time: 0.4980  data: 0.1664  max mem: 3278
Epoch: [81]  [1400/3494]  eta: 0:16:37  lr: 0.0000000  loss: 0.5669 (0.5855)  bbox_regression: 0.1015 (0.1039)  classification: 0.4625 (0.4817)  time: 0.4662  data: 0.1722  max mem: 3278
Epoch: [81]  [1500/3494]  eta: 0:15:51  lr: 0.0000000  loss: 0.5447 (0.5851)  bbox_regression: 0.0862 (0.1037)  classification: 0.4405 (0.4814)  time: 0.5287  data: 0.1715  max mem: 3278
Epoch: [81]  [1600/3494]  eta: 0:14:59  lr: 0.0000000  loss: 0.5566 (0.5854)  bbox_regression: 0.1044 (0.1037)  classification: 0.4567 (0.4817)  time: 0.3764  data: 0.1309  max mem: 3278
Epoch: [81]  [1700/3494]  eta: 0:14:04  lr: 0.0000000  loss: 0.5212 (0.5859)  bbox_regression: 0.0967 (0.1039)  classification: 0.4337 (0.4820)  time: 0.3768  data: 0.1387  max mem: 3278
Epoch: [81]  [1800/3494]  eta: 0:13:13  lr: 0.0000000  loss: 0.5689 (0.5859)  bbox_regression: 0.0943 (0.1039)  classification: 0.4451 (0.4820)  time: 0.4859  data: 0.1657  max mem: 3278
Epoch: [81]  [1900/3494]  eta: 0:12:29  lr: 0.0000000  loss: 0.5666 (0.5862)  bbox_regression: 0.0960 (0.1039)  classification: 0.4718 (0.4823)  time: 0.5329  data: 0.1718  max mem: 3278
Epoch: [81]  [2000/3494]  eta: 0:11:45  lr: 0.0000000  loss: 0.6167 (0.5857)  bbox_regression: 0.1062 (0.1040)  classification: 0.4828 (0.4817)  time: 0.5261  data: 0.1565  max mem: 3278
Epoch: [81]  [2100/3494]  eta: 0:10:58  lr: 0.0000000  loss: 0.5215 (0.5846)  bbox_regression: 0.0956 (0.1037)  classification: 0.4155 (0.4809)  time: 0.4768  data: 0.1608  max mem: 3278
Epoch: [81]  [2200/3494]  eta: 0:10:10  lr: 0.0000000  loss: 0.5806 (0.5844)  bbox_regression: 0.0976 (0.1035)  classification: 0.5024 (0.4809)  time: 0.4148  data: 0.1367  max mem: 3278
Epoch: [81]  [2300/3494]  eta: 0:09:20  lr: 0.0000000  loss: 0.5985 (0.5851)  bbox_regression: 0.0976 (0.1035)  classification: 0.4958 (0.4816)  time: 0.4038  data: 0.1516  max mem: 3278
Epoch: [81]  [2400/3494]  eta: 0:08:31  lr: 0.0000000  loss: 0.6004 (0.5855)  bbox_regression: 0.0972 (0.1037)  classification: 0.4632 (0.4819)  time: 0.5308  data: 0.1782  max mem: 3278
Epoch: [81]  [2500/3494]  eta: 0:07:46  lr: 0.0000000  loss: 0.5683 (0.5859)  bbox_regression: 0.0962 (0.1037)  classification: 0.4746 (0.4821)  time: 0.5043  data: 0.1922  max mem: 3278
Epoch: [81]  [2600/3494]  eta: 0:06:59  lr: 0.0000000  loss: 0.5535 (0.5853)  bbox_regression: 0.0891 (0.1036)  classification: 0.4632 (0.4817)  time: 0.5069  data: 0.1651  max mem: 3278
Epoch: [81]  [2700/3494]  eta: 0:06:13  lr: 0.0000000  loss: 0.5267 (0.5855)  bbox_regression: 0.0788 (0.1036)  classification: 0.4254 (0.4819)  time: 0.5179  data: 0.1610  max mem: 3278
Epoch: [81]  [2800/3494]  eta: 0:05:26  lr: 0.0000000  loss: 0.5442 (0.5852)  bbox_regression: 0.1012 (0.1035)  classification: 0.4321 (0.4817)  time: 0.4909  data: 0.1699  max mem: 3278
Epoch: [81]  [2900/3494]  eta: 0:04:39  lr: 0.0000000  loss: 0.5369 (0.5850)  bbox_regression: 0.0971 (0.1035)  classification: 0.4371 (0.4815)  time: 0.4640  data: 0.1659  max mem: 3278
Epoch: [81]  [3000/3494]  eta: 0:03:51  lr: 0.0000000  loss: 0.5298 (0.5845)  bbox_regression: 0.0822 (0.1032)  classification: 0.4412 (0.4813)  time: 0.4957  data: 0.1653  max mem: 3278
Epoch: [81]  [3100/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5560 (0.5836)  bbox_regression: 0.0995 (0.1030)  classification: 0.4604 (0.4806)  time: 0.4696  data: 0.1487  max mem: 3278
Epoch: [81]  [3200/3494]  eta: 0:02:17  lr: 0.0000000  loss: 0.5232 (0.5841)  bbox_regression: 0.1015 (0.1031)  classification: 0.4394 (0.4809)  time: 0.5127  data: 0.1629  max mem: 3278
Epoch: [81]  [3300/3494]  eta: 0:01:31  lr: 0.0000000  loss: 0.5451 (0.5838)  bbox_regression: 0.0902 (0.1031)  classification: 0.4449 (0.4807)  time: 0.5107  data: 0.1655  max mem: 3278
Epoch: [81]  [3400/3494]  eta: 0:00:44  lr: 0.0000000  loss: 0.5441 (0.5834)  bbox_regression: 0.0864 (0.1031)  classification: 0.4483 (0.4803)  time: 0.5158  data: 0.1843  max mem: 3278
Epoch: [81]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5385 (0.5827)  bbox_regression: 0.0978 (0.1030)  classification: 0.4366 (0.4797)  time: 0.3759  data: 0.1300  max mem: 3278
Epoch: [81] Total time: 0:27:31 (0.4725 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:25  model_time: 0.1845 (0.1845)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5292  data: 2.2967  max mem: 3278
Validation:  [100/437]  eta: 0:01:53  model_time: 0.1291 (0.1472)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3094  data: 0.1451  max mem: 3278
Validation:  [200/437]  eta: 0:01:23  model_time: 0.1799 (0.1665)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.3658  data: 0.1517  max mem: 3278
Validation:  [300/437]  eta: 0:00:49  model_time: 0.1968 (0.1746)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3921  data: 0.1660  max mem: 3278
Validation:  [400/437]  eta: 0:00:13  model_time: 0.1895 (0.1791)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3868  data: 0.1631  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1942 (0.1805)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3805  data: 0.1555  max mem: 3278
Validation: Total time: 0:02:41 (0.3690 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [82]  [   0/3494]  eta: 3:03:01  lr: 0.0000000  loss: 0.5329 (0.5329)  bbox_regression: 0.0756 (0.0756)  classification: 0.4574 (0.4574)  time: 3.1431  data: 2.7182  max mem: 3278
Epoch: [82]  [ 100/3494]  eta: 0:29:53  lr: 0.0000000  loss: 0.5342 (0.5823)  bbox_regression: 0.1165 (0.1083)  classification: 0.3971 (0.4740)  time: 0.5326  data: 0.1688  max mem: 3278
Epoch: [82]  [ 200/3494]  eta: 0:26:41  lr: 0.0000000  loss: 0.5478 (0.5837)  bbox_regression: 0.0922 (0.1055)  classification: 0.4545 (0.4782)  time: 0.3612  data: 0.1154  max mem: 3278
Epoch: [82]  [ 300/3494]  eta: 0:24:54  lr: 0.0000000  loss: 0.6193 (0.5887)  bbox_regression: 0.0974 (0.1054)  classification: 0.5190 (0.4833)  time: 0.4344  data: 0.1583  max mem: 3278
Epoch: [82]  [ 400/3494]  eta: 0:23:45  lr: 0.0000000  loss: 0.5921 (0.5906)  bbox_regression: 0.1037 (0.1056)  classification: 0.4996 (0.4849)  time: 0.4946  data: 0.1644  max mem: 3278
Epoch: [82]  [ 500/3494]  eta: 0:23:05  lr: 0.0000000  loss: 0.5656 (0.5906)  bbox_regression: 0.0896 (0.1050)  classification: 0.4454 (0.4856)  time: 0.4660  data: 0.1547  max mem: 3278
Epoch: [82]  [ 600/3494]  eta: 0:22:16  lr: 0.0000000  loss: 0.5706 (0.5868)  bbox_regression: 0.0934 (0.1039)  classification: 0.4602 (0.4829)  time: 0.4716  data: 0.1498  max mem: 3278
Epoch: [82]  [ 700/3494]  eta: 0:21:29  lr: 0.0000000  loss: 0.5308 (0.5848)  bbox_regression: 0.1041 (0.1034)  classification: 0.4580 (0.4814)  time: 0.4064  data: 0.1424  max mem: 3278
Epoch: [82]  [ 800/3494]  eta: 0:20:44  lr: 0.0000000  loss: 0.5959 (0.5864)  bbox_regression: 0.0983 (0.1036)  classification: 0.4910 (0.4828)  time: 0.4652  data: 0.1636  max mem: 3278
Epoch: [82]  [ 900/3494]  eta: 0:19:44  lr: 0.0000000  loss: 0.5795 (0.5848)  bbox_regression: 0.1076 (0.1037)  classification: 0.4719 (0.4811)  time: 0.3939  data: 0.1351  max mem: 3278
Epoch: [82]  [1000/3494]  eta: 0:18:49  lr: 0.0000000  loss: 0.5757 (0.5854)  bbox_regression: 0.1043 (0.1037)  classification: 0.4674 (0.4817)  time: 0.4361  data: 0.1552  max mem: 3278
Epoch: [82]  [1100/3494]  eta: 0:18:14  lr: 0.0000000  loss: 0.5598 (0.5851)  bbox_regression: 0.0943 (0.1035)  classification: 0.4771 (0.4816)  time: 0.5189  data: 0.1684  max mem: 3278
Epoch: [82]  [1200/3494]  eta: 0:17:38  lr: 0.0000000  loss: 0.6126 (0.5856)  bbox_regression: 0.0994 (0.1037)  classification: 0.4928 (0.4819)  time: 0.5118  data: 0.1695  max mem: 3278
Epoch: [82]  [1300/3494]  eta: 0:16:57  lr: 0.0000000  loss: 0.5425 (0.5850)  bbox_regression: 0.0875 (0.1032)  classification: 0.4528 (0.4817)  time: 0.4573  data: 0.1489  max mem: 3278
Epoch: [82]  [1400/3494]  eta: 0:16:10  lr: 0.0000000  loss: 0.5408 (0.5848)  bbox_regression: 0.0947 (0.1031)  classification: 0.4532 (0.4816)  time: 0.4487  data: 0.1480  max mem: 3278
Epoch: [82]  [1500/3494]  eta: 0:15:20  lr: 0.0000000  loss: 0.5914 (0.5849)  bbox_regression: 0.1139 (0.1033)  classification: 0.4826 (0.4816)  time: 0.4123  data: 0.1476  max mem: 3278
Epoch: [82]  [1600/3494]  eta: 0:14:28  lr: 0.0000000  loss: 0.5667 (0.5849)  bbox_regression: 0.0845 (0.1030)  classification: 0.4759 (0.4819)  time: 0.3849  data: 0.1369  max mem: 3278
Epoch: [82]  [1700/3494]  eta: 0:13:43  lr: 0.0000000  loss: 0.5699 (0.5848)  bbox_regression: 0.0965 (0.1030)  classification: 0.4703 (0.4818)  time: 0.4817  data: 0.1524  max mem: 3278
Epoch: [82]  [1800/3494]  eta: 0:13:01  lr: 0.0000000  loss: 0.5600 (0.5843)  bbox_regression: 0.0901 (0.1029)  classification: 0.4433 (0.4814)  time: 0.4993  data: 0.1579  max mem: 3278
Epoch: [82]  [1900/3494]  eta: 0:12:18  lr: 0.0000000  loss: 0.5638 (0.5842)  bbox_regression: 0.0896 (0.1028)  classification: 0.4860 (0.4814)  time: 0.5554  data: 0.2057  max mem: 3278
Epoch: [82]  [2000/3494]  eta: 0:11:35  lr: 0.0000000  loss: 0.5985 (0.5844)  bbox_regression: 0.0995 (0.1027)  classification: 0.4992 (0.4817)  time: 0.5218  data: 0.1877  max mem: 3278
Epoch: [82]  [2100/3494]  eta: 0:10:47  lr: 0.0000000  loss: 0.5590 (0.5831)  bbox_regression: 0.0896 (0.1024)  classification: 0.4678 (0.4807)  time: 0.4352  data: 0.1397  max mem: 3278
Epoch: [82]  [2200/3494]  eta: 0:09:57  lr: 0.0000000  loss: 0.5193 (0.5833)  bbox_regression: 0.0923 (0.1024)  classification: 0.4271 (0.4809)  time: 0.4129  data: 0.1446  max mem: 3278
Epoch: [82]  [2300/3494]  eta: 0:09:10  lr: 0.0000000  loss: 0.5965 (0.5828)  bbox_regression: 0.1046 (0.1025)  classification: 0.4792 (0.4803)  time: 0.4733  data: 0.1781  max mem: 3278
Epoch: [82]  [2400/3494]  eta: 0:08:25  lr: 0.0000000  loss: 0.5492 (0.5825)  bbox_regression: 0.0926 (0.1025)  classification: 0.4452 (0.4800)  time: 0.4856  data: 0.1537  max mem: 3278
Epoch: [82]  [2500/3494]  eta: 0:07:40  lr: 0.0000000  loss: 0.5868 (0.5832)  bbox_regression: 0.0951 (0.1026)  classification: 0.4838 (0.4806)  time: 0.4801  data: 0.1484  max mem: 3278
Epoch: [82]  [2600/3494]  eta: 0:06:55  lr: 0.0000000  loss: 0.5681 (0.5829)  bbox_regression: 0.0959 (0.1025)  classification: 0.4808 (0.4804)  time: 0.4811  data: 0.1595  max mem: 3278
Epoch: [82]  [2700/3494]  eta: 0:06:08  lr: 0.0000000  loss: 0.5715 (0.5827)  bbox_regression: 0.0930 (0.1026)  classification: 0.4790 (0.4801)  time: 0.3987  data: 0.1388  max mem: 3278
Epoch: [82]  [2800/3494]  eta: 0:05:21  lr: 0.0000000  loss: 0.5965 (0.5831)  bbox_regression: 0.0914 (0.1025)  classification: 0.4842 (0.4806)  time: 0.3934  data: 0.1360  max mem: 3278
Epoch: [82]  [2900/3494]  eta: 0:04:34  lr: 0.0000000  loss: 0.6218 (0.5835)  bbox_regression: 0.1026 (0.1027)  classification: 0.5093 (0.4808)  time: 0.4628  data: 0.1509  max mem: 3278
Epoch: [82]  [3000/3494]  eta: 0:03:48  lr: 0.0000000  loss: 0.5903 (0.5834)  bbox_regression: 0.0958 (0.1028)  classification: 0.4909 (0.4807)  time: 0.4986  data: 0.1931  max mem: 3278
Epoch: [82]  [3100/3494]  eta: 0:03:02  lr: 0.0000000  loss: 0.6154 (0.5839)  bbox_regression: 0.1077 (0.1030)  classification: 0.4926 (0.4809)  time: 0.5049  data: 0.1678  max mem: 3278
Epoch: [82]  [3200/3494]  eta: 0:02:16  lr: 0.0000000  loss: 0.5502 (0.5838)  bbox_regression: 0.0967 (0.1031)  classification: 0.4369 (0.4807)  time: 0.4784  data: 0.1579  max mem: 3278
Epoch: [82]  [3300/3494]  eta: 0:01:30  lr: 0.0000000  loss: 0.5420 (0.5837)  bbox_regression: 0.0876 (0.1032)  classification: 0.4461 (0.4805)  time: 0.4158  data: 0.1432  max mem: 3278
Epoch: [82]  [3400/3494]  eta: 0:00:43  lr: 0.0000000  loss: 0.5283 (0.5834)  bbox_regression: 0.0825 (0.1032)  classification: 0.4417 (0.4802)  time: 0.4296  data: 0.1585  max mem: 3278
Epoch: [82]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5838 (0.5833)  bbox_regression: 0.0840 (0.1032)  classification: 0.4920 (0.4801)  time: 0.4736  data: 0.1674  max mem: 3278
Epoch: [82] Total time: 0:27:09 (0.4662 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:22:32  model_time: 0.1670 (0.1670)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 3.0946  data: 2.8853  max mem: 3278
Validation:  [100/437]  eta: 0:02:15  model_time: 0.1803 (0.1856)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3717  data: 0.1606  max mem: 3278
Validation:  [200/437]  eta: 0:01:34  model_time: 0.1986 (0.1888)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.3894  data: 0.1670  max mem: 3278
Validation:  [300/437]  eta: 0:00:53  model_time: 0.1481 (0.1888)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3649  data: 0.1716  max mem: 3278
Validation:  [400/437]  eta: 0:00:14  model_time: 0.1800 (0.1876)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3710  data: 0.1724  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1530 (0.1854)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.3335  data: 0.1545  max mem: 3278
Validation: Total time: 0:02:48 (0.3852 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [83]  [   0/3494]  eta: 2:41:15  lr: 0.0000000  loss: 0.5881 (0.5881)  bbox_regression: 0.1221 (0.1221)  classification: 0.4660 (0.4660)  time: 2.7691  data: 2.2194  max mem: 3278
Epoch: [83]  [ 100/3494]  eta: 0:27:25  lr: 0.0000000  loss: 0.5567 (0.5931)  bbox_regression: 0.0983 (0.1054)  classification: 0.4383 (0.4877)  time: 0.4137  data: 0.1396  max mem: 3278
Epoch: [83]  [ 200/3494]  eta: 0:24:40  lr: 0.0000000  loss: 0.5298 (0.5853)  bbox_regression: 0.0804 (0.1022)  classification: 0.4500 (0.4831)  time: 0.3921  data: 0.1353  max mem: 3278
Epoch: [83]  [ 300/3494]  eta: 0:23:39  lr: 0.0000000  loss: 0.5414 (0.5867)  bbox_regression: 0.0972 (0.1043)  classification: 0.4298 (0.4824)  time: 0.5637  data: 0.1776  max mem: 3278
Epoch: [83]  [ 400/3494]  eta: 0:23:39  lr: 0.0000000  loss: 0.5863 (0.5843)  bbox_regression: 0.0849 (0.1042)  classification: 0.4768 (0.4801)  time: 0.5119  data: 0.1708  max mem: 3278
Epoch: [83]  [ 500/3494]  eta: 0:23:32  lr: 0.0000000  loss: 0.5643 (0.5842)  bbox_regression: 0.1016 (0.1049)  classification: 0.4516 (0.4793)  time: 0.5336  data: 0.1598  max mem: 3278
Epoch: [83]  [ 600/3494]  eta: 0:23:16  lr: 0.0000000  loss: 0.5515 (0.5819)  bbox_regression: 0.0887 (0.1045)  classification: 0.4615 (0.4773)  time: 0.5291  data: 0.1760  max mem: 3278
Epoch: [83]  [ 700/3494]  eta: 0:22:30  lr: 0.0000000  loss: 0.5541 (0.5814)  bbox_regression: 0.0948 (0.1041)  classification: 0.4479 (0.4772)  time: 0.4681  data: 0.1621  max mem: 3278
Epoch: [83]  [ 800/3494]  eta: 0:21:34  lr: 0.0000000  loss: 0.5704 (0.5842)  bbox_regression: 0.0937 (0.1045)  classification: 0.4765 (0.4797)  time: 0.4153  data: 0.1493  max mem: 3278
Epoch: [83]  [ 900/3494]  eta: 0:20:40  lr: 0.0000000  loss: 0.6136 (0.5855)  bbox_regression: 0.1034 (0.1046)  classification: 0.4978 (0.4809)  time: 0.4672  data: 0.1617  max mem: 3278
Epoch: [83]  [1000/3494]  eta: 0:20:00  lr: 0.0000000  loss: 0.5602 (0.5847)  bbox_regression: 0.0990 (0.1041)  classification: 0.4299 (0.4806)  time: 0.5299  data: 0.1760  max mem: 3278
Epoch: [83]  [1100/3494]  eta: 0:19:18  lr: 0.0000000  loss: 0.5587 (0.5846)  bbox_regression: 0.0898 (0.1041)  classification: 0.4725 (0.4806)  time: 0.4744  data: 0.1524  max mem: 3278
Epoch: [83]  [1200/3494]  eta: 0:18:29  lr: 0.0000000  loss: 0.5917 (0.5848)  bbox_regression: 0.1031 (0.1043)  classification: 0.4768 (0.4805)  time: 0.4776  data: 0.1588  max mem: 3278
Epoch: [83]  [1300/3494]  eta: 0:17:43  lr: 0.0000000  loss: 0.4993 (0.5848)  bbox_regression: 0.0859 (0.1045)  classification: 0.3974 (0.4803)  time: 0.4518  data: 0.1595  max mem: 3278
Epoch: [83]  [1400/3494]  eta: 0:16:47  lr: 0.0000000  loss: 0.5414 (0.5845)  bbox_regression: 0.0961 (0.1042)  classification: 0.4479 (0.4803)  time: 0.4498  data: 0.1551  max mem: 3278
Epoch: [83]  [1500/3494]  eta: 0:15:52  lr: 0.0000000  loss: 0.5800 (0.5842)  bbox_regression: 0.0988 (0.1039)  classification: 0.4939 (0.4802)  time: 0.3907  data: 0.1347  max mem: 3278
Epoch: [83]  [1600/3494]  eta: 0:15:06  lr: 0.0000000  loss: 0.5391 (0.5844)  bbox_regression: 0.0901 (0.1039)  classification: 0.4461 (0.4805)  time: 0.4792  data: 0.1702  max mem: 3278
Epoch: [83]  [1700/3494]  eta: 0:14:18  lr: 0.0000000  loss: 0.5442 (0.5836)  bbox_regression: 0.0856 (0.1036)  classification: 0.4578 (0.4801)  time: 0.4325  data: 0.1444  max mem: 3278
Epoch: [83]  [1800/3494]  eta: 0:13:30  lr: 0.0000000  loss: 0.5647 (0.5830)  bbox_regression: 0.0992 (0.1036)  classification: 0.4526 (0.4795)  time: 0.4647  data: 0.1609  max mem: 3278
Epoch: [83]  [1900/3494]  eta: 0:12:43  lr: 0.0000000  loss: 0.5941 (0.5821)  bbox_regression: 0.1073 (0.1032)  classification: 0.4739 (0.4789)  time: 0.5183  data: 0.1649  max mem: 3278
Epoch: [83]  [2000/3494]  eta: 0:11:53  lr: 0.0000000  loss: 0.5515 (0.5822)  bbox_regression: 0.1004 (0.1032)  classification: 0.4483 (0.4790)  time: 0.4158  data: 0.1354  max mem: 3278
Epoch: [83]  [2100/3494]  eta: 0:11:01  lr: 0.0000000  loss: 0.6133 (0.5832)  bbox_regression: 0.0967 (0.1033)  classification: 0.4991 (0.4799)  time: 0.3789  data: 0.1360  max mem: 3278
Epoch: [83]  [2200/3494]  eta: 0:10:13  lr: 0.0000000  loss: 0.5648 (0.5832)  bbox_regression: 0.0968 (0.1034)  classification: 0.4597 (0.4798)  time: 0.4590  data: 0.1603  max mem: 3278
Epoch: [83]  [2300/3494]  eta: 0:09:25  lr: 0.0000000  loss: 0.6041 (0.5835)  bbox_regression: 0.0884 (0.1033)  classification: 0.4706 (0.4801)  time: 0.5081  data: 0.1770  max mem: 3278
Epoch: [83]  [2400/3494]  eta: 0:08:38  lr: 0.0000000  loss: 0.5383 (0.5827)  bbox_regression: 0.0758 (0.1032)  classification: 0.4605 (0.4795)  time: 0.4807  data: 0.1602  max mem: 3278
Epoch: [83]  [2500/3494]  eta: 0:07:50  lr: 0.0000000  loss: 0.5332 (0.5825)  bbox_regression: 0.1073 (0.1032)  classification: 0.4460 (0.4793)  time: 0.4838  data: 0.1537  max mem: 3278
Epoch: [83]  [2600/3494]  eta: 0:07:03  lr: 0.0000000  loss: 0.5394 (0.5826)  bbox_regression: 0.0877 (0.1032)  classification: 0.4448 (0.4794)  time: 0.4608  data: 0.1477  max mem: 3278
Epoch: [83]  [2700/3494]  eta: 0:06:14  lr: 0.0000000  loss: 0.5747 (0.5830)  bbox_regression: 0.1010 (0.1033)  classification: 0.4750 (0.4796)  time: 0.4059  data: 0.1486  max mem: 3278
Epoch: [83]  [2800/3494]  eta: 0:05:27  lr: 0.0000000  loss: 0.5576 (0.5828)  bbox_regression: 0.0951 (0.1033)  classification: 0.4625 (0.4795)  time: 0.4844  data: 0.1628  max mem: 3278
Epoch: [83]  [2900/3494]  eta: 0:04:40  lr: 0.0000000  loss: 0.5481 (0.5828)  bbox_regression: 0.0838 (0.1033)  classification: 0.4496 (0.4795)  time: 0.4773  data: 0.1535  max mem: 3278
Epoch: [83]  [3000/3494]  eta: 0:03:53  lr: 0.0000000  loss: 0.5968 (0.5828)  bbox_regression: 0.1034 (0.1033)  classification: 0.4796 (0.4795)  time: 0.4303  data: 0.1436  max mem: 3278
Epoch: [83]  [3100/3494]  eta: 0:03:06  lr: 0.0000000  loss: 0.5353 (0.5825)  bbox_regression: 0.0872 (0.1031)  classification: 0.4482 (0.4794)  time: 0.4738  data: 0.1559  max mem: 3278
Epoch: [83]  [3200/3494]  eta: 0:02:18  lr: 0.0000000  loss: 0.6149 (0.5822)  bbox_regression: 0.1018 (0.1031)  classification: 0.5135 (0.4792)  time: 0.4344  data: 0.1482  max mem: 3278
Epoch: [83]  [3300/3494]  eta: 0:01:31  lr: 0.0000000  loss: 0.5071 (0.5821)  bbox_regression: 0.0911 (0.1030)  classification: 0.4149 (0.4791)  time: 0.4299  data: 0.1542  max mem: 3278
Epoch: [83]  [3400/3494]  eta: 0:00:44  lr: 0.0000000  loss: 0.6171 (0.5823)  bbox_regression: 0.0948 (0.1031)  classification: 0.4994 (0.4792)  time: 0.4806  data: 0.1745  max mem: 3278
Epoch: [83]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5545 (0.5825)  bbox_regression: 0.0963 (0.1030)  classification: 0.4712 (0.4795)  time: 0.4653  data: 0.1625  max mem: 3278
Epoch: [83] Total time: 0:27:36 (0.4742 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:19:32  model_time: 0.1700 (0.1700)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.6840  data: 2.4707  max mem: 3278
Validation:  [100/437]  eta: 0:02:14  model_time: 0.1621 (0.1857)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.3605  data: 0.1687  max mem: 3278
Validation:  [200/437]  eta: 0:01:34  model_time: 0.1758 (0.1919)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.4067  data: 0.1810  max mem: 3278
Validation:  [300/437]  eta: 0:00:53  model_time: 0.1789 (0.1933)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.3735  data: 0.1591  max mem: 3278
Validation:  [400/437]  eta: 0:00:14  model_time: 0.1407 (0.1898)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.3169  data: 0.1370  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1139 (0.1846)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2687  data: 0.1298  max mem: 3278
Validation: Total time: 0:02:44 (0.3761 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [84]  [   0/3494]  eta: 2:42:38  lr: 0.0000000  loss: 0.6373 (0.6373)  bbox_regression: 0.1146 (0.1146)  classification: 0.5226 (0.5226)  time: 2.7930  data: 2.2178  max mem: 3278
Epoch: [84]  [ 100/3494]  eta: 0:25:37  lr: 0.0000000  loss: 0.5984 (0.5795)  bbox_regression: 0.1067 (0.1043)  classification: 0.4951 (0.4753)  time: 0.4253  data: 0.1514  max mem: 3278
Epoch: [84]  [ 200/3494]  eta: 0:25:12  lr: 0.0000000  loss: 0.4997 (0.5791)  bbox_regression: 0.0867 (0.1039)  classification: 0.4146 (0.4752)  time: 0.5238  data: 0.1779  max mem: 3278
Epoch: [84]  [ 300/3494]  eta: 0:25:14  lr: 0.0000000  loss: 0.5321 (0.5800)  bbox_regression: 0.0921 (0.1025)  classification: 0.4391 (0.4775)  time: 0.5030  data: 0.1574  max mem: 3278
Epoch: [84]  [ 400/3494]  eta: 0:24:45  lr: 0.0000000  loss: 0.5618 (0.5828)  bbox_regression: 0.0945 (0.1032)  classification: 0.4721 (0.4796)  time: 0.4672  data: 0.1543  max mem: 3278
Epoch: [84]  [ 500/3494]  eta: 0:24:00  lr: 0.0000000  loss: 0.4964 (0.5804)  bbox_regression: 0.0959 (0.1031)  classification: 0.3978 (0.4773)  time: 0.5088  data: 0.1613  max mem: 3278
Epoch: [84]  [ 600/3494]  eta: 0:23:09  lr: 0.0000000  loss: 0.5574 (0.5828)  bbox_regression: 0.0926 (0.1031)  classification: 0.4737 (0.4797)  time: 0.5038  data: 0.1584  max mem: 3278
Epoch: [84]  [ 700/3494]  eta: 0:21:57  lr: 0.0000000  loss: 0.5389 (0.5825)  bbox_regression: 0.0908 (0.1032)  classification: 0.4474 (0.4792)  time: 0.4058  data: 0.1412  max mem: 3278
Epoch: [84]  [ 800/3494]  eta: 0:21:07  lr: 0.0000000  loss: 0.6183 (0.5822)  bbox_regression: 0.1099 (0.1034)  classification: 0.5065 (0.4787)  time: 0.4793  data: 0.1809  max mem: 3278
Epoch: [84]  [ 900/3494]  eta: 0:20:26  lr: 0.0000000  loss: 0.5255 (0.5827)  bbox_regression: 0.1019 (0.1036)  classification: 0.4431 (0.4791)  time: 0.4821  data: 0.1637  max mem: 3278
Epoch: [84]  [1000/3494]  eta: 0:19:45  lr: 0.0000000  loss: 0.5347 (0.5812)  bbox_regression: 0.0923 (0.1032)  classification: 0.4421 (0.4780)  time: 0.4791  data: 0.1564  max mem: 3278
Epoch: [84]  [1100/3494]  eta: 0:19:06  lr: 0.0000000  loss: 0.5535 (0.5801)  bbox_regression: 0.0965 (0.1027)  classification: 0.4643 (0.4774)  time: 0.5161  data: 0.1716  max mem: 3278
Epoch: [84]  [1200/3494]  eta: 0:18:18  lr: 0.0000000  loss: 0.5134 (0.5781)  bbox_regression: 0.0846 (0.1024)  classification: 0.4051 (0.4757)  time: 0.3936  data: 0.1416  max mem: 3278
Epoch: [84]  [1300/3494]  eta: 0:17:21  lr: 0.0000000  loss: 0.6051 (0.5797)  bbox_regression: 0.1042 (0.1029)  classification: 0.4859 (0.4767)  time: 0.4075  data: 0.1459  max mem: 3278
Epoch: [84]  [1400/3494]  eta: 0:16:28  lr: 0.0000000  loss: 0.5470 (0.5801)  bbox_regression: 0.0971 (0.1029)  classification: 0.4618 (0.4772)  time: 0.4138  data: 0.1426  max mem: 3278
Epoch: [84]  [1500/3494]  eta: 0:15:44  lr: 0.0000000  loss: 0.5251 (0.5820)  bbox_regression: 0.0878 (0.1034)  classification: 0.4351 (0.4785)  time: 0.4887  data: 0.1566  max mem: 3278
Epoch: [84]  [1600/3494]  eta: 0:14:51  lr: 0.0000000  loss: 0.5750 (0.5810)  bbox_regression: 0.0946 (0.1031)  classification: 0.4757 (0.4779)  time: 0.3856  data: 0.1407  max mem: 3278
Epoch: [84]  [1700/3494]  eta: 0:13:55  lr: 0.0000000  loss: 0.5867 (0.5811)  bbox_regression: 0.0957 (0.1031)  classification: 0.4840 (0.4780)  time: 0.4000  data: 0.1404  max mem: 3278
Epoch: [84]  [1800/3494]  eta: 0:13:00  lr: 0.0000000  loss: 0.5382 (0.5803)  bbox_regression: 0.1023 (0.1030)  classification: 0.4454 (0.4772)  time: 0.3687  data: 0.1297  max mem: 3278
Epoch: [84]  [1900/3494]  eta: 0:12:07  lr: 0.0000000  loss: 0.5479 (0.5798)  bbox_regression: 0.1063 (0.1029)  classification: 0.4543 (0.4769)  time: 0.3580  data: 0.1275  max mem: 3278
Epoch: [84]  [2000/3494]  eta: 0:11:15  lr: 0.0000000  loss: 0.5408 (0.5801)  bbox_regression: 0.1025 (0.1029)  classification: 0.4595 (0.4772)  time: 0.3620  data: 0.1278  max mem: 3278
Epoch: [84]  [2100/3494]  eta: 0:10:24  lr: 0.0000000  loss: 0.5494 (0.5802)  bbox_regression: 0.0961 (0.1029)  classification: 0.4441 (0.4773)  time: 0.3872  data: 0.1346  max mem: 3278
Epoch: [84]  [2200/3494]  eta: 0:09:35  lr: 0.0000000  loss: 0.5750 (0.5811)  bbox_regression: 0.0993 (0.1033)  classification: 0.4914 (0.4778)  time: 0.4007  data: 0.1475  max mem: 3278
Epoch: [84]  [2300/3494]  eta: 0:08:48  lr: 0.0000000  loss: 0.5428 (0.5810)  bbox_regression: 0.0966 (0.1032)  classification: 0.4523 (0.4779)  time: 0.3883  data: 0.1406  max mem: 3278
Epoch: [84]  [2400/3494]  eta: 0:08:01  lr: 0.0000000  loss: 0.5848 (0.5810)  bbox_regression: 0.0962 (0.1032)  classification: 0.4825 (0.4778)  time: 0.3866  data: 0.1354  max mem: 3278
Epoch: [84]  [2500/3494]  eta: 0:07:15  lr: 0.0000000  loss: 0.5627 (0.5814)  bbox_regression: 0.0923 (0.1033)  classification: 0.4603 (0.4782)  time: 0.3927  data: 0.1488  max mem: 3278
Epoch: [84]  [2600/3494]  eta: 0:06:29  lr: 0.0000000  loss: 0.5128 (0.5818)  bbox_regression: 0.0928 (0.1033)  classification: 0.4286 (0.4785)  time: 0.3999  data: 0.1295  max mem: 3278
Epoch: [84]  [2700/3494]  eta: 0:05:44  lr: 0.0000000  loss: 0.5389 (0.5822)  bbox_regression: 0.0859 (0.1034)  classification: 0.4652 (0.4788)  time: 0.3503  data: 0.1271  max mem: 3278
Epoch: [84]  [2800/3494]  eta: 0:04:59  lr: 0.0000000  loss: 0.5784 (0.5825)  bbox_regression: 0.0941 (0.1034)  classification: 0.4745 (0.4791)  time: 0.3814  data: 0.1336  max mem: 3278
Epoch: [84]  [2900/3494]  eta: 0:04:15  lr: 0.0000000  loss: 0.5569 (0.5828)  bbox_regression: 0.0998 (0.1035)  classification: 0.4493 (0.4793)  time: 0.3865  data: 0.1340  max mem: 3278
Epoch: [84]  [3000/3494]  eta: 0:03:31  lr: 0.0000000  loss: 0.5901 (0.5823)  bbox_regression: 0.0944 (0.1032)  classification: 0.4917 (0.4791)  time: 0.3679  data: 0.1351  max mem: 3278
Epoch: [84]  [3100/3494]  eta: 0:02:47  lr: 0.0000000  loss: 0.5246 (0.5820)  bbox_regression: 0.0895 (0.1031)  classification: 0.4354 (0.4789)  time: 0.3771  data: 0.1354  max mem: 3278
Epoch: [84]  [3200/3494]  eta: 0:02:04  lr: 0.0000000  loss: 0.5419 (0.5821)  bbox_regression: 0.0895 (0.1031)  classification: 0.4580 (0.4790)  time: 0.3900  data: 0.1352  max mem: 3278
Epoch: [84]  [3300/3494]  eta: 0:01:22  lr: 0.0000000  loss: 0.5513 (0.5822)  bbox_regression: 0.0916 (0.1030)  classification: 0.4583 (0.4791)  time: 0.4032  data: 0.1237  max mem: 3278
Epoch: [84]  [3400/3494]  eta: 0:00:39  lr: 0.0000000  loss: 0.5426 (0.5826)  bbox_regression: 0.0936 (0.1031)  classification: 0.4577 (0.4795)  time: 0.3653  data: 0.1337  max mem: 3278
Epoch: [84]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5287 (0.5827)  bbox_regression: 0.0897 (0.1031)  classification: 0.4379 (0.4796)  time: 0.3676  data: 0.1294  max mem: 3278
Epoch: [84] Total time: 0:24:40 (0.4238 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:16:43  model_time: 0.1538 (0.1538)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.2965  data: 2.1161  max mem: 3278
Validation:  [100/437]  eta: 0:01:40  model_time: 0.1340 (0.1295)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2725  data: 0.1215  max mem: 3278
Validation:  [200/437]  eta: 0:01:08  model_time: 0.1387 (0.1324)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2922  data: 0.1357  max mem: 3278
Validation:  [300/437]  eta: 0:00:38  model_time: 0.1381 (0.1316)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2874  data: 0.1283  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1282 (0.1325)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2747  data: 0.1236  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1320 (0.1320)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2645  data: 0.1183  max mem: 3278
Validation: Total time: 0:02:03 (0.2823 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [85]  [   0/3494]  eta: 2:41:07  lr: 0.0000000  loss: 0.6231 (0.6231)  bbox_regression: 0.1045 (0.1045)  classification: 0.5185 (0.5185)  time: 2.7670  data: 2.4909  max mem: 3278
Epoch: [85]  [ 100/3494]  eta: 0:22:21  lr: 0.0000000  loss: 0.5205 (0.5784)  bbox_regression: 0.0943 (0.1045)  classification: 0.4155 (0.4739)  time: 0.3829  data: 0.1275  max mem: 3278
Epoch: [85]  [ 200/3494]  eta: 0:21:27  lr: 0.0000000  loss: 0.5906 (0.5722)  bbox_regression: 0.1003 (0.1020)  classification: 0.4734 (0.4703)  time: 0.4089  data: 0.1244  max mem: 3278
Epoch: [85]  [ 300/3494]  eta: 0:20:17  lr: 0.0000000  loss: 0.6006 (0.5748)  bbox_regression: 0.0904 (0.1017)  classification: 0.4997 (0.4731)  time: 0.3564  data: 0.1266  max mem: 3278
Epoch: [85]  [ 400/3494]  eta: 0:19:27  lr: 0.0000000  loss: 0.5625 (0.5742)  bbox_regression: 0.0924 (0.1022)  classification: 0.4583 (0.4721)  time: 0.3709  data: 0.1305  max mem: 3278
Epoch: [85]  [ 500/3494]  eta: 0:18:47  lr: 0.0000000  loss: 0.5906 (0.5739)  bbox_regression: 0.0917 (0.1020)  classification: 0.4970 (0.4719)  time: 0.3656  data: 0.1298  max mem: 3278
Epoch: [85]  [ 600/3494]  eta: 0:18:14  lr: 0.0000000  loss: 0.5954 (0.5767)  bbox_regression: 0.0982 (0.1020)  classification: 0.4953 (0.4747)  time: 0.3757  data: 0.1362  max mem: 3278
Epoch: [85]  [ 700/3494]  eta: 0:17:33  lr: 0.0000000  loss: 0.6168 (0.5760)  bbox_regression: 0.1128 (0.1019)  classification: 0.4866 (0.4741)  time: 0.3529  data: 0.1279  max mem: 3278
Epoch: [85]  [ 800/3494]  eta: 0:16:56  lr: 0.0000000  loss: 0.5699 (0.5747)  bbox_regression: 0.0952 (0.1014)  classification: 0.4780 (0.4732)  time: 0.3636  data: 0.1322  max mem: 3278
Epoch: [85]  [ 900/3494]  eta: 0:16:18  lr: 0.0000000  loss: 0.5683 (0.5761)  bbox_regression: 0.1124 (0.1020)  classification: 0.4703 (0.4741)  time: 0.3643  data: 0.1298  max mem: 3278
Epoch: [85]  [1000/3494]  eta: 0:15:37  lr: 0.0000000  loss: 0.5758 (0.5772)  bbox_regression: 0.0919 (0.1020)  classification: 0.4755 (0.4753)  time: 0.3630  data: 0.1323  max mem: 3278
Epoch: [85]  [1100/3494]  eta: 0:14:56  lr: 0.0000000  loss: 0.5476 (0.5779)  bbox_regression: 0.0924 (0.1022)  classification: 0.4351 (0.4757)  time: 0.3596  data: 0.1318  max mem: 3278
Epoch: [85]  [1200/3494]  eta: 0:14:16  lr: 0.0000000  loss: 0.5692 (0.5779)  bbox_regression: 0.0967 (0.1022)  classification: 0.4814 (0.4757)  time: 0.3625  data: 0.1292  max mem: 3278
Epoch: [85]  [1300/3494]  eta: 0:13:36  lr: 0.0000000  loss: 0.5658 (0.5773)  bbox_regression: 0.0924 (0.1023)  classification: 0.4474 (0.4751)  time: 0.3661  data: 0.1302  max mem: 3278
Epoch: [85]  [1400/3494]  eta: 0:12:57  lr: 0.0000000  loss: 0.6170 (0.5781)  bbox_regression: 0.1135 (0.1024)  classification: 0.5065 (0.4757)  time: 0.3604  data: 0.1337  max mem: 3278
Epoch: [85]  [1500/3494]  eta: 0:12:18  lr: 0.0000000  loss: 0.5338 (0.5777)  bbox_regression: 0.0922 (0.1023)  classification: 0.4501 (0.4755)  time: 0.3589  data: 0.1251  max mem: 3278
Epoch: [85]  [1600/3494]  eta: 0:11:40  lr: 0.0000000  loss: 0.5864 (0.5804)  bbox_regression: 0.1037 (0.1026)  classification: 0.4864 (0.4778)  time: 0.3725  data: 0.1357  max mem: 3278
Epoch: [85]  [1700/3494]  eta: 0:11:03  lr: 0.0000000  loss: 0.5545 (0.5807)  bbox_regression: 0.0962 (0.1028)  classification: 0.4762 (0.4779)  time: 0.3779  data: 0.1394  max mem: 3278
Epoch: [85]  [1800/3494]  eta: 0:10:24  lr: 0.0000000  loss: 0.5550 (0.5802)  bbox_regression: 0.0946 (0.1025)  classification: 0.4302 (0.4776)  time: 0.3616  data: 0.1284  max mem: 3278
Epoch: [85]  [1900/3494]  eta: 0:09:47  lr: 0.0000000  loss: 0.5278 (0.5805)  bbox_regression: 0.0947 (0.1026)  classification: 0.4433 (0.4779)  time: 0.3713  data: 0.1385  max mem: 3278
Epoch: [85]  [2000/3494]  eta: 0:09:09  lr: 0.0000000  loss: 0.5212 (0.5794)  bbox_regression: 0.0846 (0.1024)  classification: 0.4395 (0.4770)  time: 0.3618  data: 0.1300  max mem: 3278
Epoch: [85]  [2100/3494]  eta: 0:08:32  lr: 0.0000000  loss: 0.5505 (0.5793)  bbox_regression: 0.0886 (0.1024)  classification: 0.4415 (0.4769)  time: 0.3543  data: 0.1285  max mem: 3278
Epoch: [85]  [2200/3494]  eta: 0:07:54  lr: 0.0000000  loss: 0.5461 (0.5798)  bbox_regression: 0.0929 (0.1024)  classification: 0.4729 (0.4774)  time: 0.3306  data: 0.1097  max mem: 3278
Epoch: [85]  [2300/3494]  eta: 0:07:17  lr: 0.0000000  loss: 0.5557 (0.5796)  bbox_regression: 0.0978 (0.1023)  classification: 0.4425 (0.4773)  time: 0.3733  data: 0.1473  max mem: 3278
Epoch: [85]  [2400/3494]  eta: 0:06:40  lr: 0.0000000  loss: 0.5548 (0.5801)  bbox_regression: 0.0996 (0.1023)  classification: 0.4513 (0.4778)  time: 0.3566  data: 0.1281  max mem: 3278
Epoch: [85]  [2500/3494]  eta: 0:06:03  lr: 0.0000000  loss: 0.5442 (0.5804)  bbox_regression: 0.0873 (0.1024)  classification: 0.4583 (0.4780)  time: 0.3758  data: 0.1406  max mem: 3278
Epoch: [85]  [2600/3494]  eta: 0:05:27  lr: 0.0000000  loss: 0.5601 (0.5816)  bbox_regression: 0.1067 (0.1027)  classification: 0.4916 (0.4789)  time: 0.3570  data: 0.1277  max mem: 3278
Epoch: [85]  [2700/3494]  eta: 0:04:50  lr: 0.0000000  loss: 0.5282 (0.5818)  bbox_regression: 0.0881 (0.1026)  classification: 0.4234 (0.4792)  time: 0.3653  data: 0.1336  max mem: 3278
Epoch: [85]  [2800/3494]  eta: 0:04:13  lr: 0.0000000  loss: 0.5941 (0.5823)  bbox_regression: 0.1019 (0.1027)  classification: 0.5017 (0.4796)  time: 0.3615  data: 0.1316  max mem: 3278
Epoch: [85]  [2900/3494]  eta: 0:03:36  lr: 0.0000000  loss: 0.5524 (0.5824)  bbox_regression: 0.1012 (0.1028)  classification: 0.4554 (0.4796)  time: 0.3487  data: 0.1210  max mem: 3278
Epoch: [85]  [3000/3494]  eta: 0:03:00  lr: 0.0000000  loss: 0.5803 (0.5825)  bbox_regression: 0.0989 (0.1028)  classification: 0.4915 (0.4797)  time: 0.3611  data: 0.1319  max mem: 3278
Epoch: [85]  [3100/3494]  eta: 0:02:23  lr: 0.0000000  loss: 0.5578 (0.5826)  bbox_regression: 0.0926 (0.1029)  classification: 0.4605 (0.4797)  time: 0.3215  data: 0.1047  max mem: 3278
Epoch: [85]  [3200/3494]  eta: 0:01:47  lr: 0.0000000  loss: 0.5557 (0.5832)  bbox_regression: 0.0932 (0.1030)  classification: 0.4665 (0.4802)  time: 0.3592  data: 0.1287  max mem: 3278
Epoch: [85]  [3300/3494]  eta: 0:01:10  lr: 0.0000000  loss: 0.5617 (0.5828)  bbox_regression: 0.0898 (0.1030)  classification: 0.4581 (0.4799)  time: 0.3544  data: 0.1255  max mem: 3278
Epoch: [85]  [3400/3494]  eta: 0:00:34  lr: 0.0000000  loss: 0.6204 (0.5826)  bbox_regression: 0.1123 (0.1029)  classification: 0.5103 (0.4797)  time: 0.3635  data: 0.1301  max mem: 3278
Epoch: [85]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5410 (0.5831)  bbox_regression: 0.1025 (0.1031)  classification: 0.4282 (0.4801)  time: 0.3418  data: 0.1208  max mem: 3278
Epoch: [85] Total time: 0:21:22 (0.3670 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:12  model_time: 0.1302 (0.1302)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8130  data: 1.6626  max mem: 3278
Validation:  [100/437]  eta: 0:01:31  model_time: 0.1165 (0.1181)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2709  data: 0.1333  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1231 (0.1196)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2609  data: 0.1214  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1167 (0.1209)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2649  data: 0.1264  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1134 (0.1202)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2583  data: 0.1218  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1164 (0.1203)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2586  data: 0.1249  max mem: 3278
Validation: Total time: 0:01:56 (0.2658 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [86]  [   0/3494]  eta: 2:22:10  lr: 0.0000000  loss: 0.7055 (0.7055)  bbox_regression: 0.1118 (0.1118)  classification: 0.5937 (0.5937)  time: 2.4414  data: 2.1929  max mem: 3278
Epoch: [86]  [ 100/3494]  eta: 0:21:36  lr: 0.0000000  loss: 0.5899 (0.5870)  bbox_regression: 0.1093 (0.1050)  classification: 0.4994 (0.4821)  time: 0.3553  data: 0.1247  max mem: 3278
Epoch: [86]  [ 200/3494]  eta: 0:20:21  lr: 0.0000000  loss: 0.5621 (0.5795)  bbox_regression: 0.0841 (0.1030)  classification: 0.4628 (0.4765)  time: 0.3567  data: 0.1281  max mem: 3278
Epoch: [86]  [ 300/3494]  eta: 0:19:33  lr: 0.0000000  loss: 0.5783 (0.5804)  bbox_regression: 0.0954 (0.1032)  classification: 0.4778 (0.4772)  time: 0.3654  data: 0.1297  max mem: 3278
Epoch: [86]  [ 400/3494]  eta: 0:18:48  lr: 0.0000000  loss: 0.5578 (0.5804)  bbox_regression: 0.0883 (0.1040)  classification: 0.4638 (0.4765)  time: 0.3456  data: 0.1168  max mem: 3278
Epoch: [86]  [ 500/3494]  eta: 0:18:12  lr: 0.0000000  loss: 0.5387 (0.5840)  bbox_regression: 0.0952 (0.1043)  classification: 0.4369 (0.4797)  time: 0.3618  data: 0.1320  max mem: 3278
Epoch: [86]  [ 600/3494]  eta: 0:17:33  lr: 0.0000000  loss: 0.5660 (0.5865)  bbox_regression: 0.0910 (0.1052)  classification: 0.4617 (0.4813)  time: 0.3538  data: 0.1262  max mem: 3278
Epoch: [86]  [ 700/3494]  eta: 0:16:53  lr: 0.0000000  loss: 0.6084 (0.5870)  bbox_regression: 0.1029 (0.1047)  classification: 0.4944 (0.4823)  time: 0.3651  data: 0.1320  max mem: 3278
Epoch: [86]  [ 800/3494]  eta: 0:16:14  lr: 0.0000000  loss: 0.5485 (0.5856)  bbox_regression: 0.0877 (0.1042)  classification: 0.4560 (0.4814)  time: 0.3535  data: 0.1267  max mem: 3278
Epoch: [86]  [ 900/3494]  eta: 0:15:37  lr: 0.0000000  loss: 0.5649 (0.5856)  bbox_regression: 0.1018 (0.1039)  classification: 0.4710 (0.4817)  time: 0.3708  data: 0.1295  max mem: 3278
Epoch: [86]  [1000/3494]  eta: 0:15:01  lr: 0.0000000  loss: 0.5765 (0.5837)  bbox_regression: 0.0979 (0.1034)  classification: 0.4765 (0.4803)  time: 0.3648  data: 0.1313  max mem: 3278
Epoch: [86]  [1100/3494]  eta: 0:14:24  lr: 0.0000000  loss: 0.5619 (0.5848)  bbox_regression: 0.0951 (0.1035)  classification: 0.4708 (0.4812)  time: 0.3615  data: 0.1280  max mem: 3278
Epoch: [86]  [1200/3494]  eta: 0:13:48  lr: 0.0000000  loss: 0.5343 (0.5843)  bbox_regression: 0.0855 (0.1034)  classification: 0.4216 (0.4809)  time: 0.3573  data: 0.1301  max mem: 3278
Epoch: [86]  [1300/3494]  eta: 0:13:12  lr: 0.0000000  loss: 0.5952 (0.5829)  bbox_regression: 0.0957 (0.1029)  classification: 0.4834 (0.4800)  time: 0.3591  data: 0.1308  max mem: 3278
Epoch: [86]  [1400/3494]  eta: 0:12:36  lr: 0.0000000  loss: 0.5587 (0.5828)  bbox_regression: 0.1035 (0.1028)  classification: 0.4621 (0.4800)  time: 0.3601  data: 0.1295  max mem: 3278
Epoch: [86]  [1500/3494]  eta: 0:11:59  lr: 0.0000000  loss: 0.5680 (0.5828)  bbox_regression: 0.1021 (0.1028)  classification: 0.4793 (0.4801)  time: 0.3568  data: 0.1267  max mem: 3278
Epoch: [86]  [1600/3494]  eta: 0:11:22  lr: 0.0000000  loss: 0.6022 (0.5841)  bbox_regression: 0.0906 (0.1030)  classification: 0.4881 (0.4812)  time: 0.3280  data: 0.1124  max mem: 3278
Epoch: [86]  [1700/3494]  eta: 0:10:47  lr: 0.0000000  loss: 0.5121 (0.5841)  bbox_regression: 0.0986 (0.1030)  classification: 0.4086 (0.4811)  time: 0.3712  data: 0.1369  max mem: 3278
Epoch: [86]  [1800/3494]  eta: 0:10:10  lr: 0.0000000  loss: 0.5241 (0.5843)  bbox_regression: 0.0810 (0.1031)  classification: 0.4269 (0.4812)  time: 0.3585  data: 0.1288  max mem: 3278
Epoch: [86]  [1900/3494]  eta: 0:09:34  lr: 0.0000000  loss: 0.5513 (0.5833)  bbox_regression: 0.0911 (0.1030)  classification: 0.4648 (0.4804)  time: 0.3706  data: 0.1321  max mem: 3278
Epoch: [86]  [2000/3494]  eta: 0:08:57  lr: 0.0000000  loss: 0.5993 (0.5831)  bbox_regression: 0.1046 (0.1029)  classification: 0.4845 (0.4802)  time: 0.3524  data: 0.1222  max mem: 3278
Epoch: [86]  [2100/3494]  eta: 0:08:21  lr: 0.0000000  loss: 0.5515 (0.5831)  bbox_regression: 0.1027 (0.1031)  classification: 0.4591 (0.4800)  time: 0.3726  data: 0.1335  max mem: 3278
Epoch: [86]  [2200/3494]  eta: 0:07:45  lr: 0.0000000  loss: 0.5379 (0.5828)  bbox_regression: 0.0927 (0.1029)  classification: 0.4393 (0.4799)  time: 0.3645  data: 0.1319  max mem: 3278
Epoch: [86]  [2300/3494]  eta: 0:07:09  lr: 0.0000000  loss: 0.5094 (0.5822)  bbox_regression: 0.0966 (0.1028)  classification: 0.4178 (0.4794)  time: 0.3721  data: 0.1411  max mem: 3278
Epoch: [86]  [2400/3494]  eta: 0:06:33  lr: 0.0000000  loss: 0.5379 (0.5828)  bbox_regression: 0.0955 (0.1029)  classification: 0.4359 (0.4799)  time: 0.3595  data: 0.1305  max mem: 3278
Epoch: [86]  [2500/3494]  eta: 0:05:57  lr: 0.0000000  loss: 0.5784 (0.5826)  bbox_regression: 0.0870 (0.1029)  classification: 0.4662 (0.4796)  time: 0.3273  data: 0.1092  max mem: 3278
Epoch: [86]  [2600/3494]  eta: 0:05:21  lr: 0.0000000  loss: 0.6000 (0.5825)  bbox_regression: 0.1029 (0.1030)  classification: 0.4973 (0.4796)  time: 0.3528  data: 0.1258  max mem: 3278
Epoch: [86]  [2700/3494]  eta: 0:04:45  lr: 0.0000000  loss: 0.5437 (0.5820)  bbox_regression: 0.0912 (0.1030)  classification: 0.4471 (0.4791)  time: 0.3428  data: 0.1211  max mem: 3278
Epoch: [86]  [2800/3494]  eta: 0:04:09  lr: 0.0000000  loss: 0.5553 (0.5818)  bbox_regression: 0.1042 (0.1029)  classification: 0.4668 (0.4789)  time: 0.3651  data: 0.1342  max mem: 3278
Epoch: [86]  [2900/3494]  eta: 0:03:33  lr: 0.0000000  loss: 0.5250 (0.5815)  bbox_regression: 0.0885 (0.1028)  classification: 0.4266 (0.4787)  time: 0.3558  data: 0.1260  max mem: 3278
Epoch: [86]  [3000/3494]  eta: 0:02:57  lr: 0.0000000  loss: 0.5722 (0.5816)  bbox_regression: 0.0853 (0.1028)  classification: 0.4877 (0.4789)  time: 0.3578  data: 0.1262  max mem: 3278
Epoch: [86]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5984 (0.5817)  bbox_regression: 0.0993 (0.1028)  classification: 0.4680 (0.4789)  time: 0.3488  data: 0.1242  max mem: 3278
Epoch: [86]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5696 (0.5819)  bbox_regression: 0.1035 (0.1028)  classification: 0.4685 (0.4790)  time: 0.3599  data: 0.1279  max mem: 3278
Epoch: [86]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5630 (0.5824)  bbox_regression: 0.0934 (0.1031)  classification: 0.4772 (0.4793)  time: 0.3512  data: 0.1251  max mem: 3278
Epoch: [86]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5916 (0.5826)  bbox_regression: 0.0837 (0.1032)  classification: 0.5050 (0.4794)  time: 0.3644  data: 0.1269  max mem: 3278
Epoch: [86]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5396 (0.5826)  bbox_regression: 0.0860 (0.1031)  classification: 0.4384 (0.4795)  time: 0.3470  data: 0.1259  max mem: 3278
Epoch: [86] Total time: 0:21:04 (0.3620 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:15  model_time: 0.1547 (0.1547)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9570  data: 1.7784  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1168 (0.1214)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2645  data: 0.1258  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1135 (0.1213)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2294  data: 0.1037  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1158 (0.1206)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2553  data: 0.1203  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1180 (0.1208)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2693  data: 0.1289  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1223 (0.1209)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2629  data: 0.1244  max mem: 3278
Validation: Total time: 0:01:56 (0.2671 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [87]  [   0/3494]  eta: 1:50:19  lr: 0.0000000  loss: 0.8576 (0.8576)  bbox_regression: 0.1150 (0.1150)  classification: 0.7426 (0.7426)  time: 1.8945  data: 1.6508  max mem: 3278
Epoch: [87]  [ 100/3494]  eta: 0:20:49  lr: 0.0000000  loss: 0.5997 (0.5914)  bbox_regression: 0.0985 (0.1008)  classification: 0.4938 (0.4906)  time: 0.3549  data: 0.1315  max mem: 3278
Epoch: [87]  [ 200/3494]  eta: 0:19:54  lr: 0.0000000  loss: 0.5651 (0.5901)  bbox_regression: 0.0950 (0.1044)  classification: 0.4652 (0.4857)  time: 0.3626  data: 0.1358  max mem: 3278
Epoch: [87]  [ 300/3494]  eta: 0:19:07  lr: 0.0000000  loss: 0.5170 (0.5780)  bbox_regression: 0.0890 (0.1017)  classification: 0.4185 (0.4764)  time: 0.3594  data: 0.1313  max mem: 3278
Epoch: [87]  [ 400/3494]  eta: 0:18:35  lr: 0.0000000  loss: 0.5935 (0.5809)  bbox_regression: 0.1007 (0.1020)  classification: 0.4745 (0.4789)  time: 0.3592  data: 0.1282  max mem: 3278
Epoch: [87]  [ 500/3494]  eta: 0:17:54  lr: 0.0000000  loss: 0.5677 (0.5803)  bbox_regression: 0.0856 (0.1018)  classification: 0.4601 (0.4785)  time: 0.3339  data: 0.1167  max mem: 3278
Epoch: [87]  [ 600/3494]  eta: 0:17:19  lr: 0.0000000  loss: 0.5462 (0.5805)  bbox_regression: 0.0919 (0.1020)  classification: 0.4674 (0.4785)  time: 0.3594  data: 0.1255  max mem: 3278
Epoch: [87]  [ 700/3494]  eta: 0:16:42  lr: 0.0000000  loss: 0.5608 (0.5814)  bbox_regression: 0.0944 (0.1024)  classification: 0.4605 (0.4790)  time: 0.3524  data: 0.1247  max mem: 3278
Epoch: [87]  [ 800/3494]  eta: 0:16:03  lr: 0.0000000  loss: 0.6293 (0.5832)  bbox_regression: 0.1001 (0.1028)  classification: 0.5247 (0.4804)  time: 0.3606  data: 0.1319  max mem: 3278
Epoch: [87]  [ 900/3494]  eta: 0:15:29  lr: 0.0000000  loss: 0.6032 (0.5842)  bbox_regression: 0.1021 (0.1033)  classification: 0.5016 (0.4809)  time: 0.3529  data: 0.1267  max mem: 3278
Epoch: [87]  [1000/3494]  eta: 0:14:53  lr: 0.0000000  loss: 0.5669 (0.5833)  bbox_regression: 0.0930 (0.1034)  classification: 0.4739 (0.4798)  time: 0.3637  data: 0.1310  max mem: 3278
Epoch: [87]  [1100/3494]  eta: 0:14:17  lr: 0.0000000  loss: 0.5527 (0.5849)  bbox_regression: 0.1036 (0.1040)  classification: 0.4442 (0.4808)  time: 0.3606  data: 0.1317  max mem: 3278
Epoch: [87]  [1200/3494]  eta: 0:13:42  lr: 0.0000000  loss: 0.5531 (0.5840)  bbox_regression: 0.0980 (0.1041)  classification: 0.4755 (0.4800)  time: 0.3459  data: 0.1248  max mem: 3278
Epoch: [87]  [1300/3494]  eta: 0:13:07  lr: 0.0000000  loss: 0.5244 (0.5832)  bbox_regression: 0.0957 (0.1037)  classification: 0.4235 (0.4796)  time: 0.3611  data: 0.1335  max mem: 3278
Epoch: [87]  [1400/3494]  eta: 0:12:31  lr: 0.0000000  loss: 0.5917 (0.5819)  bbox_regression: 0.0954 (0.1034)  classification: 0.4744 (0.4785)  time: 0.3610  data: 0.1281  max mem: 3278
Epoch: [87]  [1500/3494]  eta: 0:11:54  lr: 0.0000000  loss: 0.5745 (0.5820)  bbox_regression: 0.1050 (0.1033)  classification: 0.4562 (0.4787)  time: 0.3575  data: 0.1277  max mem: 3278
Epoch: [87]  [1600/3494]  eta: 0:11:19  lr: 0.0000000  loss: 0.5348 (0.5827)  bbox_regression: 0.1005 (0.1034)  classification: 0.4661 (0.4793)  time: 0.3588  data: 0.1277  max mem: 3278
Epoch: [87]  [1700/3494]  eta: 0:10:43  lr: 0.0000000  loss: 0.5946 (0.5833)  bbox_regression: 0.1003 (0.1036)  classification: 0.4858 (0.4797)  time: 0.3559  data: 0.1278  max mem: 3278
Epoch: [87]  [1800/3494]  eta: 0:10:06  lr: 0.0000000  loss: 0.6010 (0.5818)  bbox_regression: 0.1043 (0.1034)  classification: 0.4930 (0.4784)  time: 0.3442  data: 0.1207  max mem: 3278
Epoch: [87]  [1900/3494]  eta: 0:09:29  lr: 0.0000000  loss: 0.5902 (0.5830)  bbox_regression: 0.0892 (0.1035)  classification: 0.4786 (0.4795)  time: 0.3116  data: 0.1050  max mem: 3278
Epoch: [87]  [2000/3494]  eta: 0:08:54  lr: 0.0000000  loss: 0.5465 (0.5837)  bbox_regression: 0.0982 (0.1036)  classification: 0.4536 (0.4801)  time: 0.3653  data: 0.1302  max mem: 3278
Epoch: [87]  [2100/3494]  eta: 0:08:19  lr: 0.0000000  loss: 0.5974 (0.5837)  bbox_regression: 0.1077 (0.1037)  classification: 0.4811 (0.4800)  time: 0.3606  data: 0.1282  max mem: 3278
Epoch: [87]  [2200/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.5430 (0.5833)  bbox_regression: 0.0998 (0.1035)  classification: 0.4462 (0.4798)  time: 0.3705  data: 0.1366  max mem: 3278
Epoch: [87]  [2300/3494]  eta: 0:07:08  lr: 0.0000000  loss: 0.5951 (0.5838)  bbox_regression: 0.0950 (0.1034)  classification: 0.5023 (0.4804)  time: 0.3676  data: 0.1350  max mem: 3278
Epoch: [87]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5730 (0.5833)  bbox_regression: 0.0945 (0.1033)  classification: 0.4650 (0.4800)  time: 0.3521  data: 0.1284  max mem: 3278
Epoch: [87]  [2500/3494]  eta: 0:05:56  lr: 0.0000000  loss: 0.6016 (0.5832)  bbox_regression: 0.1029 (0.1034)  classification: 0.4953 (0.4798)  time: 0.3746  data: 0.1343  max mem: 3278
Epoch: [87]  [2600/3494]  eta: 0:05:20  lr: 0.0000000  loss: 0.5255 (0.5832)  bbox_regression: 0.0884 (0.1033)  classification: 0.4551 (0.4799)  time: 0.3302  data: 0.1135  max mem: 3278
Epoch: [87]  [2700/3494]  eta: 0:04:44  lr: 0.0000000  loss: 0.5625 (0.5831)  bbox_regression: 0.0934 (0.1032)  classification: 0.4765 (0.4799)  time: 0.3687  data: 0.1363  max mem: 3278
Epoch: [87]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5186 (0.5828)  bbox_regression: 0.0980 (0.1033)  classification: 0.4245 (0.4795)  time: 0.3552  data: 0.1282  max mem: 3278
Epoch: [87]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5625 (0.5836)  bbox_regression: 0.0990 (0.1033)  classification: 0.4837 (0.4803)  time: 0.3510  data: 0.1289  max mem: 3278
Epoch: [87]  [3000/3494]  eta: 0:02:57  lr: 0.0000000  loss: 0.6079 (0.5842)  bbox_regression: 0.1083 (0.1034)  classification: 0.4905 (0.4808)  time: 0.3611  data: 0.1337  max mem: 3278
Epoch: [87]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5705 (0.5839)  bbox_regression: 0.0887 (0.1034)  classification: 0.4622 (0.4806)  time: 0.3616  data: 0.1301  max mem: 3278
Epoch: [87]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5819 (0.5838)  bbox_regression: 0.0815 (0.1033)  classification: 0.4949 (0.4805)  time: 0.3570  data: 0.1270  max mem: 3278
Epoch: [87]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5671 (0.5836)  bbox_regression: 0.1041 (0.1032)  classification: 0.4878 (0.4804)  time: 0.3618  data: 0.1285  max mem: 3278
Epoch: [87]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5383 (0.5832)  bbox_regression: 0.0988 (0.1032)  classification: 0.4434 (0.4800)  time: 0.3642  data: 0.1323  max mem: 3278
Epoch: [87]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5870 (0.5834)  bbox_regression: 0.0997 (0.1033)  classification: 0.4746 (0.4802)  time: 0.3526  data: 0.1284  max mem: 3278
Epoch: [87] Total time: 0:21:03 (0.3615 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:53  model_time: 0.1267 (0.1267)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.7708  data: 1.6155  max mem: 3278
Validation:  [100/437]  eta: 0:01:26  model_time: 0.1138 (0.1131)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2547  data: 0.1202  max mem: 3278
Validation:  [200/437]  eta: 0:01:01  model_time: 0.1133 (0.1163)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2579  data: 0.1211  max mem: 3278
Validation:  [300/437]  eta: 0:00:35  model_time: 0.1171 (0.1179)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2603  data: 0.1223  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1141 (0.1165)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2563  data: 0.1218  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1134 (0.1165)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2533  data: 0.1196  max mem: 3278
Validation: Total time: 0:01:51 (0.2545 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [88]  [   0/3494]  eta: 2:17:27  lr: 0.0000000  loss: 0.6898 (0.6898)  bbox_regression: 0.1408 (0.1408)  classification: 0.5490 (0.5490)  time: 2.3606  data: 2.1180  max mem: 3278
Epoch: [88]  [ 100/3494]  eta: 0:21:40  lr: 0.0000000  loss: 0.5987 (0.5846)  bbox_regression: 0.1011 (0.1063)  classification: 0.4882 (0.4784)  time: 0.3491  data: 0.1242  max mem: 3278
Epoch: [88]  [ 200/3494]  eta: 0:19:56  lr: 0.0000000  loss: 0.5858 (0.5865)  bbox_regression: 0.0879 (0.1028)  classification: 0.4940 (0.4837)  time: 0.3537  data: 0.1271  max mem: 3278
Epoch: [88]  [ 300/3494]  eta: 0:19:25  lr: 0.0000000  loss: 0.6254 (0.5883)  bbox_regression: 0.1027 (0.1037)  classification: 0.5000 (0.4846)  time: 0.3606  data: 0.1277  max mem: 3278
Epoch: [88]  [ 400/3494]  eta: 0:18:40  lr: 0.0000000  loss: 0.5212 (0.5857)  bbox_regression: 0.0941 (0.1026)  classification: 0.4327 (0.4831)  time: 0.3459  data: 0.1193  max mem: 3278
Epoch: [88]  [ 500/3494]  eta: 0:18:00  lr: 0.0000000  loss: 0.5903 (0.5865)  bbox_regression: 0.0982 (0.1025)  classification: 0.4823 (0.4840)  time: 0.3604  data: 0.1307  max mem: 3278
Epoch: [88]  [ 600/3494]  eta: 0:17:22  lr: 0.0000000  loss: 0.5837 (0.5875)  bbox_regression: 0.0964 (0.1033)  classification: 0.5028 (0.4841)  time: 0.3530  data: 0.1253  max mem: 3278
Epoch: [88]  [ 700/3494]  eta: 0:16:44  lr: 0.0000000  loss: 0.5335 (0.5865)  bbox_regression: 0.0855 (0.1029)  classification: 0.4444 (0.4836)  time: 0.3630  data: 0.1308  max mem: 3278
Epoch: [88]  [ 800/3494]  eta: 0:16:08  lr: 0.0000000  loss: 0.5884 (0.5867)  bbox_regression: 0.0989 (0.1035)  classification: 0.4730 (0.4833)  time: 0.3511  data: 0.1283  max mem: 3278
Epoch: [88]  [ 900/3494]  eta: 0:15:30  lr: 0.0000000  loss: 0.5430 (0.5857)  bbox_regression: 0.0781 (0.1033)  classification: 0.4686 (0.4824)  time: 0.3533  data: 0.1259  max mem: 3278
Epoch: [88]  [1000/3494]  eta: 0:14:54  lr: 0.0000000  loss: 0.5597 (0.5859)  bbox_regression: 0.1007 (0.1033)  classification: 0.4622 (0.4825)  time: 0.3472  data: 0.1205  max mem: 3278
Epoch: [88]  [1100/3494]  eta: 0:14:19  lr: 0.0000000  loss: 0.6085 (0.5855)  bbox_regression: 0.1104 (0.1036)  classification: 0.5047 (0.4819)  time: 0.3632  data: 0.1327  max mem: 3278
Epoch: [88]  [1200/3494]  eta: 0:13:42  lr: 0.0000000  loss: 0.6014 (0.5875)  bbox_regression: 0.1035 (0.1039)  classification: 0.4733 (0.4836)  time: 0.3559  data: 0.1236  max mem: 3278
Epoch: [88]  [1300/3494]  eta: 0:13:06  lr: 0.0000000  loss: 0.5554 (0.5870)  bbox_regression: 0.0950 (0.1040)  classification: 0.4513 (0.4830)  time: 0.3575  data: 0.1303  max mem: 3278
Epoch: [88]  [1400/3494]  eta: 0:12:30  lr: 0.0000000  loss: 0.5282 (0.5869)  bbox_regression: 0.0902 (0.1042)  classification: 0.4381 (0.4827)  time: 0.3622  data: 0.1298  max mem: 3278
Epoch: [88]  [1500/3494]  eta: 0:11:54  lr: 0.0000000  loss: 0.5517 (0.5863)  bbox_regression: 0.0985 (0.1041)  classification: 0.4543 (0.4822)  time: 0.3500  data: 0.1242  max mem: 3278
Epoch: [88]  [1600/3494]  eta: 0:11:18  lr: 0.0000000  loss: 0.6115 (0.5867)  bbox_regression: 0.1085 (0.1044)  classification: 0.5248 (0.4823)  time: 0.3695  data: 0.1390  max mem: 3278
Epoch: [88]  [1700/3494]  eta: 0:10:42  lr: 0.0000000  loss: 0.5702 (0.5858)  bbox_regression: 0.1023 (0.1044)  classification: 0.4679 (0.4814)  time: 0.3662  data: 0.1352  max mem: 3278
Epoch: [88]  [1800/3494]  eta: 0:10:06  lr: 0.0000000  loss: 0.5551 (0.5855)  bbox_regression: 0.0952 (0.1042)  classification: 0.4681 (0.4813)  time: 0.3656  data: 0.1378  max mem: 3278
Epoch: [88]  [1900/3494]  eta: 0:09:30  lr: 0.0000000  loss: 0.5613 (0.5856)  bbox_regression: 0.1017 (0.1041)  classification: 0.4489 (0.4815)  time: 0.3629  data: 0.1348  max mem: 3278
Epoch: [88]  [2000/3494]  eta: 0:08:54  lr: 0.0000000  loss: 0.5899 (0.5851)  bbox_regression: 0.0964 (0.1040)  classification: 0.4934 (0.4810)  time: 0.3595  data: 0.1272  max mem: 3278
Epoch: [88]  [2100/3494]  eta: 0:08:19  lr: 0.0000000  loss: 0.5817 (0.5852)  bbox_regression: 0.1043 (0.1040)  classification: 0.4901 (0.4812)  time: 0.3660  data: 0.1324  max mem: 3278
Epoch: [88]  [2200/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.6028 (0.5852)  bbox_regression: 0.1058 (0.1040)  classification: 0.5050 (0.4812)  time: 0.3577  data: 0.1275  max mem: 3278
Epoch: [88]  [2300/3494]  eta: 0:07:07  lr: 0.0000000  loss: 0.5880 (0.5858)  bbox_regression: 0.0998 (0.1040)  classification: 0.4796 (0.4818)  time: 0.3641  data: 0.1262  max mem: 3278
Epoch: [88]  [2400/3494]  eta: 0:06:32  lr: 0.0000000  loss: 0.5370 (0.5851)  bbox_regression: 0.1002 (0.1038)  classification: 0.4285 (0.4812)  time: 0.3529  data: 0.1302  max mem: 3278
Epoch: [88]  [2500/3494]  eta: 0:05:56  lr: 0.0000000  loss: 0.5616 (0.5847)  bbox_regression: 0.0915 (0.1036)  classification: 0.4747 (0.4811)  time: 0.3563  data: 0.1256  max mem: 3278
Epoch: [88]  [2600/3494]  eta: 0:05:20  lr: 0.0000000  loss: 0.5924 (0.5846)  bbox_regression: 0.1071 (0.1036)  classification: 0.4698 (0.4810)  time: 0.3667  data: 0.1346  max mem: 3278
Epoch: [88]  [2700/3494]  eta: 0:04:44  lr: 0.0000000  loss: 0.5681 (0.5841)  bbox_regression: 0.0927 (0.1035)  classification: 0.4755 (0.4806)  time: 0.3617  data: 0.1307  max mem: 3278
Epoch: [88]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5619 (0.5844)  bbox_regression: 0.1013 (0.1035)  classification: 0.4500 (0.4810)  time: 0.3483  data: 0.1235  max mem: 3278
Epoch: [88]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5532 (0.5835)  bbox_regression: 0.0872 (0.1033)  classification: 0.4673 (0.4802)  time: 0.3718  data: 0.1332  max mem: 3278
Epoch: [88]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5628 (0.5832)  bbox_regression: 0.0959 (0.1032)  classification: 0.4525 (0.4800)  time: 0.3526  data: 0.1242  max mem: 3278
Epoch: [88]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5335 (0.5831)  bbox_regression: 0.0937 (0.1031)  classification: 0.4459 (0.4800)  time: 0.3597  data: 0.1293  max mem: 3278
Epoch: [88]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5905 (0.5834)  bbox_regression: 0.0972 (0.1033)  classification: 0.5012 (0.4802)  time: 0.3493  data: 0.1249  max mem: 3278
Epoch: [88]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.6157 (0.5836)  bbox_regression: 0.0984 (0.1033)  classification: 0.5124 (0.4803)  time: 0.3805  data: 0.1398  max mem: 3278
Epoch: [88]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5367 (0.5832)  bbox_regression: 0.0990 (0.1032)  classification: 0.4292 (0.4800)  time: 0.3606  data: 0.1306  max mem: 3278
Epoch: [88]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5627 (0.5833)  bbox_regression: 0.0959 (0.1032)  classification: 0.4619 (0.4801)  time: 0.3411  data: 0.1229  max mem: 3278
Epoch: [88] Total time: 0:21:01 (0.3610 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:38  model_time: 0.1375 (0.1375)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.1475  data: 1.9730  max mem: 3278
Validation:  [100/437]  eta: 0:01:34  model_time: 0.1232 (0.1202)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2643  data: 0.1236  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1235 (0.1218)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2640  data: 0.1230  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1230 (0.1211)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2705  data: 0.1300  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1277 (0.1219)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2720  data: 0.1274  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1135 (0.1216)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2535  data: 0.1210  max mem: 3278
Validation: Total time: 0:01:57 (0.2685 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [89]  [   0/3494]  eta: 2:14:32  lr: 0.0000000  loss: 0.4860 (0.4860)  bbox_regression: 0.0898 (0.0898)  classification: 0.3962 (0.3962)  time: 2.3105  data: 2.0522  max mem: 3278
Epoch: [89]  [ 100/3494]  eta: 0:21:04  lr: 0.0000000  loss: 0.5736 (0.5741)  bbox_regression: 0.0989 (0.1014)  classification: 0.4807 (0.4727)  time: 0.3276  data: 0.1111  max mem: 3278
Epoch: [89]  [ 200/3494]  eta: 0:20:03  lr: 0.0000000  loss: 0.5962 (0.5804)  bbox_regression: 0.0989 (0.1011)  classification: 0.4905 (0.4793)  time: 0.3610  data: 0.1268  max mem: 3278
Epoch: [89]  [ 300/3494]  eta: 0:19:19  lr: 0.0000000  loss: 0.5603 (0.5851)  bbox_regression: 0.0817 (0.1032)  classification: 0.4563 (0.4819)  time: 0.3686  data: 0.1358  max mem: 3278
Epoch: [89]  [ 400/3494]  eta: 0:18:35  lr: 0.0000000  loss: 0.5510 (0.5832)  bbox_regression: 0.0972 (0.1029)  classification: 0.4539 (0.4803)  time: 0.3537  data: 0.1260  max mem: 3278
Epoch: [89]  [ 500/3494]  eta: 0:17:57  lr: 0.0000000  loss: 0.6225 (0.5839)  bbox_regression: 0.0964 (0.1031)  classification: 0.5236 (0.4808)  time: 0.3543  data: 0.1289  max mem: 3278
Epoch: [89]  [ 600/3494]  eta: 0:17:18  lr: 0.0000000  loss: 0.5387 (0.5851)  bbox_regression: 0.0946 (0.1039)  classification: 0.4586 (0.4811)  time: 0.3642  data: 0.1324  max mem: 3278
Epoch: [89]  [ 700/3494]  eta: 0:16:43  lr: 0.0000000  loss: 0.5420 (0.5834)  bbox_regression: 0.0902 (0.1034)  classification: 0.4475 (0.4800)  time: 0.3627  data: 0.1277  max mem: 3278
Epoch: [89]  [ 800/3494]  eta: 0:16:05  lr: 0.0000000  loss: 0.5406 (0.5811)  bbox_regression: 0.1010 (0.1033)  classification: 0.4599 (0.4778)  time: 0.3300  data: 0.1106  max mem: 3278
Epoch: [89]  [ 900/3494]  eta: 0:15:30  lr: 0.0000000  loss: 0.5264 (0.5796)  bbox_regression: 0.0741 (0.1026)  classification: 0.4422 (0.4770)  time: 0.3607  data: 0.1309  max mem: 3278
Epoch: [89]  [1000/3494]  eta: 0:14:53  lr: 0.0000000  loss: 0.5585 (0.5778)  bbox_regression: 0.0806 (0.1020)  classification: 0.4564 (0.4758)  time: 0.3518  data: 0.1223  max mem: 3278
Epoch: [89]  [1100/3494]  eta: 0:14:16  lr: 0.0000000  loss: 0.5165 (0.5793)  bbox_regression: 0.0925 (0.1024)  classification: 0.4199 (0.4769)  time: 0.3509  data: 0.1229  max mem: 3278
Epoch: [89]  [1200/3494]  eta: 0:13:42  lr: 0.0000000  loss: 0.5214 (0.5778)  bbox_regression: 0.0963 (0.1022)  classification: 0.4305 (0.4756)  time: 0.3686  data: 0.1314  max mem: 3278
Epoch: [89]  [1300/3494]  eta: 0:13:05  lr: 0.0000000  loss: 0.6313 (0.5786)  bbox_regression: 0.1154 (0.1024)  classification: 0.5030 (0.4762)  time: 0.3453  data: 0.1228  max mem: 3278
Epoch: [89]  [1400/3494]  eta: 0:12:29  lr: 0.0000000  loss: 0.5276 (0.5779)  bbox_regression: 0.0806 (0.1024)  classification: 0.4259 (0.4755)  time: 0.3577  data: 0.1272  max mem: 3278
Epoch: [89]  [1500/3494]  eta: 0:11:53  lr: 0.0000000  loss: 0.5527 (0.5786)  bbox_regression: 0.0958 (0.1026)  classification: 0.4693 (0.4760)  time: 0.3254  data: 0.1122  max mem: 3278
Epoch: [89]  [1600/3494]  eta: 0:11:17  lr: 0.0000000  loss: 0.5612 (0.5788)  bbox_regression: 0.0941 (0.1027)  classification: 0.4574 (0.4761)  time: 0.3506  data: 0.1239  max mem: 3278
Epoch: [89]  [1700/3494]  eta: 0:10:42  lr: 0.0000000  loss: 0.5631 (0.5785)  bbox_regression: 0.0899 (0.1027)  classification: 0.4679 (0.4759)  time: 0.3605  data: 0.1284  max mem: 3278
Epoch: [89]  [1800/3494]  eta: 0:10:05  lr: 0.0000000  loss: 0.5717 (0.5793)  bbox_regression: 0.0894 (0.1027)  classification: 0.4757 (0.4766)  time: 0.3674  data: 0.1344  max mem: 3278
Epoch: [89]  [1900/3494]  eta: 0:09:30  lr: 0.0000000  loss: 0.5574 (0.5787)  bbox_regression: 0.0938 (0.1026)  classification: 0.4589 (0.4761)  time: 0.3639  data: 0.1344  max mem: 3278
Epoch: [89]  [2000/3494]  eta: 0:08:54  lr: 0.0000000  loss: 0.5733 (0.5786)  bbox_regression: 0.0987 (0.1028)  classification: 0.4734 (0.4758)  time: 0.3602  data: 0.1274  max mem: 3278
Epoch: [89]  [2100/3494]  eta: 0:08:19  lr: 0.0000000  loss: 0.5570 (0.5789)  bbox_regression: 0.0959 (0.1029)  classification: 0.4636 (0.4760)  time: 0.3744  data: 0.1389  max mem: 3278
Epoch: [89]  [2200/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.5359 (0.5790)  bbox_regression: 0.0829 (0.1028)  classification: 0.4470 (0.4762)  time: 0.3396  data: 0.1142  max mem: 3278
Epoch: [89]  [2300/3494]  eta: 0:07:07  lr: 0.0000000  loss: 0.5491 (0.5797)  bbox_regression: 0.1056 (0.1029)  classification: 0.4402 (0.4768)  time: 0.3537  data: 0.1245  max mem: 3278
Epoch: [89]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5574 (0.5798)  bbox_regression: 0.0930 (0.1028)  classification: 0.4495 (0.4770)  time: 0.3518  data: 0.1252  max mem: 3278
Epoch: [89]  [2500/3494]  eta: 0:05:55  lr: 0.0000000  loss: 0.5903 (0.5811)  bbox_regression: 0.1032 (0.1031)  classification: 0.4603 (0.4781)  time: 0.3620  data: 0.1314  max mem: 3278
Epoch: [89]  [2600/3494]  eta: 0:05:19  lr: 0.0000000  loss: 0.5351 (0.5804)  bbox_regression: 0.0915 (0.1030)  classification: 0.4419 (0.4774)  time: 0.3606  data: 0.1334  max mem: 3278
Epoch: [89]  [2700/3494]  eta: 0:04:44  lr: 0.0000000  loss: 0.5791 (0.5803)  bbox_regression: 0.1026 (0.1029)  classification: 0.4774 (0.4774)  time: 0.3669  data: 0.1305  max mem: 3278
Epoch: [89]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5816 (0.5811)  bbox_regression: 0.1007 (0.1029)  classification: 0.4829 (0.4783)  time: 0.3551  data: 0.1272  max mem: 3278
Epoch: [89]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5704 (0.5814)  bbox_regression: 0.0990 (0.1029)  classification: 0.4623 (0.4785)  time: 0.3550  data: 0.1230  max mem: 3278
Epoch: [89]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5617 (0.5820)  bbox_regression: 0.0895 (0.1029)  classification: 0.4759 (0.4791)  time: 0.3666  data: 0.1331  max mem: 3278
Epoch: [89]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5651 (0.5820)  bbox_regression: 0.0873 (0.1029)  classification: 0.4673 (0.4790)  time: 0.3528  data: 0.1245  max mem: 3278
Epoch: [89]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5516 (0.5824)  bbox_regression: 0.0978 (0.1030)  classification: 0.4611 (0.4794)  time: 0.3561  data: 0.1240  max mem: 3278
Epoch: [89]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5885 (0.5828)  bbox_regression: 0.1047 (0.1031)  classification: 0.4542 (0.4797)  time: 0.3571  data: 0.1283  max mem: 3278
Epoch: [89]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5709 (0.5829)  bbox_regression: 0.0941 (0.1032)  classification: 0.4676 (0.4798)  time: 0.3577  data: 0.1291  max mem: 3278
Epoch: [89]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5588 (0.5834)  bbox_regression: 0.0907 (0.1031)  classification: 0.4579 (0.4803)  time: 0.3620  data: 0.1352  max mem: 3278
Epoch: [89] Total time: 0:21:01 (0.3609 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:17  model_time: 0.1375 (0.1375)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8261  data: 1.6654  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1204 (0.1220)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2626  data: 0.1225  max mem: 3278
Validation:  [200/437]  eta: 0:01:02  model_time: 0.1126 (0.1187)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2489  data: 0.1181  max mem: 3278
Validation:  [300/437]  eta: 0:00:35  model_time: 0.1230 (0.1188)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2689  data: 0.1258  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1210 (0.1197)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2764  data: 0.1323  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1152 (0.1192)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2212  data: 0.0971  max mem: 3278
Validation: Total time: 0:01:54 (0.2620 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [90]  [   0/3494]  eta: 2:05:04  lr: 0.0000000  loss: 0.5290 (0.5290)  bbox_regression: 0.0905 (0.0905)  classification: 0.4385 (0.4385)  time: 2.1478  data: 1.8449  max mem: 3278
Epoch: [90]  [ 100/3494]  eta: 0:21:19  lr: 0.0000000  loss: 0.4948 (0.5917)  bbox_regression: 0.1049 (0.1043)  classification: 0.4062 (0.4875)  time: 0.3569  data: 0.1288  max mem: 3278
Epoch: [90]  [ 200/3494]  eta: 0:19:56  lr: 0.0000000  loss: 0.5866 (0.5806)  bbox_regression: 0.0851 (0.1025)  classification: 0.4652 (0.4781)  time: 0.3566  data: 0.1298  max mem: 3278
Epoch: [90]  [ 300/3494]  eta: 0:19:09  lr: 0.0000000  loss: 0.5966 (0.5832)  bbox_regression: 0.1047 (0.1022)  classification: 0.5012 (0.4810)  time: 0.3568  data: 0.1293  max mem: 3278
Epoch: [90]  [ 400/3494]  eta: 0:18:31  lr: 0.0000000  loss: 0.5704 (0.5852)  bbox_regression: 0.0966 (0.1019)  classification: 0.4718 (0.4833)  time: 0.3509  data: 0.1228  max mem: 3278
Epoch: [90]  [ 500/3494]  eta: 0:17:55  lr: 0.0000000  loss: 0.6199 (0.5855)  bbox_regression: 0.1148 (0.1017)  classification: 0.5016 (0.4838)  time: 0.3791  data: 0.1443  max mem: 3278
Epoch: [90]  [ 600/3494]  eta: 0:17:29  lr: 0.0000000  loss: 0.5544 (0.5866)  bbox_regression: 0.0971 (0.1020)  classification: 0.4436 (0.4846)  time: 0.3996  data: 0.1548  max mem: 3278
Epoch: [90]  [ 700/3494]  eta: 0:16:55  lr: 0.0000000  loss: 0.5242 (0.5867)  bbox_regression: 0.0915 (0.1025)  classification: 0.4401 (0.4842)  time: 0.3668  data: 0.1315  max mem: 3278
Epoch: [90]  [ 800/3494]  eta: 0:16:20  lr: 0.0000000  loss: 0.5771 (0.5880)  bbox_regression: 0.1020 (0.1027)  classification: 0.4725 (0.4853)  time: 0.3807  data: 0.1359  max mem: 3278
Epoch: [90]  [ 900/3494]  eta: 0:15:45  lr: 0.0000000  loss: 0.5479 (0.5876)  bbox_regression: 0.1062 (0.1031)  classification: 0.4652 (0.4845)  time: 0.3644  data: 0.1352  max mem: 3278
Epoch: [90]  [1000/3494]  eta: 0:15:07  lr: 0.0000000  loss: 0.5746 (0.5881)  bbox_regression: 0.0885 (0.1033)  classification: 0.4797 (0.4848)  time: 0.3556  data: 0.1272  max mem: 3278
Epoch: [90]  [1100/3494]  eta: 0:14:32  lr: 0.0000000  loss: 0.5832 (0.5875)  bbox_regression: 0.0960 (0.1032)  classification: 0.4850 (0.4843)  time: 0.3933  data: 0.1579  max mem: 3278
Epoch: [90]  [1200/3494]  eta: 0:13:54  lr: 0.0000000  loss: 0.5604 (0.5881)  bbox_regression: 0.0935 (0.1035)  classification: 0.4629 (0.4845)  time: 0.3687  data: 0.1373  max mem: 3278
Epoch: [90]  [1300/3494]  eta: 0:13:17  lr: 0.0000000  loss: 0.5941 (0.5877)  bbox_regression: 0.0979 (0.1036)  classification: 0.4832 (0.4841)  time: 0.3601  data: 0.1288  max mem: 3278
Epoch: [90]  [1400/3494]  eta: 0:12:39  lr: 0.0000000  loss: 0.5453 (0.5876)  bbox_regression: 0.0865 (0.1036)  classification: 0.4425 (0.4840)  time: 0.3588  data: 0.1307  max mem: 3278
Epoch: [90]  [1500/3494]  eta: 0:12:02  lr: 0.0000000  loss: 0.5347 (0.5870)  bbox_regression: 0.0995 (0.1038)  classification: 0.4488 (0.4832)  time: 0.3725  data: 0.1407  max mem: 3278
Epoch: [90]  [1600/3494]  eta: 0:11:26  lr: 0.0000000  loss: 0.5803 (0.5872)  bbox_regression: 0.1026 (0.1038)  classification: 0.4862 (0.4834)  time: 0.3837  data: 0.1497  max mem: 3278
Epoch: [90]  [1700/3494]  eta: 0:10:49  lr: 0.0000000  loss: 0.5759 (0.5867)  bbox_regression: 0.0973 (0.1038)  classification: 0.4845 (0.4829)  time: 0.3547  data: 0.1259  max mem: 3278
Epoch: [90]  [1800/3494]  eta: 0:10:12  lr: 0.0000000  loss: 0.5310 (0.5866)  bbox_regression: 0.0916 (0.1037)  classification: 0.4423 (0.4829)  time: 0.3456  data: 0.1231  max mem: 3278
Epoch: [90]  [1900/3494]  eta: 0:09:36  lr: 0.0000000  loss: 0.5926 (0.5862)  bbox_regression: 0.1011 (0.1036)  classification: 0.4837 (0.4826)  time: 0.3598  data: 0.1271  max mem: 3278
Epoch: [90]  [2000/3494]  eta: 0:08:59  lr: 0.0000000  loss: 0.5271 (0.5855)  bbox_regression: 0.0920 (0.1034)  classification: 0.4377 (0.4821)  time: 0.3497  data: 0.1271  max mem: 3278
Epoch: [90]  [2100/3494]  eta: 0:08:23  lr: 0.0000000  loss: 0.5832 (0.5856)  bbox_regression: 0.0890 (0.1035)  classification: 0.4914 (0.4821)  time: 0.3575  data: 0.1267  max mem: 3278
Epoch: [90]  [2200/3494]  eta: 0:07:46  lr: 0.0000000  loss: 0.5261 (0.5853)  bbox_regression: 0.0889 (0.1036)  classification: 0.4379 (0.4818)  time: 0.3326  data: 0.1147  max mem: 3278
Epoch: [90]  [2300/3494]  eta: 0:07:10  lr: 0.0000000  loss: 0.6166 (0.5850)  bbox_regression: 0.0988 (0.1035)  classification: 0.5099 (0.4814)  time: 0.3548  data: 0.1270  max mem: 3278
Epoch: [90]  [2400/3494]  eta: 0:06:34  lr: 0.0000000  loss: 0.5368 (0.5843)  bbox_regression: 0.0912 (0.1034)  classification: 0.4614 (0.4808)  time: 0.3572  data: 0.1254  max mem: 3278
Epoch: [90]  [2500/3494]  eta: 0:05:57  lr: 0.0000000  loss: 0.5507 (0.5838)  bbox_regression: 0.0933 (0.1033)  classification: 0.4368 (0.4805)  time: 0.3617  data: 0.1275  max mem: 3278
Epoch: [90]  [2600/3494]  eta: 0:05:21  lr: 0.0000000  loss: 0.5442 (0.5836)  bbox_regression: 0.0990 (0.1033)  classification: 0.4513 (0.4803)  time: 0.3509  data: 0.1278  max mem: 3278
Epoch: [90]  [2700/3494]  eta: 0:04:45  lr: 0.0000000  loss: 0.5599 (0.5836)  bbox_regression: 0.0889 (0.1033)  classification: 0.4633 (0.4803)  time: 0.3488  data: 0.1237  max mem: 3278
Epoch: [90]  [2800/3494]  eta: 0:04:09  lr: 0.0000000  loss: 0.5652 (0.5834)  bbox_regression: 0.0848 (0.1032)  classification: 0.4750 (0.4802)  time: 0.3564  data: 0.1283  max mem: 3278
Epoch: [90]  [2900/3494]  eta: 0:03:33  lr: 0.0000000  loss: 0.5099 (0.5830)  bbox_regression: 0.0881 (0.1031)  classification: 0.4143 (0.4799)  time: 0.3422  data: 0.1149  max mem: 3278
Epoch: [90]  [3000/3494]  eta: 0:02:57  lr: 0.0000000  loss: 0.5253 (0.5831)  bbox_regression: 0.0982 (0.1032)  classification: 0.4381 (0.4799)  time: 0.3439  data: 0.1215  max mem: 3278
Epoch: [90]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5654 (0.5833)  bbox_regression: 0.0995 (0.1032)  classification: 0.4495 (0.4801)  time: 0.3655  data: 0.1318  max mem: 3278
Epoch: [90]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5282 (0.5827)  bbox_regression: 0.0914 (0.1031)  classification: 0.4318 (0.4796)  time: 0.3729  data: 0.1391  max mem: 3278
Epoch: [90]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5275 (0.5823)  bbox_regression: 0.0893 (0.1031)  classification: 0.4376 (0.4793)  time: 0.3618  data: 0.1266  max mem: 3278
Epoch: [90]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5074 (0.5826)  bbox_regression: 0.0882 (0.1031)  classification: 0.4219 (0.4794)  time: 0.3525  data: 0.1261  max mem: 3278
Epoch: [90]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5846 (0.5825)  bbox_regression: 0.0885 (0.1030)  classification: 0.4810 (0.4794)  time: 0.3748  data: 0.1378  max mem: 3278
Epoch: [90] Total time: 0:21:05 (0.3621 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:45  model_time: 0.1389 (0.1389)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8886  data: 1.7259  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1184 (0.1205)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2612  data: 0.1253  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1155 (0.1196)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2565  data: 0.1212  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1136 (0.1194)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2560  data: 0.1194  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1205 (0.1204)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2737  data: 0.1306  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1111 (0.1199)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2293  data: 0.1037  max mem: 3278
Validation: Total time: 0:01:55 (0.2638 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [91]  [   0/3494]  eta: 2:01:12  lr: 0.0000000  loss: 0.5775 (0.5775)  bbox_regression: 0.1159 (0.1159)  classification: 0.4616 (0.4616)  time: 2.0815  data: 1.8258  max mem: 3278
Epoch: [91]  [ 100/3494]  eta: 0:21:20  lr: 0.0000000  loss: 0.5525 (0.5837)  bbox_regression: 0.1045 (0.1037)  classification: 0.4383 (0.4800)  time: 0.3557  data: 0.1264  max mem: 3278
Epoch: [91]  [ 200/3494]  eta: 0:20:15  lr: 0.0000000  loss: 0.5293 (0.5784)  bbox_regression: 0.0880 (0.1034)  classification: 0.4348 (0.4751)  time: 0.3497  data: 0.1216  max mem: 3278
Epoch: [91]  [ 300/3494]  eta: 0:19:18  lr: 0.0000000  loss: 0.5484 (0.5828)  bbox_regression: 0.1001 (0.1040)  classification: 0.4550 (0.4788)  time: 0.3658  data: 0.1316  max mem: 3278
Epoch: [91]  [ 400/3494]  eta: 0:18:39  lr: 0.0000000  loss: 0.5588 (0.5839)  bbox_regression: 0.0904 (0.1036)  classification: 0.4573 (0.4803)  time: 0.3546  data: 0.1240  max mem: 3278
Epoch: [91]  [ 500/3494]  eta: 0:17:57  lr: 0.0000000  loss: 0.5623 (0.5845)  bbox_regression: 0.0891 (0.1039)  classification: 0.4612 (0.4806)  time: 0.3601  data: 0.1284  max mem: 3278
Epoch: [91]  [ 600/3494]  eta: 0:17:23  lr: 0.0000000  loss: 0.5378 (0.5849)  bbox_regression: 0.0924 (0.1036)  classification: 0.4369 (0.4813)  time: 0.3672  data: 0.1332  max mem: 3278
Epoch: [91]  [ 700/3494]  eta: 0:16:43  lr: 0.0000000  loss: 0.5529 (0.5868)  bbox_regression: 0.1033 (0.1039)  classification: 0.4481 (0.4829)  time: 0.3097  data: 0.1010  max mem: 3278
Epoch: [91]  [ 800/3494]  eta: 0:16:10  lr: 0.0000000  loss: 0.5967 (0.5866)  bbox_regression: 0.0960 (0.1042)  classification: 0.4760 (0.4824)  time: 0.3610  data: 0.1251  max mem: 3278
Epoch: [91]  [ 900/3494]  eta: 0:15:33  lr: 0.0000000  loss: 0.5520 (0.5846)  bbox_regression: 0.0894 (0.1039)  classification: 0.4630 (0.4807)  time: 0.3681  data: 0.1310  max mem: 3278
Epoch: [91]  [1000/3494]  eta: 0:14:52  lr: 0.0000000  loss: 0.5798 (0.5834)  bbox_regression: 0.1007 (0.1037)  classification: 0.4722 (0.4797)  time: 0.3630  data: 0.1346  max mem: 3278
Epoch: [91]  [1100/3494]  eta: 0:14:17  lr: 0.0000000  loss: 0.5776 (0.5824)  bbox_regression: 0.1018 (0.1032)  classification: 0.4633 (0.4792)  time: 0.3571  data: 0.1272  max mem: 3278
Epoch: [91]  [1200/3494]  eta: 0:13:37  lr: 0.0000000  loss: 0.5598 (0.5818)  bbox_regression: 0.0987 (0.1031)  classification: 0.4687 (0.4786)  time: 0.3611  data: 0.1342  max mem: 3278
Epoch: [91]  [1300/3494]  eta: 0:13:01  lr: 0.0000000  loss: 0.5479 (0.5818)  bbox_regression: 0.0914 (0.1032)  classification: 0.4590 (0.4785)  time: 0.3530  data: 0.1268  max mem: 3278
Epoch: [91]  [1400/3494]  eta: 0:12:26  lr: 0.0000000  loss: 0.6088 (0.5817)  bbox_regression: 0.1037 (0.1032)  classification: 0.4911 (0.4785)  time: 0.3446  data: 0.1198  max mem: 3278
Epoch: [91]  [1500/3494]  eta: 0:11:51  lr: 0.0000000  loss: 0.5516 (0.5818)  bbox_regression: 0.1030 (0.1032)  classification: 0.4300 (0.4786)  time: 0.3597  data: 0.1275  max mem: 3278
Epoch: [91]  [1600/3494]  eta: 0:11:16  lr: 0.0000000  loss: 0.5498 (0.5829)  bbox_regression: 0.0855 (0.1036)  classification: 0.4479 (0.4793)  time: 0.3582  data: 0.1271  max mem: 3278
Epoch: [91]  [1700/3494]  eta: 0:10:40  lr: 0.0000000  loss: 0.5442 (0.5827)  bbox_regression: 0.0959 (0.1036)  classification: 0.4292 (0.4791)  time: 0.3699  data: 0.1387  max mem: 3278
Epoch: [91]  [1800/3494]  eta: 0:10:04  lr: 0.0000000  loss: 0.5339 (0.5823)  bbox_regression: 0.0974 (0.1034)  classification: 0.4265 (0.4788)  time: 0.3511  data: 0.1264  max mem: 3278
Epoch: [91]  [1900/3494]  eta: 0:09:28  lr: 0.0000000  loss: 0.5974 (0.5829)  bbox_regression: 0.1022 (0.1034)  classification: 0.4836 (0.4795)  time: 0.3642  data: 0.1311  max mem: 3278
Epoch: [91]  [2000/3494]  eta: 0:08:53  lr: 0.0000000  loss: 0.5814 (0.5825)  bbox_regression: 0.0995 (0.1033)  classification: 0.4606 (0.4792)  time: 0.3544  data: 0.1274  max mem: 3278
Epoch: [91]  [2100/3494]  eta: 0:08:17  lr: 0.0000000  loss: 0.5360 (0.5832)  bbox_regression: 0.0895 (0.1033)  classification: 0.4215 (0.4799)  time: 0.3364  data: 0.1143  max mem: 3278
Epoch: [91]  [2200/3494]  eta: 0:07:42  lr: 0.0000000  loss: 0.6046 (0.5831)  bbox_regression: 0.0893 (0.1032)  classification: 0.5016 (0.4800)  time: 0.3632  data: 0.1294  max mem: 3278
Epoch: [91]  [2300/3494]  eta: 0:07:06  lr: 0.0000000  loss: 0.5227 (0.5825)  bbox_regression: 0.0855 (0.1030)  classification: 0.4273 (0.4795)  time: 0.3631  data: 0.1325  max mem: 3278
Epoch: [91]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5152 (0.5823)  bbox_regression: 0.0867 (0.1031)  classification: 0.4316 (0.4792)  time: 0.3672  data: 0.1395  max mem: 3278
Epoch: [91]  [2500/3494]  eta: 0:05:55  lr: 0.0000000  loss: 0.5910 (0.5820)  bbox_regression: 0.0949 (0.1031)  classification: 0.4920 (0.4789)  time: 0.3582  data: 0.1247  max mem: 3278
Epoch: [91]  [2600/3494]  eta: 0:05:19  lr: 0.0000000  loss: 0.6005 (0.5820)  bbox_regression: 0.0922 (0.1031)  classification: 0.5109 (0.4789)  time: 0.3471  data: 0.1257  max mem: 3278
Epoch: [91]  [2700/3494]  eta: 0:04:44  lr: 0.0000000  loss: 0.5727 (0.5821)  bbox_regression: 0.0939 (0.1031)  classification: 0.4780 (0.4790)  time: 0.3491  data: 0.1239  max mem: 3278
Epoch: [91]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5322 (0.5813)  bbox_regression: 0.0891 (0.1029)  classification: 0.4338 (0.4785)  time: 0.3435  data: 0.1237  max mem: 3278
Epoch: [91]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.6081 (0.5817)  bbox_regression: 0.0997 (0.1028)  classification: 0.5072 (0.4789)  time: 0.3657  data: 0.1337  max mem: 3278
Epoch: [91]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5512 (0.5817)  bbox_regression: 0.0976 (0.1029)  classification: 0.4598 (0.4789)  time: 0.3668  data: 0.1337  max mem: 3278
Epoch: [91]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5419 (0.5820)  bbox_regression: 0.0884 (0.1028)  classification: 0.4785 (0.4792)  time: 0.3597  data: 0.1294  max mem: 3278
Epoch: [91]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.6208 (0.5824)  bbox_regression: 0.1077 (0.1030)  classification: 0.5001 (0.4794)  time: 0.3552  data: 0.1306  max mem: 3278
Epoch: [91]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5686 (0.5824)  bbox_regression: 0.0939 (0.1030)  classification: 0.4500 (0.4795)  time: 0.3667  data: 0.1364  max mem: 3278
Epoch: [91]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5919 (0.5829)  bbox_regression: 0.0950 (0.1031)  classification: 0.4907 (0.4799)  time: 0.3457  data: 0.1210  max mem: 3278
Epoch: [91]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5500 (0.5829)  bbox_regression: 0.0885 (0.1031)  classification: 0.4688 (0.4798)  time: 0.3254  data: 0.1140  max mem: 3278
Epoch: [91] Total time: 0:21:00 (0.3607 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:15  model_time: 0.1287 (0.1287)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0949  data: 1.9333  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1122 (0.1196)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2463  data: 0.1166  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1170 (0.1203)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2623  data: 0.1237  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1208 (0.1199)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2652  data: 0.1249  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1128 (0.1193)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2632  data: 0.1258  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1146 (0.1191)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2545  data: 0.1214  max mem: 3278
Validation: Total time: 0:01:55 (0.2636 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [92]  [   0/3494]  eta: 2:17:41  lr: 0.0000000  loss: 0.5549 (0.5549)  bbox_regression: 0.0976 (0.0976)  classification: 0.4573 (0.4573)  time: 2.3646  data: 2.1125  max mem: 3278
Epoch: [92]  [ 100/3494]  eta: 0:21:17  lr: 0.0000000  loss: 0.5314 (0.5732)  bbox_regression: 0.0932 (0.1032)  classification: 0.4298 (0.4700)  time: 0.3595  data: 0.1269  max mem: 3278
Epoch: [92]  [ 200/3494]  eta: 0:19:59  lr: 0.0000000  loss: 0.5727 (0.5850)  bbox_regression: 0.1024 (0.1044)  classification: 0.4761 (0.4806)  time: 0.3514  data: 0.1222  max mem: 3278
Epoch: [92]  [ 300/3494]  eta: 0:19:18  lr: 0.0000000  loss: 0.5755 (0.5815)  bbox_regression: 0.1087 (0.1036)  classification: 0.4499 (0.4779)  time: 0.3556  data: 0.1259  max mem: 3278
Epoch: [92]  [ 400/3494]  eta: 0:18:33  lr: 0.0000000  loss: 0.5583 (0.5800)  bbox_regression: 0.0909 (0.1032)  classification: 0.4622 (0.4767)  time: 0.3329  data: 0.1142  max mem: 3278
Epoch: [92]  [ 500/3494]  eta: 0:17:58  lr: 0.0000000  loss: 0.5430 (0.5813)  bbox_regression: 0.1021 (0.1030)  classification: 0.4695 (0.4783)  time: 0.3611  data: 0.1312  max mem: 3278
Epoch: [92]  [ 600/3494]  eta: 0:17:21  lr: 0.0000000  loss: 0.5516 (0.5812)  bbox_regression: 0.0897 (0.1031)  classification: 0.4576 (0.4782)  time: 0.3697  data: 0.1412  max mem: 3278
Epoch: [92]  [ 700/3494]  eta: 0:16:44  lr: 0.0000000  loss: 0.5467 (0.5805)  bbox_regression: 0.0981 (0.1032)  classification: 0.4409 (0.4774)  time: 0.3651  data: 0.1279  max mem: 3278
Epoch: [92]  [ 800/3494]  eta: 0:16:08  lr: 0.0000000  loss: 0.6119 (0.5828)  bbox_regression: 0.0967 (0.1033)  classification: 0.5093 (0.4795)  time: 0.3721  data: 0.1367  max mem: 3278
Epoch: [92]  [ 900/3494]  eta: 0:15:32  lr: 0.0000000  loss: 0.5454 (0.5853)  bbox_regression: 0.0917 (0.1034)  classification: 0.4617 (0.4819)  time: 0.3729  data: 0.1386  max mem: 3278
Epoch: [92]  [1000/3494]  eta: 0:14:56  lr: 0.0000000  loss: 0.5390 (0.5855)  bbox_regression: 0.0950 (0.1035)  classification: 0.4633 (0.4819)  time: 0.3597  data: 0.1280  max mem: 3278
Epoch: [92]  [1100/3494]  eta: 0:14:19  lr: 0.0000000  loss: 0.6065 (0.5874)  bbox_regression: 0.1114 (0.1041)  classification: 0.4853 (0.4834)  time: 0.3637  data: 0.1343  max mem: 3278
Epoch: [92]  [1200/3494]  eta: 0:13:43  lr: 0.0000000  loss: 0.5585 (0.5866)  bbox_regression: 0.1046 (0.1037)  classification: 0.4564 (0.4829)  time: 0.3547  data: 0.1299  max mem: 3278
Epoch: [92]  [1300/3494]  eta: 0:13:06  lr: 0.0000000  loss: 0.5660 (0.5866)  bbox_regression: 0.0974 (0.1041)  classification: 0.4792 (0.4826)  time: 0.3360  data: 0.1159  max mem: 3278
Epoch: [92]  [1400/3494]  eta: 0:12:31  lr: 0.0000000  loss: 0.5299 (0.5851)  bbox_regression: 0.0981 (0.1038)  classification: 0.4376 (0.4813)  time: 0.3548  data: 0.1282  max mem: 3278
Epoch: [92]  [1500/3494]  eta: 0:11:55  lr: 0.0000000  loss: 0.5334 (0.5843)  bbox_regression: 0.0866 (0.1035)  classification: 0.4395 (0.4808)  time: 0.3633  data: 0.1313  max mem: 3278
Epoch: [92]  [1600/3494]  eta: 0:11:19  lr: 0.0000000  loss: 0.5939 (0.5842)  bbox_regression: 0.0955 (0.1032)  classification: 0.5079 (0.4809)  time: 0.3575  data: 0.1287  max mem: 3278
Epoch: [92]  [1700/3494]  eta: 0:10:43  lr: 0.0000000  loss: 0.5396 (0.5831)  bbox_regression: 0.0925 (0.1029)  classification: 0.4302 (0.4802)  time: 0.3593  data: 0.1283  max mem: 3278
Epoch: [92]  [1800/3494]  eta: 0:10:06  lr: 0.0000000  loss: 0.5350 (0.5831)  bbox_regression: 0.0943 (0.1030)  classification: 0.4432 (0.4801)  time: 0.3561  data: 0.1254  max mem: 3278
Epoch: [92]  [1900/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5811 (0.5831)  bbox_regression: 0.1012 (0.1031)  classification: 0.4857 (0.4800)  time: 0.3640  data: 0.1342  max mem: 3278
Epoch: [92]  [2000/3494]  eta: 0:08:55  lr: 0.0000000  loss: 0.5383 (0.5831)  bbox_regression: 0.0911 (0.1031)  classification: 0.4583 (0.4800)  time: 0.3302  data: 0.1091  max mem: 3278
Epoch: [92]  [2100/3494]  eta: 0:08:19  lr: 0.0000000  loss: 0.5556 (0.5837)  bbox_regression: 0.1018 (0.1033)  classification: 0.4626 (0.4803)  time: 0.3592  data: 0.1262  max mem: 3278
Epoch: [92]  [2200/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.5820 (0.5839)  bbox_regression: 0.0942 (0.1034)  classification: 0.4748 (0.4805)  time: 0.3590  data: 0.1308  max mem: 3278
Epoch: [92]  [2300/3494]  eta: 0:07:07  lr: 0.0000000  loss: 0.5271 (0.5837)  bbox_regression: 0.0888 (0.1032)  classification: 0.4393 (0.4805)  time: 0.3576  data: 0.1290  max mem: 3278
Epoch: [92]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5832 (0.5838)  bbox_regression: 0.1070 (0.1033)  classification: 0.4728 (0.4805)  time: 0.3555  data: 0.1262  max mem: 3278
Epoch: [92]  [2500/3494]  eta: 0:05:55  lr: 0.0000000  loss: 0.5493 (0.5839)  bbox_regression: 0.0989 (0.1032)  classification: 0.4528 (0.4807)  time: 0.3532  data: 0.1246  max mem: 3278
Epoch: [92]  [2600/3494]  eta: 0:05:19  lr: 0.0000000  loss: 0.5395 (0.5833)  bbox_regression: 0.0905 (0.1031)  classification: 0.4586 (0.4802)  time: 0.3540  data: 0.1263  max mem: 3278
Epoch: [92]  [2700/3494]  eta: 0:04:43  lr: 0.0000000  loss: 0.5023 (0.5824)  bbox_regression: 0.0815 (0.1030)  classification: 0.4347 (0.4794)  time: 0.3376  data: 0.1134  max mem: 3278
Epoch: [92]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5693 (0.5828)  bbox_regression: 0.0941 (0.1030)  classification: 0.4802 (0.4798)  time: 0.3636  data: 0.1297  max mem: 3278
Epoch: [92]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5786 (0.5833)  bbox_regression: 0.0987 (0.1031)  classification: 0.4887 (0.4802)  time: 0.3474  data: 0.1234  max mem: 3278
Epoch: [92]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5593 (0.5834)  bbox_regression: 0.0900 (0.1032)  classification: 0.4729 (0.4802)  time: 0.3602  data: 0.1260  max mem: 3278
Epoch: [92]  [3100/3494]  eta: 0:02:20  lr: 0.0000000  loss: 0.6294 (0.5834)  bbox_regression: 0.1260 (0.1034)  classification: 0.5020 (0.4800)  time: 0.3502  data: 0.1233  max mem: 3278
Epoch: [92]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5418 (0.5833)  bbox_regression: 0.0910 (0.1033)  classification: 0.4442 (0.4800)  time: 0.3591  data: 0.1302  max mem: 3278
Epoch: [92]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5763 (0.5830)  bbox_regression: 0.0991 (0.1032)  classification: 0.4554 (0.4798)  time: 0.3519  data: 0.1254  max mem: 3278
Epoch: [92]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5680 (0.5833)  bbox_regression: 0.0928 (0.1033)  classification: 0.4698 (0.4800)  time: 0.3374  data: 0.1187  max mem: 3278
Epoch: [92]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5234 (0.5831)  bbox_regression: 0.0889 (0.1032)  classification: 0.4419 (0.4799)  time: 0.3597  data: 0.1332  max mem: 3278
Epoch: [92] Total time: 0:20:59 (0.3604 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:07  model_time: 0.1383 (0.1383)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.0767  data: 1.9009  max mem: 3278
Validation:  [100/437]  eta: 0:01:32  model_time: 0.1130 (0.1203)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2534  data: 0.1183  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1167 (0.1202)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2554  data: 0.1214  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1172 (0.1206)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2555  data: 0.1208  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1154 (0.1206)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2533  data: 0.1197  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1162 (0.1207)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2526  data: 0.1179  max mem: 3278
Validation: Total time: 0:01:55 (0.2648 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [93]  [   0/3494]  eta: 1:52:12  lr: 0.0000000  loss: 0.7224 (0.7224)  bbox_regression: 0.1483 (0.1483)  classification: 0.5741 (0.5741)  time: 1.9268  data: 1.6170  max mem: 3278
Epoch: [93]  [ 100/3494]  eta: 0:21:05  lr: 0.0000000  loss: 0.5228 (0.5855)  bbox_regression: 0.0940 (0.1026)  classification: 0.4414 (0.4828)  time: 0.3569  data: 0.1295  max mem: 3278
Epoch: [93]  [ 200/3494]  eta: 0:20:08  lr: 0.0000000  loss: 0.5192 (0.5825)  bbox_regression: 0.0958 (0.1031)  classification: 0.4168 (0.4794)  time: 0.3592  data: 0.1299  max mem: 3278
Epoch: [93]  [ 300/3494]  eta: 0:19:16  lr: 0.0000000  loss: 0.5569 (0.5807)  bbox_regression: 0.0889 (0.1019)  classification: 0.4794 (0.4788)  time: 0.3495  data: 0.1235  max mem: 3278
Epoch: [93]  [ 400/3494]  eta: 0:18:36  lr: 0.0000000  loss: 0.5462 (0.5850)  bbox_regression: 0.0994 (0.1028)  classification: 0.4620 (0.4822)  time: 0.3606  data: 0.1292  max mem: 3278
Epoch: [93]  [ 500/3494]  eta: 0:17:59  lr: 0.0000000  loss: 0.6412 (0.5884)  bbox_regression: 0.1088 (0.1031)  classification: 0.5163 (0.4854)  time: 0.3433  data: 0.1186  max mem: 3278
Epoch: [93]  [ 600/3494]  eta: 0:17:17  lr: 0.0000000  loss: 0.5555 (0.5885)  bbox_regression: 0.1018 (0.1037)  classification: 0.4591 (0.4847)  time: 0.3563  data: 0.1287  max mem: 3278
Epoch: [93]  [ 700/3494]  eta: 0:16:40  lr: 0.0000000  loss: 0.5837 (0.5878)  bbox_regression: 0.0929 (0.1032)  classification: 0.4910 (0.4846)  time: 0.3586  data: 0.1294  max mem: 3278
Epoch: [93]  [ 800/3494]  eta: 0:16:03  lr: 0.0000000  loss: 0.5720 (0.5879)  bbox_regression: 0.0963 (0.1031)  classification: 0.4687 (0.4848)  time: 0.3617  data: 0.1368  max mem: 3278
Epoch: [93]  [ 900/3494]  eta: 0:15:29  lr: 0.0000000  loss: 0.5220 (0.5875)  bbox_regression: 0.0865 (0.1031)  classification: 0.4297 (0.4843)  time: 0.3636  data: 0.1350  max mem: 3278
Epoch: [93]  [1000/3494]  eta: 0:14:52  lr: 0.0000000  loss: 0.5261 (0.5871)  bbox_regression: 0.0928 (0.1031)  classification: 0.4369 (0.4840)  time: 0.3444  data: 0.1180  max mem: 3278
Epoch: [93]  [1100/3494]  eta: 0:14:16  lr: 0.0000000  loss: 0.5727 (0.5860)  bbox_regression: 0.0984 (0.1030)  classification: 0.4783 (0.4830)  time: 0.3633  data: 0.1321  max mem: 3278
Epoch: [93]  [1200/3494]  eta: 0:13:39  lr: 0.0000000  loss: 0.5746 (0.5877)  bbox_regression: 0.0904 (0.1035)  classification: 0.4822 (0.4843)  time: 0.3568  data: 0.1272  max mem: 3278
Epoch: [93]  [1300/3494]  eta: 0:13:03  lr: 0.0000000  loss: 0.5254 (0.5873)  bbox_regression: 0.0973 (0.1035)  classification: 0.4324 (0.4838)  time: 0.3711  data: 0.1379  max mem: 3278
Epoch: [93]  [1400/3494]  eta: 0:12:27  lr: 0.0000000  loss: 0.4994 (0.5861)  bbox_regression: 0.0827 (0.1035)  classification: 0.4065 (0.4826)  time: 0.3459  data: 0.1212  max mem: 3278
Epoch: [93]  [1500/3494]  eta: 0:11:50  lr: 0.0000000  loss: 0.5712 (0.5851)  bbox_regression: 0.1049 (0.1033)  classification: 0.4844 (0.4818)  time: 0.3478  data: 0.1219  max mem: 3278
Epoch: [93]  [1600/3494]  eta: 0:11:15  lr: 0.0000000  loss: 0.5601 (0.5852)  bbox_regression: 0.0993 (0.1034)  classification: 0.4527 (0.4818)  time: 0.3549  data: 0.1255  max mem: 3278
Epoch: [93]  [1700/3494]  eta: 0:10:38  lr: 0.0000000  loss: 0.5573 (0.5857)  bbox_regression: 0.0931 (0.1035)  classification: 0.4804 (0.4822)  time: 0.3484  data: 0.1216  max mem: 3278
Epoch: [93]  [1800/3494]  eta: 0:10:03  lr: 0.0000000  loss: 0.6173 (0.5864)  bbox_regression: 0.1079 (0.1039)  classification: 0.4839 (0.4824)  time: 0.3581  data: 0.1283  max mem: 3278
Epoch: [93]  [1900/3494]  eta: 0:09:27  lr: 0.0000000  loss: 0.5656 (0.5859)  bbox_regression: 0.1004 (0.1038)  classification: 0.4744 (0.4820)  time: 0.3514  data: 0.1240  max mem: 3278
Epoch: [93]  [2000/3494]  eta: 0:08:52  lr: 0.0000000  loss: 0.5562 (0.5855)  bbox_regression: 0.0939 (0.1038)  classification: 0.4701 (0.4816)  time: 0.3541  data: 0.1287  max mem: 3278
Epoch: [93]  [2100/3494]  eta: 0:08:16  lr: 0.0000000  loss: 0.5219 (0.5851)  bbox_regression: 0.0898 (0.1037)  classification: 0.4253 (0.4813)  time: 0.3653  data: 0.1296  max mem: 3278
Epoch: [93]  [2200/3494]  eta: 0:07:41  lr: 0.0000000  loss: 0.5380 (0.5851)  bbox_regression: 0.0891 (0.1038)  classification: 0.4560 (0.4814)  time: 0.3629  data: 0.1314  max mem: 3278
Epoch: [93]  [2300/3494]  eta: 0:07:05  lr: 0.0000000  loss: 0.5654 (0.5843)  bbox_regression: 0.0904 (0.1036)  classification: 0.4664 (0.4807)  time: 0.3603  data: 0.1267  max mem: 3278
Epoch: [93]  [2400/3494]  eta: 0:06:30  lr: 0.0000000  loss: 0.5836 (0.5844)  bbox_regression: 0.1003 (0.1037)  classification: 0.4581 (0.4807)  time: 0.3536  data: 0.1216  max mem: 3278
Epoch: [93]  [2500/3494]  eta: 0:05:54  lr: 0.0000000  loss: 0.5611 (0.5840)  bbox_regression: 0.0966 (0.1035)  classification: 0.4781 (0.4805)  time: 0.3558  data: 0.1245  max mem: 3278
Epoch: [93]  [2600/3494]  eta: 0:05:18  lr: 0.0000000  loss: 0.5668 (0.5840)  bbox_regression: 0.0943 (0.1034)  classification: 0.4666 (0.4806)  time: 0.3593  data: 0.1276  max mem: 3278
Epoch: [93]  [2700/3494]  eta: 0:04:43  lr: 0.0000000  loss: 0.5302 (0.5839)  bbox_regression: 0.0893 (0.1033)  classification: 0.4457 (0.4806)  time: 0.3574  data: 0.1257  max mem: 3278
Epoch: [93]  [2800/3494]  eta: 0:04:07  lr: 0.0000000  loss: 0.5649 (0.5837)  bbox_regression: 0.0898 (0.1032)  classification: 0.4812 (0.4805)  time: 0.3496  data: 0.1275  max mem: 3278
Epoch: [93]  [2900/3494]  eta: 0:03:31  lr: 0.0000000  loss: 0.6290 (0.5842)  bbox_regression: 0.1116 (0.1034)  classification: 0.5167 (0.4808)  time: 0.3549  data: 0.1301  max mem: 3278
Epoch: [93]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5504 (0.5836)  bbox_regression: 0.0875 (0.1033)  classification: 0.4417 (0.4803)  time: 0.3647  data: 0.1321  max mem: 3278
Epoch: [93]  [3100/3494]  eta: 0:02:20  lr: 0.0000000  loss: 0.5417 (0.5839)  bbox_regression: 0.0978 (0.1034)  classification: 0.4250 (0.4806)  time: 0.3235  data: 0.1113  max mem: 3278
Epoch: [93]  [3200/3494]  eta: 0:01:44  lr: 0.0000000  loss: 0.5418 (0.5836)  bbox_regression: 0.1016 (0.1033)  classification: 0.4402 (0.4803)  time: 0.3553  data: 0.1259  max mem: 3278
Epoch: [93]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.6040 (0.5839)  bbox_regression: 0.0922 (0.1033)  classification: 0.4969 (0.4806)  time: 0.3478  data: 0.1237  max mem: 3278
Epoch: [93]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5488 (0.5833)  bbox_regression: 0.0974 (0.1032)  classification: 0.4471 (0.4801)  time: 0.3574  data: 0.1272  max mem: 3278
Epoch: [93]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.6037 (0.5835)  bbox_regression: 0.0979 (0.1032)  classification: 0.4890 (0.4804)  time: 0.3470  data: 0.1223  max mem: 3278
Epoch: [93] Total time: 0:20:55 (0.3593 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:19  model_time: 0.1887 (0.1887)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8298  data: 1.6172  max mem: 3278
Validation:  [100/437]  eta: 0:01:31  model_time: 0.1217 (0.1219)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2725  data: 0.1275  max mem: 3278
Validation:  [200/437]  eta: 0:01:03  model_time: 0.1162 (0.1220)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2606  data: 0.1209  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1176 (0.1219)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2610  data: 0.1234  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1128 (0.1212)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2275  data: 0.1006  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1124 (0.1209)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2591  data: 0.1292  max mem: 3278
Validation: Total time: 0:01:55 (0.2643 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [94]  [   0/3494]  eta: 2:24:25  lr: 0.0000000  loss: 0.6737 (0.6737)  bbox_regression: 0.1222 (0.1222)  classification: 0.5515 (0.5515)  time: 2.4802  data: 2.2418  max mem: 3278
Epoch: [94]  [ 100/3494]  eta: 0:21:22  lr: 0.0000000  loss: 0.5435 (0.5726)  bbox_regression: 0.0867 (0.0998)  classification: 0.4397 (0.4728)  time: 0.3590  data: 0.1280  max mem: 3278
Epoch: [94]  [ 200/3494]  eta: 0:20:04  lr: 0.0000000  loss: 0.5614 (0.5892)  bbox_regression: 0.0960 (0.1047)  classification: 0.4600 (0.4845)  time: 0.3392  data: 0.1152  max mem: 3278
Epoch: [94]  [ 300/3494]  eta: 0:19:28  lr: 0.0000000  loss: 0.5433 (0.5901)  bbox_regression: 0.0964 (0.1051)  classification: 0.4510 (0.4849)  time: 0.3632  data: 0.1294  max mem: 3278
Epoch: [94]  [ 400/3494]  eta: 0:18:47  lr: 0.0000000  loss: 0.5550 (0.5874)  bbox_regression: 0.0978 (0.1049)  classification: 0.4450 (0.4825)  time: 0.3853  data: 0.1378  max mem: 3278
Epoch: [94]  [ 500/3494]  eta: 0:18:06  lr: 0.0000000  loss: 0.5564 (0.5816)  bbox_regression: 0.0848 (0.1033)  classification: 0.4798 (0.4783)  time: 0.3579  data: 0.1232  max mem: 3278
Epoch: [94]  [ 600/3494]  eta: 0:17:30  lr: 0.0000000  loss: 0.5627 (0.5825)  bbox_regression: 0.0951 (0.1032)  classification: 0.4552 (0.4793)  time: 0.3586  data: 0.1321  max mem: 3278
Epoch: [94]  [ 700/3494]  eta: 0:16:52  lr: 0.0000000  loss: 0.5529 (0.5800)  bbox_regression: 0.0872 (0.1029)  classification: 0.4593 (0.4771)  time: 0.3661  data: 0.1298  max mem: 3278
Epoch: [94]  [ 800/3494]  eta: 0:16:16  lr: 0.0000000  loss: 0.5130 (0.5794)  bbox_regression: 0.0828 (0.1027)  classification: 0.4283 (0.4767)  time: 0.3508  data: 0.1257  max mem: 3278
Epoch: [94]  [ 900/3494]  eta: 0:15:36  lr: 0.0000000  loss: 0.6044 (0.5785)  bbox_regression: 0.1008 (0.1027)  classification: 0.4861 (0.4758)  time: 0.3487  data: 0.1225  max mem: 3278
Epoch: [94]  [1000/3494]  eta: 0:15:00  lr: 0.0000000  loss: 0.6074 (0.5792)  bbox_regression: 0.0886 (0.1026)  classification: 0.4860 (0.4765)  time: 0.3550  data: 0.1219  max mem: 3278
Epoch: [94]  [1100/3494]  eta: 0:14:22  lr: 0.0000000  loss: 0.5671 (0.5803)  bbox_regression: 0.0887 (0.1029)  classification: 0.4733 (0.4773)  time: 0.3478  data: 0.1196  max mem: 3278
Epoch: [94]  [1200/3494]  eta: 0:13:46  lr: 0.0000000  loss: 0.4899 (0.5799)  bbox_regression: 0.0823 (0.1027)  classification: 0.4154 (0.4772)  time: 0.3621  data: 0.1293  max mem: 3278
Epoch: [94]  [1300/3494]  eta: 0:13:09  lr: 0.0000000  loss: 0.5493 (0.5806)  bbox_regression: 0.1018 (0.1030)  classification: 0.4452 (0.4777)  time: 0.3543  data: 0.1274  max mem: 3278
Epoch: [94]  [1400/3494]  eta: 0:12:32  lr: 0.0000000  loss: 0.5447 (0.5813)  bbox_regression: 0.0874 (0.1031)  classification: 0.4447 (0.4782)  time: 0.3496  data: 0.1250  max mem: 3278
Epoch: [94]  [1500/3494]  eta: 0:11:56  lr: 0.0000000  loss: 0.5397 (0.5815)  bbox_regression: 0.0973 (0.1030)  classification: 0.4366 (0.4785)  time: 0.3679  data: 0.1294  max mem: 3278
Epoch: [94]  [1600/3494]  eta: 0:11:20  lr: 0.0000000  loss: 0.5941 (0.5808)  bbox_regression: 0.0860 (0.1029)  classification: 0.4679 (0.4780)  time: 0.3543  data: 0.1250  max mem: 3278
Epoch: [94]  [1700/3494]  eta: 0:10:44  lr: 0.0000000  loss: 0.6089 (0.5823)  bbox_regression: 0.0976 (0.1030)  classification: 0.4842 (0.4794)  time: 0.3520  data: 0.1258  max mem: 3278
Epoch: [94]  [1800/3494]  eta: 0:10:07  lr: 0.0000000  loss: 0.5102 (0.5827)  bbox_regression: 0.0925 (0.1029)  classification: 0.4119 (0.4797)  time: 0.3249  data: 0.1080  max mem: 3278
Epoch: [94]  [1900/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5415 (0.5829)  bbox_regression: 0.0848 (0.1030)  classification: 0.4503 (0.4799)  time: 0.3574  data: 0.1276  max mem: 3278
Epoch: [94]  [2000/3494]  eta: 0:08:55  lr: 0.0000000  loss: 0.5598 (0.5828)  bbox_regression: 0.0946 (0.1030)  classification: 0.4578 (0.4798)  time: 0.3539  data: 0.1258  max mem: 3278
Epoch: [94]  [2100/3494]  eta: 0:08:18  lr: 0.0000000  loss: 0.5273 (0.5825)  bbox_regression: 0.0918 (0.1030)  classification: 0.4280 (0.4795)  time: 0.3540  data: 0.1250  max mem: 3278
Epoch: [94]  [2200/3494]  eta: 0:07:42  lr: 0.0000000  loss: 0.5898 (0.5829)  bbox_regression: 0.1079 (0.1032)  classification: 0.4609 (0.4796)  time: 0.3671  data: 0.1372  max mem: 3278
Epoch: [94]  [2300/3494]  eta: 0:07:06  lr: 0.0000000  loss: 0.5973 (0.5835)  bbox_regression: 0.0988 (0.1033)  classification: 0.5107 (0.4802)  time: 0.3658  data: 0.1338  max mem: 3278
Epoch: [94]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5815 (0.5831)  bbox_regression: 0.0950 (0.1032)  classification: 0.4835 (0.4799)  time: 0.3665  data: 0.1369  max mem: 3278
Epoch: [94]  [2500/3494]  eta: 0:05:55  lr: 0.0000000  loss: 0.5842 (0.5832)  bbox_regression: 0.1034 (0.1032)  classification: 0.4706 (0.4800)  time: 0.3643  data: 0.1288  max mem: 3278
Epoch: [94]  [2600/3494]  eta: 0:05:19  lr: 0.0000000  loss: 0.5843 (0.5830)  bbox_regression: 0.0933 (0.1030)  classification: 0.4548 (0.4799)  time: 0.3579  data: 0.1261  max mem: 3278
Epoch: [94]  [2700/3494]  eta: 0:04:43  lr: 0.0000000  loss: 0.5313 (0.5826)  bbox_regression: 0.0944 (0.1030)  classification: 0.4467 (0.4797)  time: 0.3600  data: 0.1251  max mem: 3278
Epoch: [94]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5419 (0.5830)  bbox_regression: 0.1004 (0.1030)  classification: 0.4358 (0.4800)  time: 0.3772  data: 0.1408  max mem: 3278
Epoch: [94]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5335 (0.5830)  bbox_regression: 0.1030 (0.1030)  classification: 0.4388 (0.4800)  time: 0.3724  data: 0.1369  max mem: 3278
Epoch: [94]  [3000/3494]  eta: 0:02:56  lr: 0.0000000  loss: 0.5605 (0.5831)  bbox_regression: 0.0977 (0.1029)  classification: 0.4702 (0.4802)  time: 0.3502  data: 0.1267  max mem: 3278
Epoch: [94]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5677 (0.5835)  bbox_regression: 0.0999 (0.1031)  classification: 0.4612 (0.4804)  time: 0.3621  data: 0.1282  max mem: 3278
Epoch: [94]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5231 (0.5835)  bbox_regression: 0.0892 (0.1033)  classification: 0.4122 (0.4802)  time: 0.3457  data: 0.1232  max mem: 3278
Epoch: [94]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5888 (0.5840)  bbox_regression: 0.0915 (0.1033)  classification: 0.4815 (0.4807)  time: 0.3775  data: 0.1334  max mem: 3278
Epoch: [94]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5522 (0.5838)  bbox_regression: 0.0988 (0.1032)  classification: 0.4508 (0.4806)  time: 0.3770  data: 0.1440  max mem: 3278
Epoch: [94]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5385 (0.5837)  bbox_regression: 0.0968 (0.1033)  classification: 0.4382 (0.4805)  time: 0.3407  data: 0.1223  max mem: 3278
Epoch: [94] Total time: 0:21:01 (0.3612 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:51  model_time: 0.1573 (0.1573)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.7662  data: 1.5587  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1176 (0.1208)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2547  data: 0.1202  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1190 (0.1214)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2649  data: 0.1263  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1222 (0.1223)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2734  data: 0.1312  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1187 (0.1224)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2675  data: 0.1268  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1205 (0.1224)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2633  data: 0.1239  max mem: 3278
Validation: Total time: 0:01:58 (0.2705 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [95]  [   0/3494]  eta: 2:18:33  lr: 0.0000000  loss: 0.6063 (0.6063)  bbox_regression: 0.0895 (0.0895)  classification: 0.5168 (0.5168)  time: 2.3793  data: 2.1217  max mem: 3278
Epoch: [95]  [ 100/3494]  eta: 0:20:53  lr: 0.0000000  loss: 0.5655 (0.5982)  bbox_regression: 0.0938 (0.1072)  classification: 0.4837 (0.4910)  time: 0.3571  data: 0.1268  max mem: 3278
Epoch: [95]  [ 200/3494]  eta: 0:19:50  lr: 0.0000000  loss: 0.5281 (0.5991)  bbox_regression: 0.0825 (0.1070)  classification: 0.4434 (0.4921)  time: 0.3572  data: 0.1305  max mem: 3278
Epoch: [95]  [ 300/3494]  eta: 0:19:13  lr: 0.0000000  loss: 0.5325 (0.5885)  bbox_regression: 0.0872 (0.1049)  classification: 0.4580 (0.4836)  time: 0.3474  data: 0.1247  max mem: 3278
Epoch: [95]  [ 400/3494]  eta: 0:18:31  lr: 0.0000000  loss: 0.5263 (0.5833)  bbox_regression: 0.0956 (0.1041)  classification: 0.4463 (0.4792)  time: 0.3539  data: 0.1253  max mem: 3278
Epoch: [95]  [ 500/3494]  eta: 0:17:55  lr: 0.0000000  loss: 0.5557 (0.5805)  bbox_regression: 0.1034 (0.1041)  classification: 0.4476 (0.4764)  time: 0.3592  data: 0.1266  max mem: 3278
Epoch: [95]  [ 600/3494]  eta: 0:17:15  lr: 0.0000000  loss: 0.6036 (0.5800)  bbox_regression: 0.1004 (0.1030)  classification: 0.5109 (0.4770)  time: 0.3598  data: 0.1277  max mem: 3278
Epoch: [95]  [ 700/3494]  eta: 0:16:39  lr: 0.0000000  loss: 0.5774 (0.5789)  bbox_regression: 0.0985 (0.1027)  classification: 0.4927 (0.4762)  time: 0.3506  data: 0.1282  max mem: 3278
Epoch: [95]  [ 800/3494]  eta: 0:16:04  lr: 0.0000000  loss: 0.5929 (0.5795)  bbox_regression: 0.1032 (0.1028)  classification: 0.4897 (0.4768)  time: 0.3439  data: 0.1233  max mem: 3278
Epoch: [95]  [ 900/3494]  eta: 0:15:29  lr: 0.0000000  loss: 0.6303 (0.5795)  bbox_regression: 0.1003 (0.1025)  classification: 0.5062 (0.4771)  time: 0.3631  data: 0.1328  max mem: 3278
Epoch: [95]  [1000/3494]  eta: 0:14:54  lr: 0.0000000  loss: 0.5227 (0.5784)  bbox_regression: 0.1003 (0.1022)  classification: 0.4397 (0.4762)  time: 0.3534  data: 0.1263  max mem: 3278
Epoch: [95]  [1100/3494]  eta: 0:14:17  lr: 0.0000000  loss: 0.5546 (0.5790)  bbox_regression: 0.0946 (0.1025)  classification: 0.4605 (0.4765)  time: 0.3712  data: 0.1321  max mem: 3278
Epoch: [95]  [1200/3494]  eta: 0:13:42  lr: 0.0000000  loss: 0.6083 (0.5796)  bbox_regression: 0.1048 (0.1028)  classification: 0.4949 (0.4768)  time: 0.3757  data: 0.1388  max mem: 3278
Epoch: [95]  [1300/3494]  eta: 0:13:06  lr: 0.0000000  loss: 0.5345 (0.5787)  bbox_regression: 0.0915 (0.1029)  classification: 0.4423 (0.4758)  time: 0.3683  data: 0.1337  max mem: 3278
Epoch: [95]  [1400/3494]  eta: 0:12:30  lr: 0.0000000  loss: 0.5804 (0.5789)  bbox_regression: 0.1047 (0.1028)  classification: 0.4924 (0.4760)  time: 0.3571  data: 0.1269  max mem: 3278
Epoch: [95]  [1500/3494]  eta: 0:11:54  lr: 0.0000000  loss: 0.5185 (0.5775)  bbox_regression: 0.0881 (0.1025)  classification: 0.4234 (0.4750)  time: 0.3434  data: 0.1169  max mem: 3278
Epoch: [95]  [1600/3494]  eta: 0:11:19  lr: 0.0000000  loss: 0.5735 (0.5777)  bbox_regression: 0.0988 (0.1024)  classification: 0.4760 (0.4753)  time: 0.3603  data: 0.1349  max mem: 3278
Epoch: [95]  [1700/3494]  eta: 0:10:43  lr: 0.0000000  loss: 0.5584 (0.5792)  bbox_regression: 0.0907 (0.1027)  classification: 0.4667 (0.4764)  time: 0.3610  data: 0.1311  max mem: 3278
Epoch: [95]  [1800/3494]  eta: 0:10:07  lr: 0.0000000  loss: 0.5694 (0.5799)  bbox_regression: 0.0958 (0.1027)  classification: 0.4865 (0.4773)  time: 0.3594  data: 0.1276  max mem: 3278
Epoch: [95]  [1900/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5123 (0.5804)  bbox_regression: 0.0902 (0.1027)  classification: 0.4374 (0.4777)  time: 0.3669  data: 0.1366  max mem: 3278
Epoch: [95]  [2000/3494]  eta: 0:08:55  lr: 0.0000000  loss: 0.5587 (0.5802)  bbox_regression: 0.0904 (0.1028)  classification: 0.4467 (0.4774)  time: 0.3482  data: 0.1200  max mem: 3278
Epoch: [95]  [2100/3494]  eta: 0:08:19  lr: 0.0000000  loss: 0.5739 (0.5805)  bbox_regression: 0.0920 (0.1028)  classification: 0.4701 (0.4776)  time: 0.3554  data: 0.1272  max mem: 3278
Epoch: [95]  [2200/3494]  eta: 0:07:43  lr: 0.0000000  loss: 0.5881 (0.5812)  bbox_regression: 0.1007 (0.1030)  classification: 0.4833 (0.4782)  time: 0.3349  data: 0.1153  max mem: 3278
Epoch: [95]  [2300/3494]  eta: 0:07:07  lr: 0.0000000  loss: 0.5577 (0.5816)  bbox_regression: 0.0895 (0.1029)  classification: 0.4523 (0.4787)  time: 0.3497  data: 0.1268  max mem: 3278
Epoch: [95]  [2400/3494]  eta: 0:06:31  lr: 0.0000000  loss: 0.5855 (0.5823)  bbox_regression: 0.0954 (0.1030)  classification: 0.4854 (0.4792)  time: 0.3575  data: 0.1303  max mem: 3278
Epoch: [95]  [2500/3494]  eta: 0:05:55  lr: 0.0000000  loss: 0.4850 (0.5819)  bbox_regression: 0.0848 (0.1029)  classification: 0.4134 (0.4790)  time: 0.3508  data: 0.1243  max mem: 3278
Epoch: [95]  [2600/3494]  eta: 0:05:20  lr: 0.0000000  loss: 0.5881 (0.5826)  bbox_regression: 0.1093 (0.1032)  classification: 0.4628 (0.4794)  time: 0.3604  data: 0.1288  max mem: 3278
Epoch: [95]  [2700/3494]  eta: 0:04:44  lr: 0.0000000  loss: 0.5612 (0.5822)  bbox_regression: 0.0945 (0.1032)  classification: 0.4749 (0.4790)  time: 0.3549  data: 0.1278  max mem: 3278
Epoch: [95]  [2800/3494]  eta: 0:04:08  lr: 0.0000000  loss: 0.5769 (0.5824)  bbox_regression: 0.1001 (0.1032)  classification: 0.4763 (0.4792)  time: 0.3582  data: 0.1286  max mem: 3278
Epoch: [95]  [2900/3494]  eta: 0:03:32  lr: 0.0000000  loss: 0.5398 (0.5827)  bbox_regression: 0.0959 (0.1031)  classification: 0.4251 (0.4796)  time: 0.3744  data: 0.1400  max mem: 3278
Epoch: [95]  [3000/3494]  eta: 0:02:57  lr: 0.0000000  loss: 0.5868 (0.5828)  bbox_regression: 0.1074 (0.1031)  classification: 0.4880 (0.4797)  time: 0.3547  data: 0.1268  max mem: 3278
Epoch: [95]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5780 (0.5822)  bbox_regression: 0.1024 (0.1030)  classification: 0.4603 (0.4792)  time: 0.3633  data: 0.1297  max mem: 3278
Epoch: [95]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5816 (0.5826)  bbox_regression: 0.1070 (0.1031)  classification: 0.4658 (0.4795)  time: 0.3621  data: 0.1289  max mem: 3278
Epoch: [95]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5750 (0.5823)  bbox_regression: 0.0989 (0.1031)  classification: 0.4660 (0.4791)  time: 0.3490  data: 0.1243  max mem: 3278
Epoch: [95]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5521 (0.5825)  bbox_regression: 0.1065 (0.1032)  classification: 0.4602 (0.4794)  time: 0.3692  data: 0.1304  max mem: 3278
Epoch: [95]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5516 (0.5823)  bbox_regression: 0.1059 (0.1032)  classification: 0.4414 (0.4791)  time: 0.3506  data: 0.1257  max mem: 3278
Epoch: [95] Total time: 0:21:03 (0.3616 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:14:19  model_time: 0.2287 (0.2287)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.9667  data: 1.7057  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1166 (0.1223)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2577  data: 0.1219  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1199 (0.1221)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2648  data: 0.1255  max mem: 3278
Validation:  [300/437]  eta: 0:00:36  model_time: 0.1174 (0.1206)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2624  data: 0.1237  max mem: 3278
Validation:  [400/437]  eta: 0:00:09  model_time: 0.1165 (0.1216)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2675  data: 0.1252  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1148 (0.1213)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2547  data: 0.1199  max mem: 3278
Validation: Total time: 0:01:56 (0.2666 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [96]  [   0/3494]  eta: 2:23:39  lr: 0.0000000  loss: 0.4201 (0.4201)  bbox_regression: 0.0829 (0.0829)  classification: 0.3372 (0.3372)  time: 2.4671  data: 2.2035  max mem: 3278
Epoch: [96]  [ 100/3494]  eta: 0:21:19  lr: 0.0000000  loss: 0.5677 (0.6027)  bbox_regression: 0.0998 (0.1085)  classification: 0.4756 (0.4942)  time: 0.3443  data: 0.1136  max mem: 3278
Epoch: [96]  [ 200/3494]  eta: 0:20:07  lr: 0.0000000  loss: 0.5535 (0.6045)  bbox_regression: 0.0982 (0.1102)  classification: 0.4378 (0.4942)  time: 0.3484  data: 0.1218  max mem: 3278
Epoch: [96]  [ 300/3494]  eta: 0:19:23  lr: 0.0000000  loss: 0.5803 (0.5931)  bbox_regression: 0.1045 (0.1073)  classification: 0.4806 (0.4857)  time: 0.3547  data: 0.1233  max mem: 3278
Epoch: [96]  [ 400/3494]  eta: 0:18:36  lr: 0.0000000  loss: 0.5970 (0.5910)  bbox_regression: 0.1035 (0.1053)  classification: 0.4961 (0.4857)  time: 0.3442  data: 0.1201  max mem: 3278
Epoch: [96]  [ 500/3494]  eta: 0:17:58  lr: 0.0000000  loss: 0.5787 (0.5892)  bbox_regression: 0.0963 (0.1056)  classification: 0.4601 (0.4836)  time: 0.3557  data: 0.1257  max mem: 3278
Epoch: [96]  [ 600/3494]  eta: 0:17:23  lr: 0.0000000  loss: 0.5714 (0.5910)  bbox_regression: 0.1019 (0.1063)  classification: 0.4694 (0.4847)  time: 0.3527  data: 0.1265  max mem: 3278
Epoch: [96]  [ 700/3494]  eta: 0:16:44  lr: 0.0000000  loss: 0.5104 (0.5903)  bbox_regression: 0.0877 (0.1059)  classification: 0.4227 (0.4845)  time: 0.3573  data: 0.1265  max mem: 3278
Epoch: [96]  [ 800/3494]  eta: 0:16:07  lr: 0.0000000  loss: 0.6621 (0.5926)  bbox_regression: 0.1089 (0.1061)  classification: 0.5004 (0.4866)  time: 0.3604  data: 0.1301  max mem: 3278
Epoch: [96]  [ 900/3494]  eta: 0:15:28  lr: 0.0000000  loss: 0.5979 (0.5920)  bbox_regression: 0.0904 (0.1058)  classification: 0.4928 (0.4862)  time: 0.3539  data: 0.1255  max mem: 3278
Epoch: [96]  [1000/3494]  eta: 0:14:52  lr: 0.0000000  loss: 0.5404 (0.5902)  bbox_regression: 0.1003 (0.1055)  classification: 0.4455 (0.4847)  time: 0.3630  data: 0.1287  max mem: 3278
Epoch: [96]  [1100/3494]  eta: 0:14:16  lr: 0.0000000  loss: 0.5796 (0.5886)  bbox_regression: 0.0901 (0.1049)  classification: 0.4778 (0.4837)  time: 0.3640  data: 0.1316  max mem: 3278
Epoch: [96]  [1200/3494]  eta: 0:13:41  lr: 0.0000000  loss: 0.5892 (0.5901)  bbox_regression: 0.1053 (0.1052)  classification: 0.4966 (0.4849)  time: 0.3653  data: 0.1303  max mem: 3278
Epoch: [96]  [1300/3494]  eta: 0:13:05  lr: 0.0000000  loss: 0.5767 (0.5896)  bbox_regression: 0.1008 (0.1050)  classification: 0.4709 (0.4846)  time: 0.3641  data: 0.1344  max mem: 3278
Epoch: [96]  [1400/3494]  eta: 0:12:29  lr: 0.0000000  loss: 0.5662 (0.5889)  bbox_regression: 0.0924 (0.1049)  classification: 0.4762 (0.4840)  time: 0.3627  data: 0.1298  max mem: 3278
Epoch: [96]  [1500/3494]  eta: 0:11:53  lr: 0.0000000  loss: 0.5623 (0.5878)  bbox_regression: 0.0904 (0.1048)  classification: 0.4580 (0.4830)  time: 0.3726  data: 0.1405  max mem: 3278
Epoch: [96]  [1600/3494]  eta: 0:11:17  lr: 0.0000000  loss: 0.5950 (0.5872)  bbox_regression: 0.1166 (0.1044)  classification: 0.4681 (0.4828)  time: 0.3640  data: 0.1306  max mem: 3278
Epoch: [96]  [1700/3494]  eta: 0:10:42  lr: 0.0000000  loss: 0.5598 (0.5862)  bbox_regression: 0.0951 (0.1041)  classification: 0.4669 (0.4820)  time: 0.3690  data: 0.1281  max mem: 3278
Epoch: [96]  [1800/3494]  eta: 0:10:07  lr: 0.0000000  loss: 0.5688 (0.5851)  bbox_regression: 0.1028 (0.1040)  classification: 0.4694 (0.4811)  time: 0.3580  data: 0.1284  max mem: 3278
Epoch: [96]  [1900/3494]  eta: 0:09:31  lr: 0.0000000  loss: 0.5525 (0.5854)  bbox_regression: 0.0926 (0.1040)  classification: 0.4680 (0.4814)  time: 0.3731  data: 0.1363  max mem: 3278
Epoch: [96]  [2000/3494]  eta: 0:08:56  lr: 0.0000000  loss: 0.5915 (0.5842)  bbox_regression: 0.1192 (0.1038)  classification: 0.4803 (0.4804)  time: 0.3644  data: 0.1287  max mem: 3278
Epoch: [96]  [2100/3494]  eta: 0:08:20  lr: 0.0000000  loss: 0.5847 (0.5847)  bbox_regression: 0.1047 (0.1040)  classification: 0.4729 (0.4806)  time: 0.3598  data: 0.1270  max mem: 3278
Epoch: [96]  [2200/3494]  eta: 0:07:44  lr: 0.0000000  loss: 0.5668 (0.5849)  bbox_regression: 0.0901 (0.1041)  classification: 0.4742 (0.4808)  time: 0.3574  data: 0.1290  max mem: 3278
Epoch: [96]  [2300/3494]  eta: 0:07:08  lr: 0.0000000  loss: 0.5840 (0.5845)  bbox_regression: 0.1045 (0.1040)  classification: 0.4861 (0.4806)  time: 0.3644  data: 0.1302  max mem: 3278
Epoch: [96]  [2400/3494]  eta: 0:06:32  lr: 0.0000000  loss: 0.5531 (0.5841)  bbox_regression: 0.0860 (0.1037)  classification: 0.4480 (0.4804)  time: 0.3593  data: 0.1324  max mem: 3278
Epoch: [96]  [2500/3494]  eta: 0:05:56  lr: 0.0000000  loss: 0.5750 (0.5843)  bbox_regression: 0.0878 (0.1037)  classification: 0.4698 (0.4806)  time: 0.3719  data: 0.1367  max mem: 3278
Epoch: [96]  [2600/3494]  eta: 0:05:20  lr: 0.0000000  loss: 0.5182 (0.5833)  bbox_regression: 0.0873 (0.1034)  classification: 0.4229 (0.4799)  time: 0.3663  data: 0.1359  max mem: 3278
Epoch: [96]  [2700/3494]  eta: 0:04:45  lr: 0.0000000  loss: 0.5533 (0.5840)  bbox_regression: 0.0897 (0.1035)  classification: 0.4630 (0.4805)  time: 0.3660  data: 0.1331  max mem: 3278
Epoch: [96]  [2800/3494]  eta: 0:04:09  lr: 0.0000000  loss: 0.5346 (0.5834)  bbox_regression: 0.1057 (0.1033)  classification: 0.4593 (0.4801)  time: 0.3592  data: 0.1285  max mem: 3278
Epoch: [96]  [2900/3494]  eta: 0:03:33  lr: 0.0000000  loss: 0.5475 (0.5828)  bbox_regression: 0.0927 (0.1032)  classification: 0.4591 (0.4797)  time: 0.3478  data: 0.1240  max mem: 3278
Epoch: [96]  [3000/3494]  eta: 0:02:57  lr: 0.0000000  loss: 0.5641 (0.5834)  bbox_regression: 0.0976 (0.1032)  classification: 0.4683 (0.4801)  time: 0.3649  data: 0.1324  max mem: 3278
Epoch: [96]  [3100/3494]  eta: 0:02:21  lr: 0.0000000  loss: 0.5911 (0.5832)  bbox_regression: 0.0954 (0.1030)  classification: 0.4894 (0.4802)  time: 0.3686  data: 0.1331  max mem: 3278
Epoch: [96]  [3200/3494]  eta: 0:01:45  lr: 0.0000000  loss: 0.5371 (0.5828)  bbox_regression: 0.0985 (0.1029)  classification: 0.4487 (0.4799)  time: 0.3816  data: 0.1411  max mem: 3278
Epoch: [96]  [3300/3494]  eta: 0:01:09  lr: 0.0000000  loss: 0.5885 (0.5828)  bbox_regression: 0.1037 (0.1030)  classification: 0.5035 (0.4799)  time: 0.3730  data: 0.1382  max mem: 3278
Epoch: [96]  [3400/3494]  eta: 0:00:33  lr: 0.0000000  loss: 0.5849 (0.5835)  bbox_regression: 0.1028 (0.1031)  classification: 0.4767 (0.4803)  time: 0.3629  data: 0.1273  max mem: 3278
Epoch: [96]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5878 (0.5834)  bbox_regression: 0.1018 (0.1032)  classification: 0.4779 (0.4802)  time: 0.3829  data: 0.1400  max mem: 3278
Epoch: [96] Total time: 0:21:12 (0.3641 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:12:28  model_time: 0.1456 (0.1456)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.7126  data: 1.5273  max mem: 3278
Validation:  [100/437]  eta: 0:01:33  model_time: 0.1167 (0.1212)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2544  data: 0.1200  max mem: 3278
Validation:  [200/437]  eta: 0:01:04  model_time: 0.1224 (0.1230)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2699  data: 0.1293  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1146 (0.1237)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2688  data: 0.1289  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1227 (0.1242)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2754  data: 0.1294  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1208 (0.1241)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2663  data: 0.1241  max mem: 3278
Validation: Total time: 0:01:59 (0.2732 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [97]  [   0/3494]  eta: 2:09:26  lr: 0.0000000  loss: 0.6188 (0.6188)  bbox_regression: 0.1037 (0.1037)  classification: 0.5151 (0.5151)  time: 2.2229  data: 1.9509  max mem: 3278
Epoch: [97]  [ 100/3494]  eta: 0:22:10  lr: 0.0000000  loss: 0.5766 (0.5815)  bbox_regression: 0.1159 (0.1089)  classification: 0.4487 (0.4727)  time: 0.3696  data: 0.1351  max mem: 3278
Epoch: [97]  [ 200/3494]  eta: 0:20:40  lr: 0.0000000  loss: 0.5286 (0.5806)  bbox_regression: 0.0822 (0.1039)  classification: 0.4537 (0.4767)  time: 0.3664  data: 0.1292  max mem: 3278
Epoch: [97]  [ 300/3494]  eta: 0:19:49  lr: 0.0000000  loss: 0.5782 (0.5860)  bbox_regression: 0.0960 (0.1042)  classification: 0.4810 (0.4818)  time: 0.3489  data: 0.1119  max mem: 3278
Epoch: [97]  [ 400/3494]  eta: 0:19:05  lr: 0.0000000  loss: 0.4984 (0.5847)  bbox_regression: 0.0900 (0.1041)  classification: 0.4189 (0.4805)  time: 0.3730  data: 0.1348  max mem: 3278
Epoch: [97]  [ 500/3494]  eta: 0:18:30  lr: 0.0000000  loss: 0.5456 (0.5803)  bbox_regression: 0.0937 (0.1039)  classification: 0.4621 (0.4764)  time: 0.3747  data: 0.1325  max mem: 3278
Epoch: [97]  [ 600/3494]  eta: 0:17:53  lr: 0.0000000  loss: 0.5975 (0.5814)  bbox_regression: 0.1092 (0.1038)  classification: 0.5075 (0.4777)  time: 0.3866  data: 0.1372  max mem: 3278
Epoch: [97]  [ 700/3494]  eta: 0:17:17  lr: 0.0000000  loss: 0.5528 (0.5803)  bbox_regression: 0.0970 (0.1033)  classification: 0.4418 (0.4771)  time: 0.3640  data: 0.1303  max mem: 3278
Epoch: [97]  [ 800/3494]  eta: 0:16:39  lr: 0.0000000  loss: 0.5680 (0.5786)  bbox_regression: 0.0938 (0.1026)  classification: 0.4704 (0.4759)  time: 0.3726  data: 0.1409  max mem: 3278
Epoch: [97]  [ 900/3494]  eta: 0:16:03  lr: 0.0000000  loss: 0.5691 (0.5766)  bbox_regression: 0.0960 (0.1026)  classification: 0.4661 (0.4740)  time: 0.3790  data: 0.1349  max mem: 3278
Epoch: [97]  [1000/3494]  eta: 0:15:25  lr: 0.0000000  loss: 0.5579 (0.5754)  bbox_regression: 0.0899 (0.1024)  classification: 0.4455 (0.4730)  time: 0.3584  data: 0.1239  max mem: 3278
Epoch: [97]  [1100/3494]  eta: 0:14:50  lr: 0.0000000  loss: 0.5666 (0.5756)  bbox_regression: 0.0938 (0.1023)  classification: 0.4648 (0.4733)  time: 0.4138  data: 0.1540  max mem: 3278
Epoch: [97]  [1200/3494]  eta: 0:14:11  lr: 0.0000000  loss: 0.5581 (0.5762)  bbox_regression: 0.0927 (0.1022)  classification: 0.4800 (0.4740)  time: 0.3668  data: 0.1273  max mem: 3278
Epoch: [97]  [1300/3494]  eta: 0:13:35  lr: 0.0000000  loss: 0.5521 (0.5764)  bbox_regression: 0.0921 (0.1021)  classification: 0.4775 (0.4743)  time: 0.3746  data: 0.1350  max mem: 3278
Epoch: [97]  [1400/3494]  eta: 0:13:00  lr: 0.0000000  loss: 0.5827 (0.5763)  bbox_regression: 0.0848 (0.1020)  classification: 0.4984 (0.4743)  time: 0.3800  data: 0.1380  max mem: 3278
Epoch: [97]  [1500/3494]  eta: 0:12:24  lr: 0.0000000  loss: 0.5679 (0.5776)  bbox_regression: 0.1015 (0.1023)  classification: 0.4884 (0.4752)  time: 0.3578  data: 0.1251  max mem: 3278
Epoch: [97]  [1600/3494]  eta: 0:11:46  lr: 0.0000000  loss: 0.5416 (0.5779)  bbox_regression: 0.1096 (0.1026)  classification: 0.4409 (0.4753)  time: 0.3539  data: 0.1248  max mem: 3278
Epoch: [97]  [1700/3494]  eta: 0:11:08  lr: 0.0000000  loss: 0.5421 (0.5773)  bbox_regression: 0.1020 (0.1023)  classification: 0.4310 (0.4750)  time: 0.3706  data: 0.1284  max mem: 3278
Epoch: [97]  [1800/3494]  eta: 0:10:32  lr: 0.0000000  loss: 0.5774 (0.5779)  bbox_regression: 0.0933 (0.1023)  classification: 0.4675 (0.4756)  time: 0.3728  data: 0.1432  max mem: 3278
Epoch: [97]  [1900/3494]  eta: 0:09:55  lr: 0.0000000  loss: 0.5793 (0.5780)  bbox_regression: 0.0946 (0.1024)  classification: 0.4761 (0.4756)  time: 0.3838  data: 0.1416  max mem: 3278
Epoch: [97]  [2000/3494]  eta: 0:09:17  lr: 0.0000000  loss: 0.5493 (0.5781)  bbox_regression: 0.0972 (0.1022)  classification: 0.4479 (0.4759)  time: 0.3719  data: 0.1435  max mem: 3278
Epoch: [97]  [2100/3494]  eta: 0:08:40  lr: 0.0000000  loss: 0.5616 (0.5794)  bbox_regression: 0.1000 (0.1026)  classification: 0.4658 (0.4768)  time: 0.3859  data: 0.1376  max mem: 3278
Epoch: [97]  [2200/3494]  eta: 0:08:02  lr: 0.0000000  loss: 0.5620 (0.5799)  bbox_regression: 0.0966 (0.1027)  classification: 0.4629 (0.4772)  time: 0.3744  data: 0.1321  max mem: 3278
Epoch: [97]  [2300/3494]  eta: 0:07:24  lr: 0.0000000  loss: 0.5410 (0.5802)  bbox_regression: 0.0917 (0.1028)  classification: 0.4551 (0.4773)  time: 0.3513  data: 0.1253  max mem: 3278
Epoch: [97]  [2400/3494]  eta: 0:06:47  lr: 0.0000000  loss: 0.5316 (0.5797)  bbox_regression: 0.0987 (0.1027)  classification: 0.4497 (0.4769)  time: 0.3822  data: 0.1397  max mem: 3278
Epoch: [97]  [2500/3494]  eta: 0:06:10  lr: 0.0000000  loss: 0.5432 (0.5785)  bbox_regression: 0.1003 (0.1026)  classification: 0.4602 (0.4760)  time: 0.3745  data: 0.1395  max mem: 3278
Epoch: [97]  [2600/3494]  eta: 0:05:33  lr: 0.0000000  loss: 0.5120 (0.5790)  bbox_regression: 0.0940 (0.1027)  classification: 0.4255 (0.4764)  time: 0.3811  data: 0.1434  max mem: 3278
Epoch: [97]  [2700/3494]  eta: 0:04:56  lr: 0.0000000  loss: 0.5315 (0.5790)  bbox_regression: 0.0848 (0.1025)  classification: 0.4388 (0.4765)  time: 0.3643  data: 0.1268  max mem: 3278
Epoch: [97]  [2800/3494]  eta: 0:04:18  lr: 0.0000000  loss: 0.5689 (0.5790)  bbox_regression: 0.1049 (0.1024)  classification: 0.4751 (0.4766)  time: 0.3747  data: 0.1360  max mem: 3278
Epoch: [97]  [2900/3494]  eta: 0:03:41  lr: 0.0000000  loss: 0.5544 (0.5791)  bbox_regression: 0.1008 (0.1025)  classification: 0.4420 (0.4766)  time: 0.3777  data: 0.1404  max mem: 3278
Epoch: [97]  [3000/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5820 (0.5797)  bbox_regression: 0.0926 (0.1027)  classification: 0.4861 (0.4771)  time: 0.3692  data: 0.1322  max mem: 3278
Epoch: [97]  [3100/3494]  eta: 0:02:26  lr: 0.0000000  loss: 0.5162 (0.5800)  bbox_regression: 0.0923 (0.1026)  classification: 0.4432 (0.4774)  time: 0.3629  data: 0.1277  max mem: 3278
Epoch: [97]  [3200/3494]  eta: 0:01:49  lr: 0.0000000  loss: 0.5508 (0.5808)  bbox_regression: 0.0945 (0.1028)  classification: 0.4563 (0.4780)  time: 0.3846  data: 0.1416  max mem: 3278
Epoch: [97]  [3300/3494]  eta: 0:01:12  lr: 0.0000000  loss: 0.5163 (0.5808)  bbox_regression: 0.0947 (0.1028)  classification: 0.4239 (0.4780)  time: 0.3850  data: 0.1421  max mem: 3278
Epoch: [97]  [3400/3494]  eta: 0:00:34  lr: 0.0000000  loss: 0.5886 (0.5814)  bbox_regression: 0.0988 (0.1028)  classification: 0.4675 (0.4785)  time: 0.3354  data: 0.1130  max mem: 3278
Epoch: [97]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.6244 (0.5817)  bbox_regression: 0.1042 (0.1028)  classification: 0.5063 (0.4789)  time: 0.3665  data: 0.1298  max mem: 3278
Epoch: [97] Total time: 0:21:51 (0.3753 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:13:33  model_time: 0.1779 (0.1779)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 1.8615  data: 1.6501  max mem: 3278
Validation:  [100/437]  eta: 0:01:36  model_time: 0.1139 (0.1261)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2547  data: 0.1218  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1193 (0.1242)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2794  data: 0.1397  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1163 (0.1255)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2696  data: 0.1268  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1175 (0.1248)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2671  data: 0.1255  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1182 (0.1249)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2662  data: 0.1248  max mem: 3278
Validation: Total time: 0:01:59 (0.2745 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [98]  [   0/3494]  eta: 1:50:32  lr: 0.0000000  loss: 0.5126 (0.5126)  bbox_regression: 0.1046 (0.1046)  classification: 0.4081 (0.4081)  time: 1.8982  data: 1.6017  max mem: 3278
Epoch: [98]  [ 100/3494]  eta: 0:22:31  lr: 0.0000000  loss: 0.5107 (0.5974)  bbox_regression: 0.0819 (0.1046)  classification: 0.4286 (0.4928)  time: 0.3671  data: 0.1316  max mem: 3278
Epoch: [98]  [ 200/3494]  eta: 0:20:49  lr: 0.0000000  loss: 0.5558 (0.5916)  bbox_regression: 0.1015 (0.1036)  classification: 0.4531 (0.4880)  time: 0.3610  data: 0.1303  max mem: 3278
Epoch: [98]  [ 300/3494]  eta: 0:20:06  lr: 0.0000000  loss: 0.6238 (0.5931)  bbox_regression: 0.1187 (0.1041)  classification: 0.4956 (0.4889)  time: 0.3561  data: 0.1229  max mem: 3278
Epoch: [98]  [ 400/3494]  eta: 0:19:31  lr: 0.0000000  loss: 0.5848 (0.5913)  bbox_regression: 0.0959 (0.1037)  classification: 0.4757 (0.4876)  time: 0.3785  data: 0.1344  max mem: 3278
Epoch: [98]  [ 500/3494]  eta: 0:18:50  lr: 0.0000000  loss: 0.5473 (0.5893)  bbox_regression: 0.0900 (0.1037)  classification: 0.4669 (0.4856)  time: 0.3848  data: 0.1412  max mem: 3278
Epoch: [98]  [ 600/3494]  eta: 0:18:07  lr: 0.0000000  loss: 0.5454 (0.5868)  bbox_regression: 0.0910 (0.1037)  classification: 0.4330 (0.4831)  time: 0.3565  data: 0.1296  max mem: 3278
Epoch: [98]  [ 700/3494]  eta: 0:17:25  lr: 0.0000000  loss: 0.5984 (0.5858)  bbox_regression: 0.0972 (0.1038)  classification: 0.5081 (0.4820)  time: 0.3521  data: 0.1144  max mem: 3278
Epoch: [98]  [ 800/3494]  eta: 0:16:49  lr: 0.0000000  loss: 0.5393 (0.5865)  bbox_regression: 0.0933 (0.1041)  classification: 0.4386 (0.4824)  time: 0.3988  data: 0.1488  max mem: 3278
Epoch: [98]  [ 900/3494]  eta: 0:16:10  lr: 0.0000000  loss: 0.5716 (0.5863)  bbox_regression: 0.0977 (0.1043)  classification: 0.4793 (0.4820)  time: 0.3732  data: 0.1313  max mem: 3278
Epoch: [98]  [1000/3494]  eta: 0:15:33  lr: 0.0000000  loss: 0.5713 (0.5856)  bbox_regression: 0.0869 (0.1041)  classification: 0.4818 (0.4815)  time: 0.3834  data: 0.1401  max mem: 3278
Epoch: [98]  [1100/3494]  eta: 0:14:58  lr: 0.0000000  loss: 0.5501 (0.5855)  bbox_regression: 0.0896 (0.1041)  classification: 0.4604 (0.4814)  time: 0.3845  data: 0.1400  max mem: 3278
Epoch: [98]  [1200/3494]  eta: 0:14:20  lr: 0.0000000  loss: 0.5417 (0.5848)  bbox_regression: 0.0954 (0.1040)  classification: 0.4555 (0.4809)  time: 0.3825  data: 0.1380  max mem: 3278
Epoch: [98]  [1300/3494]  eta: 0:13:41  lr: 0.0000000  loss: 0.5607 (0.5854)  bbox_regression: 0.0939 (0.1040)  classification: 0.4607 (0.4814)  time: 0.3676  data: 0.1437  max mem: 3278
Epoch: [98]  [1400/3494]  eta: 0:13:03  lr: 0.0000000  loss: 0.5347 (0.5839)  bbox_regression: 0.0954 (0.1036)  classification: 0.4394 (0.4803)  time: 0.3744  data: 0.1302  max mem: 3278
Epoch: [98]  [1500/3494]  eta: 0:12:27  lr: 0.0000000  loss: 0.5180 (0.5821)  bbox_regression: 0.0909 (0.1034)  classification: 0.4362 (0.4787)  time: 0.3878  data: 0.1419  max mem: 3278
Epoch: [98]  [1600/3494]  eta: 0:11:49  lr: 0.0000000  loss: 0.6104 (0.5821)  bbox_regression: 0.1192 (0.1034)  classification: 0.4758 (0.4787)  time: 0.3851  data: 0.1390  max mem: 3278
Epoch: [98]  [1700/3494]  eta: 0:11:13  lr: 0.0000000  loss: 0.5263 (0.5814)  bbox_regression: 0.0948 (0.1032)  classification: 0.4401 (0.4781)  time: 0.3627  data: 0.1294  max mem: 3278
Epoch: [98]  [1800/3494]  eta: 0:10:35  lr: 0.0000000  loss: 0.6263 (0.5819)  bbox_regression: 0.1024 (0.1033)  classification: 0.5105 (0.4787)  time: 0.3426  data: 0.1193  max mem: 3278
Epoch: [98]  [1900/3494]  eta: 0:09:58  lr: 0.0000000  loss: 0.5641 (0.5814)  bbox_regression: 0.0942 (0.1032)  classification: 0.4478 (0.4782)  time: 0.3737  data: 0.1410  max mem: 3278
Epoch: [98]  [2000/3494]  eta: 0:09:20  lr: 0.0000000  loss: 0.5772 (0.5820)  bbox_regression: 0.0955 (0.1033)  classification: 0.4633 (0.4787)  time: 0.3697  data: 0.1356  max mem: 3278
Epoch: [98]  [2100/3494]  eta: 0:08:43  lr: 0.0000000  loss: 0.5273 (0.5821)  bbox_regression: 0.1085 (0.1032)  classification: 0.4374 (0.4789)  time: 0.3695  data: 0.1318  max mem: 3278
Epoch: [98]  [2200/3494]  eta: 0:08:05  lr: 0.0000000  loss: 0.5683 (0.5816)  bbox_regression: 0.0917 (0.1031)  classification: 0.4806 (0.4785)  time: 0.3750  data: 0.1427  max mem: 3278
Epoch: [98]  [2300/3494]  eta: 0:07:28  lr: 0.0000000  loss: 0.5240 (0.5816)  bbox_regression: 0.0912 (0.1031)  classification: 0.4346 (0.4786)  time: 0.3985  data: 0.1428  max mem: 3278
Epoch: [98]  [2400/3494]  eta: 0:06:50  lr: 0.0000000  loss: 0.5147 (0.5818)  bbox_regression: 0.0876 (0.1031)  classification: 0.4432 (0.4787)  time: 0.3753  data: 0.1346  max mem: 3278
Epoch: [98]  [2500/3494]  eta: 0:06:12  lr: 0.0000000  loss: 0.5815 (0.5818)  bbox_regression: 0.1107 (0.1030)  classification: 0.4998 (0.4788)  time: 0.3746  data: 0.1354  max mem: 3278
Epoch: [98]  [2600/3494]  eta: 0:05:35  lr: 0.0000000  loss: 0.5242 (0.5813)  bbox_regression: 0.0894 (0.1028)  classification: 0.4522 (0.4785)  time: 0.3613  data: 0.1268  max mem: 3278
Epoch: [98]  [2700/3494]  eta: 0:04:57  lr: 0.0000000  loss: 0.5555 (0.5818)  bbox_regression: 0.0834 (0.1029)  classification: 0.4586 (0.4790)  time: 0.3783  data: 0.1362  max mem: 3278
Epoch: [98]  [2800/3494]  eta: 0:04:19  lr: 0.0000000  loss: 0.5283 (0.5820)  bbox_regression: 0.0925 (0.1029)  classification: 0.4476 (0.4790)  time: 0.3577  data: 0.1265  max mem: 3278
Epoch: [98]  [2900/3494]  eta: 0:03:42  lr: 0.0000000  loss: 0.5578 (0.5826)  bbox_regression: 0.0919 (0.1030)  classification: 0.4368 (0.4796)  time: 0.3473  data: 0.1228  max mem: 3278
Epoch: [98]  [3000/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5720 (0.5832)  bbox_regression: 0.0978 (0.1031)  classification: 0.4820 (0.4802)  time: 0.3673  data: 0.1315  max mem: 3278
Epoch: [98]  [3100/3494]  eta: 0:02:27  lr: 0.0000000  loss: 0.5631 (0.5830)  bbox_regression: 0.0882 (0.1030)  classification: 0.4450 (0.4799)  time: 0.3859  data: 0.1361  max mem: 3278
Epoch: [98]  [3200/3494]  eta: 0:01:49  lr: 0.0000000  loss: 0.5489 (0.5829)  bbox_regression: 0.0921 (0.1030)  classification: 0.4572 (0.4799)  time: 0.3497  data: 0.1259  max mem: 3278
Epoch: [98]  [3300/3494]  eta: 0:01:12  lr: 0.0000000  loss: 0.5697 (0.5828)  bbox_regression: 0.0905 (0.1028)  classification: 0.4744 (0.4799)  time: 0.3700  data: 0.1320  max mem: 3278
Epoch: [98]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5560 (0.5831)  bbox_regression: 0.0991 (0.1030)  classification: 0.4550 (0.4801)  time: 0.3766  data: 0.1456  max mem: 3278
Epoch: [98]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5361 (0.5827)  bbox_regression: 0.0929 (0.1029)  classification: 0.4541 (0.4798)  time: 0.3496  data: 0.1196  max mem: 3278
Epoch: [98] Total time: 0:21:55 (0.3765 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:18:18  model_time: 0.1255 (0.1255)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.5145  data: 2.3490  max mem: 3278
Validation:  [100/437]  eta: 0:01:37  model_time: 0.1177 (0.1245)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2675  data: 0.1242  max mem: 3278
Validation:  [200/437]  eta: 0:01:06  model_time: 0.1236 (0.1253)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2801  data: 0.1300  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1178 (0.1240)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2709  data: 0.1263  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1204 (0.1239)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2718  data: 0.1280  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1165 (0.1238)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2622  data: 0.1238  max mem: 3278
Validation: Total time: 0:01:59 (0.2737 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: [99]  [   0/3494]  eta: 2:22:33  lr: 0.0000000  loss: 0.5892 (0.5892)  bbox_regression: 0.1291 (0.1291)  classification: 0.4601 (0.4601)  time: 2.4479  data: 2.1970  max mem: 3278
Epoch: [99]  [ 100/3494]  eta: 0:22:19  lr: 0.0000000  loss: 0.5372 (0.5811)  bbox_regression: 0.0932 (0.1045)  classification: 0.4290 (0.4766)  time: 0.3674  data: 0.1314  max mem: 3278
Epoch: [99]  [ 200/3494]  eta: 0:21:03  lr: 0.0000000  loss: 0.5846 (0.5861)  bbox_regression: 0.1083 (0.1048)  classification: 0.4827 (0.4813)  time: 0.3881  data: 0.1425  max mem: 3278
Epoch: [99]  [ 300/3494]  eta: 0:20:04  lr: 0.0000000  loss: 0.4915 (0.5795)  bbox_regression: 0.0847 (0.1030)  classification: 0.3898 (0.4765)  time: 0.3705  data: 0.1301  max mem: 3278
Epoch: [99]  [ 400/3494]  eta: 0:19:19  lr: 0.0000000  loss: 0.5738 (0.5815)  bbox_regression: 0.0891 (0.1026)  classification: 0.4847 (0.4789)  time: 0.3730  data: 0.1349  max mem: 3278
Epoch: [99]  [ 500/3494]  eta: 0:18:40  lr: 0.0000000  loss: 0.5384 (0.5805)  bbox_regression: 0.0986 (0.1019)  classification: 0.4329 (0.4787)  time: 0.3626  data: 0.1292  max mem: 3278
Epoch: [99]  [ 600/3494]  eta: 0:18:02  lr: 0.0000000  loss: 0.6244 (0.5811)  bbox_regression: 0.1043 (0.1023)  classification: 0.4971 (0.4789)  time: 0.3713  data: 0.1274  max mem: 3278
Epoch: [99]  [ 700/3494]  eta: 0:17:23  lr: 0.0000000  loss: 0.5926 (0.5836)  bbox_regression: 0.1015 (0.1027)  classification: 0.4912 (0.4809)  time: 0.3496  data: 0.1221  max mem: 3278
Epoch: [99]  [ 800/3494]  eta: 0:16:41  lr: 0.0000000  loss: 0.5650 (0.5834)  bbox_regression: 0.0988 (0.1027)  classification: 0.4592 (0.4807)  time: 0.3413  data: 0.1132  max mem: 3278
Epoch: [99]  [ 900/3494]  eta: 0:16:03  lr: 0.0000000  loss: 0.5618 (0.5845)  bbox_regression: 0.0786 (0.1027)  classification: 0.4729 (0.4818)  time: 0.3789  data: 0.1387  max mem: 3278
Epoch: [99]  [1000/3494]  eta: 0:15:28  lr: 0.0000000  loss: 0.5759 (0.5872)  bbox_regression: 0.1045 (0.1039)  classification: 0.4439 (0.4833)  time: 0.3872  data: 0.1408  max mem: 3278
Epoch: [99]  [1100/3494]  eta: 0:14:50  lr: 0.0000000  loss: 0.5879 (0.5872)  bbox_regression: 0.1044 (0.1041)  classification: 0.4848 (0.4831)  time: 0.3582  data: 0.1315  max mem: 3278
Epoch: [99]  [1200/3494]  eta: 0:14:11  lr: 0.0000000  loss: 0.5613 (0.5863)  bbox_regression: 0.0905 (0.1042)  classification: 0.4591 (0.4822)  time: 0.3576  data: 0.1283  max mem: 3278
Epoch: [99]  [1300/3494]  eta: 0:13:36  lr: 0.0000000  loss: 0.5676 (0.5866)  bbox_regression: 0.0950 (0.1041)  classification: 0.4558 (0.4825)  time: 0.3877  data: 0.1464  max mem: 3278
Epoch: [99]  [1400/3494]  eta: 0:13:00  lr: 0.0000000  loss: 0.5649 (0.5859)  bbox_regression: 0.0997 (0.1040)  classification: 0.4809 (0.4820)  time: 0.3742  data: 0.1347  max mem: 3278
Epoch: [99]  [1500/3494]  eta: 0:12:22  lr: 0.0000000  loss: 0.5955 (0.5863)  bbox_regression: 0.0998 (0.1042)  classification: 0.4984 (0.4821)  time: 0.3817  data: 0.1437  max mem: 3278
Epoch: [99]  [1600/3494]  eta: 0:11:46  lr: 0.0000000  loss: 0.5592 (0.5846)  bbox_regression: 0.1036 (0.1037)  classification: 0.4484 (0.4808)  time: 0.3829  data: 0.1449  max mem: 3278
Epoch: [99]  [1700/3494]  eta: 0:11:09  lr: 0.0000000  loss: 0.5727 (0.5850)  bbox_regression: 0.1152 (0.1040)  classification: 0.4664 (0.4809)  time: 0.3607  data: 0.1285  max mem: 3278
Epoch: [99]  [1800/3494]  eta: 0:10:32  lr: 0.0000000  loss: 0.5082 (0.5828)  bbox_regression: 0.0860 (0.1033)  classification: 0.4229 (0.4795)  time: 0.3657  data: 0.1295  max mem: 3278
Epoch: [99]  [1900/3494]  eta: 0:09:54  lr: 0.0000000  loss: 0.5582 (0.5830)  bbox_regression: 0.0917 (0.1034)  classification: 0.4841 (0.4796)  time: 0.3586  data: 0.1338  max mem: 3278
Epoch: [99]  [2000/3494]  eta: 0:09:17  lr: 0.0000000  loss: 0.5542 (0.5828)  bbox_regression: 0.0925 (0.1034)  classification: 0.4516 (0.4794)  time: 0.3781  data: 0.1373  max mem: 3278
Epoch: [99]  [2100/3494]  eta: 0:08:40  lr: 0.0000000  loss: 0.5931 (0.5832)  bbox_regression: 0.0937 (0.1034)  classification: 0.4893 (0.4798)  time: 0.3744  data: 0.1386  max mem: 3278
Epoch: [99]  [2200/3494]  eta: 0:08:02  lr: 0.0000000  loss: 0.5857 (0.5839)  bbox_regression: 0.0931 (0.1035)  classification: 0.5033 (0.4803)  time: 0.3469  data: 0.1204  max mem: 3278
Epoch: [99]  [2300/3494]  eta: 0:07:25  lr: 0.0000000  loss: 0.5025 (0.5833)  bbox_regression: 0.0874 (0.1034)  classification: 0.4197 (0.4799)  time: 0.3754  data: 0.1344  max mem: 3278
Epoch: [99]  [2400/3494]  eta: 0:06:48  lr: 0.0000000  loss: 0.5500 (0.5836)  bbox_regression: 0.0978 (0.1035)  classification: 0.4378 (0.4801)  time: 0.3902  data: 0.1479  max mem: 3278
Epoch: [99]  [2500/3494]  eta: 0:06:11  lr: 0.0000000  loss: 0.6348 (0.5845)  bbox_regression: 0.1001 (0.1037)  classification: 0.5288 (0.4808)  time: 0.3609  data: 0.1276  max mem: 3278
Epoch: [99]  [2600/3494]  eta: 0:05:33  lr: 0.0000000  loss: 0.5311 (0.5838)  bbox_regression: 0.1014 (0.1036)  classification: 0.4276 (0.4802)  time: 0.3718  data: 0.1365  max mem: 3278
Epoch: [99]  [2700/3494]  eta: 0:04:56  lr: 0.0000000  loss: 0.5787 (0.5835)  bbox_regression: 0.1003 (0.1035)  classification: 0.4850 (0.4800)  time: 0.3968  data: 0.1450  max mem: 3278
Epoch: [99]  [2800/3494]  eta: 0:04:19  lr: 0.0000000  loss: 0.5835 (0.5837)  bbox_regression: 0.0893 (0.1035)  classification: 0.4839 (0.4802)  time: 0.3766  data: 0.1371  max mem: 3278
Epoch: [99]  [2900/3494]  eta: 0:03:41  lr: 0.0000000  loss: 0.5423 (0.5837)  bbox_regression: 0.0871 (0.1033)  classification: 0.4469 (0.4804)  time: 0.3787  data: 0.1362  max mem: 3278
Epoch: [99]  [3000/3494]  eta: 0:03:04  lr: 0.0000000  loss: 0.5650 (0.5843)  bbox_regression: 0.0987 (0.1035)  classification: 0.4539 (0.4808)  time: 0.3764  data: 0.1347  max mem: 3278
Epoch: [99]  [3100/3494]  eta: 0:02:27  lr: 0.0000000  loss: 0.5063 (0.5841)  bbox_regression: 0.0849 (0.1033)  classification: 0.4284 (0.4807)  time: 0.3748  data: 0.1362  max mem: 3278
Epoch: [99]  [3200/3494]  eta: 0:01:49  lr: 0.0000000  loss: 0.5375 (0.5839)  bbox_regression: 0.0999 (0.1033)  classification: 0.4336 (0.4806)  time: 0.3930  data: 0.1443  max mem: 3278
Epoch: [99]  [3300/3494]  eta: 0:01:12  lr: 0.0000000  loss: 0.5223 (0.5833)  bbox_regression: 0.0955 (0.1032)  classification: 0.4348 (0.4801)  time: 0.3589  data: 0.1236  max mem: 3278
Epoch: [99]  [3400/3494]  eta: 0:00:35  lr: 0.0000000  loss: 0.5733 (0.5831)  bbox_regression: 0.1013 (0.1031)  classification: 0.4578 (0.4800)  time: 0.3744  data: 0.1288  max mem: 3278
Epoch: [99]  [3493/3494]  eta: 0:00:00  lr: 0.0000000  loss: 0.5223 (0.5830)  bbox_regression: 0.0948 (0.1031)  classification: 0.4540 (0.4799)  time: 0.3587  data: 0.1267  max mem: 3278
Epoch: [99] Total time: 0:21:58 (0.3773 s / it)
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
/user/sbini/anaconda3/envs/dgx1/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Validation:  [  0/437]  eta: 0:15:41  model_time: 0.1367 (0.1367)  loss: 1.0475 (1.0475)  bbox_regression: 0.1268 (0.1268)  classification: 0.9207 (0.9207)  time: 2.1555  data: 1.9940  max mem: 3278
Validation:  [100/437]  eta: 0:01:35  model_time: 0.1171 (0.1214)  loss: 0.7714 (0.9010)  bbox_regression: 0.1663 (0.1626)  classification: 0.6141 (0.7383)  time: 0.2616  data: 0.1254  max mem: 3278
Validation:  [200/437]  eta: 0:01:05  model_time: 0.1158 (0.1228)  loss: 0.7656 (0.8628)  bbox_regression: 0.1419 (0.1532)  classification: 0.6512 (0.7096)  time: 0.2700  data: 0.1269  max mem: 3278
Validation:  [300/437]  eta: 0:00:37  model_time: 0.1247 (0.1228)  loss: 0.8970 (0.8652)  bbox_regression: 0.1452 (0.1499)  classification: 0.7642 (0.7153)  time: 0.2772  data: 0.1305  max mem: 3278
Validation:  [400/437]  eta: 0:00:10  model_time: 0.1183 (0.1230)  loss: 0.7398 (0.8613)  bbox_regression: 0.1418 (0.1500)  classification: 0.6161 (0.7113)  time: 0.2649  data: 0.1264  max mem: 3278
Validation:  [436/437]  eta: 0:00:00  model_time: 0.1167 (0.1230)  loss: 0.7317 (0.8623)  bbox_regression: 0.1222 (0.1502)  classification: 0.6351 (0.7121)  time: 0.2520  data: 0.1193  max mem: 3278
Validation: Total time: 0:01:58 (0.2718 s / it)
That's it!
